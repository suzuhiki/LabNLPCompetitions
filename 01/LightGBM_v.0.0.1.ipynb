{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyproject-toml in /usr/local/lib/python3.10/dist-packages (0.0.10)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (4.17.3)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (0.38.4)\n",
      "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (65.6.3)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pyproject-toml) (0.10.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->pyproject-toml) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->pyproject-toml) (0.19.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sudachipy in /usr/local/lib/python3.10/dist-packages (0.6.6)\n",
      "Requirement already satisfied: sudachidict_core in /usr/local/lib/python3.10/dist-packages (20221021)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT_PATH = \"../../\"\n",
    "\n",
    "datapath = PROJECT_ROOT_PATH + \"lab_competition/data/\"\n",
    "outpath = PROJECT_ROOT_PATH + \"lab_competition/output/01/\"\n",
    "\n",
    "# sudachiの小さい辞書をインポート\n",
    "!pip install pyproject-toml\n",
    "!pip install sudachipy sudachidict_core\n",
    "!pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各データを読み込みリストに格納\n",
    "def read_file(path):\n",
    "    with open(path, mode=\"r\") as f:\n",
    "        result = f.read().splitlines()\n",
    "    return result\n",
    "\n",
    "train_text = read_file(datapath + \"text.train.txt\")\n",
    "dev_text = read_file(datapath + \"text.dev.txt\")\n",
    "test_text = read_file(datapath + \"text.test.txt\")\n",
    "train_label = np.loadtxt(datapath + \"label.train.txt\")\n",
    "dev_label = np.loadtxt(datapath + \"label.dev.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sudachipy in /usr/local/lib/python3.10/dist-packages (0.6.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sudachidict_full in /usr/local/lib/python3.10/dist-packages (20221021)\n",
      "Requirement already satisfied: SudachiPy<0.7,>=0.5 in /usr/local/lib/python3.10/dist-packages (from sudachidict_full) (0.6.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Tokeize\n",
    "\n",
    "!pip install sudachipy\n",
    "!pip install sudachidict_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テキストを眺める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>眠い、眠れない。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0                     ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…\n",
       "1     1  今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...\n",
       "2     0                 早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。\n",
       "3     0                                           眠い、眠れない。\n",
       "4     0    ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df = pd.DataFrame({\"label\" :[str(int(l)) for l in train_label], \"text\" :train_text})\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>29867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>森拓郎さんのストレッチDVD30日全身コース。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9227</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                     text\n",
       "count   30000                    30000\n",
       "unique      5                    29867\n",
       "top         0  森拓郎さんのストレッチDVD30日全身コース。\n",
       "freq     9227                       24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>5593</td>\n",
       "      <td>5587</td>\n",
       "      <td>しんど</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2</th>\n",
       "      <td>3543</td>\n",
       "      <td>3522</td>\n",
       "      <td>はー</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9227</td>\n",
       "      <td>9178</td>\n",
       "      <td>森拓郎さんのストレッチDVD30日全身コース。</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7760</td>\n",
       "      <td>7747</td>\n",
       "      <td>朝マック！</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3877</td>\n",
       "      <td>3872</td>\n",
       "      <td>しごおわりあん！</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                     \n",
       "      count unique                      top freq\n",
       "label                                           \n",
       "-1     5593   5587                      しんど    2\n",
       "-2     3543   3522                       はー    6\n",
       "0      9227   9178  森拓郎さんのストレッチDVD30日全身コース。   24\n",
       "1      7760   7747                    朝マック！    4\n",
       "2      3877   3872                 しごおわりあん！    2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>眠い、眠れない。</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  message_len\n",
       "0     0                     ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…           30\n",
       "1     1  今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...           51\n",
       "2     0                 早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。           34\n",
       "3     0                                           眠い、眠れない。            8\n",
       "4     0    ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!           47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df['message_len'] = train_text_df.text.apply(len)\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Message Length')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "train_text_df[train_text_df.label=='-2'].message_len.plot(bins=35, kind='hist', color='blue', \n",
    "                                       label='-2', alpha=0.2)\n",
    "train_text_df[train_text_df.label=='-1'].message_len.plot(bins=35, kind='hist', color='red', \n",
    "                                       label='-1', alpha=0.2)\n",
    "train_text_df[train_text_df.label=='0'].message_len.plot(bins=35, kind='hist', color='gray', \n",
    "                                       label='0', alpha=0.2)\n",
    "train_text_df[train_text_df.label=='1'].message_len.plot(bins=35, kind='hist', color='green', \n",
    "                                       label='1', alpha=0.2)\n",
    "train_text_df[train_text_df.label=='2'].message_len.plot(bins=35, kind='hist', color='orange', \n",
    "                                       label='2', alpha=0.2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Message Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3543.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.483489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>32.318008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_len\n",
       "count  3543.000000\n",
       "mean     36.483489\n",
       "std      32.318008\n",
       "min       1.000000\n",
       "25%      13.000000\n",
       "50%      26.000000\n",
       "75%      49.000000\n",
       "max     151.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df[train_text_df.label=='-2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5593.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.158949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.501219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_len\n",
       "count  5593.000000\n",
       "mean     39.158949\n",
       "std      30.501219\n",
       "min       1.000000\n",
       "25%      18.000000\n",
       "50%      30.000000\n",
       "75%      51.000000\n",
       "max     166.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df[train_text_df.label=='-1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.388534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.809770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>157.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_len\n",
       "count  9227.000000\n",
       "mean     40.388534\n",
       "std      31.809770\n",
       "min       1.000000\n",
       "25%      17.000000\n",
       "50%      31.000000\n",
       "75%      52.000000\n",
       "max     157.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df[train_text_df.label=='0'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.672423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.797956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_len\n",
       "count  7760.000000\n",
       "mean     36.672423\n",
       "std      28.797956\n",
       "min       2.000000\n",
       "25%      16.000000\n",
       "50%      28.000000\n",
       "75%      47.000000\n",
       "max     148.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df[train_text_df.label=='1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3877.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.497808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.496652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_len\n",
       "count  3877.000000\n",
       "mean     34.497808\n",
       "std      27.496652\n",
       "min       3.000000\n",
       "25%      16.000000\n",
       "50%      26.000000\n",
       "75%      43.000000\n",
       "max     164.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df[train_text_df.label=='2'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単語分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "from itertools import chain\n",
    "\n",
    "tokenizer_obj = dictionary.Dictionary(dict=\"full\").create()\n",
    "mode = tokenizer.Tokenizer.SplitMode.C\n",
    "\n",
    "# 前処理\n",
    "def text_cleaning(textlist, mode, clear_part_of_speech_list, stopword_list):\n",
    "    morphemelist = [tokenizer_obj.tokenize(text, mode) for text in textlist]\n",
    "    result = []\n",
    "    for morpheme in morphemelist:\n",
    "        words = []\n",
    "        for word in morpheme:\n",
    "            if word.part_of_speech()[0] not in clear_part_of_speech_list[0]:\n",
    "                if word.part_of_speech()[1] not in clear_part_of_speech_list[1]:\n",
    "                    if word.normalized_form() not in stopword_list:\n",
    "                        words.append(word.normalized_form())\n",
    "        result.append(\" \".join(words))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['。', '、', '.', '為る', '成る', '居る', 'とこ', ':', '/', '_', '-', '〜', '(', ')', '私', '御', '」', '「', '人', '物', 'ー', '言う', 'こと', '見る', '行く', '・', 'さん', 'ちゃん', 'そう', 'よう', ';', '`', '分', '今', '今日', '日', '有る', '又', '来る', '思う', '此の', '時']\n"
     ]
    }
   ],
   "source": [
    "clear_part_of_speech_list = [[\"助詞\", \"助動詞\"],[\"数詞\"]]\n",
    "\n",
    "with open(datapath + \"stopwords.txt\") as f:\n",
    "    stopword_list = f.read().splitlines()\n",
    "\n",
    "print(stopword_list)\n",
    "\n",
    "train_data = text_cleaning(train_text, mode, clear_part_of_speech_list, stopword_list)\n",
    "dev_data = text_cleaning(dev_text, mode, clear_part_of_speech_list, stopword_list)\n",
    "test_data = text_cleaning(test_text, mode, clear_part_of_speech_list, stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>message_len</th>\n",
       "      <th>clean_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…</td>\n",
       "      <td>30</td>\n",
       "      <td>ぼけっと こんな 時間 ちゃり 食べる 出る</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...</td>\n",
       "      <td>51</td>\n",
       "      <td>月 白い 明るい 昨日 雲 少ない 奇麗   立ち止まる 帰り道 ちゃり なし 生活 悪い 無い</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。</td>\n",
       "      <td>34</td>\n",
       "      <td>早寝 積もり 飲み物 なくなる コンビニ んっ 風 涼しい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>眠い、眠れない。</td>\n",
       "      <td>8</td>\n",
       "      <td>眠い 眠る</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!</td>\n",
       "      <td>47</td>\n",
       "      <td>只今   新体操 ! 外食 気 満々 家 何 無い ! テレビ 離れる !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  message_len  \\\n",
       "0     0                     ぼけっとしてたらこんな時間。チャリあるから食べにでたいのに…           30   \n",
       "1     1  今日の月も白くて明るい。昨日より雲が少なくてキレイな〜 と立ち止まる帰り道。チャリなし生活も...           51   \n",
       "2     0                 早寝するつもりが飲み物がなくなりコンビニへ。ん、今日、風が涼しいな。           34   \n",
       "3     0                                           眠い、眠れない。            8   \n",
       "4     0    ただいま〜 って新体操してるやん!外食する気満々で家に何もないのに!テレビから離れられない…!           47   \n",
       "\n",
       "                                          clean_msg  \n",
       "0                            ぼけっと こんな 時間 ちゃり 食べる 出る  \n",
       "1  月 白い 明るい 昨日 雲 少ない 奇麗   立ち止まる 帰り道 ちゃり なし 生活 悪い 無い  \n",
       "2                     早寝 積もり 飲み物 なくなる コンビニ んっ 風 涼しい  \n",
       "3                                             眠い 眠る  \n",
       "4             只今   新体操 ! 外食 気 満々 家 何 無い ! テレビ 離れる !  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df['clean_msg'] = train_data\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベルごとの頻出単語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "[('!', 845), ('無い', 617), ('…', 408), ('何', 365), ('?', 357), ('良い', 269), ('仕事', 221), ('もう', 194), ('過ぎる', 192), ('寝る', 164), ('仕舞う', 156), ('遣る', 153), ('出来る', 146), ('時間', 140), ('どう', 136), ('自分', 132), ('明日', 132), ('分かる', 117), ('辛い', 113), ('本当', 110), ('悪い', 107), ('終わる', 103), ('其れ', 99), ('帰る', 96), ('ああ', 94), ('此れ', 92), ('呉れる', 90), ('気', 90), ('出る', 89), ('食べる', 87), ('欲しい', 86), ('嫌', 85), ('後', 83), ('使う', 79), ('無理', 79), ('未だ', 79), ('^q^', 77), ('前', 76), ('方', 74), ('考える', 73), ('痛い', 73), ('悲しい', 72), ('中', 71), ('こんな', 71), ('眠い', 68), ('聞く', 67), ('まじ', 67), ('疲れる', 67), ('みたい', 65), ('頑張る', 65), ('買う', 63), ('年', 63), ('其の', 62), ('やめる', 61), ('気持ち', 60), ('目', 59), ('死ぬ', 58), ('会社', 58), ('朝', 57), ('凄い', 56), ('一寸', 56), ('起きる', 56), ('あー', 55), ('家', 55), ('怖い', 55), ('頭', 54), ('話', 53), ('はあ', 53), ('忘れる', 53), ('多い', 51), ('早い', 50), ('月', 50), ('最近', 50), ('為', 49), ('誰', 49), ('所', 48), ('作る', 48), ('御腹', 48), ('そんな', 47), ('職場', 47), ('入る', 47), ('出す', 46), ('奴', 45), ('眠る', 44), ('矢張り', 43), ('飲む', 43), ('過ぎ', 43), ('こう', 42), ('やばい', 42), ('さ', 42), ('何故', 42), ('毎日', 41), ('知る', 40), ('取る', 40), ('かける', 40), ('駄目', 40), ('貰う', 40), ('普通', 40), ('泣く', 40), ('好き', 39), ('生きる', 39), ('昨日', 39), ('感じ', 38), ('知れる', 38), ('全部', 38), ('ずっと', 38), ('糞', 37), ('訳', 37), ('色々', 37), ('電車', 37), ('せい', 36), ('直ぐ', 36), ('目茶', 36), ('先輩', 36), ('働く', 35), ('当たる', 34), ('苛々', 33), ('おく', 33), ('連絡', 33), ('侭', 33), ('辞める', 33), ('嫌い', 33), ('(笑)', 32), ('違う', 32), ('まあ', 32), ('人生', 32), ('いつも', 32), ('動く', 32), ('しんどい', 32), ('学校', 32), ('一人', 31), ('面倒', 30), ('回', 30), ('持つ', 30), ('全然', 30), ('電話', 30), ('気付く', 30), ('余り', 30), ('いー', 30), ('迚も', 30), ('父', 30), ('で', 29), ('以上', 29), ('心', 29), ('うち', 29), ('部屋', 29), ('そして', 29), ('全て', 29), ('夜', 29), ('(´;ω;`)', 29), ('全く', 28), ('掛かる', 28), ('結局', 28), ('もん', 28), ('ストレス', 28), ('御前', 27), ('意味', 27), ('上司', 27), ('お金', 27), ('子', 27), ('(´Д`)', 27), ('つく', 26), ('つ', 26), ('以外', 26), ('病院', 26), ('円', 26), ('つける', 26), ('会う', 26), ('此処', 26), ('残業', 26), ('声', 26), ('怒る', 26), ('切れる', 25), ('いつ', 25), ('絶対', 25), ('手', 25), ('どこ', 25), ('休み', 25), ('→', 25), ('体', 25), ('夫', 25), ('や', 25), ('家族', 24), ('人間', 24), ('戻る', 24), ('W', 24), ('雨', 24), ('付く', 24), ('幸せ', 24), ('書く', 24), ('間', 24), ('大丈夫', 24), ('なくなる', 24), ('寂しい', 24), ('酷い', 24), ('忙しい', 24), ('取り敢えず', 24), ('ω', 24), ('臭い', 23), ('皆', 23)]\n",
      "\n",
      "\n",
      "-1\n",
      "[('無い', 1008), ('!', 975), ('?', 740), ('何', 536), ('良い', 495), ('…', 470), ('過ぎる', 341), ('遣る', 333), ('出来る', 284), ('仕舞う', 277), ('自分', 245), ('もう', 227), ('時間', 224), ('分かる', 213), ('寝る', 209), ('気', 202), ('出る', 196), ('仕事', 194), ('どう', 185), ('方', 168), ('此れ', 165), ('買う', 162), ('食べる', 149), ('前', 147), ('欲しい', 145), ('辛い', 142), ('後', 139), ('終わる', 138), ('未だ', 137), ('悪い', 135), ('明日', 134), ('みたい', 132), ('其れ', 125), ('本当', 124), ('一寸', 122), ('中', 118), ('使う', 114), ('起きる', 112), ('痛い', 110), ('年', 107), ('考える', 105), ('家', 104), ('帰る', 104), ('其の', 103), ('矢張り', 103), ('忘れる', 103), ('最近', 102), ('聞く', 101), ('呉れる', 100), ('飲む', 97), ('怖い', 97), ('奴', 96), ('入る', 96), ('凄い', 93), ('好き', 91), ('多い', 89), ('円', 89), ('頑張る', 88), ('朝', 87), ('持つ', 87), ('さ', 86), ('ω', 86), ('目', 85), ('早い', 84), ('出す', 83), ('全然', 83), ('作る', 83), ('所', 82), ('月', 80), ('誰', 80), ('取る', 80), ('こんな', 78), ('無理', 78), ('目茶', 77), ('ああ', 77), ('昨日', 77), ('訳', 76), ('そんな', 76), ('やばい', 76), ('やめる', 76), ('書く', 76), ('眠い', 75), ('嫌', 74), ('皆', 74), ('気持ち', 74), ('まじ', 74), ('感じ', 73), ('御腹', 73), ('此処', 73), ('色々', 73), ('知る', 71), ('死ぬ', 70), ('為', 69), ('話', 66), ('駄目', 65), ('寒い', 64), ('どこ', 64), ('度', 63), ('ずっと', 62), ('貰う', 61), ('W', 61), ('会社', 61), ('知れる', 60), ('一人', 60), ('過ぎ', 59), ('疲れる', 59), ('入れる', 59), ('頭', 59), ('結局', 58), ('気付く', 58), ('同じ', 57), ('せい', 57), ('あー', 56), ('´', 55), ('いつ', 54), ('そして', 53), ('こう', 53), ('コロナ', 52), ('回', 52), ('何故', 52), ('結構', 51), ('つ', 50), ('乗る', 50), ('悲しい', 49), ('余り', 49), ('つける', 49), ('掛かる', 49), ('子', 49), ('まあ', 48), ('部屋', 48), ('しんどい', 48), ('うち', 48), ('生きる', 47), ('増える', 47), ('かける', 47), ('戻る', 47), ('夢', 47), ('難しい', 47), ('ぽい', 46), ('良く', 46), ('始める', 46), ('他', 46), ('見える', 45), ('侭', 45), ('俺', 44), ('なくなる', 44), ('電車', 43), ('全部', 43), ('別', 43), ('外', 43), ('問題', 43), ('感じる', 42), ('休み', 42), ('変わる', 42), ('つく', 41), ('全く', 41), ('会う', 41), ('働く', 41), ('直ぐ', 41), ('毎日', 41), ('大丈夫', 40), ('目茶苦茶', 40), ('友達', 40), ('取り敢えず', 40), ('勉強', 40), ('付く', 40), ('雨', 40), ('いつも', 39), ('眠る', 39), ('手', 39), ('下がる', 39), ('泣く', 39), ('普通', 39), ('(´・ω・`)', 39), ('楽しい', 38), ('足', 38), ('違う', 38), ('夜', 38), ('多分', 38), ('減る', 38), ('お金', 38), ('次', 38), ('笑い', 37), ('遣る気', 37), ('上', 37), ('マスク', 37), ('音', 37), ('人生', 37), ('読む', 37), ('ちゃんと', 37), ('(・・;', 37), ('今年', 36), ('思い出す', 36), ('流石', 36), ('もっと', 36), ('待つ', 36), ('意味', 36), ('実家', 36), ('心', 36), ('←', 36)]\n",
      "\n",
      "\n",
      "0\n",
      "[('!', 1768), ('無い', 1446), ('?', 1299), ('良い', 957), ('何', 715), ('…', 543), ('遣る', 510), ('出来る', 481), ('過ぎる', 403), ('分かる', 348), ('方', 344), ('気', 335), ('食べる', 322), ('仕舞う', 318), ('自分', 316), ('時間', 314), ('買う', 303), ('寝る', 298), ('もう', 274), ('出る', 271), ('どう', 263), ('欲しい', 251), ('其れ', 241), ('前', 221), ('年', 216), ('後', 215), ('此れ', 213), ('みたい', 206), ('仕事', 206), ('中', 197), ('凄い', 196), ('好き', 195), ('使う', 195), ('終わる', 194), ('明日', 190), ('多い', 187), ('其の', 185), ('作る', 182), ('書く', 181), ('呉れる', 178), ('聞く', 176), ('矢張り', 176), ('持つ', 167), ('目', 164), ('最近', 163), ('W', 161), ('一寸', 160), ('考える', 156), ('未だ', 152), ('貰う', 149), ('知る', 148), ('飲む', 147), ('月', 147), ('話', 146), ('入る', 146), ('目茶', 144), ('所', 144), ('為', 143), ('本当', 142), ('円', 138), ('知れる', 137), ('奴', 137), ('そんな', 136), ('誰', 132), ('動画', 132), ('帰る', 131), ('読む', 130), ('起きる', 130), ('訳', 129), ('皆', 128), ('出す', 124), ('回', 122), ('さ', 121), ('笑い', 119), ('入れる', 117), ('つ', 117), ('どこ', 115), ('早い', 115), ('頑張る', 114), ('家', 113), ('高い', 112), ('感じ', 109), ('良く', 107), ('昨日', 106), ('取る', 104), ('本', 103), ('強い', 100), ('面白い', 98), ('気付く', 96), ('こんな', 94), ('悪い', 94), ('同じ', 94), ('結構', 94), ('子', 93), ('ああ', 91), ('駄目', 91), ('余り', 89), ('始める', 89), ('此処', 88), ('難しい', 88), ('暑い', 88), ('夢', 87), ('必要', 86), ('色々', 85), ('全然', 85), ('普通', 84), ('生きる', 84), ('場合', 84), ('忘れる', 84), ('うち', 84), ('次', 83), ('気持ち', 83), ('お金', 82), ('まじ', 82), ('見える', 81), ('感じる', 81), ('おく', 81), ('付く', 80), ('会社', 80), ('君', 79), ('いつ', 79), ('朝', 79), ('上', 79), ('ぽい', 78), ('眠い', 76), ('まあ', 75), ('頃', 75), ('アニメ', 75), ('多分', 74), ('つく', 74), ('掛かる', 74), ('全く', 73), ('可愛い', 73), ('過ぎ', 72), ('違う', 72), ('やばい', 72), ('辛い', 72), ('→', 72), ('意味', 72), ('的', 72), ('えっ', 71), ('絶対', 71), ('変わる', 71), ('俺', 70), ('ω', 70), ('目茶苦茶', 69), ('旨い', 69), ('思い出す', 69), ('乗る', 68), ('子供', 68), ('取り敢えず', 68), ('日本', 68), ('ずっと', 67), ('御飯', 67), ('上がる', 67), ('一人', 67), ('頭', 67), ('別', 67), ('易い', 67), ('友達', 66), ('声', 65), ('美味しい', 65), ('よる', 65), ('流石', 65), ('つける', 64), ('度', 64), ('Twitter', 64), ('一番', 64), ('他', 64), ('ちゃんと', 63), ('以上', 63), ('初めて', 63), ('コロナ', 63), ('何故', 62), ('夜', 62), ('無理', 62), ('そして', 62), ('楽しい', 62), ('笑う', 62), ('名前', 62), ('結局', 61), ('こう', 61), ('下さる', 61), ('曲', 61), ('せい', 61), ('←', 61), ('人生', 60), ('働く', 60), ('以外', 60), ('かける', 59), ('饂飩', 59), ('増える', 59), ('覚える', 59), ('%', 59), ('YouTube', 59), ('死ぬ', 58), ('達', 58), ('否', 58), ('寒い', 57), ('筈', 57)]\n",
      "\n",
      "\n",
      "1\n",
      "[('!', 2847), ('良い', 980), ('無い', 875), ('?', 674), ('…', 487), ('遣る', 436), ('何', 431), ('出来る', 359), ('好き', 331), ('過ぎる', 301), ('買う', 291), ('食べる', 280), ('自分', 256), ('可愛い', 243), ('凄い', 241), ('方', 218), ('面白い', 217), ('明日', 207), ('仕事', 205), ('出る', 204), ('仕舞う', 201), ('此れ', 199), ('後', 198), ('気', 197), ('もう', 195), ('頑張る', 188), ('時間', 188), ('呉れる', 184), ('欲しい', 180), ('分かる', 171), ('年', 169), ('聞く', 169), ('楽しい', 164), ('目茶', 161), ('貰う', 160), ('寝る', 158), ('前', 149), ('使う', 147), ('美味しい', 138), ('本当', 137), ('W', 137), ('其れ', 136), ('飲む', 133), ('みたい', 132), ('さ', 131), ('一寸', 131), ('矢張り', 130), ('中', 128), ('入る', 127), ('終わる', 125), ('所', 122), ('知る', 120), ('作る', 118), ('感じ', 116), ('最近', 114), ('どう', 114), ('月', 112), ('読む', 112), ('笑い', 109), ('嬉しい', 108), ('旨い', 108), ('円', 107), ('皆', 105), ('其の', 105), ('目', 103), ('帰る', 103), ('♪', 99), ('未だ', 99), ('夢', 99), ('幸せ', 98), ('考える', 98), ('話', 98), ('書く', 98), ('取る', 97), ('楽しみ', 97), ('多い', 96), ('奴', 90), ('昨日', 86), ('こんな', 86), ('出す', 85), ('持つ', 85), ('曲', 84), ('初めて', 83), ('家', 83), ('迚も', 82), ('知れる', 79), ('君', 78), ('回', 77), ('強い', 76), ('早い', 75), ('そして', 74), ('かける', 73), ('気持ち', 73), ('本', 72), ('為', 72), ('入れる', 71), ('今年', 71), ('良く', 71), ('笑う', 70), ('誰', 70), ('始める', 70), ('悪い', 68), ('ああ', 68), ('一人', 67), ('朝', 67), ('うち', 66), ('部屋', 64), ('久し振り', 64), ('同じ', 64), ('ずっと', 64), ('俺', 64), ('此処', 63), ('取り敢えず', 63), ('全部', 63), ('頃', 63), ('御飯', 62), ('子供', 62), ('次', 62), ('色々', 61), ('生きる', 61), ('起きる', 61), ('普通', 60), ('まじ', 59), ('目茶苦茶', 59), ('振り', 58), ('最高', 58), ('いつ', 58), ('お金', 58), ('少し', 57), ('あー', 57), ('訳', 57), ('漸と', 57), ('会社', 57), ('映画', 56), ('声', 56), ('毎日', 56), ('一番', 56), ('高い', 56), ('感じる', 55), ('こう', 54), ('乗る', 54), ('ちゃんと', 54), ('夜', 54), ('『', 54), ('勉強', 54), ('箇月', 54), ('結構', 53), ('ぽい', 53), ('新しい', 53), ('*', 53), ('直ぐ', 53), ('おく', 53), ('感', 53), ('達', 52), ('泣く', 52), ('違う', 52), ('アニメ', 52), ('』', 52), ('ライブ', 52), ('そんな', 52), ('まー', 51), ('よる', 51), ('待つ', 51), ('もっと', 51), ('多分', 51), ('気付く', 51), ('遊ぶ', 51), ('←', 51), ('奇麗', 50), ('下さる', 50), ('流石', 50), ('間', 50), ('コナン', 50), ('やばい', 49), ('忘れる', 49), ('上げる', 49), ('いつも', 49), ('超', 49), ('過ぎ', 49), ('易い', 49), ('娘', 49), ('子', 49), ('増える', 48), ('つ', 48), ('まあ', 48), ('言葉', 48), ('上', 48), ('動画', 48), ('→', 48), ('余り', 48), ('つける', 47), ('付く', 47), ('友達', 47), ('彼の', 47), ('思い出す', 47), ('得る', 47), ('会う', 46), ('御腹', 46), ('上がる', 46), ('ω', 46)]\n",
      "\n",
      "\n",
      "2\n",
      "[('!', 2462), ('良い', 490), ('?', 273), ('…', 262), ('無い', 246), ('ああ', 192), ('買う', 177), ('遣る', 173), ('何', 169), ('好き', 167), ('過ぎる', 163), ('出来る', 160), ('♪', 144), ('楽しい', 138), ('可愛い', 130), ('食べる', 123), ('凄い', 122), ('仕事', 118), ('明日', 113), ('後', 106), ('聞く', 103), ('最高', 99), ('此れ', 99), ('面白い', 96), ('嬉しい', 95), ('頑張る', 95), ('楽しみ', 90), ('矢張り', 88), ('呉れる', 88), ('方', 87), ('W', 84), ('美味しい', 83), ('目茶', 82), ('幸せ', 81), ('出る', 81), ('貰う', 78), ('前', 78), ('本当', 77), ('ライブ', 74), ('自分', 73), ('終わる', 72), ('時間', 71), ('使う', 70), ('寝る', 67), ('仕舞う', 65), ('円', 65), ('曲', 65), ('中', 63), ('年', 62), ('入る', 60), ('作る', 59), ('(笑)', 58), ('帰る', 57), ('旨い', 56), ('もう', 56), ('みたい', 56), ('未だ', 56), ('気', 55), ('\\\\(^O^)/', 55), ('昨日', 54), ('其れ', 54), ('今年', 54), ('飲む', 52), ('迚も', 50), ('子', 50), ('さ', 49), ('感じ', 49), ('月', 49), ('一寸', 48), ('知る', 47), ('大好き', 46), ('欲しい', 46), ('どう', 46), ('*', 46), ('取る', 45), ('^q^', 45), ('君', 44), ('最近', 44), ('目', 44), ('皆', 43), ('笑い', 42), ('ええ', 42), ('有り難う', 42), ('分かる', 42), ('所', 41), ('其の', 41), ('っ', 40), ('アニサマ', 40), ('久し振り', 39), ('読む', 39), ('早い', 39), ('初めて', 38), ('笑う', 38), ('まじ', 38), ('久々', 38), ('入れる', 38), ('目茶苦茶', 38), ('夢', 38), ('休み', 37), ('達', 37), ('コナン', 37), ('持つ', 37), ('話', 37), ('一番', 37), ('生きる', 37), ('為', 36), ('強い', 36), ('友達', 35), ('写真', 35), ('楽しむ', 35), ('あー', 34), ('本', 34), ('こんな', 34), ('過ぎ', 34), ('色々', 34), ('奇麗', 34), ('おお', 34), ('会う', 33), ('上がる', 33), ('気持ち', 33), ('泣く', 33), ('出す', 32), ('先生', 32), ('まー', 32), ('様', 32), ('忘れる', 32), ('声', 32), ('書く', 32), ('奴', 31), ('御飯', 31), ('家', 31), ('良く', 31), ('そして', 31), ('取り敢えず', 31), ('えー', 31), ('漸と', 31), ('最後', 30), ('一杯', 30), ('WWW', 30), ('いー', 29), ('切る', 29), ('次', 29), ('『', 29), ('』', 29), ('回', 29), ('ぽい', 28), ('気分', 28), ('♡', 28), ('少し', 28), ('歌う', 28), ('始める', 28), ('多い', 28), ('此処', 28), ('卓球', 28), ('神', 27), ('超', 27), ('さあ', 27), ('全部', 27), ('結構', 27), ('夜', 26), ('格好', 26), ('いつも', 26), ('知れる', 26), ('やばい', 26), ('うち', 26), ('振り', 26), ('もっと', 26), ('朝', 25), ('御腹', 25), ('まさか', 25), ('かける', 25), ('撮る', 25), ('考える', 25), ('誰', 25), ('子供', 25), ('ちゃんと', 24), ('素敵', 24), ('予定', 24), ('懐かしい', 24), ('映画', 24), ('そんな', 24), ('俺', 24), ('はあ', 24), ('ジャム', 24), ('違う', 23), ('大', 23), ('遊ぶ', 23), ('沢山', 23), ('祭', 23), ('つ', 23), ('安い', 23), ('漫画', 22), ('手', 22), ('わあ', 22), ('同じ', 22), ('絶対', 22), ('描く', 22), ('易い', 22), ('嫌', 21), ('作品', 21)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "words = train_text_df[train_text_df.label=='-2'].clean_msg.apply(lambda x: x.split())\n",
    "negativeL_words = collections.Counter()\n",
    "\n",
    "for msg in words:\n",
    "    negativeL_words.update(msg)\n",
    "\n",
    "print(-2)\n",
    "print(negativeL_words.most_common(200))\n",
    "\n",
    "\n",
    "words = train_text_df[train_text_df.label=='-1'].clean_msg.apply(lambda x: x.split())\n",
    "negativeS_words = collections.Counter()\n",
    "\n",
    "for msg in words:\n",
    "    negativeS_words.update(msg)\n",
    "    \n",
    "print(\"\\n\\n{}\".format(-1))\n",
    "print(negativeS_words.most_common(200))\n",
    "\n",
    "\n",
    "words = train_text_df[train_text_df.label=='0'].clean_msg.apply(lambda x: x.split())\n",
    "neutral_words = collections.Counter()\n",
    "\n",
    "for msg in words:\n",
    "    neutral_words.update(msg)\n",
    "\n",
    "print(\"\\n\\n{}\".format(0))\n",
    "print(neutral_words.most_common(200))\n",
    "\n",
    "\n",
    "words = train_text_df[train_text_df.label=='1'].clean_msg.apply(lambda x: x.split())\n",
    "positiveS_words = collections.Counter()\n",
    "\n",
    "for msg in words:\n",
    "    positiveS_words.update(msg)\n",
    "\n",
    "print(\"\\n\\n{}\".format(1))\n",
    "print(positiveS_words.most_common(200))\n",
    "\n",
    "\n",
    "words = train_text_df[train_text_df.label=='2'].clean_msg.apply(lambda x: x.split())\n",
    "positiveL_words = collections.Counter()\n",
    "\n",
    "for msg in words:\n",
    "    positiveL_words.update(msg)\n",
    "    \n",
    "print(\"\\n\\n{}\".format(2))\n",
    "print(positiveL_words.most_common(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形回帰を回してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['。', '、', '.', '為る', '成る', '居る', 'とこ', ':', '/', '_', '-', '〜', '(', ')', '私', '御', '」', '「', '人', '物', 'ー', '言う', 'こと', '見る', '行く', '・', 'さん', 'ちゃん', 'そう', 'よう', ';', '`', '分', '今', '今日', '日', '有る', '又', '来る', '思う', '此の', '時', '新体操', '表情筋', 'シャレード', 'モテキ', '小宮山', '夏樹', 'バッティングセンター', 'COWCOW', 'BIGBANG', '笑む', '立石', '生半可', '達者', 'たんと', 'しい', '外反母趾', '昔夢', 'チョコケーキ', '天地明察', '不確か', '連れ去る', '微か', '絡み付く', '投げ掛ける', '茶碗蒸し', 'シナモンロール', '́з', '2700', 'wy', '愛と誠', '在り来り', 'ミランダ', 'カー', 'お子様', '岩', '整骨院', 'テーピング', '丸腰', '整体', '釣れる', '自己否定', '自己肯定', '鬼太郎', '彦', '門', '豚骨', '茄子', '田楽', 'パトラッシュ', 'エビマヨ', '煮', 'ふじ', 'ピール', 'なか卯', 'ジャーナリスト', '祈り', 'さめる', 'メルヘン', '齧り付く', '同志', '求', '本が好き', '立ち読み', '流し読み', 'standardbookstore', 'ノーベル賞', '山中', '育む', '西田辺', '割り箸', 'ニーハイ', '歯痒い', '信託', '別口', '著作', '田中里奈', 'たなか', 'りな', 'ティーナカリーナ', 'キョンキョン', '悪の教典', 'ニモ', 'ケズ', '出家', 'がぶり', 'カブレ', 'たらふく', 'ホームパーティー', '祭りのあと', 'BARBEE BOYS', '差し込む', 'はだける', '生田斗真', 'てれび戦士', '精神年齢', '体年齢', '串カツ', '有耶無耶', '怪しむ', '挙式', '緩巻き', '冠', 'ベール', '木漏れ日', 'ふらり', 'ハモネプ', 'To Be Continued', 'アットホーム', 'ダッド', '支配', '建設的', 'アッコ', '正装', 'ヘアメイク', 'はたと', '此の方', 'ずら', '新大阪駅', '心拍', '握り締める', '少年漫画', '臆病者', '暖まる', 'がぶがぶ', '喉飴', '水割り', '小朝', 'コルセット', 'ぼくらの', 'HEY!HEY!HEY!', 'ッ', 'アスリート', 'ガードル', '後藤', '鯛焼き', 'ブルース', 'カレーパン', '齧る', '車内', '(^▽^)', '先客', '本年', '無口', '凧揚げ', '電線', '巻き付く', 'ぐさり', 'はずい', 'ドッグカフェ', '早死に', 'えべっさん', 'つよし', 'SPA', 'フェットチーネ', 'いやはや', '中山功太', '改名', '人相', '新成人', 'うし', 'ミナミ', '不本意', '装う', '思い直す', '自堕落', '右往左往', '終業', 'チャイム', '未婚', '聞き苦しい', '目白押し', 'Ted', 'ライフ・オブ・パイ', '艶', 'ストロベリー', 'レ', 'ミゼラブル', 'タレント名鑑', 'MAJI', '奇行', '最高の離婚', 'ワンプレート', '平らげる', 'あたら', '未熟', '菊田', '辛いです', 'モーロー', 'りんご酢', '5.5', '精進料理', 'ラザーニャ', '省エネ', 'Ogg', 'KBB', 'ぶつ', 'ツレがうつになりまして', 'マキダイ', '面影', '人間味', 'チゲ', 'カレー鍋', 'クリームチーズ', '攻防', '多額', '延滞金', '親しい', '無力感', '大沢たかお', '提唱', '経年変化', '体現', '川柳', 'ひらり', 'ばたばたばた', '償い', '会合', 'アラサーちゃん', '三角座り', '切り口', '開眼', 'ターイム', '材料', '桑田', 'みっともない', '転た寝', '帳尻', '個性的', 'くう', 'ハズイ', 'イールーミーネイション', 'GLAY', 'ウインター', 'アゲイン', '鐘', 'すかさず', 'カテゴライズ', '任命', 'カラオケバトル', '腫れ上がる', 'センチメンタルジャーニー', '退っ引き', 'お会計', '泣かす', '横殴り', 'ジャンカラ', 'プラチナデータ', 'キコ', '極道', '半顔', 'インデアンカレー', '歪み', 'good night', '吹き出る', 'ニベア', '小腹', 'zzz', 'ゆずぽん', '混同', '抱き付く', '愛情表現', '舟', '高跳び', 'クリームバス', '鯉', 'コノヤローッ', '千本', '鳥居', '挑む', '名物', '稲荷鮨', '湯豆腐', '漫ろ歩き', '食べ比べ', 'フィニッシュ', 'ほとほと', 'ネガツィート', '梅田彩佳', '今宮', 'ダンス部', '押し出す', '入賞', 'グリー', '圧縮', 'ボーゼン', 'あわわ', '脂', '大沢', 'ガリレオ', 'こく', '趣', '危機的状況', 'デファイン', '暗め', '延滞料', '宮沢りえ', 'ヤバイ', '逸早く', 'ヤメロヨォ', 'くどい', '節々', 'スウェット', '着込む', 'ヴィックスヴェポラップ', 'べたべた', '塗り込む', '保湿', '枕元', 'ポカリ', '武装', 'うわさの', 'テラフォーマー', '少々', '餌付く', '遣り過ぎ', '刃渡り', '銃刀法', '常套', '贈り物', '花崗', '来店', '小中学', 'ラストシンデレラ', 'ハンコック', 'ippon', '速水もこみち', '冷しゃぶ', 'どんどこ', '黒々', '円ら', 'どっぷり', '飯島直子', 'ちち', '涙脆い', 'ハミング', 'チャコちゃん', 'チョイス', 'ラブリー', 'スポーティー', '喉越し', 'ジャッキー', 'カンフー', '取り返し', 'おあとがよろしいようで', '刹那的', '雑念', '自作', 'コラージュ', 'にんまり', 'MIYAVI', 'セットアップ', '雅ちゃん', '減す', 'ヨヲコ', 'アウトデラックス', '黒田勇樹', '(゜ロ゜;', 'ひかる', 'サマーヌード', '(`ロ´;)', '挿入歌', 'ウエート', '真心', '情け', '点検', '来客', '選挙戦', '合致', '再燃', 'ジャガー横田', '紀里', '谷和明', 'ドンズバ', 'ガッ', '布袋', 'MISIA', 'IN LOVE AGAIN', 'MIYOKO', '羊歯', 'リゴロ', '秋の気配', '服屋', '乙女系', 'そそる', 'ゲイ', '同業', '梅屋敷', '方正', '三四郎', 'リツ', '受付時間', '頓挫', '舘ひろし', 'NMB', 'ダンエボ', '紛らす', 'ポメラニアン', '励み', 'NGK', 'キョド', '塾れる', '雀々', 'スイッチツィート', '桂三四郎', '蒸気', 'アイマスク', '新発売', 'メントール', '三宮', '挙る', '芦屋', '本分', '賢者', '森三中', '即興', '渡辺直美', 'フレームイン', '缶入り', 'ジンジャーエール', 'ジョージア', '永作', '博', 'ポンバシ', 'ゆか', '拒絶', '盗み見', '今朝方', 'ハートマーク!', '踏み躙る', '兆し', 'パワーアップ', '川崎麻世', '麻世', 'スケートリンク', 'ダウンベスト', 'ミニスカート', '三田', '真意', '802', 'てっちゃん', '大樹', 'あや', '天誅', 'はなす', '人気漫画', 'オールスター', 'ラッキーマン', '判断力', '鈍る', 'ツィッター', '返り咲く', 'ぶら', '晩餐', 'カルビ', 'しましまんず', '池上', '草臥れる', '海苔巻き', 'マスカラ', '叶姉妹', '快諾', '洗顔', 'まつ', 'エク', 'アイライン', '装着', 'せこい', '綯う', 'テーマソング', '揃い', '龍馬伝', '濱田龍臣', 'マメピカ', '最新版', '地毛', '巻き毛', '椀子', '昼顔', '(;´_ゝ`)', 'ヒロミ', 'レキシ', 'ティキソゥソゥ', 'イー', 'ポルノ', '彩る', '了', '教え子', '真摯', '( ´△`)', 'VAMPS', 'HYDE', 'じゃんけん', 'HOTEI', '満遍', '思い掛ける', 'ミナミの帝王', '千原', 'ファーストクラス', 'しろー', '下駄箱', '44', 'ぞっと', '落胆', '御出座', 'イロモン', '秀逸', '煙い', 'オオサカ', 'トータス松本', '捩れる', 'トータス', '不滅', '古市憲寿', '成仏', 'リツィート', 'スカパラ', '不満足', '聞く力', 'パニック', '親孝行', 'がっちり', '手ぶら', 'KinKi', 'ラルク', 'KEN', 'PATA', 'YOSHIKI', 'がちむち', '鞭', 'ラスティネイル', '金魚', '突く', '胸鰭', '蟹江敬三', '遮二無二', '鮨詰め', 'ぎゅうぎゅう', '米粒', '出来物', '塗り塗り', 'My Revolution', 'ハナ', 'のたうち回る', '飛び上がる', 'ペディキュア', '見回す', '呼び出し', 'ペニシリン', '天城', '物入れ', '理解不能', '裏技', '聞き方', 'rosia', 'かさ', '着付け', '無知の知', '一頻り', '軋む', '背ける', '波動', '激しく同意', '紛い', '端くれ', '書き物', '91', '鉛', '仕分け', '紙製', 'バインダー', '宮川', '大介', '大花', 'カラフル', '同居人', 'コンパ', 'インテリ', '顔付き', 'ディテール', '踏み外す', 'チリアン', 'メート', 'タッパー', 'フェミニズム', '癪', '反面教師', 'ワーホリ', '原動力', '曇り空', '幕開け', '飲み歩く', '英語力', '平均寿命', '相棒', '伴侶', 'Skoop On Somebody', '画数', '角い', '飛び越える', '卵子', '養子', '見通し', '脚立', 'Gossip Girl', 'ファルセット', 'シンセサイザー', '掻き毟る', '悩み相談', '知らせ', '同じく', '憂さ晴らし', '肉体労働', '喜び勇む', '前の日', 'ひしひし', '排除', '無用', '行動指針', 'ラブソング', '肯定', '震わせる', '愛について', 'メジャーデビュー', 'yukihiro', '丸儲け', '偉', '美しいひと', '奮い立つ', '卒業祝い', '追い求める', '緩める', '作り出す', '宿命', '真ん丸', '日当たり', 'スタイリスト', 'Ally', 'スター誕生', 'ポリス', 'MADONNA', 'マダム', '絡まり', '昔馴染み', '茶屋', '雑居ビル', '屋上', 'ペアリング', '微笑ましい', '祖父母', '出入り', '色気', '宮本浩次', '御老人', '238', 'シルク', '飲むヨーグルト', 'レリック', 'くしゃ', '咳エチケット', '行方', 'デマクソ', 'サレタガワ', 'ミヤネ', '週刊誌', '情報源', 'ジジババ', '覚え立て', 'まとめサイト', '簡略', 'シバ', 'クッソョンハハァンデ', 'パウダー', 'コンプレッサー', '肛門', 'デカデカド', '注意書き', '水泡', '医療崩壊', 'ァー', '群馬県太田市', '好転反応', 'イタリア', '綾鷹', '濃い味', 'クラ', 'ポテイト', 'トリュフオイル', '爆上', '広め', '事変', '感染症専門医', '擁護', '豆柴', 'カホィ', '迅速', '臨床検査技師', '検体', '余', '察し', '軽症', '早期発見', '周知', '単色', '暇人', 'クリープ', 'モッツァレラチーズ', 'コレ', '関電', 'ヘイト', '木次', 'パスチャライズ', '消毒液', 'ティッシュトイペ', 'クソデカボイス', 'タッソ', 'キャット', 'ウワーン', 'タクロウー', 'あべ', '浮き彫り', 'パウダーホアンディシャン', 'MAQuillAGE', 'Lips', 'パウファン', 'ボーボボ', '土木工事', '職業病', 'ラーメソ', '飛沫感染', '症候性', 'ツイフェミ', '毛頭', '仮想', '案内員', '逆立ち', '往なす', 'グロ', '心霊', 'ショッキング', 'ダム', '地形', 'ヨビノリ', 'たくみ', 'スチ', 'ウオオオオオオオオオ', '地下労働', 'リヘナラドールキモ', '意識不明', '伊藤隼也', '言い寄る', '粘着', '受給', '差別', '医療従事者', '生き長らえる', '後ろめたい', '一括り', '不正受給者', '良好', 'くも', 'モッツァレラ', 'オリーブオイル', '味の素', 'ステイン', '商品券', '利権', '公費', '冷食', '大量購入', '差し迫る', '単体', '毒性', '保守', 'マンセー', '全血', '献血', 'トイペ', 'ガンアクションゲー', 'ロッカー', 'ちびる', 'ECMO', 'サーチ', 'くす', 'フェミ', 'サムス', '焼き立て', 'オメェ', '分煙', '飛沫', '月寒', 'ラクレット', 'タレ', '不死身', 'デカブツ', '正体', 'リッカー', '画像検索', 'エイダ', '替わる', 'パニる', 'パチ', '並び', '基礎疾患', '致死率', '病床', '医療機関', 'てんやわんや', '籤引き', '失神ゲーム', '焙煎', '挽き', '言い掛かり', '受診', 'アッヒョヒョ', '重低音', '御見舞い', 'コロワクチン', '骨壺', '見殺し', '典型例', 'じょう', '競る', '茶飯', '大っぴら', '国籍', '外国籍', '日本国籍', '横這い', '全休', '問い掛ける', '結核', '勝ち戦', '負け軍', 'ベッキー', 'ずばずば', '調教', 'アフリカ', 'サツドラ', 'ドラスト', 'アフリカン', 'ジャーニー', '通せん坊', '謳歌', '中心地', 'カッペ', '激混み', '中華料理', '料理酒', '拡声器', '村八分', '鼻糞', 'CHANEL', 'パウダリー', 'がき', 'やっとかめ', 'ランジエリノベ', '奇襲', 'ハミマ', 'いちごみるく', '上級国民', '斗', 'wwwwwwwwwwwwwwwwwwwwwwww', 'ボリス', 'ラクーンシティ', '抗体検査', '酒精', '綿', '寝取る', 'てい', 'ぽん酢', 'メチコ', 'ホリエモン', '都知事', 'ひろゆき', 'ヒカルェ', '目盛り', 'エッペン', 'ウザシステム', '臨場感', '逃げ込む', '暗室', '驚かす', '表裏', 'レベルアップ', 'ぱくり', 'コーヒー豆', '買い漁る', 'TW', 'apparition', 'ピッチ', 'リードミス', '野望', 'TRP', 'STR', 'TalesWeaver', 'Perc', 'CL', '07', 'fl', '尻尾', '誤変換', 'コーヒーフィルター', 'NEXON', 'サウンズ', 'もののけ姫', 'サウンド', '言い渡す', 'コンタミ', 'センブブイレブイ', 'メープルパソ', '神ゲー', 'ミルカラー', '居住', '気管支炎', 'イプサ', '水気', 'ごっそり', '点す', '涎', 'ぶつくさ', '侮蔑', '殴り掛かる', '信頼性', '添える', '垂れる', '数え切れないくらい', '属性', '受け流す', 'Tokyo', '還', 'ot', '酪農家', '不良品', '売り捌く', '遅らせる', 'エタノール', '無垢', 'ディスポ', '漂白剤', '味玉', '毎食', '対処療法', '顔芸', '気紛れ', 'クック', '6480', 'コイツ', '買春', '定期便', 'ニトリル', 'グローブ', 'はち', '尊厳', '惑', '適職', ';;', 'ロソソーソ', 'ローソソ', 'ハバネロビアスティック', 'ETVOS', '薬用', 'VC', 'TUNEMAKERS', '甘草', 'エキス', 'ぽたぽた', '電子証明書', '入籍', 'ラジオ体操', '東大王', '伊沢拓司', '商品名', 'モザイク', '語学力', '貴殿', '爆売れ', '番う', '御襁褓替え', '素揚げ', '石鹸', '誇張', '詰め替え用', '黒にんにく', 'キムパテロ', '映え', '大嘘', 'スペイン産', '改行', '句点', '希', '放課後', 'ガールズトライブメッチャ', '出っ張る', '捕捉', 'ビビ', '主語', 'オジサン', '無駄金', 'びんた', '脳汁', '叩き', '防犯意識', '這う', 'クラッシュ', 'qk', 'クレベリン', 'ビタミーナ', 'ハーブ', 'フルーニュ', '芝刈り機', '硬直', 'ぷるぷる', '想定の範囲内', 'すみません', '平易', '鑑みる', '常識的', '御の字', 'レールガン', '酸味', '冷麺', 'コンドーム', 'と金', '避妊', '方便', '法律的', '藁', 'シャトーブリアン', 'ネトゲイキリオタク', '味見', '99.9999', 'ねっちり', '塩加減', 'マグロサク', '再現度', 'スタバナナ', '破ける', '自己修復', '生チョコ', '乗じる', '灘', '負んぶ', '所望', '肩車', 'ミート', 'フレッシュ', 'ヮィャ', 'レスイヤホホ', 'レスジャナイデスイヤンホホイ', 'ブチアゲ', '頸', 'ラー', 'プシ', '過眠症', '排便', '鳰', '高尚', '悪影響', '公', '電動', 'コーヒーミル', '安倍晋三', '内閣総理大臣', '筋力', '挽く', '火鍋', 'ブッッッッッッッッッッッッッッ', '生やす', '性転換', '遣らせ', '恋愛事情', '欠片', '男なら', '直結', '行動変容', '代理', 'フラストレーション', 'アベノ', 'ドラム式洗濯機', 'ブチ', '異物感', 'ペチコート', 'にた', '鰤', 'のた', 'M・A・O', '給料泥棒', 'ツカレッティ', '躁鬱', '喜多方ラーメン', '患う', '喫煙', '自己負担', 'タバコ税', '納税', '肺癌', '急冷', 'マイベスト', '半熟卵', '直輸入', 'かぎ', '白粉', '釣る', 'クソデカニキビ', 'マジョマジョ', 'オールインワン', 'スノビュ', '口コミ', '悪用', 'カステテフ', 'センシティブ', 'ワインヤレスイヤホホイン', '破片', '前歯', 'レモネードコシーシ', 'ベッドダイブキメ', 'サイコ', 'ニューチャイナボカン', '都知事選', 'イボーン', 'ばす', '銀貨', 'シワチュウ', '捥げる', 'ウエーン', 'フジモン', '乗降', '陣取る', '重罪', '開閉', 'Gackt', '夢女子', '01', '揺り籠', '爆食', '消化管', 'クソビックリ', 'バルバトス', 'セルフレジ', '手掴み', 'ESTEE LAUDER', 'ごり', '垂乳根', 'ミモレ', 'パブリッシュ', '衛生観念', '譫妄', '朝っぱら', '転倒', 'ゴローニャ', 'ンアーッ', '池田', '愛知県岡崎市', '固体', '液状', 'マンゴラチチ', '吸引', 'キンモクセイー', 'パイナツプル', 'べろ', 'なおき', '海豹', 'ハムテル', '個包装', '企業努力', '医療用', '言うだけタダ', '狭まる', 'Dir en grey', '老人ホーム', 'トリュフ塩', '痒み止め', '幼女戦記', '明日見', '雑音', '男性器', '食み出す', '民度', '常態化', '素っ飛ぶ', '意思疎通', 'フォロバ', 'μm', 'めげる', '小樽', 'ゴル', 'コントローラー', 'サーターアンダギー', 'サターアンターギ', '陥落', 'ネムスギ', 'シンドニア', 'ぽっぽ', '分け合う', '百均', '義父', '無頓着', 'ゴッドオブブラックフィールド', '新巻', 'ジ', 'ハンパない', '刑務所', 'すうすう', '吹き', 'ぱちぱち', '煽り', '致命的', '判子', 'でこ', '押印', '竹', '足壺', '杖', '含嗽', '読み進める', '閏', '紙切れ', '実例', '観測', 'コウノドリアマプラ', '道明寺', '司', 'カッコイイ', 'キンキン', 'ぐい', 'クー', 'ソース焼きそば', 'キショ', 'Lux', '参列者', '御祝儀', '腹八分', '暑', 'ロン', '校歌', 'カンカイ', 'アイヌ語', 'かま', 'テイルズオブジアビス', '乗り降り', 'たらす', 'BBQ', '防寒', 'ヤメロ', '治療効果', '合併症', 'ランジエ', '弾倉', '座薬', '烏滸', 'くら', '招待状', '返信用', 'じゅうじゅうカルビ', '破壊', '思惑', 'どのような', '衛門', 'ファミリーサイズ', '味覚', '慰労金', '性的', 'ほしい物リスト', '乞食', '着衣', '必然性', '内地', '示し合わせる', '御多福', '麻疹', '価', 'MMR', 'λ', '乳児', 'アイエエエエ', '法隆', '謙信', '残暑', 'ざんす', 'ミ', '梨', '授受', '変色', '転勤', 'ジェイド', '既', '触発', 'バンナム', 'ルンバ', '織田裕二', '選挙カー', 'ガースー', '黒光り', '内閣', 'キター', '定職', 'クリスマスケーキ', '拡張型', '心筋梗塞', '沢', '直樹', 'ショコリキサー', 'チャンポン', '腹下し', 'ブーブ', 'ぽこぽこ', 'モモモモモモモ', 'スガー', '車体', '安全靴', '前菜', 'フォアグラ', 'モエシャン', '義姉', '召し', 'ロー', 'そそ', '辛口', 'ビーフジャーキー', '逆らう', '退職日', '日数', '指折り', 'マンゴー', '欠き氷', '干', '神田', 'deno', 'meetfresh', 'うざったい', 'しゅう', 'ysl', 'セレブ', '外装', 'アマンゾゾ', '宅配ボックス', '不在票', '頑な', 'オンエア', '踏み切る', 'ラベル', '丸呑み', '大多数', '女神降臨', 'ヤバー', 'はるし', '本当の話', '上り下り', '方向転換', '後続', '張り倒す', '軟便', 'グルメパン', 'ルーローパン', 'バイアス', 'キンモクセイ', '痙攣', '飼い主', 'どすどす', '聞き耳', '叫び声', '時折', 'TOKYO', 'トウキョウ', '宜野座', '伸元', 'タンジェロ', 'クソマズタピオカ', 'ゴキゲン', '内見', '間取り図', '大方', '残骸', '一丁', '洗い流す', '大炎上', 'ドーピングコンソメスープ', '有料化', 'イヤンホホ', 'ク', 'ワインヤレスイヤンホホイ', 'けー', 'アベスガ', '骨伝導', 'イヤンホ', 'ワイヤレンスウホホイ', '不快指数', '握り潰す', 'ウホ', '慎重', 'ポッケ', '検針票', '白檀', '活火山', 'スリーコインズ', '素晴らしき日', 'ワイヤレスイヤホ', 'ぷらぷら', 'ズボ', 'ワイヤレスジャナイデスイヤホン', '束ねる', '雁字搦め', '気質', 'beastars', '転居先', '強盗', 'オングロ', '2004', 'アンダイン', '未完成', 'エロゲー', 'イリダン', '党', '岩手県', '県境', '射殺', 'スイスドロー', 'マスターズ', 'ドルイド', 'プリースト', 'ウイルス対策', '絞り込み', '最低ライン', '没収', 'OTK', '珠代', '先送り', 'さして', 'どかん', '非常事態', 'ゆりこ', 'ミラー', 'ブリザード', 'ツイッチ', 'レジェ', '創価学会', '事業撤退', '全従業員', '解雇', '題名', '信天翁', '切除', '飼い猫', '去勢手術', 'トロッコ問題', '猫好き', 'ストリーマー', '蒼', '米崎', 'スカイプ', 'GPS', '発信器', '感染経路', '義足', 'asmr', '囁き', '読み聞かせ', 'ごんぎつね', 'キズナアイ', '住み分ける', '鮫島', '未完', 'ラム肉', '忌む', 'デモハンデッキ', '振る舞い', '清楚', 'ビッチ', 'ドロソ', '混沌', '基づく', 'オイル', '0.01', '石油', 'プリーステス', 'フェルスクリーマー', 'シャドウフーフスレイヤー', 'メイジ', 'hsreplay', 'DT', '鰻屋', '立て籠もる', '霊視', 'グルダン', '骸骨', 'バリュー', '過大評価', '手札', '余分', '香川県', '知恵の輪', 'かつん', '日本国民', '選別', 'シムシティ', '出し方', 'ぶん', 'ASAPIN', '雑多', '実写化', '手品先輩', 'サタノファニ', '玉置', '成美', 'ラジアータストーリーズ', 'ミストレス', 'シナジー', '構え', 'キャンベラ', '岡江久美子', '豈', '桃乃', 'ゆらり', '委員長', '手仕舞い', '経営判断', 'ニキ', '広義', '狭義', '船長', 'ラビュー', '切り開く', 'うじゃうじゃ', '突然変異', '岩手県民', 'マッシュルーム', 'アヒージョ', '昭恵夫人', 'ダブスタ', 'ブラック・ロータス', '竜崎', 'boarcontrol', 'solve', 'tornedo', 'スポット', 'GTO', 'ベット', '企業向け', '貧乏人', '負け惜しみ', '猶予期間', '滞納', '県内', '市町村', '単年', '用法', '保健所', '感染リスク', '交際', '伊藤優', '考', '浦田', '和子', 'マージャンプロ', '俄か', '手一杯', '自己破産', '生活保護', 'ホロライブ', 'デリバリー', 'ゆみ', '白かび', 'ミモレット', '半々', '蛆', 'クアトロフォルマッジオ', 'ゴルゴンゾーラ', 'ハイハン', '乏しい', '萌やし炒め', 'いためる', '先手', 'かぶり', '伸び', 'フェル', 'ウイング', 'もじぴったん', 'ネトマ', 'bigwave', '塩焼きそば', '差別意識', '岡村隆史', '困窮', '厳重注意', 'リーグ戦', 'だんまり', '自浄', '作用', 'サービス開始', 'マイナポータル', 'ティア', 'ロープマン', '賞金', '正常位', '森山', '指定暴力団', '軍勢', '再申請', '切り替わる', 'グロマッシュ', 'コルクロン', '狂瀾', '高設定', '効果的', '憲法', '条文', 'ハリソン', '蒲田', '京急', '絶対無理', 'covid', '神戸市民', '外来患者', '一般市民', '人頭', 'ウヒョ', 'ホットケーキMIX', 'エボラ出血熱', '不運', '下家', '中田カウス', 'みちる', 'Kindle Unlimited', '賠償請求', 'LOL', '下限', '鈴原', '其奴', '太志', '卓上', '壊したい', 'ウーズ', '電波少年', '水曜どうでしょう', 'シャドバ', '前月', 'はす', 'もっと強く', '長考', '一休み', '楠', 'ハツ', 'レバー', 'アバンギャルド', '後ろ見', '同刻', '清一色', '両天秤', '飛び交う', 'さばさば', '女運', '籤運', '所々', 'sorachi', '1984', 'ハネマン', 'ツモ', 'アル中', 'カラ', '雀士', '会長', '課する', '現実的', 'じと', 'ホロ', '仲違い', 'ワンポイントリリーフ', '試合時間', 'ムーブ', '近代麻雀', '福本', '年俸', 'メジャーリーグ', 'サラリーキャップ', 'マリガン', '栞', 'フェミニスト', '男女平等', '徴兵制', '徴兵', 'たわい', '闘技場', 'アンケ', 'エンジョイ勢', '上辺', '販売元', '需要と供給', '価格設定', '転売ヤー', '据え置く', '気化', '加熱', '沸騰', '操作方法', '激怒', '練度', '元アイドル', '犬夜叉', '籠目', '育児放棄', 'バーサーカー', '鋸', '即席麺', 'ケミカル', 'ドラッグ', 'レッドオーシャン', 'アンジュ', 'ロア', 'ティランダ', '片言', 'ヒトラー', 'ナイチンゲール', '近現代史', '日本の歴史', '明治維新', '事業者向け', '平べったい', '大正義', '厚み', 'シェード', 'ICカードリーダー', 'アンドロイド', '平塚', '名人戦', 'シュラスコ', 'Apple Music', '現代人', 'lor', 'アスペ', 'トルヴィア', 'ゼフリス', 'メタカード', '1500000', 'くわ', 'スウェーデン', 'しくじる', '財政', 'ショッピング', '砂丘', '選出', 'ノーパン', '傀', '村田', 'ライバー', '短期バイト', '嘘吐き', 'サイコパスアイドル', '高田純次', 'ズー', 'クエウォロ', 'メックトゥーン', 'ヴィーガン', 'ゴミカス', '意向', '最重要', 'SEED', 'あさ', 'チンイツ', '倍満', '名字', '近田', '単文', '覇権', '自我', '競輪', '水底', '潜む', 'シャーマン', 'しょぼ', 'デマーシア', '344', 'ケミパンロッカー', '駆除', '使い捨てライター', '可燃', 'ダメスペル', 'バースト', 'チェーン', 'ぶんぶん', '槍', 'マツコデラックス', '話法', '伊集院', '解き放つ', 'イセラ', '有象無象', 'スティック', '松明', 'ハイテク', '生活困窮者', '税負担', '滅ぶ', '低所得者', '切り捨てる', 'ウルフ・オブ・ウォールストリート', '二酸化炭素', '応仁の乱', '中東', '内戦', 'ウィキ', '黒川', '検事長', 'ネマタ', '浸透', '消しゴム', 'ほろ酔い', 'クモデッキ', 'エリス', '国士', 'テンパイ', 'アニメ版', 'エバンゲリオン', 'あずまんが', 'ミサト', '供する', '法解釈', '雀荘', 'マッチアップ', '牌', '難点', '特殊能力', '配牌', '蛇足', '瑣末', '点る', '教育水準', 'シンガポール', '下位互換', '削減', '一人当たりGDP', '大当たり', '緊急事態', 'ポケパラオンライン', 'デュエリスト', 'ZOO', '労働量', '長時間労働', 'ヤード', 'スペフリ', 'フィリア', '交渉力', '総会屋', 'タコス', '入星', '鳳凰', 'データサイエンティスト', '待機列', '耕う', '乗り合わせる', '物産展', '神霊廟', '準備中', '夕御飯', '西船橋', 'gdgd', '大江戸線', '霊夢', '真後ろ', '人違い', 'コストパフォーマンス', 'がら空き', 'サブコミュ', '障害物', '走', '尖む', 'マイミク', 'ニコ', 'カップリング', 'ルナサ', '咲夜', '幻想', '挙手', '橋姫', 'コインロッカー', '宇治', '姫神社', '安井金比羅宮', '地主', '晴明神社', '三ノ宮', 'カラオケオフ', '聞き違い', '掛川', 'スケブ', '地元民', '雪洞', '常磐線快速', '仙人', '電話機', 'ひかり電話', '市外局番', 'ケタ', '宿泊費', 'コテハン', '気触れ', '片山津温泉', 'ヒゲイベ', '蘇我', '幕張メッセ', '仰せ', 'とりつく', 'カミングアウト', 'おかげ様', '早出', '書き心地', '諏訪湖', '南船橋', 'ららぽーと', 'レイトショー', '現金払い', '美鈴', 'ローマ字', '松茸', '青娥', '州', '短', '苦渋', '流し', '販売店', '飯炊き', '遣り遂げる', '創業者', '稲盛和夫', '東方プロジェクト', '無料通話', '東西線', '光景', '日帰り旅行', '節目', '風景画', '咳き込む', 'スペルカード', '掻き上げる', '文献', 'まはり', '滅する', 'akiba', '電気ポット', 'チバテレビ', 'CPU', 'ほこり', '舞浜駅', 'ディズニーリゾートライン', '車掌', '移転', 'ホワキャン', 'がらん', 'Project DIVA', 'アーケード', 'ミルキィホームズ', 'kogasanalove', '締め切る', '新木場', '両さん', '亀有', '原宿', '参拝', 'おう', '石動駅', '(;;)', 'ゆるゆり', '正月休み', '(-_-;)', '相方', 'kogasana', '小規模', '音楽サークル', 'イラスト集', '華扇', '萃香', '北千住', '瀟洒', '市販', '鏡餅', '切り餅', '味気無い', '転送', '大成功', 'アクセス特急', '高砂', '本数', '運賃', '町家', 'ぱちスロ', '競馬', 'チゲ鍋', '船橋', 'フリル', '衣玖', 'ラス', 'みんな大好き', '英辞郎', '受験シーズン', 'りんかい線', '山手線', '都会的', '上野駅', 'ナカ', 'ウイルス対策ソフト', '心当たり', '英文', '排水', '経路', '定期代', '永夜抄', 'カフェオフ', '帰省中', '鵺', '募集中', '武蔵野線', '33000', '建国', 'モノレール', '遠目', 'レティ', 'チルノ', '田町', '京浜東北線', '神主', '天界', 'ばらす', '密室', '存続', '危ぶむ', '青戸', '西新井', '梱包資材', '中央線', '各駅', '悪友', 'ブッキー', '並びに', 'コミゲスト', '鈴熊', 'ワンドロ', '昼食代', '告知', '本当にありがとうございました', '了承', '商業', 'ペンネーム', '法人', 'WIiU', 'キャラカプ', '風神録', '書き替える', '通勤電車', '強引', '大ニュース', '挨拶回り', '通り掛かる', '京葉', 'ゲスト参加', 'ローアングル', 'ッサン', '蓬莱', '一般参加', 'ゆき', 'メーキング', 'ラピュタ', '区間', '長崎ちゃんぽん', '退去', '有楽町線', 'ライナー', '上から目線', 'なぐ', '根回し', '徒', '自転車通勤', '遠方', '登用', '必須条件', '東上線', 'Grandeir', 'MILK SNAKE', '二の舞', '気象学', '毛嫌い', '埼玉県', '成城学園前', '二子', '印西', '北総線', '朝霞', '朝霞市', 'グレード', '文月', 'アクオス', '森林', '昇給', '社員教育', '参議院選挙', 'ビタミン剤', 'やり', '羽黒山', '御参り', '標高', 'カープ', 'こち亀', 'JR東日本', '休刊日', 'ブラック企業', '新大阪', '色紙', 'ポスカ', '好評', 'Shadowverse', 'ルナ', '喫茶マウンテン', '設立', '酒とつまみ', '廃棄', '手描き', 'コミトレ', 'サクチケ', '潮見', '電話予約', '中古車', '日産', '普通車', 'スポーツカー', 'テレビ局', '馬橋駅', '筆圧', '感知', 'インスコ', '東日本', '情報誌', 'プリンスホテル', 'マーガリン', '馬刺し', '花丸', '納車', '後程', '(涙)', '鉄人', '兵団', '越乃', '寒梅', 'ドコモショップ', '下取り', 'Android', '雇用保険', 'フィルタリング', '飯代', '姫路', '待機児童', 'アライ', '新井薬師前駅', '退職願', '部署内', '週刊', '話し合い', '顛末', 'ダーウィン', '南関東', '月極駐車場', '格安スマホ', '割高', '早変わり', '在住', 'スペーシア', '東武動物公園', '夕月', 'ここだけの話', 'ジャパリケット', '下り', 'ストロー現象', '駅近', 'とんこつラーメン', 'シャイ', '熊本城', '別府温泉', '再来月', '愛娘', '一緒に暮らしたい', '金沢駅', '自動改札', 'みさき公園', '南海', '山科駅', 'デレステ', 'バストイレ', '都市ガス', '引っ越し費', '見舞う', '埼京線', '夏コミ', 'ざっ', 'リハビリ', '新八柱', '法典', 'シャチハタ', '印', 'UFO', 'パラパラ漫画', 'コミッション', '国際展示場', '催し物', 'ジェットコースター', '鴨の嘴', '酷使', '思いの丈', '綻び', '渋谷駅', '発車メロディー', 'ラズベリー', '多淫', '冬のボーナス', 'イカセット', '活計', '宇治抹茶', 'ホワイト企業', '従事', '綺譚', '明日花', 'ロクボ', 'けろっと', '大阪駅', '追い越す', '歩き', 'ダイハツ', 'ディーラー', 'マツダ', '落書き', 'ラッピング', '雑記', 'ひらがな男子', 'てっきり', 'デージー', 'プレゼント企画', 'Bamboo', '片隅', '永眠', '盛る', 'BAMBOO', 'ハロデジ', '塗り', '鮟鱇', '参加予定', 'もしぼくが', 'Nintendo Switch', 'サン', '徒歩圏', 'きらら', '設問', '本腰', 'フエール', '利率', '開発部門', '下請け', 'エーデルワイス', '草津', '自動車保険', '契約更新', '保険料', '大戸屋', '湯葉', '山菜', 'ポプテピピック', '三編み', '行司', '掻い出す', '仄々', '野兎', '再来年', 'ガールズバー', 'ゴリラ', '爬虫類', '並行在来線', '反対派', '当たり外れ', '三セク', '通勤ラッシュ', '水面', '年前', '快速列車', '金槌', 'ノーリスク', 'グラブル', 'ハンサム', '自負', '社宅', '復旧', 'ファインダー', '閲覧', 'はてなブログ', 'SSL', '秋口', '琵琶湖', '高知', 'サークルカット', '入場券', '路', '自腹', '移動中', '青色', '異人館', 'ロングシート', 'のぞく', '神戸牛', 'デスクトップ', 'オキザリス', 'お姉ちゃん', '不愉快', '名所', '写す', '追記', 'ダリア', '越前', 'ICOCA', '敦賀', '油菜', 'つんでれ', '植物園', '知恩院', 'ドアツードア', '冬場', '関連性', '一纏り', 'ウェルスナビ', '明石海峡大橋', '姫路城', '短期決戦', '意気込み', 'コピー機', '競合', '依怙', '贔屓', '当座', 'アフィリエイト', '大日', '住環境', 'クリオネ', 'スプラトゥーン', 'ガチアサリ', '早期', '借り入れ', '東海道本線', '新住所', 'リミット', '初期費用', '140000', '練馬', '160000', '建設', 'スパワールド', '河豚', 'プレミアムカー', '9000', 'マイカップ', '即戦力', '積極性', '業績', '運転免許証', '裏面', '年パス', 'メッチャコスパ', '利便性', '貢献', '鑑', '如月', '家電量販店', '手助け', 'マーケ', 'ティング', '圧倒的多数', 'アラフィフ', '人通り', '通勤ルート', '中吊り', '応', '優良', '固定観念', '消費増税', '住居', 'エリ', '清い', '法律相談', 'ごたごた', '下関', 'ユリカ', '小倉駅', 'コミティア', '編集部', '持ち込み', '楽天証券', '小額', '積み立てる', '資産運用', 'ポルタ', '2014', '無闇', 'キャラ被り', 'A型', '自宅療養', 'フットワーク', 'アナリティクス', '防振', '通勤時間', 'エルシャダイ', '発売前', '即売会', '政令指定都市', '県庁所在地', '中核市', '出身地', '柵', '見合う', 'アイキャッチ', '菜刀', 'へこたれる', '女性キャラ', 'レパートリー', '枝', '豆御飯', 'エビチャーハン', '炒め', '生産的', '革新的', '尿意', '大違い', '光回線', '相互フォロー', 'オンシ', 'ノマカプ', 'ニチアサ', '描き方', '一緒くた', '横髪', '後ろ髪', 'Kindle Paperwhite', '昨年末', '仮住まい', '感染拡大', '差し', 'クリスタ', '尻込み', 'ゲーム課金', '規則', '清掃業', '220000', '有償', 'オリキャラ', '観察眼', '揺らぐ', 'Dragon Quest', 'ユアストーリー', 'ハリケーン', '谷原章介', 'テーマパーク', 'NetNews', 'アートアクアリウム', 'マーガレット', 'フランスパン', 'ひとり飯', '町並み', 'ばしゃばしゃ', 'ぐぐ', 'イケブクロ', 'ユリオン', '愚図', '八重歯', 'ぐち', 'OH', 'ローランド', '顧客', '育て', '火災', '水卜', 'ランナー', 'おっさんずラブ', '原作厨', '真央ちゃん', 'モブサイコ', '73', 'ザベ', '来場', '戻', '干瓢', '掻き混ぜる', '場当たり', '福士蒼汰', '背徳', '基地局', '電力', '自家発電', '局員', '日高屋', '仰天ニュース', '沙汰', 'エンタ', 'IMAX', 'マスカット', '殺伐', '再チャレンジ', '昼夜逆転生活', 'いかにんじん', '天宝', 'ポストカード', '壁掛け', 'よれる', 'ゴンチャ', 'やよい軒', 'ルミネ', '西武線', 'チケホル', '宝石', 'アイビー', '一巡', 'じゅく', 'まるはま', 'しぶや', 'あんかけチャーハン', '死霊館', '嘉美', 'ローチケ', '舞台化', 'あいち', '交付', '官僚', '78000000', '何物', '派閥', '表面化', 'スマップ', '引き上げ', 'バナ', 'ボナフェスタ', '鎌倉', '長蛇', '定期券', '斤', '樹状細胞', '白血球', '終演後', 'キラー', 'マチネー', 'ソワレ', '弄り', '激悪', '所行', 'ヒプマイ', 'ネルケ', '蔓延', '日高', 'ズッ友', '輪投げ', '頬袋', '和田', '異文化', '安全第一', '文化的', '定例会', 'リファラ', 'コネ', '元手', 'カードローン', '原価計算', '世知', '木金', 'ゴンザレス', 'キメツアニメ', '剥ぐ', 'ゆた', '痰', '滅全', '生鮮食品', 'みそラーメン', '公式Twitter', '直営', '一部店舗', '危険地帯', 'ア゛ア゛ア゛ア゛ア', '゛としか', '高層マンション', 'ナポレオン', 'アフタヌーンティー', 'メンバーシップ', '福島県', '日当', 'パンツスーツ', '奇声', 'シンバル', '猿', '婚約指輪', 'チケット代', '述語', '異議', '覚束無い', '自由席', '指定席', 'グリーン', 'リクライニング', '倒し', 'リクライニングシート', 'メンシプ', '引き出物', 'デュラ', '串揚げ', '最大手', 'ドルイット子爵', '定期購読', '狭き門', '竈門炭治郎', '小林亮太', 'ボイメンボクアカ', '爆轟', '竈門禰豆子', '高石', '02', '生まれ', '我妻善逸', '植田圭輔', '王室教師ハイネ', 'ハイネ', '嘴', '佐藤祐吾', '双子', 'ナルトロックリー', '冨岡義勇', '本田', '礼', '菊丸', '鱗', '左近', 'トモユキ', '土方', '錆兎', '星璃', 'ショウリ', '劇団', '真菰', '其原有沙', '飛び抜ける', '柿澤', '03', '東宝芸能', '久家', '珠世', '舞', '羽美', '宝塚', '平安', '絵巻', '比丘尼', '愈史郎', '佐藤永典', '財前', '鬼舞', '佐々木喜英', '黒執事', '子爵', '薄', '舞台『刀剣乱舞』', '宗三', '月山', 'ミネ', 'ララ', '振り替え', '心残り', '口実', '成田空港', '国際空港', '前後編', '刷毛', 'BiSH', 'ぷり', 'バカヤロー', 'キンプリ', '秋田美人', '津軽弁', '米沢牛', '原発', '慈しむ', 'ふくしま', 'ハッピーアイランド', '宝庫', 'ハロ', '河野', '雨男', '謝罪会見', '野党', '赤司', '嵌まり役', 'ヴィンチ', '一角', 'サブナード', '自社', '即買い', '750', '費用負担', 'スクエア', 'マレフィセントレンタル', '愚行', 'スタデューバレー', 'デザフェス', '健気', 'ハピエン', '憎しみ', 'ピ', '宙', '鬼畜', '不器用', '擦れ', 'プリキュア', 'スタセルフ', 'よみうりランド', '値切る', '男子中学生', '全種', '苛めっ子', '臓', 'ぱーん', 'いとう', 'あやこ', '外資系', '最終進化', '無問題', '当落', '一般発売', '破損', '天道', '島根', '新潟駅', 'スナック', '交際相手', 'ばや', 'チ', 'ジャンフェス', '缶バッジ', '昼前', 'ミップ', '幕張', 'ペンラ', 'ショルダーバッグ', '暁', '譲り', '買い取る', '盾', 'さくさくぱんだ', '人狼', 'レターパック', '平静', '宮崎駿', '子安', 'オリビエ', '竈馬', '外遊び', 'ジムバッジ', 'チャンピオン', '道程', '詮無い', '至高', 'ハーレー', 'エネコ', '渋谷パルコ', '久保田', 'テースティング', 'コイキング', 'イメトレ', 'キムヨナ', '滅本', 'データセンター', 'ゆめ', 'アフロ', '貝柱', 'コーンロウ', 'ランダム', 'ソーセージ', 'ジョンソン', 'ウィル', 'プリンス', 'ウェールズ', 'ノリタケ', 'ナルミ', 'Francfranc', '茶器', 'きの', '送り込む', '製薬', '東武東上線', 'どの道', '原田', 'ヴァ', 'ティーカップ', '堂本', '心理テスト', '菊池', '織部', '楕円', '扇', '台形', '目標達成', '女性専用車両', '赤井', '暴露', '由美', '次男', '確たる', 'のめり込む', '熟考', 'エレン', '飛雄', '煉獄', '無常', 'コスオタ', '公式名称', '生殺し', 'ミルメーク', '本番環境', '不可抗力', 'かながわ', 'あっと', '万力', 'リース', '本紙', '序の口', '開始時間', '舞台俳優', 'HelloWorld', 'かり', 'ますい', 'はける', 'ダブクロ', 'ユナイテッド', 'シネマ', 'まします', 'ガラルサニーゴ', '個体値', 'サニーゴ', 'サーナイト', 'じん', 'レイド', 'シュシュプ', 'フル回転', 'セガカフェ', 'ポケルス', 'よろ', '民族', 'がけ', 'あけおめ', 'ことよろ', '配線', '最後の晩餐', 'ゴースト', 'がっくん', 'ブックオフ', 'ホワイ', 'ゴーン', 'ポケモン図鑑', '東北地方', '菱', '越', '手子摺る', '長期休暇', '慣らす', 'どでかい', 'テディベア', '大雑把', 'クーデター', '司法', '公平', 'リチャード', 'アニメ絵', 'ブロマンス', '譲渡', '引き取り', '行き場', 'ソラマチ', '越谷', 'キメステ', '影ナレ', '紬', 'まお', '一慶', '天桴', 'まじる', '幕', 'エメラルド', '磨き', '世古口', '後学', 'ルイス', 'やり込み', 'コンテツ', '後出し', 'ガブリアス', 'ポフィン', 'デコる', 'ごーん', 'レバノン', 'ツラミ', 'ヤドン', 'キンブレ', 'リピチケ', 'センブロ', '双眼鏡', 'ドアップ', 'フランス語', 'モリステ', 'アドリブ', '手錠', '発煙筒', 'ハプニング', 'パプ', 'カーテンコール', '一発芸', '夕刻', 'ワロリン', 'アサクサ', 'ディビジョン', '伏せ字', '締め日', '沙庭', 'みらの', '参加型', '巻き込み', '牛乳プリン', 'カイロス', 'アブソル', 'ルビサファ', 'グレイシア', 'ムンボ', 'ほん', 'キョダイラプラス', 'ドリボ', '夢特性', 'オシャボ', 'むん', 'うごうご', '声優業', 'ブリミュギン', 'ブリミュ', '公道', 'モビリティー', '電動カート', '専用道路', '危険すぎる', '道路標識', 'コーナリング', '性善説', '危険性', '自動車事故', '左利き', 'jo', 'コミカライズ', 'そうさく', 'さばく', 'アンド', '更新プログラム', 'サインアウト', '税', 'ブクロ', 'どぎつい', '非公式', 'アップダウン', '平坦', 'シアター', '成人男性', '烈火', '笑止千万', '烈火の炎', 'べる', 'おね', 'プリライ', 'アベイル', '麗', '逆手', '自国', '近代史', '予備費', '沿線', '防音', 'アトリエ', '光熱水費', 'もも', '一読', 'switchlight', 'ニンテンドー', '菱形', 'ヒトモシ', 'ウルボ', '個体', '鶏がらスープ', '塩味', 'フサパック', '房', 'フォロワ', 'キョダイマックス', 'キョダイマックスリザードン', 'サンムン', '高性能', '値下がり', '抗議', 'むしゃくしゃ', '駿河屋', 'バリバリノーメイクマスクマン', 'カナー', 'レア', '諸刃', 'ピカブイクリア', '卑怯者', '氷柱', '犬鳴村', 'プライドオブ', 'ピー音', '鍛刀', '数珠丸', '大典太', '光世', 'アヴ', 'アメリカン・エキスプレス', '老害', 'えぶり', 'ミッドサマー', 'シュミ', '酢飯', 'ゲッコウガ', '東城', '時渚', '赤飯', '花崗岩', '350', '感情論', 'ライター', 'アンテナショップ', 'ざ', 'アリア', 'ヘアスプレー', 'まじまじ', 'コマ', '入間', '豊田', '持ち越す', '集い', 'フラッシュ', '先見', '明', '有罪', '受取手', '読解力', 'ドュドュー', 'フェルナンド', '楽天ブックス', '牡丹雪', 'ハンドル', '余す', '角切り', '一条', 'シン', 'デレマス', 'ノーマル', '開花', 'スワイプ', 'AirDrop', '高々', 'NY', '軽々', '所為', '初回限定', '風花', 'ギネス', 'フィッシュ&チップス', 'はげる', 'RTA', '隅々', 'サブ', '開発者視点', 'ルーク', 'リドル', 'シエル', '触覚', 'RIDDLE', '既視感', '栗鼠', '銀河団', '遣り直し', 'ハンズ', 'マイル', 'スカイ', '島原の乱', '浦島', '馴れ合う', '伽羅', '鶴丸', '豊前', '元気印', '清涼剤', '振り付け', '天祥', '英知', '深入り', '濃やか', '白黒', '潜在', '表立つ', 'シリアル', '肖る', 'スカイブルー', 'ジュラ', 'ルドン', 'ダイオウドウ', '巻数', 'しずえ', '午後一', 'ヒギャー', '暴落', 'パーチー', 'ヒプ', 'レッドライン', '馬太郎', 'アネモネ', 'ヒヤシンス', 'チューリップ', '生理用品', 'みお', '命じる', '駅構内', 'ニセコイ', '離島', 'クリエート', '映画史', 'ナンバーワンヒット', 'メヒコ', 'アズール', '137', 'カブ', 'アル', '共闘', '魔人', '整地', '住宅街', '枡目', '乙女ゲーム', '性別', '希薄', 'どっこいどっこい', '遣り繰り', '数多', '寮長', '手土産', 'ゲイツ', 'クドウ', 'とん', 'アールグレイティーラテ', 'アールグレイ', 'SMS', '絶不調', '1600', '加州', 'マレ', '印象操作', '弱者', 'フーコ', 'アムネシア', 'ジェシカ', '絶え間', '投げ出す', '欲深い', 'わけわかめ', 'クマ', 'まっきー', 'ダイ', 'バリエーション', '真相', '大爆笑', 'ツッコミどころ', 'いしだ', 'あきら', '中央公会堂', '添え', '撤去', 'ジェットタオル', 'ビフォー', 'くびれる', '電球', 'ソロウエディング', 'インナー', 'スイミング', 'プ', '契約書', '発効', '払い戻し', 'いちょう', '尼崎', '新恐竜', 'グラサージュドリップケーキ', '関所', '煎餅布団', '一式', '御寝しょ', 'リフォーム', 'タイル', '目地', '黴', '張り替え', '新婚', 'スチーム', 'オーブンレンジ', '丈夫', '極度', '肥満', '院長', 'アクシデント', 'モーゼ', 'カッポカポ', 'ウェデイングドレス', 'ソロウェデイング', 'モアナ', '経過観察', 'HAPPY SET', '消し', 'ヨヨヨ', 'フィットネスジム', 'チェリーブランデー', '減税', '緊縮', '本降り', 'ビリー隊長', '准教授', '本好き', '魔女宅', 'ちょき', '奮闘', '押し込む', 'リングフィットリズムゲー', '配当', '一時金', 'どんより', '再読', '塩気', '塩昆布', '膵炎', '公立', 'マイページ', '残', '金券ショップ', '京橋', '京阪沿線', '額面', 'しゃっ', '甲', '由', '申', '餅網', 'そらす', 'ダイナマイト', '物流', 'マーニー', '受け', '学校施設', '数検', 'スト', '万代', '週明け', '新一', '体育会', 'ぞろり', '新番組', 'スタディサプリ', '持ち替える', '緻密', 'ジンジャー', '守備範囲', '力強い', '天てれ', 'プレート', '製造業', 'ゴマアイス', '色物', '公文', '府', 'フェーク', '称号', '体育館', '全館', '百貨店', '何百', '司法試験', '予備試験', '即日', 'JUDY AND MARY', 'パーソナルトレーニング', '狙い打ち', 'インターホン', 'ポストイン', 'POS', '教頭', '懇談', '総会', '家庭訪問', '復習', '通り次る', '非常時', '容赦', 'チャン', '大阪ほんわかテレビ', '釘付け', '黒の組織', 'キュラソー', 'スケール', 'はくしょん', '大魔王', 'よいとまけ', '回し者', '婦人科検診', '切り干し大根', '頂き物', 'バウムクーヘン', '低空飛行', 'アクセス数', '過去最高', '26000', 'TKB', '透け透け', '溝', '窪み', '素肌', '虎柄', 'ショートパンツ', 'マラカス', '45000', '日和る', '5500', 'ミルフィーユ', '先週末', '臨時休業', 'hinotori', '棒読み', '休業補償', '交渉中', 'ミニゲーム', '坊っちゃん団子', 'マドンナ', '陣太鼓', '両端', '直帰', '北部', '京都市内', '投票率', '当確', 'ルイージマンション', '公認会計士', '頑固', '人類滅亡', 'ビフォーアフター', 'スキニー', '過去作', 'ハイロウズ', '小松未歩', '一本', 'びしゃびしゃ', '擦った揉んだ', '迷惑行為', '退店', '冊子', '挟み込む', 'アトピー', '松井', '育ち', '電子ピアノ', 'ディスタンス', '桐葉菓', 'ロアンヌ', '岡江', 'Z会', '年齢的', '尾崎豊', '生き様', '能登半島', '戯ける', '思い留める', '聞く耳', 'ラプンツェル', 'ガストン', '憎たらしい', 'あやふや', '抱き合う', 'ローラ', '仕立てる', '中庭', 'バンザイコシフリ', '水土', '取り止め', '蕗の薹', '2013', 'ギリギリchop', '注文書', 'よりすぐり', '険悪', 'DaiGo', '兼用', 'だいすけ', '過疎', '新型', 'ばら売り', 'フレンチ', '粒々', '撃破', 'ユージン', '麦茶', '聞き入れる', '沸点', '小中学生', '児童手当', 'オンライン申請', '広報', '立体マスク', '型紙', '曲げる', '説明書', 'スーファミ', '立体', '気晴らし', '野口', '淀川', '河川敷', '城', 'だら', 'ミニデビル', '徳政令', '夫婦円満', '双六', '休', 'ハンクラ', '捕獲', 'フェリシモ', 'ガーゼ', '手拭い', '役職', 'モニ', '阿諛', '遣り込む', '実店舗', 'ハイリスク', '年代', '温存', 'アイスクリームの日', '新キャベツ', '108', '奴隷', '妊活', 'ヲチ', 'パタパタママ', 'べとべと', '槽', '680', '2176', '見直し', '兼ね合い', '休会', '堅実', '中級', 'ポツポツ', 'クックルン', '必要経費', '府民', '常在菌', '弱め', 'こいこい', '併設', 'ホームランバー', '変化球', 'ホウセンカ', '福知山', '大河', '誘致', '光秀', '尼子', '惣兵衛', 'ぴちぴち', '革パン', 'ショーパン', '解放感', '用布', '2032', '海苔', 'mgmg', 'ハムストリングス', '大臀筋', 'ラブコン', '長瀬君', 'ドルガバ', '机上', '一斉', '剥き出す', '掏摸', '不貞腐れる', 'ドラゴ', 'ノーダメージクリア', '中上', '捻る', '住民', 'マッスル', 'マリメ', '純朴', 'ミレービスケット', '531', 'kcal', '鶏ハム', '探り', '面識', '割り', '色盲', 'プディング', 'スティッキートフィープディング', 'デーツ', '平均点', '全品', '児童クラブ', '招待', 'ほぼほぼ', '済し崩し', '濃厚接触', '作業服', '登録名', '名入れ', '足留め', '届け出る', '王朝', '聲', 'ほろ苦い', '1900', '陰性', '接触者', 'バッタンバッタン', '大目', '出勤時', 'かちん', 'ドッタンバッタン', '処女', '漁', 'インターナショナルハブ', '簡易書留', '繰り下がり', '守護', '魔力', '忍ばせる', '普通郵便', '弁論大会', 'aquagirl', 'agby', '味気', 'イズミ', '地域限定', 'ピンポイント', '海賊', 'ノーミス', '渋', '特別出演', '一席', 'しば', '納会', '何万', '藪蛇', '流し見', '空気入れ', 'サドル', 'バッタバタ', '凡ミス', '許可制', '息巻く', '気性', '4500000000', '火星', '日月', '山奥', '物置', '父ちゃん', '皺寄せ', 'ボイコット', 'ちょっちょっ', '音無', '麻婆春雨', '糸瓜', 'blw', 'ワンカルビ', '焼かす', '迎え', '親元', '憑き物', 'トトロ', 'バトルジム', 'そんじょそこら', 'プッシュ', 'ヨガマッタ', 'がっくり', '揉め', '定年退職', '生涯賃金', 'かぼちゃの皮', '母さん', '老母', '一人っ子', '第一子', 'チェック表', 'フリータイム', '温かさ', '大阪府', '幼女', '白ご飯', '締め鯖', 'マリオブラザーズ', 'WiiFit', '直近', '什器', 'シャッペスパン', '杜撰', 'マカロニグラタン', 'スライス餅', 'フロス', '苦行', '隔年', 'カリフラワー', 'シロッコリー', 'にや', 'ドヤ顔', 'カリッコリー', 'きらり', '一番風呂', 'フジロック', 'ZEEBRA', 'Yuki', '分岐', '大縄跳び', '居た堪れる', 'スーファミミニ', '84', '浴槽', 'ヘアドネーション', 'ハリボー', 'グミ', 'サンディー', '受検', '非接触', '検温', '基準値', '続出', '日傘', '適宜', '大ウケ', '近大', '横腹', '従来', '免除', '見開き', 'ノンタン', '小西', '英子', 'シャワ', 'けけ', '伐採', '外観', '醸し出す', 'アベガー', '緊縮財政', '安倍さん', '任期', '新生児', '洗濯挟み', 'こぼれる', '置き去り', '人身', '責任者', '受験者', 'NANA', 'ぼっさ', 'ぼさ', '江口のりこ', 'があ', '美脚', 'へろへろ', '機種変', '秋冬', 'cocoa', 'ざらざら', 'お裾分け', '塩水', '塩キャラメル', '組成', '体脂肪率', '筋肉量', '家庭用', '目安', '不意打ち', '漢字ドリル', '21000', '私立', 'ピー助', 'モモアケコンボ', 'エプロン', 'オフロスキー', '互助', 'イフ', 'ぎゃあぎゃあ', '適', '酒癖', 'アリストテレス', 'バカばっか', '繰り上がる', '手書き', '鯉幟', '小泉純一郎', '中村紀洋', 'タフィー', '情勢', '心理的', 'すけ', 'すくすく子育て', 'リングコン', '接続', '振り下ろす', 'ザード', 'クレ', 'ハロー', 'みさえ', '空き缶', '初回購入', '付与', '有効期間', '改悪', '187', '総裁', '菅ちゃん', 'ロザン', '垂直', '四手', 'アイスラテ', 'ごくごく', '振り仮名', '御襁褓', '然う然う', '元奥', 'すぱ', '決断', '経済力', 'ブンバボン', '地銀', '本店', '仕出す', '自前', '父子', '義', 'エンゼルフレンチ', 'チョコファッション', 'ナゲット', '生活力', '安井', '由梨', 'パン焼き', '輪っか', 'ロシアン', 'ツイスト', 'ほったらかす', '史緒', '食卓', '付随', '偶数', 'ピラミッド', '組体操', 'ダブルダッチ', 'アクロバチック', 'リレー', 'バトンパス', '見切り発車', '次走者', '掛け声', '駆ける', '紅蓮', 'そうらん', '島歌', 'エイサー', '選り好み', 'やさぐれる', '表れる', '爆破', '物騒', 'ぱし', '爪切り', '消', '紺色', '紺', '先月末', 'ペイカード', '繰り上げ返済', '月々', '定額', '楽々', '歌い上げる', '運動音痴', '品評会', '農林水産大臣', '才木', 'れい', 'かちゃん', '隠れん坊', '恐', '洗い出す', 'ラストワンプレー', 'コーナーキック', '福森', 'FK', 'みっちり', 'ストライダー', '全角', '聴衆', '演者', '自走', '少子高齢化', '読み物', '聞き物', '決定的', '湧き上がる', '呈する', 'ネットスケープ', 'ブロードバンド', 'Yahoo!', '打破', 'お年玉', '恨み', '首里城', '消し止める', 'プルデンシャルタワー', 'ウェディングドレス', '天下一品', '箱買い', '校庭', '振り子', '振り切る', '坂本勇人', '熱気', '史上', '熊本弁', '博多弁', 'トラックバック', 'バジルソース', 'セロリ', '食感', '撤退戦', '最前線', 'ありのままで', '自己開示', '再発防止', '未然', '意気揚々', 'があん', '手遅れ', 'トゥントゥトゥントゥントゥトゥン', 'トーン', 'トイレの神様', '周東', '大蛇丸', 'ありよりのあり', '切腹', '萎縮', '産業', '具体', '解決策', '他部署', '減点', '加点', 'バチェラー', '田尻夏樹', '上田', '岡本', '執着心', '剣先', 'マネー', 'タクる', 'んふんふ', '滑子', '文書', '石崎', 'DW', '押し潰す', 'ジャイアント', '総額', '決済手段', '多様性', 'リアル店舗', '導線', 'ギガホ', 'ギガホライト', '透明性', 'アカウンタビリティー', '説明責任', '吹き出す', '流行語大賞', '流行語', '軽々しい', '無論', 'フレーズ', '闘争', '代弁者', '対話', '黄金比', 'SDGs', '協会', 'プレーオフ', '白熱', '湘南', '敗因', 'GEBO', '連れ回す', '鰆', '体長', 'はまち', 'インセンティブ', '爆増', 'シャリキン', '蜆', '見立てる', 'スポーツ選手', '追体験', '2100', '論う', '無機物', '近未来', '親密', '切り出す', '鮃', 'ドクターシェティ', 'MILK BOY', 'コーンフレーク', '煩悩', '源泉', '単なる', 'クリスマスイブ', '頑張り', '不燃', '中山', 'ホープフル', '馬券', 'ウィッシュ', '茗荷谷', '代物', 'コンプライアンス', 'ディスカッション', '本質的', 'ダイアローグ', 'ブラッシュアップ', 'コーヒーブレーク', '赤本', '大学受験', 'gnu', 'フェイタス', '積み重ねる', '年賀はがき', '西岡', '理詰め', 'クエバス', 'シャッタースピード', '絞り', 'ホワイトバランス', '王位継承', '数千人', '皇位継承', '女帝', '紐解く', '忘却', 'モナリザ', 'しまじろう', 'ゆうゆう窓口', 'とらす', '祈念', '米国', '人間ドック', 'バックパス', '嗜好', '私考', '食らい付く', '静脈', 'ドルミカム', 'ペチジン', '整形外科', '何分', 'レントゲン', '認知症', 'リコード', 'メッセ', '即ち', '蹴飛ばす', 'パブリックコメント', '思惑買い', 'ひゅう', 'アイカ', 'イコウ', 'コンドーオアズカリ', 'コンドーチェンジ', 'コンドー', '論外', '進捗度', '20200115', '445', '461', '590', '9380', 'Swarm', 'オフラインチェックイン', 'イークラ', 'モナコイン', 'ドミナンス', 'ポートフォリオ', '0.0003', 'ほうじ茶ティーラテ', 'イタリア語', '心穏やか', '父性', 'newszero', '落合陽一', '戦闘', 'ヘリコブラ', 'ガトリング砲', '操縦士', '銃身', 'ユア', 'かー', 'プラス思考', 'ヘッドホン', '松任谷由美', '磁力', '唐田えりか', 'ピーポ', 'コービー', '英国王のスピーチ', 'コリン', 'ファース', 'ロケットマン', 'エルトン・ジョン', 'タロン', 'エガートン', 'シエシエ', 'リバース', '三菱', '皇居', '腹ごなし', '生還', '背面', '皹', 'ソフトウェア', '512', 'ビックカメラ', 'ボタフォゴ', '南米', '北米', '20200131', '675', '652', '761', '29.16', '10078', 'スタートダッシュ', '仙骨', '飛び出る', 'プローン', 'レッグ', '市川インター', '焼肉キング', 'コーチング', '市場価値', '豆撒き', '洗練', 'バットマン', 'ニガミ', '音楽シーン', 'ファクト', '坂東', '銀座ルノアール', 'スルーパス', '浮かす', 'ドウグラス', '横浜FM', '蛍', 'ヴィッセル神戸', 'アビスパ福岡', '境地', '河村', '勇輝', 'ノムさん', '球界', '月見草', '説く', '指導者', '功績', '計り知る', 'ライフハック', '敬之', '流量', '輻湊', '遠く遠く', '力一杯', '砂場', 'デトックス', '20200215', '981', '919', '1131', '34.16', '9976', 'がんばりましょう', 'うまかっちゃん', 'オリジナリティー', 'チャーシュー', '煮卵', 'ヴェルディ', '東京ヴェルディ', '福岡ブルックス', 'アビスパ', '長谷部', 'イズム', '0410', '積極', 'ハ', '努', 'メテモ', 'ホ', 'ヨリ', '遠', 'シ', '槙野智章', '鈴木大輔', '次節', '本八幡', 'ブリヂストン', 'なりたけ', 'アレルギー性鼻炎', 'スカウター', '必要不可欠', '先っぽ', 'ジェットスター', '帰福', '成田', 'ジョーダン', '跳躍', 'Amazon Prime', '加入者数', 'Uber EATS', 'ドラモリ', '除菌', '壮絶', '罵詈', '雑言', '統合失調症', '不安障害', '日本記録', '思考停止', '幻聴', '過労', '棘', 'アレグラ', 'とんとん', '音声認識', 'テステス', 'コスティッチ', 'クロス', '走り込み', 'ボレー', '通称', 'コロハラ', '急増', '憚る', '雛人形', '広々', '外圧', '中断', 'ツーリズム', '春闘', 'ジロー', '歩数', '夢遊病', '一蓮托生', 'ぶた', 'トナラー', '始発駅', '乳化', '還暦', 'プロファイル', 'プロリーグ', 'プロサッカー選手', '南アフリカ', '南極大陸', '大口', 'いずこ', 'モーニングコール', 'Cygames', '柳田國男', '極限', '南方熊楠', '独仏', '語学', '大英博物館', '館員', '頭突き', 'ネーチャー', '最多', '51', '粘菌', '熊楠', 'フォーカス', '逃避', 'オリャンタイタンボ', '首都', '出口治明', '一言一句', 'なぞる', '出口', '頻発', 'シャッポ', '交差点', '満載', '前兆', '歩道', '取り扱い', '地点', '千葉県', '急ブレーキ', '水回り', '鱶', 'ピキピキ', '三重苦', '両肩', 'ワイシャツ', '屈める', '細長い', 'メガホン', '開封の儀', '切り返す', '内股', 'ソリューション', '正午', '搬送', '奏', '救急隊員', '救急', 'ナース', '依然', '可動域', '予後', 'そろり', '髭剃り', '3500', '電撃', '凝り固まる', '虻', '雷撃', '余波', 'ウィズ', '治療法', '実際問題', '2.65', 'ぱたり', '新宿三丁目駅', '社会インフラ', '声高', '喫緊', 'バッファー', '終息宣言', '終わらす', 'リーダーシップ', '飛躍', '未曾有', '開示', 'ヒエラルキー', '即する', 'ごにょごにょ', '定例会議', '信頼関係', '腕立て', '延伸', '申し入れる', '前者', '36.3', 'ムズ', 'ファシリテーション', '盛り上げる', '色分け', '際する', '崩れ落ちる', '当て嵌める', '押し殺す', '揺さぶる', '透析', '糖尿病', '心臓発作', '痴呆症', '看病', '裏表', 'プリーツ', '襞', '上向き', '接着', '個別具体', 'タニタ', 'healthplanet', 'エントロピー', '震', '朝夕', 'ポケットモンスター', '縄', 'バブリー', '有り余る', 'webex', '寝息', 'はた', 'コープ', '長友佑都', '佑都', 'プログリット', '久留米駅', '孔雀', 'kaggle', 'カグル', '股', '天下一武道会', '継続的', '問題点', '浮かび上がる', '自然体', '商い', '東京都知事選', '告示', '投開票', '小池百合子', '再選', '出馬', 'ビン', '為合う', '半減期', '短期的', '時価総額', '日本円', '17000000000000', '格差', '本格化', '区画', '蓄積', '総武線', 'ピンセット', '博多天神', '活気', 'mattermost', '余計仕事', '解像度', '値付け', '夜泣き', '声色', '泣き止む', '快調', 'Breakout', '双', 'ファイト', '読本', 'バッジ', 'タネボー', 'サーブ', '平野早矢香', 'ダブルパンチ', '散乱', '断面積', '大袋', '中性子', 'ボディソープ', '敗', '執行', '最終面接', 'オセロ', '内々定', '準安定状態', 'カード支払い', '南山', 'OB', 'シューアイス', 'ドッジボール', 'オアシス', '合歓', '時空', '先制', 'バレー', 'チュニジア戦', 'パナマ', 'あちゃ', 'ノイアー', 'じめじめ', '利尿', '高密度', '純正', 'イヤホンマイク', 'スペイン', 'ロシアワンチャン', 'ロシアー', '出身校', '鴨川', '氾濫', 'はや', 'オウンゴール', '研究会', '京大', '新人戦', 'テク', '竜巻', '名鉄', '友達登録', 'USA', '近隣住民', '中部電力', '詫び石', '入試', 'エコキップ', '快挙', 'ダメ押し', '粉々', 'ラインアップ', 'バイナリーオプション', '避暑地', '定位置', 'hotdog', '信玄袋', '節電', 'ジョンダリー', '寒冷', '暴風警報', 'AVE', '豊田線', '東山線', '生田', '栄', '999', 'ちょびちょび', '4001', '跡', '心理状態', '代目', '芝本', 'ヒッキー', '前日入り', '下宿', 'おつ', 'ドビー', '温室', '稲井', '大輝', '立ち回る', 'シュレディンガー', 'ドラえもん展', '飛行機代', '旅費', '無欲', 'レディース', 'ビジネスクラス', 'VOICHA!', '打っ続け', '瞬間接着剤', 'cashshow', '衰退', 'イージーミス', '虚偽', '符号', 'ちゃっちゃ', '参考文献', '匙加減', 'キルレ', 'SR', 'ティラノサウルス', '暴れ回る', 'スモーク', '栄え', '年越しそば', '血液検査', '蕎麦屋', '団地', 'kar', 'ヘッショ', '索敵', 'サノック', 'パイナン', 'パンデミック', '悪寒', 'アブスト', '半数', 'ads', 'オフトゥン', '山場', '初乗り', 'プリペイド', 'SiM', 'マイマビ', '鉄筋', 'キル', 'し終わる', '動線', 'パセリ', '手汗', 'ラブホ', '建', 'シュラン', 'ES', 'マイ★ボスマイ★ヒーロー', '写輪眼', '安置', '若松', '卒研', 'ミュンヘン', 'フランクフルト', '観光名所', 'jism', 'ファッシング', 'ノイシュバンシュタイン城', 'オーストリア', 'ドイツ語', 'ユーロ', '物価', 'ブ', '椙山', '集合場所', 'フライト', 'スコープ', '感度', '修了式', 'メイカ', 'ウクレレ', '雀卓', '入寮', 'データ通信量', 'のし', '繰る', 'MB', '顔写真', 'トラップ', '寮内', '猛者', '寮生活', 'オヌヌメ', 'おはよう日本', '新元号', '征服者', 'スクワッド', '所得税', '貸し切る', '非課税', '有用', '檜', '討論', 'グループワーク', '一定期間', '社割', '遠距離', '目見', '労働賛歌', '現なま', '武豊線', '車選び', 'ハイブリッド', '肘掛け', 'ラリー', '駆使', '還元率', '潮干', 'スプリット', 'ストライク', 'ピン', '考え出す', 'ETC', '新生活', '立ちしょん', '面積', 'バイオハザード', '自己研鑽', '納入', '受信料', 'モンキーレンチ', '銀行口座', 'メガバンク', '優しい世界', 'フィールドワーク', '隣の部屋', 'グノシークーポンチャレンジ', '投資信託', 'linepay', '年休', 'ターキー', '松阪市', '歓迎会', '台上', '水道代', 'マネーフォワード', 'プラチナ', '院生', '回り込む', '分泌', '公共料金', 'ドミノ', '生乾き', '逝く', 'pubgmobile', 'SUMMER WARS', 'SSD', '段違い', 'MicrosoftOffice', 'プロダクトキー', '早まる', '増水', '都市銀行', '金利', '感謝デー', 'サマー', 'マージ', 'ジェイソンベルモンテ', '夏季休暇', 'マイボウル', '交際費', '鶴岡東', 'プロボウル', '立ち位置', '左寄り', '釈由美子', '美人すぎる', '内部崩壊', '上り詰める', '亀崎駅', 'ユニドル', '漫喫', 'にらめっこ', 'すか', 'スペイン村', '週休', 'プロパンガス', '前借り', 'バックハンド', 'フォア', 'monsteridol', '徳井', 'イモト', '年休申請', 'マックスバリュ', 'イオンカード', '振れる', '郵便振替', '単元株', '源泉徴収票', '自然対数', 'クロス取引', '封ずる', '静まる', 'buysell', '値上がり', '頭脳', 'ツリー', '最新情報', 'マクスウェル', '物理学科', '読み違う', 'えな', '暢気', '能', 'イオン銀行', '預金', '突き出す', 'ハケン', '品格', 'Superfly', '歌唱力', 'ナンバーワン', 'ぐらんぶる', 'Pop', 'なまる', 'あか', 'マイハートハードピンチ', '鴨しゃぶ', '反復横跳び', 'ほあー', 'CSS', '保温', '音響機器', 'すらすら', '間違い探し', '゛っえっ゛', 'カラサドウデシタカー', '仕業', 'うさ', 'ぴょん', 'ぴょーん', 'ツタヤ', 'YUKI', 'ジュディマリ', 'フィジカル', 'ドック', 'キングオブ', 'ギャハハハー', 'ワンルームディスコ', '白文字', '近視', '茨城県民の日', 'どんぶり勘定', '仕打ち', '守銭奴', '獄', '整備', '失点', 'ホヤヤヤー', '心臓血管センター駅', '小布施', 'デザートワイン', 'クソオブクソ', '真宵', 'ぺろぺろ', '利根', '三成', 'べらべら', 'tx', 'うろちょろ', '掠める', '゛ん', '家賃収入', 'げろげろ', 'コロコロコミック', 'ぐぎ', 'ムラカミ゛ィ', '百里基地', '゛ー', '擦り付ける', '発泡酒', 'ゲートウェー', 'ソフバン', 'SOLO', '年額', '取り繕う', 'うい', '決裁', 'どばどば', 'ビッカメ', '予告', '前世', '略語', '何本', '2060000', 'バツ', 'ネッッ', '言い返す', '0.00001', '正当化', '惚け', 'クソクソ', '胎児', '福田', '敬礼', 'ぺいぺい', 'ラム', 'ムラカミ', 'カトラス', 'amazonprime', '蝶々', '関東平野', '大洗', 'ろん', '王女', '任す', 'ほよ', 'べべ', 'ゲラゲラ', 'パッパラパー', 'フッフゥ', '悪しい', '引き換える', '愛蛙', 'ロードスター', '岬', 'ブリュリュブチー', 'イデア', '保険契約', '大丈', '上陸', 'ッツ', 'クレンジング', 'プラザ', '飯盛山', 'SE', '制圧', 'びびび', 'びた', '樹木希林', 'がはは', '降', 'アッアー', '宮野真守', 'クリームフラペチーノトールエスプレッソショット', '追', '加', '恒例行事', '茨城新聞', '一面', '142', '349', 'バイパス', '物忘れ', '水雲', 'フコイダン', '某駅', 'コインパーキング', 'みどりの窓口', 'キオスク', '江戸', 'せく', '桐谷美玲', 'にゅう', '全席指定', '全廃', '髪染め', '歌詞画', '前略', '職人', '画鋲', '打ち抜く', 'シャボン', 'MMF', 'ボーダフォン', '着うた', 'フォン', 'ソフトバンクー', '普通の女の子に戻りたい', '結婚生活', 'プヨヨヨミング', '湯切り', 'マッハ', '茨城県', '民集', '打ち当たる', 'ひたち', '水戸', 'あず', 'ワングー', 'コレコレ', 'ゼェ', 'オペラ', '公式サイト', '値引き', 'ぶりぶり', 'OL', '亀の子', '信じ込む', '堕落', '着席', 'ミヤン', '蒙古タンメン中本', 'ほろほろ', '懐', 'hoi', '目先', 'アカウンヨ', '茨城県民', 'クナイプ', 'バスソルト', '温む', '賞与', 'チェック項目', '自律神経失調症', '温泉たまご', 'ガッタガタ', '恩師', '出世', '吉報', '脱法風俗', 'インターネッツ', '配', '室温', '寒冷地', 'wwwwwwwwwwwwwwwwwwww', 'ファービー', 'ちんちくりん', 'しゅり', 'ゲレンデ', '独活', '試写会', '予知夢', 'イエベ', '諏訪部', 'Java', '追い焚き', '綾瀬駅', '痕', '禿げ', 'ハゲハゲハゲハーゲンダッツ', '潜り込む', 'ッッッツツツ', 'アアアア゛゛゛', '飯田', '8.7', 'シリア', 'アーバン', 'wwwwwwwwwwww', 'wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww', 'キッコーマン', '複', '郭', '補完', '誤る', 'ガードレール', 'ころりん', '大破', 'ギリセーフ', '49', '偲ぶ', 'ウィルコム', 'ライス', 'リトル', 'トゥース', '安城', 'ポディマハッタヤ', '地名', '路線名', 'サンホラ', 'クラブイベント', '地方都市', '春日', '詰め替える', '中年男性', '土産屋', '敗北', '富士急', 'Google検索', '中華料理店', 'ピエール', '倖田來未', 'ステッカー', '堀江由衣', '過呼吸', '翔んで埼玉', 'ロケ地', 'スギィ', '形跡', '駅メモ', 'ボートショー', '按摩', '以下略', 'モーモールルギャバン', '番犬', '両腕', '揺らす', '山雅', 'ッッッアアアー゛', '゛゛゛゛゛゛', '赤道', '何々', 'えつ', '杉', '豚丼', '来月末', 'しゅく', 'ちょく', '亀虫', '天声ジングル', 'トート', 'サコッシュ', 'PASMO', 'エモエモ', 'ひらひら', 'リアフレ', 'DK', 'セッション', 'ホームシアター', '楽天ポイント', '成功率', '定期預金', '品川ナンバー', 'ダァーッ', '山崎', 'ヤマザキパン', 'ライブ会場', 'プリクラ', '新宿駅', 'バスタ', '変数分離', 'FLASH BACK', '焼き付く', 'ワ', '元素', '紀行', '元素記号', 'げん', '和', 'さ迷う', '混ぜ蕎麦', 'たれ', 'ブルガリアヨーグルト', 'ブンブブ', '没', '写真屋', '行かす', 'ふてぶてしい', '目付き', '歴史写真', 'クレーマー', 'もにょる', 'モフアニマルカフェ', '長野市', '青大将', 'ニホントカゲ', '取っ捕まえる', 'ワイモバイル', '山梨', '大洗鹿島線', '水郡線', '袋叩き', 'ギプス', '天地創造', 'SOS', '音響', 'サブカル', 'カルカル', 'かまってちゃん', '会社負担', 'ミュウツー', '逆襲', 'コレジャナイ', 'ラプラス', 'パートナー', 'もさもさ', 'ネスカフェ', 'けたたましい', 'ネスレ', '外仕事', 'イズ', 'ゼッッ', '゛い', 'アスパラ', '貴洋', '準備物', '素麺', '水水母', 'スポイト', '餌遣り', 'ロストバゲッジ', 'rrr', '貴重品', '首都高', '佐和', '筑波山', '噴火', 'アイウォントブラックコーヒー', 'キャラメルマキアート', 'ミスパラレルワールド', 'ナツヤスミ', '辞典', '付け合わせ', '日本食', 'キャラメルBOX', '演目', 'けっ', 'ティー', 'ディー', 'フラッペ', 'バルーン', 'pentaxq', 'オリンパス', 'OM', 'ヤンキーピラフ', 'デスマーチ', 'wmm', 'フリーソフト', '抜き出す', 'aviutl', '泊まり込み', '長距離', 'バーニラバニラ', '付け替える', '冷や冷や', '出先', 'サーフェス', 'ミルクティー', '白いたい焼き', 'IT系', '足掛かり', 'DTP', '一般企業', '出張前', 'キャラメルソース', '肩凝り', 'サンシャイン池崎', '引率', 'ねるねるねるね', '醤油ラーメン', '柚子コショウ', '教訓', '似合い', 'カーブス', 'ラバ', 'モンベル', '善良', 'ジャスコ', 'カルディ', 'コーヒーセット', '水遣り', '外貨両替', 'US', 'ウエルシア', '売れ残る', '簡易郵便局', 'ピンキリ', '毛染め', '蒸し暑い', 'ノコギリクワガタ', 'スーパーセンター', '東京都心', 'バカンス', '飯山', '仙台育英', '鹿尾菜', 'デンカレ', '木曽駒', '御役所', 'オリエンテーリング', '氏名変更', '小型船舶', '名倉', 'honeybee', '突っ走る', '選定', '由々しい', 'finc', 'レーナウーンレナウンレナウンレナウン', 'ズンッ', 'ダー', 'ズズン', '身の回り', '旧版', 'ネクスト', '物語シリーズ', '親戚宅', 'セコマ', 'パトロール', 'ねくすと', '食品スーパー', '点在', 'アマギフ', '栃木県', 'オオタニ', 'デッド寿司', '千曲川', '抹茶ティーラテ', '中央本線', '松本駅', 'ロフト', 'エッセンシャル', '多部', '群馬', 'エテュセ', 'クイックケアコート', 'バチクソ', 'ヒョロロロー', 'Zepp Tokyo', '鴨川ホルモー', '占地', '年季', 'ヘアアイロン', 'サロニア', '救急箱', 'ヨルシカ', '海百合', '海底', '譚', 'アッアア', 'なかがわ', '遊園', 'ローソンファミマ', 'グラマー', '乾燥肌', '1111', 'アンノウン', 'ワールドマップ', '瞼', 'ジェニー', 'とちぎ', '梱包材', 'チャイティーラテ', '飯食い', 'ラングラー', 'Adobe', '通常価格', 'iphonexs', '128', '256', 'InDesign', '愛知県', 'トリビア', '宇都宮', '使用者', 'リニューアル', '筐体', 'ジョイジョイジョイフィット', 'ガルパ', 'イラレフォトショ', 'ヒーッッ', 'ぎこちない', 'モリサワ', '一太郎', '聴診器', 'コラ', '探し物', '個人用', '海藻', 'クリスタル', '旧姓', 'ヤンマママジ', '草原', 'アメリカン', 'エスプレッソ', '日の目', '鰯', 'ランマン', '獺祭', 'リコーダー', '御上手', '猛', 'グッバイ', 'めんち', 'マア', '明太子', 'ビジネスライク', '退勤時', '立て込む', '宿直', '松屋', 'SchoolDays', '既婚', 'メリークリスマス', 'けえる', 'ウレピィ', 'とちテレ', '海蔵', '亮太', 'アフリカツメガエル', '由緒', '何千', '具現化', '多量', '不思議ちゃん', '酒のあて', 'マネ', 'mineo', '時間制限', 'ックルルルルル', '命日', 'きょく', 'べる。', 'モンベルー', 'ガイアの夜明け', 'パタゴニア', 'フリース', 'ブラシ', 'マス', '赤ワイン', '隠', 'キャリスト', '毛玉', 'シチュー', '公的機関', '深', '視力検査', 'ハンドクラップダンス', '背徳のシナリオ', 'WINK', '淋しい熱帯魚', '酒盛り', '音量', '雑収入', '青色申告', 'freee', 'ずく', '女子小学生', '八王子', '経理', 'あずさ', 'オザケン', 'トド', 'マイルド', '辛め', 'ほぼ日', '糸井重里', 'まぜそば', '観念', 'ーィィィ', 'えつこ', 'ネムミウイルス', '配合', '最後の仕事', '航空', '散布', 'まじレス', 'ウポポイ', 'カクノ', 'EF', 'スケルトン', '気違い', '集結', '食器棚', 'ナァン', 'ジモティー', '密売', 'クリームソーダ', 'PM', 'デカフェ', '客層', 'トムヤムクン', 'スヤァ', '別役実', 'ムード', '陸前高田', '塩害', 'プリントスクリーン', 'テプラ', 'TRIP', 'キマッ', 'ワッフル', '遅め', '立ち会う', '残務', 'かわく', 'グリル', '転入', '公用語', '栃木弁', '本籍', '氏名', '記載事項', '国交省', '錯覚', '追悼番組', '追悼', '言い付ける', 'ロジクール', '併記', 'yeah', 'バリシーア', '備忘録', '竹の子', '油揚げ', '牛蒡', 'ッッッヒーィ', '長椅子', '花林糖', '聳え立つ', '過ち', '西川貴教', '茨', 'いばらき', 'テースト', '道家', '鶴弥', '虹色', 'Photoshop', '鸚鵡', '見切り', 'ファッキン', '応用', 'まほろ', 'アイソン', 'ラブジョイ彗星', '金星', '存在感', '超新星', 'ニューバランス', 'ナイキ', 'ジーンズ', 'ファクトリー', '雑食', '懐こい', 'スタミナ', '死体', '遺体', '泣き叫ぶ', '微睡む', '自論', '退化', 'アバウト', 'ファスナー', '談笑', '欠伸', '独占欲', '丸大', '鮮魚', 'バイヤー', 'ドナルドダック', 'ファックス', '閏年', '夢見', '地震酔い', 'ペースメーカー', '金属アレルギー', 'ニッケル', '貧乳', '巨乳', '結果論', '言い放つ', '曝け出す', '呼吸困難', '細胞分裂', 'エルニーニョ現象', '打ちのめす', '深海', '酒のつまみ', 'ぱり', '象徴', '買い戻す', 'ポップコーン', '一眼レフ', 'レフ', '強姦', '逃げるが勝ち', '被写体', '月光', '月桂冠', '大潮', '大室', '高潮', 'カミキリムシ', '逃がす', '不安の種', '干し椎茸', '擦れる', 'ミラーボール', '鯣', 'バロメーター', '初期設定', '朗らか', 'グネ', '腹下', '医療保険', '竹野内豊', '成海璃子', 'マックシェイク', '紫芋', 'ぐうたら', '呼び出す', 'ブーケ', 'メンタームリップ', '43', '氷菓', 'ミルクパン', 'ココアパウダー', '機内モード', 'ニコ動', 'デュラララ', 'デュラハン', '擦れ違い', 'もみじ饅頭', '公共の場', '馬鹿騒ぎ', '絶える', '年の瀬', 'かり出す', '感性', 'おしゃれアイテム', 'gelato pique', '氏神', '倉庫', 'コピー用紙', '伝票', '真紫', '覚せい剤', '睡眠欲', 'グンナイ', 'ざら', '借金取り', '帆立', '渇き', '潤す', '罰する', '溺死', '騒がしい', '大風', '悲劇のヒロイン', 'かぐや姫の物語', 'ふんわり', 'べた', 'コーディネート', '吃逆', '下向く', 'もごもご', '言い合い', 'した', '口角炎', '信号', 'ライザップ', 'エンドレスリピート', '触れ', '干渉', '先回', '大荒れ', '仕送り', '住民票', 'リップグロス', 'アプリコット', 'ドラマチック', '特徴的', '膿', '鈍痛', '化膿', 'ケチャップ', '切らす', '目頭', '備前焼', '老いる', '絶対量', '使い果たす', 'びびり', '次女', '待ち合い', '読み聞かせる', '聞き入る', '聞き役', 'オールドファッション', '分かち合う', '倉敷', 'ピノ', '砂抜き', '変わり身', '右足', 'フルテンション', '歌い踊る', '生温かい', '白球', '泥塗れ', 'トンネル', '冷え冷え', '倉敷駅', 'KIOSK', 'ラウンドワン', 'ドクターマーチン', 'きんきん', 'オータム', 'TBS', '羽織', '衝動買い', '流れる雲', '締まり', '残虐', '麗らか', '刈り込む', '芝生', 'イケボ', '擽ったい', '生者', '金閣', '比喩', '金閣寺', 'キタコレ', '天才的', '兵隊', '総動員', '駆け付ける', '目脂', '成れの果て', 'ファンタジック', '360', 'ビブラート', '不規則', '倍音', '聴力', 'ぱさぱさ', '柳', '失格', '合いの手', '明日海', '藤戸饅頭', '蛇の目', '練り香', '出汁', '南部鉄器', 'レシート', '保管', '木曜日', 'ハニー', 'ロースト', '一長', '一短', '意識高い系', '対極', '薄ぼんやり', '消去法', '積み上がる', '順当', '拇印', 'ブラックホール', '渦中', '鬱陶しい', '陰鬱', 'うつ伏せ', '瑛太', '邦画', '一個人', '飽食', '厘', 'ワセリン', '暮れ泥む', 'オーナメント', '愛想', '尽かす', 'へどろ', '締め括り', '分け目', '頚動脈', 'どくどく', 'さわさわ', 'ガスコンロ', '鉄製', '継ぎ目', '斜め読み', '横書き', '一句', '信頼度', '母と暮せば', '甘', '海鼠', '夢じゃない', '備前', '哲学的ゾンビ', '日産スタジアム', '貰い泣き', '炊き立て', '食い気', '反芻', '耳垢', '中三', '景品', 'ストレンジャー', '旋律', '誘く', '未明', '小火', '発泡スチロール', '煤', '消化器', '鎮火', '漏電', '走り込む', '肉離れ', '辻褄', '絆創膏', '正露丸', '電卓', 'パソコンテンキー', '科', 'ブラインドタッチ', '甘茶', 'ティラミス', '高笑い', '雨宿り', '屋根', '楽天モバイル', '他人の顔', '撫で回す', 'りざえもん', '神谷', '蝋燭', '和太鼓', '3.1', 'きっかり', '6.2', '親子連れ', '熊', '銃', '撃ち殺す', 'ドグラマグラ', '飲ん兵衛', '遅れ馳せ', '冷暗所', '直射日光', '思い付き', 'クリーピー', '偽り', '退席', '漫才', 'いろはに千鳥', '靨', '研ぐ', 'ぴんぴん', '新聞紙', '漂白', '挽き肉', 'クドイ', '夢野久作', '冷たい方程式', 'オムニバス', '天職', 'ギブアップ', 'タン', '後味', '噴射', '海ぶどう', 'COSMONAUT', '飛行船', '腑', '小躍り', '薄っぺらい', '文明', '利器', 'csmonaut', 'メモアプリ', '逃亡', 'ねた帳', '妬ましい', '2675', 'ハッピーターン', '歌野晶午', '神秘', 'ハイデッガー', '時計台', 'ヨカッタネ', 'ツナ缶', '食み出る', '増殖', '浅瀬', 'ぴちゃぴちゃ', '捲れる', '素手', 'ストローク', '鉄琴', '鼓笛隊', 'ツイン', 'ティンパニ', 'マリンバ', 'ベルリラ', 'アコーディオン', '打楽器', '降水確率', '通販番組', 'オペレーター', '足先', '羽毛布団', '喘ぐ', '激甘', '捻り出す', '寄り掛かる', 'うだうだ', 'ブラックコーヒー', '栄螺', '皆目', '見当', 'ピンキーリング', '醜い', '相応しい', '阻止', '破壊衝動', '逃げ帰る', '菠薐草', '恵方', '北北西', '右下', '金色', 'ひと目でわかる', '監禁', '枝分かれ', '察知', '台無し', '嘆き', 'フルカラー', '揺らぎ', '琴線', '共鳴', '右肩', '肩掛け', 'ずり落ちる', '股関節', '忍者', 'スガシカオ', 'アシメトリー', '時分', 'アスペクト比', 'ニュース番組', 'パネル', 'スッタフ', '前後不覚', '投げやり', '隠れる', '反する', '精巧', '漫画喫茶', 'Soul', 'BPM', 'オーオー', '音階', 'キングコング', '連弾', '鍵盤', '飛んだり跳ねたり', '手の甲', '生理現象', '生憎', 'アキレス腱', '不定期', 'ぼりぼり', '読み取る', '晴れ間', 'MOZU', '倉木', '走行中', '衝突', '二重生活', '尾行', '足跡', '奥行き', '新調', 'キモチイイ', '主旋律', '爪弾く', '耳コピ', '二十歳', '青空', '野球部', 'じわ', 'トーキョーグール', '酒臭い', 'スンスン', '窪田正孝', '青年', '回し蹴り', 'ダッフルコート', 'ボタンホール', '首元', 'チンストラップ', 'フード', '復唱', '書き留める', '上書き', 'ドイツの森', '後方', '正規分布', '展示物', '砂金', '意地悪', '一雨', '時雨', '裏返し', 'ガハッ', '梅醤', '番茶', '実写', '家族連れ', '単品', '回し飲み', '白葱', '突っ張る', '誤爆', '外聞', '儚い', 'ブレーカー', '縫い付ける', 'ドライトマト', '処方箋', '乱視', '利き手', '逆剥け', '外側', '擦り剥く', 'スピッツ', '草野', '発声', '副鼻腔', '蝶形骨', '洞', '長電話', '音漏れ', '女子校生', 'ごしごし', '手荷物', '平均的', '道徳的', '湿る', '耳鳴り', 'ローストビーフ', 'バナナマン', '設楽', '裏声', '渋々', '抗生物質', '快方', '治癒力', '買い被る', '扁桃腺', 'ちぎる', 'アルフォート', '牛歩', '飲み掛ける', '中耳炎', 'イヤー', 'プロテクター', '耳栓', '付け外し', 'みんな元気', '皆既月食', '対処法', '悲愴', '第二楽章', '肖像画', '絵画', '豆知識', '歓声', '立ち姿', '片足', '重心', '行間', '合鍵', 'カンガルー', '鰹', '眼球', '断り', '無断', '言', '羅列', '脈打つ', '塩漬け', '見越す', '預言者', '尋問', '柏餅', '先取り', '生き急ぐ', '余震', '木片', '願掛け', '手折る', '紛う', '舎利', 'シャリ', '切れ味', '刃物', '内出血', 'googleearth', '重力', '力ずく', '未遂', 'ギッチギチ', '上塗り', 'ハンモック', 'あたりめ', '結膜炎', 'ゴーグル', '塵', '音姫', '吐息', 'とんずら', '金貸し', '手放し', 'ワープロ', '黄昏る', '海老天', '冷や', 'ごちそうさま', 'かしわ', '機種変更', '宝物', '境遇', '窓際', '傾ける', '飲み干す', '紫蘇', '食べるラー油', '除霊', '外出先', 'ドレッシング', '塩分', '鹿野', '足長', 'ルパン', '避難準備', '鬼のよう', '形相', '岡山県立美術館', '知性', 'ポール・セザンヌ', 'アルルカン', '前衛的', '館内', 'モーターサイクル', '俯く', '布石', '進行中', 'しゃかりき', '専属', '情報屋', '際どい', 'モンバス', '与島', 'SA', '右耳', 'マーチ', '検察側の罪人', 'ずっしり', 'ベビーフェース', 'ギレ', '焼き飯', '浮き島', '押し掛ける', '鼻歌', '掌', '筒抜け', '閉ざす', '立入禁止', '風雨', '断続的', 'スタイリング剤', 'パッサパサ', '多用', 'シリウス', '顰め面', '^ ^', '手渡す', 'アー写', 'アンニュイ', '方向性の違い', 'ざわざわ', 'バスケットボール', 'ブレ', '直井', '強いる', '大勝ち', '夏目友人帳', 'ムクオ', 'ほんわり', '高良健吾', '祠', '竜胆', '供える', '空蝉', 'Bluetooth', '抗い', '聞き', 'ピック', '感情爆発', '潤さん', 'メーデー', '救難信号', '宣伝会議', '危機管理', '猛勉強', '瀧廉太郎', '荒城の月', '捜し回る', 'ボイジャー', '隼', 'ナレーション', '行く先', '人工物', '流星群', 'ボヘミアン', '微炭酸', '藤くん', '起毛', 'ボトムス', 'だしパック', '鎌倉ものがたり', '振り向く', 'クロネコヤマト', '集荷', '印籠', '翳す', '町人', '濃霧', 'カロリーゼロ', 'ロストマン', 'アウトロ', '駆け出す', '未練', '風邪引き', 'ザッピング', '到底', '両者', '宝箱', '一摘み', 'ドライイースト', '娑婆', 'ビニール', '分け入れる', 'スイートポテト', 'パスファインダー', '別行動', '月島', 'マシンガン', '打っぱなす', '血眼', 'ようこそ', '喜', 'Aurora', 'ローマ神話', '神話', 'ラメ', 'イチロウ', '湯水', '端折る', 'ネットリテラシー', '携える', '顕著', '定点', '同族嫌悪', 'アリオ', 'リンツ', 'リンドール', 'ズッキーニ', '今さっき', 'アデノウイルス', '田植え', 'さいたまスーパーアリーナ', 'スー', '深め', '照れ笑い', '鋭い', 'ランナーズハイ', '片鱗', 'ズゴゴゴゴ', '地面', '船酔い', '三半規管', '激弱', 'おっかない', '持ち合わせる', '新ジャガ', 'じゃがバター', '色鉛筆', 'ゴアテックス', '待ち焦がれる', '許容範囲', '飛び跳ねる', '諤々', '箍', 'テント', 'boyz', '峯田', 'バリカン', 'ぐらぐら', 'GEZAN', '野外フェス', '虱潰し', 'それぞれに', '越後湯沢駅', '漉す', '麻婆丼', '80000000', 'ツヤピカ', '三木道三', '江原道', 'ペリペリ', '遍路', 'ローカル', 'かぐや姫', '水島コンビナート', '915', 'hPa', '抜け', '湯冷め', '即位礼正殿の儀', '大学芋', '正座', '生中継', '左上', '包まる', 'ぬくぬく', '部品', 'アロンアルファ', 'アガペー', '感激', 'よいしょ', '乗り出す', '同調', 'ベテルギウス', 'オリオン座', 'ShootingStar', '特技', '絶好調', '方向音痴', '大通り', '実在', '霊感', 'ポンデリング', 'プラマイゼロ', '大寒', '金運', '中吉', '待ち合わせる', 'トマトジュース', '文房具', '画材', '話半分', '残像', '流鏑馬', '東京ばな奈', '食器洗い', '着色', 'グレープフルーツ', 'フローラル', '香る', '湯気', 'キュキュット', '無香', '塞ぐ', '架空OL日記', 'バカリズム', 'サエ', 'エベレスト', '各々', '帰り際', 'kanzai', 'boya', 'ずたずた', '毟る', '見届ける', '絹豆腐', 'シュガー', '不純', '血豆', '大型車', 'アイドリング', 'ガスバーナー', 'イースト', '焼き麩', '綽々', '軒下', '除け', '噴霧', '朝晩', 'ホーホークルック', 'レゴ', 'プラレール', '遊び倒す', '不整脈', 'カッターナイフ', '庵', '雨期', '胃腸炎', '内臓脂肪', '皮下', '脂肪', '仕舞い込む', '化石', '画素', 'アラ', 'ソニー損保', 'マキノ', 'ファンタ', 'グレープ', 'ソープ', '感傷的', 'ぴいぴい', '発信履歴', 'レモンティー', 'ひいひい', '見せ掛ける', '古古米', '玄米', '精米', '土鍋', 'BUMP OF CHICKEN', 'ペラ', 'ピターッ', '鼻呼吸', 'ピター', '鬘', '運転中', 'エアリズムマスク', 'スナフキン', '駄賃', '雲竜', 'ばしばし', '観音', '仏像', '螺髪', '誘発', '人工', '涙液', '反時計回り', '攪拌', '980', '異性', '責付く', '天秤', '水平', '病院代', '緩め', '聴覚', '不協和音', '呼び止める', '迷わない。', 'たく', 'ウォーム', '白と黒', 'アイボリー', 'ベージュ', '黒白', '灰', '部外者', '誠心', '誠意', '落とし前', 'ナポリタン', '案じる', '怨恨', 'ぎゅん', '着ぐるみ', 'ペッパー', 'ポンツカ', '弁', 'ポテトチップス', '講演', 'ままどおる', 'エナジードリンク', '自動車学校', '特典映像', '栄光', '架橋', 'SSM', 'ラストシーン', '正式発表', 'スクラッチ', 'ハリー・ポッター', '金メダル', 'ittv', '世界チャンピオン', 'ふーみ', 'コルン', 'two', '気まぐれロマンティック', 'ファンファーレ', 'ニュートラル', '金銀', '内田有紀', '恐ろしいことに', 'じんと', 'ウォッカ', '紙飛行機', 'ビュー', 'イング', 'クリスマスパーティー', 'ステスーパーライブ', 'じょいふる', 'クリスマスイヴ', '光のページェント', '己等', '選考会', 'アモーレ', '陽炎', '仕事初め', '洋間', '乱入', 'サービス業', '願い事', '日本卓球', '日体大', '集団行動', '耳掻き', '声優総選挙', '山寺', '雪景色', '積雪', 'ナンバーズ', '立て続け', '準々決勝', '放牧', 'シード', '初戦敗退', '波乱', '神木', '隆之介', 'テレ', '史上最年少', 'リオ五輪', 'サブチャンネル', '早田', '中高大', '据え置き', 'メジャーリーガー', 'カントリー', 'ブレーキ', 'ゴーイング', '結成', 'どっさり', 'miwa', '大谷', '躍動', 'ウレシイ', '楽曲提供', '福原愛', '現実世界', '音楽番組', 'ヘビーローテーション', '病み上がり', 'まさおくん', '倉木麻衣', '最年少', '大塚愛', 'Love music', 'メリットゼロ', '顧問', 'きゃぴきゃぴ', 'マツケン', '62', 'オフチャロフ', '知英', '森園', '大島', 'ペア', '点差', '縮まる', '成人式', '中居', '日本誕生', 'スマステ', '完封負け', '勝ち上がる', 'オーストラリア戦', '中国戦', '侍ジャパン', '快勝', '粘り', '全勝', 'バラスーシ', 'オランダ戦', '死闘', '秋吉', '対戦', '灰原', '回想', '明美', '志保', 'たかみな', '決勝ラウンド', '下剋上受験', '生意気', '真昼の悪魔', 'サクラ', '麦チョコ', '関係者', '木村沙織', '開幕前', '早稲田実業', '摩天楼', '異次元', '狙撃手', '使い分け', '離任式', '業火', '向日葵', 'ルパン三世', '巨人戦', 'テレビ中継', 'ルパコナ', '重大発表', 'ばればれ', 'リッチマン', 'プアウーマン', '佐藤瞳', '松井玲奈', 'カラムーチョ', '名探偵コナン', 'セ', 'ぽか', '茜色の約束', '浅田真央', '個人戦', '美宇', '青山', 'イオンシネマ', '開場', '大岡', '波瑠', '報道ステーション', '放送事故', '盛', '百人一首', '接近', 'ミニライブ', 'プロ野球中継', 'パイプオルガン', '礼拝', 'メレンゲの気持ち', 'メレンゲ', '明晰', 'テレビ東京', '小林麻耶', '闇金ウシジマくん', 'めろめろ', 'ドンキー', '女囚セブン', '宇津井', 'うんこ漢字ドリル', '踏ん張る', '静養', '完全復活', '試合中', '私立恵比寿中学', 'なないろ', 'ダブルス', '銀メダル', 'アンインストール', 'ホームズ', '黙示録', '密着', 'Sunday Morning', '兵法', 'サムソノフ', '寝付き', '点灯', '山崎ケイ', 'ソフトボール', 'ピッチャー', 'ミニスーパーファミコン', 'スーパーマリオRPG', '前輪', 'アジア太平洋', 'MUSIC DAY', 'オーストラリア・オープン', '警視庁', '東北弁', '初戦突破', '猛暑日', '卓球台', '沖', '矢', '最新巻', '校', 'かちかち', 'レッドブル', 'カフェイン', 'アニオリ', '数日間', 'スイミングスクール', 'エキサイトスタジアム', '野球ゲーム', '大橋', 'STREET FIGHTER', 'ぐるぐるカーテン', '新妻聖子', '神田沙也加', 'ゾンビーバー', '毬藻', '熱戦', '順延', 'ブルガリア', '痛快TVスカッとジャパン', '広陵', 'チェコ', '丸山ゴンザレス', '再結成', '放送時間', '野口啓代', '三太郎', '蝮', 'スピンオフ', 'エンタの神様', 'グラチャンバレー', '普通じゃない', 'セリーグ', '秋季', '高校生クイズ', 'ゲーム差', '情熱大陸', 'バーム', '出身大学', '電磁パルス', '太陽フレア', 'ハーモニカ', 'おしゃれイズム', '高橋メアリージュン', 'メアリー', 'ジュン', '大学祭', '新垣結衣', '必見', '感動的', 'ミサイル発射', 'アジアカップ', '球団', '飯豊', 'まりえ', '武田玲奈', '一直線', 'カットマン', 'トゥルース', '保育所', '月暈', 'ミニスーファミ', 'わにとかげぎす', '花子さん', 'ホワホワホワホワ', '花子', '福原', '愛さん', '戦力外', '渡月橋', '先に生まれただけの僕', '選抜', '繰り広げる', 'レポ', '休刊', '卓球王国', '公務員', '固定費', 'FINAL STAGE', 'ももクロちゃん', '足立梨花', '休載', 'ミックスダブルス', 'ドラフト会議', '年金事務所', 'マルモ', '掟', '日本シリーズ', '大根下ろし', '温玉', '七味唐辛子', '肝心', '日ハム', 'コウノドリ', '戌亥', '犀', '茜', '塗り絵', 'グラン', 'メゾン', '木村拓哉', 'マスカレード', '水谷隼', 'ガソリンスタンド', '給油', '小梅', '太夫', '巷', '教場', '男子シングルス', '宇田', '幸矢', 'ケージ', 'ケンジ', '今田美桜', '人気投票', 'コスモ石油', '襲い掛かる', '立春', 'GARNET CROW', 'チャットモンチー', 'バレンタインデー', '全国各地', 'ライブカメラ', '台湾まぜそば', 'ハンガリー', '逆転勝利', '紺青', '拳', '辛味噌', '伊藤美誠', '準優勝', '川嶋あい', '旅立ちの日', 'インストアライブ', 'paravi', '愛菜', 'フレーム', '本格', '毎日テレビ', '徹', '本業', '川口春奈', 'ミュージック・ビデオ', 'WALKMAN', 'blu', 'Ray', '捕らえる', 'バックナンバー', '膵臓', 'ハルノヒ', 'もしドラ', '躍る', '36.6', '36.9', 'イメソン', '薄墨', '月華', '遊ばす', 'angelic', '松本梨香', '国際線', 'サクララウンジ', '泡風呂', 'ペナン', 'クアラルンプール', '市内', 'ベンツ', 'fop', 'オルデコ', 'ポプテ', '栗', 'まっくん', 'デビュー曲', 'プレシャス', 'メモリー', '新都心', 'スタンド席', 'MOTSU', 'シクレ', '各社', '歴然', 'ブシロ', 'テイマーズ', 'オーイシマサヨシ', 'ライブ音源', '忌憚', 'はたらく細胞', 'とお', '無銭', '(*_*)', 'まちまち', 'リスアニ', '石川智晶', 'gela', 'チキンレグ', '人大杉', 'シュタゲ', '飛', 'めぐむ', 'プーさん', 'flying DOG', 'soultaker', 'ビクター', 'ショーケース', 'Roland', '松尾', '洋一', '逸話', 'ジャケダサ', 'シベハス', 'ツイートファボ', 'シンクロナイザー', '下北', '宇宙戦艦ティラミス', 'BABYMETAL', 'ひでき', 'Ikuo', '回答者', 'エレクトリカルパレード', 'Atsuko', 'DEAD OR ALIVE', '蒼穹', '殺し', '日比谷野音', 'こてこて', 'TAIGA', 'fighting', 'アニュータ', 'LOUDNESS', 'FES', 'Vol.', 'グール', 'wwwqq', 'グリッメン', 'キルラキル', 'aniuta', 'このマンガがすごい', '電飾', 'ボヘミアン・ラプソディー', 'ドライブー', 'サイラバ', '田村直美', 'ゴッドグラヴィオン', '伊藤由奈', 'スターティング', '編曲', '展示会', '英会話', 'stand by', 'れお', '同窓', '会行', 'ダイミダラー', 'クーリングオフ', 'ガジェット', 'チョリソー', 'ソニー', 'RIS', 'クリスマス休暇', 'wug', 'SSA', '王国', 'こす', 'プレミア', '紐育', '撃', '団', 'トリセツ', '市村正親', 'ミューツー', '下町', '内田真礼', '千歳', '森雪之丞', 'Storm', '古参', 'GoPro', 'Fate', 'サルベージ', 'デパーチャー', 'ストーム', 'アニメイトカフェ', 'ANA', 'ウルトラマン', '野村', 'SRS', '打ち壊す', 'レッサーパンダ', 'ジャイアントパンダ', '小林太郎', 'ALL', 'LETS', '橋本みゆき', '佐', '咲紗', '美郷あき', 'CooRie', 'yozuca', 'MINAMI', '緒方', '黒須', 'Lantis', 'jamproject', '次回予告', 'ベジータ', 'ワンルームワンコ', 'フェスライブビューイング', '機動戦士ガンダム', 'ドズル', 'オープニング曲', '曲追加', 'GARO', '旅人', 'シャロン', 'フェネック', 'よしき', '大坂なおみ', 'トレッド', 'タイガー', 'テール', '2030', '出演決定', '音楽的', 'めざましテレビ', 'シンエヴァ', 'ミレーヌ', 'Fire Bomber', '仮面ライダー', 'はじ', 'ミラーワールド', '自由が丘', '懐メロ', 'ロウリュウ', 'トゥルー', 'ナショジオ', '浜田麻里', '蒼井翔太', '釧路', 'along', 'バトスピ', 'SOS団', 'djkg', '絵の具', '刻印', 'さいたま', 'スザク', 'ルルーシュ', 'サンドウィッチマン', '圧巻', 'ハム太郎', 'LiSA', 'ギラサマ', '御徒町駅', '前め', '東大テニミュ', 'よつばと', '軽井沢', '疾し', 'staring', 'stylemv', 'ワンコーラスラッシュ', 'チョコラータ', 'セッコ', 'mora', '37000000', '終物語', '神原', '駿', '河', '打ち殺す', 'ぐり', 'めえ', 'Aqours', 'JCD', 'BEST ALBUM', 'イヤモニ', 'ヴァージン', '大勝利', 'サヨナラノツバサ', 'ピロコ', '固目', 'チャリオッツ', 'レクイエム', '閣下', 'ワックス', 'マクロスエリシオン', 'マクロスΔ', 'バディーゴー', '反則', '武内', 'ナランチャ', 'サブマリーン', '地黄', 'ミクル', 'オリ', '御大', 'セブエク', 'マキシマイザー', 'hj', 'シンカリオン', '披露宴', '歌わす', 'カタログギフト', '外国為替ブローカー', 'ロボアニ', 'fabio', 'KING SUPER LIVE', 'シェリル', 'ロッテリア', '芳子', '吐血', 'ロンギング', 'なお', 'きめきめ', 'シンセ', 'ロボヲタ', 'アーガー', '伊丹空港', 'ラウンジ', '遊', 'ハヤシ', 'ソーナンス', 'ナタリー', 'アンジー', 'マーベル', 'ポートマン', 'ソー', '弾き語る', 'basara', 'EXPLOSION', 'ゾンサガシークレット', '急上昇', '黒服', 'ジョルノ', 'エクスペリエンス', 'DIO', 'NoB', 'サイクリング', '飯塚', '瀧田', '翼', 'シンフォメタル', '富野', '殺人的', '単独ライブ', 'デノン', 'ALTIMA', 'バンナムデー', 'ラバーズ', 'でじこ', 'トゥエンティース', 'age', 'knights', 'ドラゲナイ', 'ビバップ', '不可避', 'バーリアル', 'リキュール', '姉ちゃん', '湯河原', '温泉旅館', '朝風呂', 'フォーティース', '酷', 'バイオレット', 'エバー', 'ガーデン', '梨香', 'Kevin', 'ASCA', 'ダンスミュージック', '弾き', '休暇期間', 'ワックス脱毛', 'スース', '吉村家', 'SM', 'キテルグマ', 'VF', 'パイロット', '武蔵小杉', '漏', '錦糸', 'mages', 'シナリオライター', '林直孝', '英樹', 'ワンパンマンゲーム', 'RISE', 'コラサワ', '国歌斉唱', '影山ヒロノブ', '整理番号', '時間的', 'ハミングバード', '体力測定', '茅原実里', 'エミリー', 'anison', 'days', 'ピロ', 'ζ', '刻', 'スパイダーバース', '東映', 'スパイダーマッ', 'チャーチャラーチャチャラ', '名乗り', 'サンアンドムーン', 'experia', '防水', 'ファフナーファン', '真矢', '切に', '一騎', '総士', 'ビヨンド', '立上芹', 'Beyond', 'オガタメシ', 'Nintendo', 'ピチュウ', 'ミュウ', '配給制', 'ルギア', 'DAM', 'victress', 'ハモる', 'フラン', 'シュシュ', '椎名町', '東長崎', '踏切', 'かまくら', 'ロデオ', 'キョダイマックスアーガマ', 'exdous', 'マレスペロ', 'ドーピング', 'エルサ', 'CG', 'オマージュ', 'オラーフ', 'シンフォニックメタル', 'gong', '独占', 'シャア', 'ワンダー', '口ぱく', '侠', 'トゥッティ', 'アアアアアアアアアアアアアアアアアアアアアアアアアアアアアアアアアアイラアアアアアアアアアアアアアア', 'エイミー', 'ブラス', '横浜ビブレ', '副', 'アンフィ', 'タイアップ', '真音', 'ボーカリスト', 'EIZO Japan', 'ヤマハ吹奏楽団', 'プレコンサート', 'クリボッチ', '精子', 'オナニー', '電子化', '(⌒0⌒)/~~', 'SHIROBAKO', 'Victory', '元曲', 'Max Heart', 'ポッチャマ', 'クラウン', 'マッショイ', 'きよし', 'トライ', 'ニセコ', 'freaking', '七福神', '世界恐慌', 'フラッグス', 'みかこし', 'ウィンナーネタ', 'fripdide', '休養', 'サトシ', 'カイリュー', 'ホエルオー', 'ホエホエー', 'でかパン', '昌明', 'xpo', '栗林みな実', '新谷良子', '谷山紀章', 'BLEACH', 'frip', 'マク', '関東大震災', 'のら', 'ゆかりん', 'アグモン', 'ガブモン', 'デジモンアドベンチャー', '臆病', 'むか', '高校卒業', 'イルイミ', '御箱', 'fripSide', 'ライブ映像', '焦', 'EMG', 'ネットゲーム', '足る', 'ラ王', '周到', '各国', '指数関数', '歌手', 'キングレコード', 'トミカ', '新作アニメ', 'マギー', '一門', '桐谷', 'oneness', '音楽業界', 'レコーディング', '宅録', 'キャビン', 'つり球', 'NT', '東山', 'アカペラ', 'ヒルナンデス!', '三浦大知', '事業部長', 'ウォーキング', '暦', 'sawano', 'wwwcd', '聖地', '鬼頭', '攻殻機動隊', 'SAC', 'ツアーファイナル', 'ぴあ', '調整中', 'サンムス', 'HEAVEN and Earth', 'ピカデリー', 'ショタ', 'ジョギング', 'タツキ', 'フェアリーテイル', '置換', '積分', '置き換える', '上端', '下端', '症候群', 'リード', 'α', 'ミュージアム', 'ウィッフルボール', '朝会', '縦割り', '松北', '帝京', '王者', '団体戦', '筆箱', '負かす', 'unravel', 'パイレーツ・オブ・カリビアン', 'アウトストラーダ', 'デル', 'ソーレ', '教科', '書き捨てる', '優越感', 'テラロッサ', 'テラローシャ', '全校', 'タバスコ', '水原希子', '這い寄る', 'こん', '胴体', '埃塗れ', '道理', '息子たち', '勉強法', 'オクタニトロキュバン', 'フッ化水素', '爽快感', 'ニンニク臭', '文字式', '数学科', '解答', '済ます', 'シス単', 'プチパニック', '下山', '待遇', '手応え', '兆候', '電影少女', '乃木恋坂道の下で、あの日僕は恋をした', '小馬鹿', '荒野', '中毒性', 'おら', '作り直す', '偽名', '仕掛ける', 'まんまと', 'カルタ', '第二外国語', '受験勉強', '与謝野', '婦人会', '合格発表', 'プロフィール画像', 'はるやま', '問題集', '武井壮', '名古屋城', '大道芸', '拭い取る', 'こたえる', '剣道部', '丸出し', '至近', 'チアー', '課程', 'キャラ設定', '直面', '凍え死に', 'ダウンタウン', '教職', '歩き寄る', '理学部', '劣等感', '一山', '万札', 'モロ', 'wwwwwwwwwwwww', '声質', '高得点', 'クソダサ', '朝練', 'いかれる', '準急', '切符売り場', '鍵アカ', 'm(_ _)m', '三島', 'ハンデ', '仏語', 'ギガ', '不名誉', 'ボッチ', '建物', '不採用', '必要書類', '帰らす', '夏風', '朝ドラ', '防具', '竹刀', '503', '識別', '当店', '並盛り', '飲み食い', '屡々', '背凭れ', '高二', '旅行カバン', '吊り革', 'オランウータン', '勘違い野郎', '必修', '役員', '法学', '痴漢冤罪', '思い当たる', 'ピー', '強行', '乃木坂工事中', 'タコパ', '部内', '肝臓', '班分け', 'アダルトグッズ', '三原', 'ブラックバイト', '失恋', 'ユーチューバー', 'ぽちぽち', '際限', '哲学的', '空回り', '逃げ', '追い抜く', '身体的', '活動限界', 'カッター', '体動', '通話記録', 'ぼろ儲け', 'クロちゃん', '愛媛県', 'ノーヘル', 'レコ大', 'スパイダーマン', 'ホライゾンゼロドーンオモロイ', '新記録', '刻み', '有効活用', 'ぼろい', '過言', '取り消し', '取り消す', '痕跡', 'ホライズン', '(´▽`)', '450', 'ヤサイ', 'アブラカラメオニオンマシ', 'ロット', '大学生協', '写真集', '恥じらう', '毀損', '帰納法', '自明', '≧', '足首', 'バリゴリゴリ', '上村ひな', 'バリテンション', '部活動', 'クリ', 'メリケンパーク', '操虫棍', 'マーボー', '卵綴じ', 'ローテーション', '蛋白質', '食生活', 'クオーター', '前期', 'GPA', '履', 'バイハ', '新年度', '曲調', 'どんぴしゃり', '(≧∇≦)', 'ラストソング', '感傷', '廃車', '右踵', 'ドギツイ', '坊主', 'スポーツ刈り', '六甲道', 'トニー', '影山', '武元', '半クラ', 'ばおわ', '賄い', '上位者', '演習', '殺傷事件', '河田', '勇敢', '掛橋', '沙耶香', 'トマレタ', '脱輪', 'エンスト', '3.4', '柿崎', 'むつ', 'デトロイト', 'おくる', 'レタス', '黒板', '選抜発表', '世代交代', 'アンチコメ', '井口', 'コチュジャンダレ', '板書', 'クリーナークソ', '耳障り', 'ニブモネア', '見本', '山掛け', 'バッドエンド', '倍増', '紛失', 'サトミツ', '祈願', 'あはは', '(⌒▽⌒)', 'えへ', 'へへへへ', '(*´∀`*)', '戦士', 'ぐさ', '夜な夜な', 'dasada', '肉鍋', '飽和', 'ごわごわ', '備え付ける', '福神', 'フォーメーション', '尤も', '物干し', '再認識', '左肩', '六甲', '☆*:.｡. o(≧▽≦)o .｡.:*☆', 'かげ', '辞め時', '美声', '数多く', 'きもおた', '増幅', '拡声', 'やまびこ', 'まりな', 'ソロダンスパート', '一遍', '片目', 'スキャンダ', 'ぴくぴく', '負傷', 'セルバ', 'アマゾン盆地', 'おもて', 'WALKING DEAD', 'パターキー', '振れ幅', '研修生', 'フルボッコ', '同感', '映す', '絢音', '卒する', 'あすか', 'ガチオタ', '高山', '1000000000006', '商品化', 'ななみ', '初々しい', 'まゆ', '徐に', '無邪気', 'かき', '雄', '日村', 'ガチサイコ', 'ちゅん', 'どう森', 'ツーショットトーク', '立ち回り', 'フワフワオーラ', 'マツミン', 'お菓子の家', 'パニクる', 'see', 'ガチライブ', '番組内', '団結力', 'しの', 'みなみ', '草々', '大量発生', 'デス・ゲーム', 'キリト', '三密', '科学的', 'バスケ部', '低酸', 'ちんぷんかんぷん', 'へばる', '見極め', '卒検', '叩き飛ばす', '死骸', 'アラゴグ', '現す', '浜辺美波', 'DNA', '採取', '阿部', 'さる', '巻き戻す', 'イメチェン', '天パー', '反抗期', 'ルックス', 'アニメ映画', '完成度', '全編', '逃走', '大根の皮', 'むける', '松田', '教員', 'ネタビデオ', '座布団', 'ぶん殴る', 'ぶま', '集', '酢', 'エロイザ', 'ななー', 'ロールケーキ', 'アルファベット', '癒し系', 'モスラ', 'ラーッシュ', '総受け', 'アイシング', 'イケ', 'dwww', '高一', '黄', '((((;゜Д゜)))', '空耳', '耐久', 'インター', 'フューチャー', 'バスコミック', 'レイアース', 'クレフー', '佐々木望', 'アスコット', 'パシ', 'レイアースタイム', '24.5', 'デガイ', 'Orz', 'カード払い', 'カールス', 'シーブリーズ', 'OPP', '待ちきれない', '呂', '死に目', '下野紘', '梶裕貴', 'ミスティ', 'コミュニティー', '(・o・)', 'アッカ', 'リーン', '代永', '救助', 'ハンガー', '地べた', 'バスケ', '注目度', '萌', '実習室', '星座', 'MOBB', '半ズボン', '屈む', '訳有り', 'アニバス', 'サボル', '図案', '延着', '大奥', 'テンペスト', '(・∀・)ノ', 'iPod', '放送局', 'よな', '合羽', 'wwwipod', '写真部', '(・∀・)', 'ペン先', '抜糸', '優柔不断', '豹柄', '徳山', '検便', '検査結果', '開', 'ウイッグ', '数調べ', '物好き', 'ウィークリーランキング', '神谷浩史', 'アリババ', '黒鬚', '早送り', 'かじ', 'きゅーん', 'モルジアナ', 'ファイ・ブレイン', '石田', '逃げられない', 'もてもて', '昆布', '非情', '潘', '下絵', '技法', 'ワープ', 'パンドラ', '採寸', '臨終', 'gf', '二度見', '(><)', '掘り下げる', '連れ出す', 'ソリティア', '写真館', '性別不明', '楔', '/(^o^)\\\\', 'リクルートスーツ', 'blcd', 'エロ', 'シリアスエロ', '続き物', '何たる', '不如意', '兄ちゃん', 'antique', '無慈悲', 'オタロード', 'リアルホモ', '餌食', 'チラミ', 'クレヨン', 'しんちゃん', 'バイバイ', '変人', 'ぼったくり', 'スマフォ', 'チャット機能', '取説', 'gg', '使用量', '負け組', 'コレッ', 'ぶなしめじ', '関わり', '廃人', 'キレッキレ', '断固', 'オベリスク', '矢部浩之', 'ぐるナイ', '三日月', 'クーデリア', 'ガンダムシリーズ', '再就職先', '2016', 'マイペース', 'ぽ', '暖める', 'ちゃりん', '植え替え', 'KAT', 'tun', '佐藤ゆうこ', '林原', 'めぐみさん', '高山みなみ', '石田彰', '小野大輔', '女性声優', '待ち望む', 'フェルト', '織り目', 'スタミュ', '放す', 'キメラ＝アント', 'HUNTER', '上映会', '盛り合わせ', '図書館戦争', '商業誌', 'ナルシシスト', '書き送る', '新撰組', '真撰組', '喜八郎', '菊', '菊比古', 'サイクリングリカ', 'oh', 'no', 'キャミ', '(*´-`)', 'ベレー帽', '義理チョコ', '病人', 'クローバー', '大倉', '武井咲', 'ベッドシーン', '丸まる', '軽音', '一期', 'ポイズン', '雇用条件', '頂戴', 'ロスト', 'シップ', 'チェーサー', 'ベーカー', '亡霊', '送り届ける', '入社時', '関の山', '再検査', '小道具', '歩き疲れる', '(*^▽^)/★*☆♪', '裁断', '暗殺教室', '肩幅', 'ごつい', '未読', '気取り', '安否', '長続き', '受理', 'サービス残業', '疲労感', '勤まる', '敵う', 'ダルイ', '代休', '後輩ちゃん', '丁重', '一番乗り', '超過分', '゜ロ゜', 'シノヤマー', '(^o^)/', 'ドラマCD', '自己満足', 'アゾン', 'ライリ', '柚葉', '撮影会', '(-_-)zzz', 'さなちゃん', '前任', '無駄話', '浴衣姿', '色っぽい', 'やっ', 'ねんどろいど', '写メ', '管', '引き連れる', '改札口', '踏み止まる', '岨', '添わる', '思い止まる', '大量生産', '二人目', 'カメラマン', '頭蓋', '短距離走', '本職', '契約日', 'ポシェット', '出張中', 'リンドン', '整列', '払い除ける', 'ぷんすか', '魔物', '炬', '燵', '流し台', '充', '図', 'ヒステリック', '舞い戻る', '始業', '学校法人', 'めりはり', 'アストン', 'タカキ', '土足', '踏み場', '現像', 'メンズ', 'ナマステ', '被り', '滞り', '緩まる', '別れ際', 'あきひろ', 'みか', 'じする', '風圧', '|(-_-)|', 'リクナビ', '鉄血', '♪ヽ(´▽`)/', 'ネクタイ', '仕事場', '受信', '鈴倉', '情報流出', '電話番号', '品名', 'カモフラージュ', 'ダブルベッド', '購入履歴', 'ごった煮', '腰掛ける', '窮屈', 'オビツッキー', 'ドキがムネムネ', '備品', '廃番', '冷や汗', 'ざわ…', '穏便', '波風', '(´;д;`)', 'ちくる', '新米', 'いも', '激近', '激かわ', 'ボーイズラブ', '近藤', '名札', '問診票', 'ドルドル', '根元', '要望', 'ボブ', 'ボブヘア', '拭き', 'メドゥーサ', '金欠', '資金不足', '印刷機', '退社時間', 'スメル', '根源', 'オーガンディー', '端切れ', '上機嫌', '擬き', '縫い目', 'ハイステ', '近藤さん', '研磨', 'ベビースターラーメン', 'スメルテロ', '責務', '爆発しろ', 'バレ', '滋賀', '鍾乳洞', '入力ミス', '平謝り', 'どや', '海鮮丼', '持参', '(ｰ ｰ;)', '居眠り', '落下', '保護フィルム', '小人さん', '伝え方', 'ストール', 'ペアウェア', '借りパク', '貴女', '見落とす', 'ホルモン', '勝ち目', '継承', '喪中', '(´Д` )', '鳥羽水族館', 'マスカレード・ホテル', 'コスモタワー', '小坂', 'ジェラパケ', 'ジェラピケ', '発疹', '併発', '徳川家', '代々', '果てし', '服多', '体操服', '断髪', '終業時間', '死活問題', 'サスケ', '0.7', '0.4', '前年度', '腹囲', 'ジッパー', '揉みくちゃ', '白石', 'バイブル', 'くま吉', 'ばった', '殺生', 'レター', 'マクドゥ', '頻尿', '尿', '自己管理', 'カジュアル', 'ニット', '靴箱', '洗い方', '座', '膝掛け', 'ぽっこり', '大罪', '保険証', '痛め付ける', '触り心地', 'まだら', '剥ける', 'ミミミミミミ', 'ローラー', '掻き壊し', '掻き壊す', '伝染', 'バンソコ', 'ナイン', '宅飲み', '滴る', 'ナンジャ', '猫耳', 'ほわ', 'WITH YOU', '哀歌', '天罰', 'ねんね', 'ルビー', '卵かけご飯', '刻み海苔', '胡麻油', '瀕死', '右から左', 'メルタン', 'メタモン', 'きい', '小宮', 'ヘアオイル', '塩焼き', '豆腐ハンバーグ', '森永', 'フレーク', '買い占める', 'ブレスケア', '粒', '召す', '坦々', 'さんま', 'コンディショナー', 'リッチ', 'バーサス', 'ほくほく', 'かりかり', '取り付ける', '第六感', 'バーサーカーランスロット', '闊歩', '環壮', 'プレミアムロールケーキ', '乗り気', '秋葉原駅', '運動量', 'ペッパーバターライス', 'トモ', '羚羊', '微々', '豚肋', '満員', 'カンジダ', '折', 'ネコトモ', '画像編集', 'げほげほ', '口元', '雪見だいふく', 'たた', 'ぷっ', 'ぷう', '凹み', '突き落とす', '薄手', 'トレンチコート', '笑い合う', '反り', '女性陣', '長歌', '語り合う', '入浴', '入浴剤', '確約', '夜景', '星の見える丘', '畏まる', 'フラッシュモブ', '私情', '交える', 'ズーン', 'えぐえぐ', 'もくもく', 'ぎゅるぎゅる', 'ごっちゃ', '35.5', 'がつ', 'ぐずぐず', '変哲', 'タップ', 'ィェーィ', 'あいこ', 'もこもこ', 'ビクーッ', 'イヤリング', '790', '珪藻', 'レディースDAY', '求人広告', '270000', 'コンビニ弁当', '断然', 'フィットネスアプリ', 'サングリア', '同量', '端子', '年末進行', '330', '揚州商人', '不公平', 'ゴマ', '区役所', '南口', '坂登', '西口', '近', '戸籍', '色落ち', 'ヤダー', '通り口', 'すっからかん', 'まどか', 'イェー', 'xs', 'ギャン泣き', '寝正月', '激烈', 'なんじゃこりゃー', '水洗', '逆様', '乱闘', '費用対効果', 'ヘアアレンジ', '総集編', '交配', '生まれ落ちる', 'ピッピ', 'いなさ', '秋頃', '出動', '厚塗り', '陶器', 'ツムツム', 'たまちゃん', '大泣き', '旗振り', '役目', 'ゼルダの伝説', '滅ぼす', 'みんなみんな', 'とり', '怪訝', 'どうでしょう', '晴れ姿', '同盟', 'ワンオク', 'げんなり', '女子会', '支社', '運び屋', '抗がん剤治療', 'クヌルプ', '聖地巡礼', 'ミシシッピ', 'マッド', '物量', '突っ撥ねる', 'おえー', 'イヤァー', 'amazonkindle', 'paperwrite', '家政婦', '利害', '権限', '施術', 'コンクリ', '突き出る', '蒲公英', '垣間見る', '歌い手', 'うわー', '剃る', '駆け寄る', 'きなこもち', 'どんぶり', 'チワワ', '生温か', 'ジャムム', 'itunesstore', 'ドトール', 'クレカ支払い', 'ナウノ', '立方メートル', 'ざり', 'Janne Da Arc', '悪気', '可笑しな', '論法', '大人のマナー', '薫製', 'ピャー', '育休明け', '席替え', '追い遣る', 'おかえりなさい', '只飯', '弛み', '積み込み', '荷解き', '拵える', 'ひゃっほう', '開通', '組み立て', 'ヒャッホーイ', 'ノーパ', 'フッフー', '目玉焼き', 'テーレッテレー', 'ヒック', 'ヴッッ', '給食当番', 'ささくれ', '腿肉', '世間体', '蒼井優', '山里', 'どっきり', '首振り', '仕事好き', 'ヒャッハー', '本読み', '自動的', '木陰', '新潟地震', '柏崎', 'サボり', '今家', 'ベスプリ', 'レバ韮', '冷製', 'タカトシ', 'プラシーボ効果', 'プラシーボ', '辟易', '独り身', '山寺宏一', 'シンバ', '通りすがり', '下腹部', 'ガルパンアニメ', '生徒会長', 'カチューシャ', 'スロット', 'アンツィオ', 'ペパロニ', 'アンチョビー', '下拵え', '出社時間', 'リズム天国', 'リズム感', 'ボリューミー', '台本', 'イヌ', '岸', '風俗', '墓場', 'ナンセンス', 'シノアリス', 'いばら姫', 'プライムデー', '生活用品', '纏め買い', 'Smart Watch', '誤操作', '飲', '鳥頭', 'アイズ', 'としま', '首回り', 'スパイシー', '糖質制限', '里帰り', '再訪', '噛み合う', 'プリコネ', 'コッコロ', 'ナビ', '従順', 'ペコリーヌ', '食いしん坊', 'バトイ', 'タイプミス', '間違え', 'どす', '泣き顔', 'ぱりぱり', 'ニャンちゅう', '難病', '旧居', 'テニ', 'トロパズル', 'キャンディクラッシュ', 'ソーダ', '34.5', 'コーヒー牛乳', '跨がる', '若菜', '幸せいっぱい', '見下す', '履き違える', '残り物', 'hahaha', 'ノスタルジア', '濡れ衣', 'ソフトドリンク', '食事制限', '胸元', '遠くまで', 'べちゃ', 'いい夫婦の日', '結婚報告', '舌下免疫療法', 'シダキュア', 'アナフィラキシーショック', 'すくう', '重曹', '出迎える', '結弦', '物貰い', '満点', 'ドアノブ', 'ヒッッ', 'のろのろ', '死に掛ける', 'ドルツ', 'ギヤ', '初体験', 'つるっつる', 'にま', '低糖質', 'ロカボ', '食物繊維', 'ぺこ', '静電気', '纏わり付く', 'ヒーター', '惚気', 'アクシーズ', '彼岸島', '杭', '雑煮', '存分', '陰口', 'そんなもんだろう', 'ひそひそ', '午後休', '腕枕', 'カワイイイイ', '置き傘', '軍資金', 'アビス', '牛タン', '夏のボーナス', 'ほわほわ', '東日本大震災', '満つ', '離れ離れ', '覆い被さる', '止す', 'ヒィヤー', 'ファインプレー', '安らか', 'ナーバス', '出社時刻', '心意気', '引き継ぐ', '叱り', 'マーブル', '断食', 'ダイエットモチベ', '諸君', 'シッシッ', '上層部', '直属', '降り頻る', '守りたいもの', '真央', '胸きゅん', 'サーティワンダブル', 'カスタード', 'ドラちゃん', '病み', 'くも膜下出血', '蝕む', '再就職', 'ベーコンポテトパイ', '大喜び', 'グッジョブ', '外車', 'レジャー', '0.2', 'キログラム', '決め顔', '玉蜀黍', 'てまえ', 'くちゃ', 'オブザイヤー', '寝返り', 'ぎっ', '仕事内容', 'ルフィ', '短所', '大台', 'ノーメイク', '散らす', 'マシマシ', '薄力粉', '擦り合わせ', '羽織る', 'オムレツ', '遅める', 'とう', 'のびる', '茶会', '食べ頃', 'サザン', '人魚', '脳死', '治まる', 'ごわ', 'Zumba', 'ズンバ', '分かち', 'コージーコーナー', '余所行き', 'りくろー', '見聞き', '嗅覚', 'ギイイ', 'たげる', '寂しい日々', '実用化', 'ワクワクデー', 'スーサイドガール', '魔法少女', '一味', '赤の他人', '別居', '同性カップル', '岡崎律子', '37.5', 'ビリギャル', '有村架純', 'カワ', '周期的', '子供目線', '度無し', '行き倒れる', '火照り', 'マットレス', '臨時', '感染対策', '鍼', '罪滅ぼし', '愛犬', '見受ける', 'ヒップ', '激旨', 'ぶるぶる', '蒙古タンメン', '人形町', 'ラー油', '角煮', '血栓症', 'ポップアップ', 'ゴーヤチャンプルー', 'サーティワン', 'ジタ', '夏の風物詩', '腑甲斐無い', 'ヒプノシス', 'DAPUMP', '山田一郎', 'ジャイアン', '木村昴', 'イタリアンプリンアイスバー', 'ねっとり', '極み', '元気いっぱい', 'ペパマリ', 'ハッシュポテト', '月頭', '祝い事', '停滞', '時間厳守', '銀歯', '蕩ける', 'プリンー', '葱とろ', '縁側', 'うるうる', '内巻き', 'デジタル化', '身分証明書', '御年寄', '返納', '手羽元', 'フルーツバスケット', '努力家', 'かわいくなりたい', 'スロ', '入り乱れる', '新天地', 'booth', 'ブースト', '不良債権', 'ストレスフリー', 'ディナー', 'コープス', 'フリーズ', 'bcaa', 'きつめ', 'コツコツ', '足立', '区議', '一念', '発起', '神さまの言うとおり', 'シヌカーテン', 'ぐれる', 'オナカイタイ', '補講', '被らす', 'フルコマ', '八十八', '駐車スペース', '通路', 'ケースパカパカ', 'ベボベ', '湯浅', 'うひゃ', 'オカモトズ', 'ズットズレテルズ', '果汁', 'SOL', 'やましげ', '素性', '明かす', '芸名', 'ビッグサイト', 'しげさん', 'ライオット', '小六', 'タイブレーク', 'バッター', '帰宅難民', '早見あかり', '元メンバー', 'ラウワン', '225', 'wwwwwwwwwwwwwwww', 'ラッキーボーイ', 'wwwwwwwwwwwwwwwwwwwwwwwww', 'ぐわあ', '860', '腹一杯', '人酔い', '整髪料', 'ネチャクチャ', 'わっしょい', 'itis', 'わんど', '陸上競技部', '砂嵐', 'モンスト', 'ナッゲツ', '県立', '八戸', '有島', 'とみ', 'ボイメン', 'マサキ', '加薬', '絡み合う', 'みき', 'るう', 'youtubertv', '替え', 'サマナーズウォー', 'クラブチーム', '紅白試合', 'ぐいー', '嗚咽', 'ゴールデン', 'イケメ', 'インサイド・ヘッド', '番組表', '稲メン', '注意報', '変わり目', '日車', '時刻表', '大勝軒', 'ぴんぽーん', '杉丸', '青森市', 'ねぶた', '敷田', '球審', 'ファウルチップ', '(・д・)', 'あべこうじ', 'グラターニ', '比べ物', 'きなこ棒', 'チンパンジー', 'ゲロフラグ', 'FUJIFABRIC', '電光石火', '引き止める', '154000', '浜名湖', '仕事着', '買い揃える', 'ローファー', '貸し出す', '作務衣', '強羅', 'フルグラ', '逆上せる', '現実味', '中長期的', 'ネッ友', '高三', '表出', '呼び込む', '電子マネー', 'WAON', 'ヒューマ', 'バイトくん', '出退勤', '挙げ句の果て', 'へらへら', '暖かさ', '人件費', '生活雑貨', '備わる', '目的地', '乗り継ぐ', 'がたん', 'ごとん', '捥ぐ', '覗き見', '韻', 'にゃあにゃあ', '出戻り', 'ライフプラン', '著名人', '修善寺', '訛る', '襤褸', '独り立ち', 'カクテル', 'ユニットバス', '作動', '水滴', '抜け出る', '結露', '富士サファリパーク', '宿代', 'しゅしゅ', '目星', '配膳', '性格的', '娯楽施設', '事務系', '伊豆', 'ヒキコモリロリン', 'ペイペイ', 'ミニプ', '練乳', 'ベアード', 'ベアードブルワリーガーデン', '近め', '牧場', 'ジェラート', 'シャンディガフ', 'ベビーチーズ', '母国語', '短期留学', '諸費', '見間違い', '明細', '生山葵', 'WASABI', '給食センター', 'じゃが', 'ビー', '紀州', '梅味', '寛大', '旺盛', '取り払う', '安め', '中途', '77', '言い触らす', '元年', '横浜中華街', 'イカチリ', 'ぴり辛', 'ランチタイム', 'ダイナブック', '自家用車', '考え込む', '酒類', '浄蓮の滝', '受け入れ', '単純作業', '実体験', '店主', '話し込む', '貫禄', '素っ飛ばす', '急停車', '最後の夜', '巡り会う', '退寮', '甘夏', 'ニューサマーオレンジ', '電機', '秋田県', '秋田', 'NZ', 'アウェー', '消灯', '素朴', 'ヘルパー', '出勤時間', '転々', 'ゴタ', 'ギリギリピーポー', 'フリースペース', '社保', '壁側', 'にょろ', 'ちゃりんこ', '三ノ宮駅', '淡路島', '発着', '男友達', 'wgw', '追い打ち', '滅び', 'メルペイ', '託ける', '聞き流す', '積み重なる', 'アクター', '水系', 'アナザー', 'ヒート', 'メタル', '充満', '濁る', '飛び散る', '獅子王', 'リズムネタ', '電王', 'ガイム', '高岩', '平成ライダー', '新東', '候補生', 'ニュイ', 'ヤミー', 'ガメルヤミー', 'ツクヨミ', 'メンタルゲロ', '黴臭い', '共同', 'ロビー', '番頭', '入れ替え', '断面', 'けじめ', '裏切り', 'スパン', '筋合い', 'ぐわ', 'しゃがむ', '短め', '念押し', '飛び回る', 'ぼそぼそ', '的外れ', '生理的', '損得', '北側', '爪痕', '体験談', '愚図る', '拭う', 'USJ', 'ハーバー', 'アメニティー', '凝り', '道頓堀', '食べ歩き', '恐怖感', '連チャン', '名古屋駅', '有限', '限度', '無法地帯', '粉もん', 'ビビンバ', 'スラックス', '男性向け', '脱衣所', '吹き抜け', 'ひょこ', '後付け', '剥き出し', 'ゲームセンター', '水溜まり', 'バス会社', '移動距離', '菊花', '丸十', '雪が降る', '降り積もる', '本州', '最北端', '無償', 'ショッパー', 'ンョ゛ハー', '゛っていう', '絶やす', 'ペーペー', '遣り場', 'ぺろん', '基盤', '家族って', '一般論', '守り', 'きれいごと', '歯ブラシ', '取り替える', '給与明細', '率直', '振り分ける', 'にょろにょろ', 'つ折り', '最小限', '布製', '銭入れ', '軽量化', '対人', 'TPO', 'すーい', 'ローストビーフドンッ', 'ぴょい', '最低価格', '視力低下', '0.1', '求人募集', '肩出し', 'キャタイプ', 'ダイビング', '1150', '950', '小まめ', 'グッドマン', 'ビーグッド', 'フェローズ', 'TEL', '着任日', '残席', '仮予約', '柔軟', '仕事面', 'Qoo', 'シャインマスカット', '生理日', '温泉街', 'クロックス', '襖', '赴任日', '人目', '猫飯', '給料計算', '南下', '他社さん', '6400', '1400', '消防車', 'グレードアップ', '伝達', '残り香', '功', '奏する', '各地', '人頼み', '暴風', '風通し', '障', 'ため', '見掛け', '仲居', '東京都民', '方民', 'シェアハウス', '35000', 'おさめる', '勤務日数', 'ハイボール', 'クラフトビール', '呂律', 'リポ', '罅割れる', '泉質', '励まし', '厳しさ', '対応力', 'ぎちぎち', '濃ゆい', '飲食物', '酎', 'ルーレット', 'フラー', 'レッツ', '菌', '出向く', '一線', 'ぱたぱた', 'ぽーん', '建物内', '無断転載', '一会', 'インキャ', 'クラス会', 'アフィカス', '油汚れ', '未踏', 'NGT', '貶す', '持ち上げる', '背伸び', 'ガタンゴトン', 'ウィンブレ', '執筆', '飲食代', '退ける', 'あずきな', 'チョコレートラテ', 'ソフドリ', 'サワー', '掻き消す', '完備', '新型肺炎', '移動費', 'ネット関係', '駅中', 'ガムテープ', '滞在時間', '潜伏', 'グルチャ', '同性', 'ラウン', 'GET', '優先事項', 'バスキャンセル', 'バスタオル', '対価', '単発バイト', '洗い場', '手荒れ', '肘下', 'スポンジ', '荒れ', 'ばっくれる', '切磋琢磨', '紛らわす', '芽', 'ロンティー', '送り返す', '定まる', '避難場所', '食い', 'ミニクロワッサン', 'バターパン', '赤色', 'ぽわー', '小中高', '優等生', '名義', '粗品', '面的', '思い上がる', '根っ子', 'きっぱり', '極論', 'ノー', 'アイブロー', 'タッチペン', '様子見', 'ぐは', 'オモイ', '3037.5', '急速', '測定', '37.8', '37.6', '37.7', 'むずむず脚症候群', '意図的', '貧乏ゆすり', '優先的', '補助費', '呼び掛ける', '保菌者', 'オシゴト', '昆虫食', '近辺', '運休', '賢明', '手伝わす', '培う', '無休', '極め付け', '社交的', 'クソガキ', '一喜一憂', '字面', '痴話喧嘩', '勃発', '薄め', '隠し', 'ワンパターン', '記載内容', '記載ミス', '着払い', 'ちゃら', 'ばち', '非表示', '塗り薬', '飲み薬', '食い物', '振り出し', 'スフレ', 'CO', 'ya', 'ショートヘア', 'マーク', 'かる', '同化', '絶叫マシン', 'ヘアケア', '注ぎ込む', '高価', '大々', '足腰', 'シヌ', 'hiromasu', '女子寮', '大浴場', '洗面', 'トースター', '正方形', 'リゾバスタート', 'アピタ', '伊勢神宮', '衛生的', '瞑る', '清野菜名', '太っ腹', '草刈り', '外気', '気長', '北東北', '期限内', '落ち度', '合格率', 'こーん', '延長線', 'ウユニ塩湖', '道中', '襤褸糞', '走り回る', 'ヒートアップ', '寄せ書き', '油性ペン', '稲庭うどん', 'アベノマ', 'ズオズオムー', '抱き枕', 'トリートメント', '無造作', 'ぼっ', 'シュワ', '赤味噌', '八丁味噌', '世界遺産登録', 'イタリアチ', 'チュウゴク', 'トライアル', '応募者', '取引先', '超マイペース', '絨毯', 'ワロチ', '短髪', '南無', 'Tinder', '標準体重', '痩せ形', 'アカウント名', '三重県', 'マルチ商法', 'じめ', 'どよーん', '忍耐力', '指標', '移動時間', '赴任', '最安値', 'PR', '自然災害', '無力', '自然学校', '自宅警備員', '全う', 'RION', 'ナイーブ', 'カスタム', 'マイナス思考', '行動派', '人恋しい', '活発', '裏話', 'リピーター', '出会い系', 'MRS', '髭男', 'rad', 'ELLE', 'ROM', 'テンションブチ', 'ブタメン', 'wacci', '点描', '日用品', 'ママン', 'うねうね', '山道', '逃げ場', '責め立てる', '介護', '生温い', 'ぎすぎす', '未知数', '心配性', '精神状態', '交通経路', '掛け合う', 'たられば', 'ごろ', '果肉', '取り掛かる', 'ハラヘッタ', 'マイボール', '気付き', 'ケトル', '肥やし', '引っ掛かり', '蛸足', 'マイ箸', '三銃士', 'デミグラスソース', '薯蕷', '卵黄', 'ごちゃ混ぜ', 'はは', '自己採点', '分厚い', '寮費', '光熱費', '傾向と対策', '貢ぎ', 'わた', 'ガチクソニート', '390', 'ラフ', 'もえ', 'リゾバイター', 'モチベチーノ', 'ze', '有言実行', '秘密のケンミンSHOW', '味噌カツ', 'ネル', '標準語', 'フルーツジュース', 'カフェインゼロ', 'ルイボスティー', '午後ティー', 'ガムシロップ', '甘党', 'きつきつ', 'グアバ', '南国', '調', '作業用BGM', 'jpop', 'ネルー', 'シャトルラン', 'テストガチ', '94', 'ハンドボール', '校内', 'スケボー', 'ずっこける', 'ベッドメーク', '囁く', 'ずれ込む', 'DV', '檄', '喫煙所', '撒き散らす', '盆期', '盛り下げる', '(¬_¬)', '垣間見える', '返送', '詰み', '次いで', 'ネミー', '完徹', '不快感', 'ウォシュレット', 'メキシコ', '南米大陸', '国名', 'ベリーズ', 'アンティグア・バーブーダ', 'ファジル', 'ゲビ', 'ゴンダール', 'ファジルゲビ', '壁画', '高齢', 'BAD NEWS', 'フライング', 'メンブレ', '柴犬', '柴', 'イッヌツイ', 'ずいと', '74', '採', 'ゼロ状態', 'テレビドラマ', '物出', '飛び込み営業', '竹内結子', '死去', '通り雨', 'カシス', '売り払う', 'ファッションセンスゴミ', '名古屋メシ', '締め切り日', '作業時間', '飴ちゃん', 'ガム', '消費量', '現在進行形', '洋装', '仕事用', '南側', '∞', '負わす', '去り行く', '喉元', '横目', '札本', 'スリップ', '揺れ動く', '衰え', '努める', '身の丈', '兜', '初節句', '家族旅行', '買い食い', 'がつん', 'Hot Pepper', 'ビューティー', 'トレードオフ', '夢物語', '欠落', 'カントリーマアム', '根絶やし', '労働時間', '打ち間違い', '血圧計', '低血圧', 'サラダチキン', '牛蛙', 'ジョブホッパー', '通算', '育休', '物強請り', '離職', '裕福', '軽重', '厨房', 'マーブルチョコ', 'にゃんこ大戦争', '実働', '五月病', 'ターミナル駅', '職務', '夏物', '焦げ臭い', 'ナノケア', '飛び下りる', '無下', 'ピザポテトパーティ', '婿', '普段着', 'ワンマイルウェア', '値札', '藻屑', '他責', '白い巨塔', '小一時間', '就任', '炎天下', '有り様', 'トップス', '老ける', '離散', '汗疹', '内勤', '折り合い', '幸福感', '平均賃金', 'しなやか', '強か', '完遂', '温まる', '余談', '柳葉', '敏郎', '岸本加世子', '踏み入れる', '主軸', 'バックグラウンド', '上履き', '同行', '身銭', '養育費', '社会的責任', '諸用', '保育園児', '駱駝', '砂漠', 'ミルクティ', '平和主義', '敵意', '細心', 'カプレーゼ', 'エジソン', '博物館', '営む', '数式', 'セロトニン', '胃腸薬', '暴飲暴食', '複数個', '土色', 'チームメンバー', '取り除く', '白バイ', '荷', '集め', '流派', '天使みたい', '最上', 'カーペンターズ', '混線', '処理速度', '長持ち', '給湯器', '敷地内', '嘸', '現職', 'ざる', 'リタイア', '話し合う', '蓄財', '溶け込む', '引き算', 'ぱこ', '俯瞰', '飛び火', '一夏', '不行き届き', 'ツバキ科', '植物', '椿', '限り無い', '対等', '引き渡す', '古賀', '率先', '月火', '一学期', '通い', '図工', '集金', '繁雑', '早帰り', '怠け', '紆余曲折', '思い入れ', '介護問題', 'トピックス', '幼稚園児', '情熱的', '改まる', '悪酔い', '乗り物酔い', '気品', 'ビジホ', '高層', '特権', '雀斑', '美容皮膚科', '巻き返す', '掻き乱す', '頻り', '顔負け', '淀む', '途中駅', 'コントロールカラー', 'ファンデーション', 'アイシャドウ', 'ブースター', '保冷剤', 'ワサオーロ', 'アドバンデージ', '消え失せる', '用件', '独身男性', '苦慮', 'テレビ番組', '万国', 'ちびまる', 'ねこねこ', '幻想曲', '天ない', 'クッキングパパ', '余暇', '10862678', '生卵', '一進', '一退', '投票券', '免許証', '登龍門', '対象年', '時短勤務', '通常業務', '社外研修', 'ふつふつ', '承諾', 'ワーク', '異動', '恩返し', 'ヒアリング', '半径', 'どなり声', '急かす', '肉屋', '研鑽', '栄養ドリンク', '一抹', '纏わる', 'エトセトラ', '放心', 'パスコ', 'スライス', '果て', '安堵', 'ハーネス', '献立', '八百屋', '明き', 'テンションアゲアゲ', '僭越', '有休数', '醸成', '照り返し', '致死', '今夏', '幾分', '泰山', '朝顔', '蝙蝠', '昆虫', '余生', '当たり散らす', '有給数', '申請方法', '電子申請', '上長', '口頭', '伺い', 'くもん', '算盤', '保守的', '口達者', '織り込む', '親業', '放置子', '未就学児', 'じゃらん', '少数', '水の事故', 'ライジャケ', '毛量', 'ア', 'バイオリズム', '結婚指輪', '無趣味', '多趣味', '家族構成', '親類', 'ハードモード', 'スマッシュブラザーズ', 'バッカ', '翌朝', '仕出し屋', '社内報', '独身女性', '掲載', '職務経歴書', 'ヒアリングシート', '空前', 'いろはにほへと', '働き掛け', 'ばた', '産後', '仕付け', '時代錯誤', '甚だしい', '問題解決', '世代間', '大前提', 'ミニトマト', '丹念', '会心', '爪楊枝', '紙皿', 'トレー', '歩む', '起き抜け', '任意', '授業参観', '夏草', '思い込み', '不定愁訴', 'クロレラ', '健康食品', 'バイオリン', '芸術的', 'バテ', '秀でる', '凸凹', 'ケアレスミス', '最良', 'エージェント', 'キィーッ', '要検討', '自主的', '強弱', '泣かせ', 'ハノン', '機械的', '情操教育', '配偶者', '日用雑貨', '底値', '計画的', '活字中毒', '読破', '電話帳', '広報誌', '郵便物', '医学', '片田舎', '町会', '前籠', 'トーマス', '生中', 'カルボナーラ', '付帯', '決断力', 'オーバーヒート', 'カルシウム', '覿面', '月見バーガー', 'カットソー', 'お月見', '因む', '跳ね', '青白い', '無臭', '種蒔き', '当たり障り', '無人島', '人間界', '何しろ', 'バスツアー', '好転', '家計', 'Mario Kart Wii', '狂喜乱舞', 'つゆ', '縄文時代', '最高齢', '買い溜める', '在庫処分', 'スカルプ', 'ボーテ', '光年', '錚々', '悔い', '子供服', '打ち消す', 'ジェンダー', '使途', '抱っこ紐', '仕事柄', '御高齢', 'やんわり', '諭す', '小娘', '若い世代', '骨無し', '切り身', 'レアチーズタルト', '巣窟', 'カップヌードル', 'グリーンカレー', '認定試験', '値上げ', '小売り', '札総', '取り替え', '豪語', '浮腫む', '弁当箱', '無数', 'すっぽかす', '簡素化', 'ショルダー', 'レザー', '始末書', 'ルームランプ', '110000', '脆弱', '頭が回らない', '寝込み', '万一', '見初める', '軽やか', 'ワイドショー', '持ち越し', '掻き分ける', '糞真面目', '紛れ', 'さらう', '前撮り', '晴れ女', 'ゲリラ豪雨', '煮え繰る', 'ボッサボサ', '引き詰める', '華やか', '通勤用', 'よれよれ', '七五三', '調剤', '賑わう', 'サトウ', '植木鉢', '最小', '排水口', '安全確保', 'プロスタグランジン', '駆逐', '資格者', '成分表示', '見比べる', 'ぼさぼさ', '治水', '痛く', 'エゴイズム', '健康寿命', '町内会', '老人会', '町内', '宴会', 'カウンセラー', '持続可能', '御飯粒', '目覚ましい', '円やか', '暴食', 'オキシ', '春夏秋冬', 'UNIQLO', 'アンクル', '貧相', 'せがむ', '家庭事情', '障る', '干し', 'カレー店', 'チーズナン', '注意力', '散漫', '介助', 'エブリデイワンピ', '夢のひとつ', '固形物', '温かいご飯', 'きゅるきゅる', 'ぼした', 'ビオフェルミン', '大腸', '商業ビル', 'ヒカリエ', '柿の種', '山葵味', 'イーグルス', '感謝祭', '軽量', '音楽室', '選定理由', '持ち運び', 'フォーマル', '気迫', '蝶ネクタイ', '新郎', '渾身', '商業施設', 'パレード', 'COINS', '(苦笑)', '先般', '小細工', '行い', '輪廻', '爆弾', '貧乏性', '戦略的', '立ち話', '漏れ聞こえる', '謝恩会', '幹事', '年中組', 'さささ', '足早', '立ち去る', '薄化粧', '産前', '茶髪', '程遠い', 'きょとん', '性差', '植え付ける', '小刻み', '漲る', '気落ち', '見返り', '肋骨骨折', '不義理', 'パジャマのまま', 'クロスステッチ', '休息', '無償化', '給食費', '冷え', '48000', 'クイズ番組', '磯野', '愛読書', '殺気', '大らか', '19800', 'サイクル', 'マシン', '麦門冬', '物色', '漢方', 'はねる', '斜', '寿退社', '若気の至り', '高学年', '四国地方', '狭小', '地権者', '合同会社', '香ばしい', '読み漁る', '昇級', '生年月日', '技能', '平ら', '容易', '虫歯菌', '食べ掛け', '潔癖', '共働き', '軈て', '祟り', '過労死', '断腸の思い', '落とし所', '凌ぐ', '控除金額', 'amazoneco', '中二', '堅気', 'たき', 'ジャー', 'あたたまる', '温め', '猫舌', 'ニュートンの林檎', '歯科矯正', '続報', 'リテーナー', '歯科医', '元来', '検診', '心成し', 'ポリデント', '洗浄', '見回る', '昔ながらの', 'こどもちゃれんじ', '封', '手前味噌', '一通り', 'そつ', '称賛', '滞る', '子年', '長女', 'おちおち', '授乳期', 'ボージョレ', '息む', 'カセットテープ', '擦り切れる', 'ラジカセ', '半音', '硬質', '書き初め', 'マジックペン', 'ネット予約', '最先端', '軽快', '数段', '付け直す', '赤玉', 'ヒント', 'iz', '買い物客', '悪ふざけ', '力負け', 'とほほ', '待ち遠しい', 'こってり', '咳止め', '呼吸器', '内科', '臓器', '手際', '家庭的', 'リアルゴールドキメ', '服飾', 'メゾンカイザー', 'クロワッサン', '老眼', 'ステーショナリー', '称える', 'びり争い', '況んや', '登', '澱み', '式典', 'スケジュール管理', '提出物', '申請書類', '仰ぐ', '芋掘り', '産婦人科', '妊婦健診', 'ベロベロバー', 'メロメロ', '医する', '見窄らしい', 'プロフィールビデオ', '豹変', '新郎新婦', '折衝', 'ツーショット', '乱発', 'おっとり', '自主', '勉', '就学', '身支度', '預かる', '難儀', '皮籠', '塩茹で', '流行遅れ', '複数回', '充足感', '食い込む', '卒', '夏頃', 'ガクブル', '大都会', 'ランドマーク', 'シャネル', 'フェラガモ', 'フードコート', '⁇', '遂行', 'リスタート', 'モラトリアム', '鬩ぎ合い', '成就', 'ちくちく', '看護休暇', '法定', '要件', '疾病', '絶対数', '美魔女', '兄姉', '山程', 'しどろもどろ', '駅名', 'ホワット', '運動系', '濃密', '優劣', '強固', '髄', '重荷', '乳汁', 'リングルアイビー', '安価', '酸化マグネシウム', '便秘薬', '四則', 'ミドルエイジ', 'クライシス', '粉雪', 'はらい', '厳守', '85', 'スパルタ', '公立小', '交換日記', '廃', '硬筆', '用紙', '浪人', '浮つく', 'ジェニフィック', 'LDK', 'お品', 'スパークリングワイン', '極細', 'superstar', '取り違える', '143', 'ハンカチ', '偽', 'つぶり', 'リツイ', '心構え', '厨二病', 'クリスマスツリー', '掛け算', '九九', '出題', '算出方法', '34', '68', '編み出す', 'ホワホワ', '割引券', 'ヘルシア', '緑茶', '効能', '後ろ盾', '玉石混交', '買い与える', '全文', '特訓', '耐熱容器', 'ティファール', '沸かす', '究極', 'ズボラーメン', '推奨', '多方面', '小出し', 'ぐる', '推測', 'ストレスフル', '再診', 'からあげクン', 'ピザポテト', '忘年', '汚濁', 'プリンドラ', 'ギュルギュル', '成り立ち', '多大', '一覧表', '侮る', '国民栄誉賞', '途中覚醒', '抗', '対抗', '遅出', 'ぐら', '修行僧', '麺類', '煮麺', '蚊帳の外', '自販', '鱶鰭', 'コーンスープ', 'ポテトサラダ', '鳥皮', 'にんじんしりしり', '営業日', '平たい', 'カスタマー', 'サンタプレ', '後ろ倒し', 'ぶち切れ', '申し上げる', '成り立て', '付け足す', '削ぐ', 'ほとぼり', '量的', '質的', 'お供え', 'ざく', '栄える', '高値', '居住地', '戸建て', '恩', '読み掛け', 'ラストチャンス', '生死', '小三', '土産話', '冊数', '生っ粋', '活字本', '驚愕', '五線譜', 'ペリ環状反応', '禿びる', 'まるこ', '黒電話', '育休中', '早める', '年少', '極小', '生魚', '近年', 'がら', 'ノンフライヤー', '油物', '右利き', '双方', '色素', '突き詰める', '概念的', '太り', '不摂生', 'キムチ鍋', 'チーズイーチキン', '正攻法', '滲む', '所用', '交感', '道具箱', '体操着', '風習', '届け出', '感染力', '出席停止', '類推', '投影', 'きっと大丈夫', 'フタアミン', '一夜漬け', '受験票', 'レトロ', '投げ売り', '男児', 'Florida', 'Memphis', '張り扇', 'ぎっくり', '相乗効果', '過熱', 'iherb', '人柱', '雑貨', 'ブラトップ', 'ローテ', '育毛剤', '疎ら', 'シューマイ', 'フリーズドライ', '69', '右上', '歯茎', '知覚', '赤木', '振り撒く', '熱烈', '関ジャニ∞', '判別', '属する', '背丈', 'ぶら下げる', '画用紙', '記憶喪失', '大富豪', '修業', '野菜炒め', 'バスチー', '悪天候', 'ヘルメット', '掻き攫う', '多様化', '絶滅', '怠る', '泣き寝入り', '微力', '滑り込む', 'ぼけ', 'MONCLER', 'CANADA GOOSE', 'ロビンソン', 'ルララ', 'ソーラー', '長谷川京子', '取り残す', '怠慢', '根気', '疎遠', '無礼', '焼肉の日', 'kokoro', 'A to Z', 'saintsnow', 'アケフェス', 'ベーコン', 'オジマンピックアップ', '日陰', '身分証', 'ポロシャツ', 'こよなく', '愛ちゃん', '右脹脛', '眠民', '衝動的', 'アイマスSP', 'ZEAL', '静寂', '舞台セット', '安気', '狂騒', '姫石', '逢来', 'straylight', 'wandering', 'Dream Chaser', '和泉', '依', 'アルストロメリア', 'アイカツ', 'Guilty Kiss', 'eyes', '絢瀬絵里', 'サイエンティスト', 'ソックス', '無精', '内職', 'グレーゾーン', '特異', '不得意', '逃れる', 'ラブコメ', 'ラッキースケベ', 'スポ根', 'カプ', 'ペンライト', '持ち色', 'フェット', '褒め合う', 'スピーチ', '御曹司', 'ふにゃふにゃ', 'ちらちら', 'FURFUR', 'スタァライト', 'カレスコ', 'ギル', 'ブラジャー', '妹キャラ', 'らいと', 'レイン', 'アドベントカレンダー', 'キービジュアル', '黒歴史', 'オタワ', 'ワンマンズドリーム', '必需品', '整理券', '肋骨', '活動量計', '映り込む', 'そそっかしい', '佐藤日向', 'スタァ', '稿', 'ぱふぱふ', '願書', '腿上げ', 'コスジャンル', 'ゾォ', '南西', 'シンカンセンスゴクカタイアイススゴク', 'カタイデス', '箇条書き', 'ギルガメシュ', '金ぴか', '三箇日', 'クハハ', '箱根駅伝', 'セコム', '駅伝', '短気', 'オエー', 'AA', '略', 'コツニフレック', 'ちょこっと', '胃痛', '子宮内膜症', '卵巣嚢腫', '腹腔', 'からから', '迫り上がる', 'たったった', 'ぼら', '雪肌', '目元', '惰眠', 'ダーミン', 'ウエスト', '合わせ', 'クソデブ', 'ぶよぶよ', 'だぶだぶ', 'ぽいぽい', '研究費', 'ワンちゃん', '試み', 'diverdiva', '真姫', '高坂穂乃果', '副代表', '極寒', 'ユメノトビラ', 'ぬっくぬく', 'デイドリ', 'ドロップアウト', '⁉', 'もぞもぞ', '曲数', 'メタメタ', '穂乃果', 'ドキピポ', '近江', '朝香', 'ぬるぬる', 'エチチチチチチチチチチ', '理亞', 'ぺこり', '御辞儀', '聖良', '超越', '高級感', 'みほ', '鈴木愛奈', '焼き付ける', 'Self Control', '言葉にできない', 'キラセン', '昇天', '音源化', 'ツァ', 'フッフーフワフワ', 'わて', '回生', 'uo', 'TVアニメ', '打ち上がる', 'ぽかーん', 'とける', 'グウゥ', '満面', '笑み', '夢占い', 'ハライテー', 'ソリソリ', 'ウィーン', 'レーザー', 'おみ足', 'エチチ', '腰使い', '躍動感', 'ヒードラン', 'ナメクジデー', 'ぴぴ', '救急外来', 'ヨカッタ', '空席', 'ディレイビューイング', '塞がる', '小走り', '傷跡', 'ボヨボヨ', 'ぎょっと', '網走', 'すわ', '快い', 'あいにゃ', '舞台挨拶', 'カービィ', 'とぼとぼ', 'イートインスペース', 'タスケテ', 'ビッッッウウ', 'ひなひな', '真田', '不動峰', 'ルドルフ', '山吹', '帝', '六角', '無許可', 'アマチュア', '機材', '観劇', '振り入れる', 'ふがふが', '入れ歯', 'チョコレート嚢胞', '卵巣', '渋る', 'セトリバレ', 'ウオオオオ', 'ドロヘドロ', 'おえる', 'モワンモワン', 'ハムチーズ', 'ポテチチョコ', 'シウマイ弁当', '原木', 'ビキニ', 'レノ', 'ゾゾスーツゲット', '東京事変', 'マキシマム', 'スパイス', '鳥肉', '低脂肪乳', '脂質', 'ごくり', '西地区', 'へなへな', 'ビラデータ', 'モダモダ', '́w', '赤門', 'ローブ', '修了生', '御母様', 'キモオタク', 'サーオリ', '委員会', 'シリコン', '一信', 'エアー', 'バッバーン', 'ボドゲ', 'ガッサガサ', 'リップクリーム', 'よーい', '湿っぽい', 'スーン', '酒蒸し', 'アゼ', 'まり', '果南', 'るりこ', 'お主', 'サーヴァント', 'ルーファウス', '若僧', '好戦的', '脳内イメージ', 'くぅー', 'イマジナリー', '鹿角理亞', '家の子', 'ポニテ', '高貴', '劣情', '木端', '鹿角', '梻', 'ねばねば', '初心', 'ぶれ', '愛香', '愛奈', '正式名称', 'ツッターン', 'アルゴート', '欠点', 'パンパンアンパンマン', 'チャッタァ', 'ヤンデレ', 'コンペイトー', 'マイリス', '2007', 'ドゥーンホワワワワワーン', 'ダブステップ', '年度', '93', '仰天', '家族になろう', '持病', '大手町', 'ナナチキ', '777', '59', '無制限', 'アアアッ', '生活費', 'スクリーンショット', 'マーリン', 'np', 'フローチャート', 'UC', 'ティファ', 'バトン', 'ヒーマー', '素顔', 'シーリングライト', '手早い', '一体感', '拙者', '横断歩道', 'ワタワタ', '駒場祭', 'でび', '散らばる', '外付け', '神のまにまに', 'ファイブ', 'GOD', 'ラッキーピエロ', '戦後', 'ぐんにゃり', 'もふもふ', '88', 'ばばば', 'ニチャ', '高菜', '明太', 'マヨ', '新香', 'かみさま', '出社日', '弥陀', 'フレックスタイム', 'お昼休憩', 'テレテレワーク', 'ぴぽ', '吐き', 'エクレア', '洗車', 'かっぱえびせん', '月給', '歩合', 'QUOカード', '万屋', '脱力感', '感得', '気侭', '体内', '電気ケトル', '気付かす', 'ましゅ', 'チョミント', '磯', 'ガパオライス', 'ぽんぽこりん', 'だーん', 'チコリ', 'チコリータ', 'コロッケパン', 'ユーフーキャッチャー', 'アベノマスク', '山帰来', '135', 'ビズリーチ', '言い替え', 'ふぁい', 'づける', 'カフェイン中毒', 'だつ', '新聞配達', '袋詰め', '言葉選び', 'ポエマー', 'リープ', '手料理', '早起', '無駄足', '生姜焼き', '無料配信', 'ホットドック', '自己愛', 'バイブス', '片栗粉', '所存', '慕う', 'ネム', 'ソンヌ', 'チアリーダー', 'セルフ・エスティーム', '憂い', '搗ち割る', 'ピンク色', '美ら', '泡立て器', 'ハンドミキサー', '給う', '宇垣', 'ながすぎ', '福利厚生', 'ほえ', '青汁', '遣り甲斐', 'コーヒーメーカー', '萎', 'てーん', '職探し', '麻呂', 'かえ', '苗', 'コロちゃん', 'にゃーん', 'だめだこりゃ', 'まだか', 'Microsoft', 'シナモンパン', '15000000', '生涯年収', '150000000', '1800000', '72000000', '28000000', '小さめ', '400000000', '制する', '対戦ゲーム', 'かてる', '連勝記録', 'チップスター', '甘々', '働き方改革', 'フレクス', '梯姑', '多重人格', '自尊感情', '永続', '不変', 'ピンチヒッター', '明々後日', '黍', '電場', 'lz', 'GOE', 'コスギ', 'ポーアイ', 'レアワード', 'ザギトワ', '阪', '邦和', '貸し', 'seq', '臨海', '部員', '定員', '講評', '主務', 'ジブリ', 'LO', '副務', '120000', '立て替え', '練', '82', 'ボーヤン', '月化粧', '滑走', '会計処理', '難民', '印刷用', '学連', '名簿', 'DS Lite', '天皇誕生日', '字数制限', '出回る', '弁論', 'インカレ', 'Microsoft Office', 'いくら丼', 'トナカイ', 'ネオ', '記入欄', 'アクセル', 'TS', '原案', '御堂筋', '巡', 'ビミョ', '1250', '大政', '04', 'POT', '学内', '陸', 'トレ', 'どさくさ', 'Superdry', 'ゲト', 'プレモル', 'テカ', '立ち', '矢口', 'インスト', 'ぷる', '死角', 'むっく', 'インタブ', '踏み締める', 'ひぐらし', 'tlww', 'アニハン', 'フーッフッフ', 'ホムセン', 'マイサン', 'シャイン', 'アメリカンドッグ', '肉じゃが', 'ノーチラス号', '家路', 'ファファファファファファ', 'ジャマイカ', '単音', '土佐', 'とち', 'WA', 'ライトノベルネタ', 'わたる', '初老', 'けんと', 'ロリ', '鷺', 'スタートライン', 'ロッキー', '正弘', '能登鉄道', 'ジョグ', 'スパイカー', 'プレイヤーズハイ', '縁結び', 'ニアミス', '運気', '天守閣', 'ギルガメ', 'むす', '道楽', 'ペロ', '撮影許可', '水玉', 'ビンゴ', 'スパナチュ', '飲ます', 'トップランナー', 'ギンガム', '塗装', 'モンド', 'ホットドッグ', 'くるくる', 'ティン', 'いいえ', 'ポップイズデッド', 'サイボーグ', '礎', 'きょろきょろ', '愛媛', '伊予弁', '横並び', 'X', 'ソソ', '拍', 'リズム隊', 'スゴス', 'サングラス', '執り行う', '耳打ち', '炸裂', 'ぴょんぴょん', 'ビックス', 'サクブラ', '悩', 'なっちゃ', 'ソウダ', '腹ちら', '小出シンバル', 'スネア', '盤', '車線', 'みるテスト', \"World's End\", 'シャングリラ', '上条', '引き起こす', '能登', 'ジョ', '手近', 'ぽっ', 'ぷい', 'マリス', '逸る', '美肌', 'ヨウダ', '感涙', 'カコイイ', '伊勢谷', '介', 'ヤハリ', '秘める', 'サイン会', '中腰', 'テイストオブカオス', '南武線', 'イエーロ', '江古田', 'かめ', 'アイルランド', 'テカサークルモッシュ', 'モッシュ', 'オッサン', 'ナンダッテー', '脳貧血', '腱鞘炎', '魔性', '軟派', '会報', '九州男児', 'KERA', 'つくしんぼ', 'サイドステップ', 'サマータイム', '踊るダメ人間', '雌', '笛', '小野D', 'キネマ倶楽部', 'ヘブンズゲート', '再現', '異変', 'フリーマーケット', 'ドーン', 'キニナル', '渉', 'レボリューション', '急性', '腸炎', '自業自得', 'エメラルドフロウジョン', 'ゴロゴロ', 'マイッカ', 'ホムペ', 'MALICE MIZER', 'えみる', 'スズモク', 'sugi', '黒澤', '周波数', '噎せる', 'ストラップ', '高らか', 'ミキティー', 'タッタラッター', '知恵袋', 'ファファファファファファファ', 'ファファファファレミ', '♭', 'ファ', '確', '定め', '告げ', 'バンギャル', 'moll', 'ラソ', 'ファーミーレーラッ', 'ドーレドシ', 'シドレー', 'ドレミー', 'レミミーファー', 'F dur', 'ファソ', 'シドッレファ', 'ミミッミッミッファ', '夜桜', 'd moll', 'ラレファラーソ', 'ドレミソーファ', 'シドレファミレ', 'ラファミミーレ', '時刻', '聖徳太子', 'エリックベネイ', '任せ', 'レキシネーム', '犯科', '帳', 'umber session tribe', '窓越し', 'ディメンション', '腹筋崩壊', 'セラミック', '株式会社', '宮川純', 'キーシン', '公開日', 'マンダラ', 'やまと', '親馬鹿', '激眠', 'マステ', '324', '押し切る', 'ニューアルバム', '燕返し', '木管', 'トリオさん', '環七', '環状', 'サガ', '多数派', 'ようつべ', '弱拍', '滝汗', '楽曲', '動員', '向井太一', '戒', 'テカライブ', '出待ち', '大竹', '恐喝', 'ライトユーザー', '笹塚', 'スモーガス', 'BA', '藤沢', 'ぼっち参戦', '小上がり', '楽団', '管楽器', 'りゅう', 'フォース', '瑯', '固執', 'こうちゃん', 'モエ', 'ソイル', '類家', 'BARB', '椿屋', 'メイドさん', 'そそぐ', 'ポット', '鶴岡', 'アルケッチャーノ', 'I WiSH', 'WAM', 'ネモ', 'ミデアム', 'シーデー', 'レコーデング', 'マーキュリー', '160', '178', '東横', '発車ベル', 'スターウォーズ', 'ラーファ', 'ラーファド', '芋煮', '真空パック', '連結', 'ドラモニカ', 'I WISH', '八景島', 'ソロツ', '三鷹', '佐賀', '尾道', '森彦', '冨樫', 'ルーズリーフ', '田圃', 'イシイ', 'ハナヤマタ', '応援団', 'ズ', '降臨', 'モア', 'The Man', '納得感', 'オーケン', '整', '和声', '筋少', 'ラフランス', 'タンブラー', 'ウッドベース', 'インベンション', 'ロイ', '石川さん', 'たっ', '知的', 'プリッツ', 'バリボリ', '報', 'サックス', '手品', 'チューバ', '5000000000', '脳天', 'ハイフン', '354', '御輿', 'リップサービス', '降らす', '緊迫感', 'ドンチチ', 'ミスター', 'LiAR', 'ENDER ENDER', '天美', 'ひびき', 'カルメラ', 'ハヤト', 'コレド室町', 'モントルー', 'タイテ', 'ソレソシレ', 'モーツァルト', 'アイネクライネナハトムジーク', '節子', 'ソレ', 'テナー', \"I'll\", 'クローズ', 'MY EYES', '聞き覚え', '玉置浩二', 'ワインレッド', 'オカン', '呼び捨て', 'プレイングマネジャー', 'ハラショー', 'フィロソフィー', 'ファウンダー', 'ふじわら', 'けいじ', 'ナディア', 'BBB', '公開収録', '小葱', '雨上がり', 'マイワールド', 'パンツマン', 'シカシ', '皆空', 'クリス', '商店街', '緊迫', 'ハッケソ', 'インストバンド', '門田', '晃介', 'ストナリニ', '健康体', '利き', 'パー', 'DNS', 'Emerald', 'ストーカー機能', 'ゲストプレイヤー', '輸血', 'HARCO', '森道', 'パラダイス', 'トリビュートアルバム', '表面張力', 'バンギャ', 'エフェクター', 'コイントス', 'ディストーション', '花笠', 'mash up', 'チャー', '定', 'おおの', 'ざす', '宗太', 'ヤセイコレクティブ', 'rsg', 'SOFFet', 'さゆ', '多福', 'スライディング', '留守', '恐怖症', '通訳', 'エスケン', 'ヒージョー', 'MJ', 'ジョーズ', 'キャーニレサーン', '代々木', 'うおん', '観覧', '象牙', 'デデドン', '出荷', 'Akatsuki', 'マイクスタンド', 'Let It Go', '客側', 'シカシヘドバン', 'たたた', 'バーブ', '画期的', 'あらい', '人生相談', 'ビオトープ', '管理士', '施工', '妖怪ウォッチ', '高校球児', 'カエンダケ', '学名', '樹木', '命拾い', 'のんちゃん', 'うぐ', '聞き上手', 'キムワイプ', '再利用', 'アクセル全開', 'サブカル女', 'じたばた', 'ビニールシート', '食む', 'でろでろ', '新発見', '捨身', 'ハイドロポンプ', '寒', '裸足', '環境教育', '主夫', 'お手伝いさん', '江別市', '浜風', 'べこべこ', '城島', '魂ラジ', '気象', '段取り', 'ホルダー', '納まる', '吹雪', '振り袖', '殺生丸', '超音波洗浄機', 'ガスマスク', 'アルミ', '落とし', 'NC', 'ベースライン', '謹製', 'コロニー', 'レオ・レオニ', 'ut', '農耕民族', 'ジョブ', 'ハンティング', '和式', '洋式', 'マンティス', '松岡修造', '粉薬', 'アップルパイ', '左腕', '腕捲り', 'One Direction', 'ゼイン', 'マルク', 'ひさ', 'TED', '不在者投票', 'バス代', 'アラスカ', 'コマツナ', 'ことこと', '調査', 'ふるふる', '給料明細', 'だらー', 'カルディー', 'ブレンド', 'まど', '部室', '青いベンチ', '魅惑', 'MUSIC BOX', '括れる', '滑り台', '瞬く', '洗い', '土塗れ', '電話相談', '退散', 'ヨヒー', 'じっけん', '割る木', 'チャリカゴ', 'オータムフェスト', 'コフレ', '黄金', '塩辛', '吹石一恵', '一命', '取り止める', 'ユビツメ', '漆', '水疱', '葉っぱ', '札駅', 'あやの', '修造', 'データ処理', '手当たり', 'アジエンス', 'オオハンゴウソウ', '外来種', '冷や奴', '酢橘', '蕁麻疹', '漆かぶれ', 'イノダ', 'サイレージ', '出来立て', 'キャラメルポップコーン', 'ヨーカドー', '蕪島', '全焼', 'しゃわ', '不吉', 'モノポリー', '長丁場', 'キルフェボン', '遮光', 'ビーカー', '布巾', '強打', 'カードキー', '森羅万象', 'すすきの', 'シワシワネーム', 'さだまさし', '亭主', '関白宣言', '西野カナ', '腐植', '赤ペン先生', '添削', 'レットイットゴー', 'と学会', '通り越す', 'ぽんぽん', '目上', '桜島', '火山灰', 'プレイリスト', '流れ来る', '酒石酸', 'アンチモニル', '吹雪く', '縄文杉', 'トレッキング', '欠航', '高速船', '取り直す', '共済', 'モノリス', '夕鉄', '精製', '凝視', '漕ぎ着ける', '帯状疱疹', 'ヤンマー', 'OA', 'ぼこる', 'ラボ', 'かつ', '住処', 'SOAR', 'ビジュアル系', '禁物', '国王', 'ボーイズ', '酪農', '北大', 'ハチ', 'ペーパードライバー', '助手席', '失禁', 'ハイキングウォーキング', 'キュー', '新訳', '銀河鉄道', '雀蜂', '監修', 'ハンドブック', '群れ', '事例', 'ズートピア', 'ゆりな', 'ニック', 'フェフ', '土取り', '屋久', 'ガイド', 'アシタカ', 'ヨヒージョ', 'ファイターズ', '教務', '樹木葬', '物質', '循環', '樹種', '水楢', '逞しい', '穴掘り', 'スコップ', 'ポリビン', '北国', '大学院生', 'タイ産', 'スプーン', '円山', '会費', '北極', '南極', '玄人', 'インスタント', 'ホームシック', 'アーユーオーケー', 'アイム', 'ぴか', '業務用', '会員登録', '競歩', '開催決定', '美容部員', '和装', '1300', '矢先', 'マチカフェ', '遅寝', 'ボー', 'ピカーン', 'ジャンボ', '青学', '仏壇', '線香', '着物姿', '新メンバー', '鯖落ち', 'セブイレ', '近隣', '無料クーポン', '豪栄道', '親方', '武隈', '相撲界', '箱入り', '中国製', 'イトメン', '恵方巻', '巻き巻き', 'ニュース速報', 'シャープ', 'ごそっと', '相撲', '春場所', '力士', '散らし寿司', '雛霰', 'ファミチキー', 'ミンチ', 'ジムビーム', 'パン生地', '薄桜鬼', '山火事', '小泉', 'びく', '三ツ矢サイダー', 'ガクガクブルブル', 'グーボ', 'リシ', 'ヤマザキ', '親子丼', '丸美屋', 'ジャパンフリトレー', '武士', 'ロードショウー', 'キングダム', '暴行', 'ホットプレート', 'ホームセンター', 'チキ', 'ペプシ', 'かさかさ', '晴天', '切手代', 'ソフト麺', 'キリンザストリング', 'マイバッグ', '朝飯', 'しかく', 'アイスボックス', 'ピザパン', 'ローマジ', 'ジメジメムシムシスル', '13.5', '参加人数', 'コンビニエンスストア', '有効期限', '逆上せ', '蜂の巣', '手間取る', 'モンテール', 'サッポロ', '黒ラベル', 'マー君', '打球', 'ドラマ化', '津田', '小野賢章', '花澤香菜', '5980', '公式ホームページ', 'ホームページ', '藤井', 'ネオワイズ', '土用の丑の日', '蒲', '嗅ぐ', 'オウェ', '悪臭', '照ノ富士', 'ギフト', 'カスタマイズ', 'バーコード', '必要事項', '記入漏れ', 'おいなりさん', '台湾ラーメン', '殿様蛙', '脱げる', '高スペック', 'マゼンタ', 'シアン', '強制終了', 'ついー', '膨張', '鳥取城北', '明徳義塾', '指紋認証', '蹲る', '急性胃腸炎', '食前', 'くろすけ', '具材', '代謝', '整腸剤', '帯広', '農業高校', '静岡県浜松市', 'かんかん', '照り', 'ぼうぼう', 'ラディッシュ', '間引き', '植える', '甲虫', 'アニメソング', 'ギンビス', '胡椒', '食べ応え', 'ボンビーガール', 'テンプレート', 'パァ', 'モッチッチ', 'Hello Kitty', '警察学校', '聞き直す', 'カーナビ', '刹那', '炭治郎', '猪突猛進', '善逸', '義勇', 'カナヲ', '村田さん', '柱', '那田', 'モニプラ', '井村屋', 'ワンタン麺', 'チリトマト', 'ドミノピザ', '縮める', 'オト', '伊達', 'バファローズ', 'アダム・ジョーンズ', '猛攻', '醒', 'セラピー', '三岐鉄道', '罰金', '科する', 'ソロビ', 'ベンチマーク', '早坂', 'ポップ', 'INSIDE IDENTITY', 'カースト', '裾', '結び', 'ペンタ', '瓦町駅', '中小私鉄', '二塁', '打', '榊原', '降板', 'キリ', '代える', '設い', '外乱', '発達障害者', 'ジスイッチ', '外的', '相殺', '鬼頭明里', '葵', '千秋', '張り合い', 'アンダースロー', '高速道路', '国道', '号線', '標識', 'ブーメラン', '古賀葵', '対照的', '核', '振り掛ける', '蒸発', '乗せ', '65536', '山本', '専用機', '長打', '愛環', '伊豆箱根鉄道', '〆', '御茶漬け', 'FPS', '塁', '暴投', '死球', 'サヨナラ負け', 'SH', '琴平線', '仏生山', '複線化', '膠着', '恰も', 'フォークワンバン', '捕手', '鈴木優', '恒常', '空振り', 'リプレー', '誤審', '審判団', '二塁打', '目する', '誤報', '避難訓練', 'ワルカプ', 'jeb', '超人的', '脚光', '小手先', '回し', '個々人', '殴り合う', 'GD', '心停止', '口金', 'コイノシルシ', '期末試験', 'ツイフィール', '夏色', '無色', '春季', '立花理香', '天敵', '有原', 'スロー', '円軌道', 'プレカラ', 'マビマカ', 'ラッション', '共々', '投手戦', '範疇', 'クォナイェン', '紛らわせる', '塩素', '浸透圧', '生理食塩水', '大腸癌', 'ダーウィンズゲーム', '似非', '評価基準', 'イコール', 'microSD', 'レンタルレイアウト', '不能', 'レール', 'がしがし', 'ジョッチ', '球', '鳥谷', 'ツイタ', '衝撃波', '核爆発', '総社', '在校生', '過干渉', '卒業生', '担わす', '理想像', '自己批判', '渡', 'PW', '四股', 'jl', '123', '精出す', 'ξ', 'エ', '肉薄', '粛々', '都市部', 'ジャイアンツ', '手投げ', '勝ち星', '星野伸之', '司る', '客車', 'Chrome', 'PWA', '失調', '入団', '難', '東三河', '応援歌', '野崎', 'ステラのまほう', '宇佐美みずき', '振るう', 'ェー', '勝ち負け', '争う', '伊井野', 'ミコ', '見覚え', 'gifmagazine', 'GIF', '消費期限', '一体型', '口角', '突き破る', '押上', '迷い込む', 'えちごトキめき鉄道', '翡翠', 'えちご押上ひすい海岸駅', '体育会系', 'アニメオタク', '断片的', '秋月', '大石昌良', '小林裕介', '得意分野', '包括', 'ヒゲドライバー', '若月健矢', 'ユーティリティープレーヤー', '重点', '昇降', '日陰者', '千賀', '投げ合う', '球場', '川瀬', '勝ち投手', 'フライ', '可逆圧縮', 'AVI', 'OneDrive', 'プレビュー', '海外勢', '拾い', 'PSh', '告る', '轟く', '伊呂波', '試験監督', '打者', '敬遠', '登場曲', '春擬き', 'レプリカ', 'コミックス', '生存報告', '妖狐', 'パレット', 'デーゲーム', 'アルミホイル', '球威', 'ちんこ', '兵器', 'ボンディック', '硬化', 'ちよ', '胡蝶', '初手', '電流', '室外機', 'サーモオフ', 'ノーコン', 'フォーク', '糖', '蒲郡', '千賀滉大', '田原', '小川泰弘', '藤嶋健人', '希望的観測', '小川', '小久保', '美術部', '主導権', '心肺', 'マルコフ連鎖', '惜しむ', '安値', 'tips', 'abema', '小分け', '配信期間', '竹達彩奈', '雑務', '由比ヶ浜', '解', 'モノローグ', '渡航', '明日葉', '作中', '木佐貫', 'ワンバン', 'エンコード', 'セキュリティー', 'iwara', '罵倒', '愛知県民', '宅急便', '車線変更', '東海交通', 'ザッハトルテ', '結び付く', 'スル', 'KAN', 'フリーパス', '野田', '西村', '解任', 'チーム力', '中嶋', '選手時代', '斎藤', '暗黒', 'ゴッツ', '風岡', '咎める', 'ブレイクダンス', '竹原', 'エンカウント', '吊り目', '美憂', '大城', '中川', 'ラオウ', '内野手', '投手陣', '制球力', '消失', '西春江ハートピア', '打ち出す', '西大路御池', '監督退任', '追い追い', 'スルカン', '近畿', '来日', '野球界', '打診', '疎い', 'スクロール', 'ガックガク', '安済知佳', 'サインアップ', 'ゲ', '若鷹軍団', '差し代わる', '視認', '490000000', '玉縄', '折り本', 'キャラデザ', '高洲', 'コミュニティーセンター', 'ウォーニング', '大掛かり', '断裂', 'ゴッツイ', 'リサーチ', '公平性', 'せっかち', '貨物', '勝ち頭', '主力', 'イニング', 'イーター', 'チームトップ', 'スライダー', '斡旋', '旋', '旋転', 'オリックス・バファローズ', '潰瘍性', '大腸炎', 'ワンハンドロウ', '広背筋', '三角筋', 'コンサル', '君野', 'ミライ', '竹達', 'チョロオタク', '好美', '合格点', '軽度', '北鉄', '6010', 'セレクト', '加賀', 'herenz', '即席', 'アンテナ', '激低', '連中', 'nanoko', 'リリア', '常同行動', '試合開始', 'テトリス', '内輪ノリ', '言い替える', '内輪', '細字', 'マルチ', '廃盤', 'ウィーラー', 'モーガン', '価値判断', '多寡', '高低', '宝の持ち腐れ', '阿波市', 'マレーシア', 'ベトナム', '打ち叩く', '適合者', '合わす', '神のみぞ知るセカイ', 'グラデーション', 'ワイプ', 'RGB', '255255255', 'コマンドライン', '画像加工', '合成', 'vegas', 'プリセット', 'トランジション', '全能', '倍速', '威嚇', '陽乃', '年甲斐', '論語', 'そりゃそうだ', '楽観的', '中和', 'ハブ', '結節点', '頷く', '屁理屈', 'くっ付ける', '大層', '担ぎ上げる', '宗', 'キャッチャー', '制球', '東尋坊', '坂井市', '記述', '引数', 'GRAVITY', 'grabity', 'wwwwwwwwwwwwwwwwwwwwwwwwwwwww', '中学時代', 'CSV', '一括', 'リネーム', 'CUI', '同点', 'オモタ', 'スクリプト', '落雷', '活動度', '光尊', 'HA', '復調', '肌質', '2127', '稲沢', '調べ物', 'レーダー', '鉄道会社', '種別', '芦原', 'ココラアベニュー', '川根温泉', '単回', '甲種', 'スジ', '施行', 'しゃべくり', '姫坂', '乃愛', '堀北鈴音', '言及', 'キトアカ', '一押し', '碓氷', '咲月', '不必要', '執拗', '所沢', '沢村', 'ホールド', '連続三振', 'wwwwwwwwwwwwww', '打法', '記録的', 'ジャペーソ', 'トレペ', 'ジムノック', '三河湾', '悠長', '稲光', '駐', 'ウインカー', '縦横無尽', '思考盗聴', 'パナウェーブ研究所', 'ASKA', '普通預金', '貸し付け', '自衛', 'ぼこ', '平井', 'ダブる', '保', '住信SBIネット銀行', '執念', '不正送金', '涼む', 'ビートレ', 'アンリトン', 'AH', '557', 'MX', 'ノーヒットノーラン', '480', 'コンバート', 'ガハママ', '大原', '清子', 'うかい', '道化る', '浮かべる', '名称', 'シオン', '違憲', '手段の目的化', '改める', '書き散らす', '電脳化', '痛切', 'キチゲ', '決壊', '反動', '内野安打', '日内', 'コールド', '魔改造', 'チタン', 'ボトルマン', '近鉄', '名張', '志摩', '見捨てる', 'ぼったくる', '自戒', '浦島太郎', '■', '時間泥棒', 'nkf', 'cmd', 'ホエー', '規約違反', '抹消', 'ダイナミック', 'クリエーター', '喪失', 'ペンケース', 'ウケモク', 'メタ', '王子駅', 'ぱく', '情シス', '初歩', 'クラウドソーシング', 'コミュニケーション能力', 'IIS', '食わす', 'マウスジェスチャ', 'だま', '社交性', '躁転', 'ihc', '優先度', '信憑性', '他界', '支配的', 'ブクマ', 'トップページ', '右クリック', '艦', '染み入る', '電気暖房', '特殊清掃業', '横道', 'ウワァーァウーッー', '雪乃', '歩道橋', 'タスクバー', 'pause', 'リク', '赴く', 'アニメキャプ', 'マゾ', 'インクラインベンチ', '強度', '焼き鮭', '政宗くんのリベンジ', 'タイムリー', 'しお', '戸部', '探訪', '名画', 'パイプ', '環境変数', 'シコティッシュ', 'PNG', 'BIT', '背景色', 'CMYK', '遠ざける', 'Inkscape', 'CMS', '域外', '手持ち無沙汰', '靄', '特色', 'トリミング', 'クリエーティブ', '入札', '崖', '金庫', '母港', 'ランチャー', '女房', '進水', '編集者', '初期微動', '主要動', '赤身', '笹身', '匹敵', '支払額', 'CF', '村上', 'コマンドプロンプト', 'MS', 'remote', 'クリップボード', '保持', 'PowerShell', '保留', '与奪', '見本市', 'googirl', '極太', 'ツインテ', 'ヌル', 'ISUZU', '制作者', 'エイニメ', '冥', 'カワイイ゛ッ゛', '提督', '引き締まる', '手始め', '正視', '惨状', 'カルト', 'くーろくろ', '御父様', 'SD', 'FireAlpaca', 'フリーハンド', '曲線', 'ショートカットキー', '目途', 'ワンクリック', 'claunch', '手軽い', 'クラファン', '限定的', '一環', 'sendkeys', 'カーソル', '座標', '900', 'PX', '邪神', 'ガヴ', 'マジモン', 'クレカ決済', '狂い', 'キャバ嬢', '伊富魚', '貴族', '好調', '関谷あさみ', '一花', '伊良湖港', '甲板', '日間賀', '本土', '22.4', 'km/l', '蛸', '落札', 'アクセス回数', '中盤', '小町', '悠木', '佐倉', '断ずる', '聖母', '常駐', '寄与', 'premirepro', '神明', 'ニコニコ静画', '長良', 'オトッペ', '井口裕香', '清', '中村井', '小島', '背番号', 'PB', '損傷', '超回復', '井上', '見栄え', 'リランカ', '海域', '庶民的', '加盟', 'ラーメン店', '状況下', '配り', 'シグノ', 'リサイクルショップ', '開催日', 'リリックビデオ', '混成', '親睦会', 'ウインク', 'LAN', 'NAS', '無線LAN', 'ネットワーク', 'ルーター', '朝霜', '改め', 'ディクソン', 'NRA', '地鉄', '先代', '賄賂', 'もとい', '最低金額', '描写', '享受', '搾り出し', '仕掛かる', 'チャタリング', '大胸筋', '下部', 'インクライン', '描き直す', '変顔', 'ポニー', '受け狙い', '賛否', '新堂', '初月', '雪ノ下陽乃', 'ルンスト', '定理', '登場人物', '悪い部分', '煮凝り', '荒西', 'チーム全体', '万人', '賜る', 'ナニカツ', 'エフェクト', 'シギル', 'ブォン', 'メールボックス', '代わる代わる', '左手マウス', 'キャラ萌え', '意欲的', 'ヘラツイ', 'システムエラー', 'ウーツーベァー', '外注', 'ソフトーク', '口直し', 'アーム', 'なにわ', '海綿体', '出直す', 'MCM', '練り歩く', 'カコグリ', '使い込む', 'さらさら', 'フォーリナー', '風俗嬢', '半殺し', 'ひばり', '嘔吐', 'シリグリ', '19000', '猫カフェ', 'イエッサ', '除毛', 'meves', 'jubeat', 'SAW', 'ケイコ', 'MAC', 'アデーレ', '添い遂げる', '襷', 'ツーリング', '革ジャン', '軽微', 'サウスポー', '高級車', '乗り回す', 'zetto', '雲隠れ', 'ストレージ', '斧', 'ドロポ', 'ライチ光クラブ', 'エニー', '胃袋', '大食い', '特盛', '米料理', '飛騨地方', '五平餅', '他意', '爆乳', '垢擦り', '花壇', '腐葉土', '土壌', 'PH', '肥料', '止む無い', '疾走', '心中', '飛び降り自殺', 'カッツソロ', 'エニカツ', 'ハープ', 'ヤンゴシ', 'Logicool', 'デジ', '高杉晋作', '童心', 'ルイベ', 'コロチキ', 'どんけつ', '喰いタン', '花札', '結石', 'ねお', '神経内科', '脱糞', '守谷', 'ガルーラ', 'サクラサインペン', 'スイカラ', 'valorant', 'パーティゲー', '渡部一夫', 'ピザパ', '大喧嘩', '石神井公園駅', '隣駅', 'ねねっち', 'GAMECUBE', 'サヘル', 'OBS', '431242363464544532234', '金縛り', 'きしょい', '田園都市線', '打っ通し', 'フライドポテト', '小麦', '地下アイドル', '最寄り駅', 'マロタ', 'guys', 'ウィー', 'HAVE', 'For You', '唐澤', 'JC', '結果次第', '拳銃', 'Natalie Portman', 'エイジ', 'アスカ', 'アニメストア', '北斎', '覆刻', '1.3', '家庭菜園', '立木', '電撃ホビーマガジン', 'カオスガンダム', 'アビスガンダム', '合体', 'ポッド', 'ストライクガンダム', 'ディズニーランド', 'エンボス', '人肉', 'yua', 'ZUMI', 'えんこ', 'unpack', 'tribe', 'revengeance', '百瀬', '律', '場違い', 'クリムソン', 'もさ', '佐々木希', 'ベルルッティ', 'スイスポ', '1080', 'gh', 'WAZA', 'ずずん', 'ペンサンダー', '超音波', 'MG', 'PG', '筋彫り', '墨入れ', 'プラモデル', '股間', '邪念', '僧', '影武者', 'mazeru', 'RIO', '集会', 'にわか鉄', '成田エクスプレス', 'Dr.イエロー', 'あらき', '横アリ', 'マンキン', 'オロロンライン', 'ビーナスライン', 'JIRO', 'ガレバン', '曲作り', '逆流', '無水', '松島', 'ピザーラ', 'アッツ島', '下見', 'バーバリー', '中新宿', 'グッチ', 'スパグリ', '富士見台', '無線', 'logi', 'ゲーミング', 'えいみ', 'まんがな', '割り勘', 'osmo', 'ジンバル', '今川焼き', 'アクリル', '国大', '強奪', 'ゲェ', '戦犯', '対決', '失恋ショコラティエ', 'バカチン', 'バカスケ', 'チー', 'stic', 'DIY', '鳥居みゆき', '内田理央', '朝日奈', '央', '根本凪', '一貫性', '四国カルスト', '1100', '鶴ヶ島', '都心部', 'ジャグリング', 'ディアボロ', 'バレット', 'パンティー', '局部', '壊死', 'アカウント凍結', 'ペンスピ', 'ドラネス', 'lol', 'こばと', 'インプ', 'アクセラ', '試乗', 'アテンザ', 'アクリルペンスタンド', '東京急行電鉄', 'THULE', '御伽', '原江', '切り抜き', 'FG', '巧む', '仕事復帰', 'AS', '作り上げる', '空豆', '葈耳', '天と地', '中途採用', 'ラッパー', '平常', 'こっ酷い', '見舞い', '糖尿', '上沼恵美子', '支持', '街道', 'テェ', '服部', 'パル', 'gline', '山本太郎', '百合子', 'baaron', 'ポケモンガチ', 'ランカー', 'eno', 'プレカラキャップ', 'Zoff', '13000', '火鉢', 'ドルオタ', 'ポニーテールとシュシュ', '神曲', '殺し合う', 'スタビロ', 'haon', '億万長者', '女性アイドル', 'プロデューサー', 'RAB', '涼宮', 'ガッシュ', '大人買い', 'メタゲル', 'くしろ', 'ディズニーシグノ', '蛍光', 'ギアリング', 'リプトン', 'フワ', '露出狂', '東久留米', '椎名町駅', '屋内', '洋室', '焜炉', 'エキストラ', '水溜りボンド', 'クソデカランタン', 'ツーブロ', '刈り上げ', 'ジャラ', '時代遅れ', 'シャロ', 'ダンプカー', 'テンパる', '電動歯ブラシ', 'シルバーカー', '幸三', '家系', 'ドルジ', 'yelo', 'コムサ', '色合い', '妥協点', '政党', 'ボカクラ', 'Skyteam', '車種', '絢', '悪口大会', '相模原', '総出', '大蛇', '86', 'トップレベル', 'マツケンサンバ', '1600000', 'chr', '彷彿', 'もっさん', 'トシ', 'プロテア', '西野七瀬', '夏の思い出', 'レコード', 'カスゴミ', 'arezeat', 'ソロデビュー', 'ケツパック', '800000000', 'チカラメシ', 'がらり', 'セルケー', 'wwwwwwwwwwwwwww', 'グラディアンレッドドラゴン', 'ぱお', '春日局', '竹林', 'カリフォルニア', '州立大学', 'モルガン', '自爆', 'プロトマーリン', '愛歌', 'ケイ', '卿', '放屁', '郡山', 'tubegameplayer', 'エロイゾ', 'カンタユルセナイゾ', '半同棲', 'エニス', 'カンバラバレット', '材料費', '徒花', '風梨', '梟', '斑鳩', 'ENA', 'ミリオンアーサーサービス', 'ナランハマジ', 'メタゲルグリップ', '輸入', 'Aちき', 'STA', 'りえ', 'DAOKO', 'おはスタ', '廃材', 'ヤフー', 'shezo', '専売特許', 'STX', '台座', '麺食い', '巨漢', '単焦点', '目押し', '天龍源一郎', '理解力', '腋臭', '腋毛', 'もっさり', '吊る', '原爆ドーム', '馬車', '袋井', 'バカデカ', '規模感', '金時', '麻布十番', '通い詰める', 'テトラ', '転げ落ちる', 'ジャペントリ', '大臣', 'フリック入力', 'インド人', 'ファーストサマーウイカ', '氷川きよし', 'メンバー募集', 'がりがり', 'りつ', '武蔵', 'alter EGO', 'AMP', 'シグルド', '沖田', '山本美月', 'twps', 'ラウラ', 'リバー', '明治時代', '変体', '盛り沢山', '保有', 'バチコリ', '雷帝', 'スカディ', 'NPF', '自滅', 'クルシメ', 'モット', 'マシュ', 'banz', 'バーベル', 'これでいいのだ', '義務化', '916731629737316598', '磯巾着', 'エミヤ', '人事部', 'エモポスト', 'クソデカ', 'チームイクイク', 'iur', '発足', '儲け', '練馬区民', '豊島園', 'spsl', '水タバコ', 'ニコチン', 'タール', 'ロリンチ', 'Kay', 'ちやほや', '粗末', 'AV女優', 'キアラ', '新宿高校', '泡盛', '夜通し', '言語障害', 'ビデオテープ', 'VHS', '店側', '藤井聡太', '正念場', '延命治療', '植物状態', '結晶', 'シボ', '建築士', 'パパジェル', '玉袋', '翻車魚', '跛', 'レイキャビク', '徐福', '525', '巴御前', 'イーアソウン', 'GOM Player', 'ナッツ', 'wwwwwwwwwww', 'BLOOM', '紫陽花', 'ウイーク', 'ハーフ', 'ニューハーフ', 'カラゲル', '赤と黒', '多田李衣菜', 'ヒョロガリ', 'カンバ', 'レット', 'ジョット', '染色', 'SeN', 'com', 'ASIN', '金融機関', '利用制限', '朝礼', '後任', '莫大', 'Sherry', 'クレメンス', '西東京市', '新設', '田中', '麻美々', '総理大臣になったら', '製作委員会', '重度', 'キチィ', 'デーリックシリーズ', 'エバン', 'ベビードール', 'hal', 'uneek', 'ARTS', 'オンオン', 'シッケ', '泣く泣く', '伝承', 'ヒョロワー', '何とぞ', 'イリア', '狒々', 'スパチキャップ', '所有者', 'erys', 'skyper', 'ETSU', '人工無能', 'けつ穴', 'アイスコーヒー', '生殖', 'purely', 'pulucy', '立候補', '営業再開', '保険外', '治療費用', '構文', '野猿', '世界線', '凛', '便所飯', '粉瘤', '摘出手術', '黒川温泉', '混浴', '本厄', 'クソハッピー', '年男', 'ぼやける', 'KAY', '談話', '筆記', 'マジミラ', '先行予約', '昼休憩', 'ペマ', 'のの', 'オノノクス', '肌色', 'オレンジジムノック', 'lavacchi', '免れる', '小切手', 'イクイク', 'ka', '~~~~~~~~~~~~~~', 'ひね', '86437367683734681738386486', '双頭', 'ハイライター', '猫も杓子も', 'いごっそう', 'ペンクソ', 'カッツ', '描', '艶消し', '吸わす', '証券取引', 'アトランティス', '竜', '撲殺', 'Core', 'japen', '総合的', '模範的', '未経験', '決算', '有給申請', 'facerig', '8426872384268426984136', '山姥', '洒落る', 'ノンアル', 'アーラシュ', 'ライネス', '縋る', 'メルト', '裏山', '50.6', 'ホスト部', '自己暗示', '糸目', 'オダチェン', 'ツイ消し', '作曲者', '本青', 'INF', '桜美', '小便', 'ディスアド', '8000000000000000000000000', 'ブギボ', 'ギフトカード', '大友', 'yuljung', 'Axes', 'ローキック', 'ウタハ', 'レアペン', 'ジャイモン', '演歌', '間接照明', '鎧', 'ボ', '紫色', 'さとみ', 'BREITLING', '対応策', '咄嗟', '模型', '言い掛ける', '栗御飯', 'ジェット機', '麻原彰晃', '死刑', '休店', 'ユニコーン', '自己投資', '車道', 'チャリダー', 'しょっぴく', 'SBI証券', 'ネット銀行', 'MONKEY MAJIK', 'qp', '非対応', '別途', 'サムゲタン', 'ツエェ', 'ゼブラ', '任意保険', 'ヘッドライト', 'たえる', 'darkt', '盲腸', '古舘', '吹き返す', '泊める', '宅建', 'FP', '証券', '小突く', '源頼朝', '戦国時代', 'Harry Potter', 'あし', 'ダルゴナトッピング', '殴', '天下', 'ロマン', '惨敗', '流体', '滅観', 'contradict', '蓮根', '年末年始休暇', '天下統一', 'AERIAL', '信長', '平清盛', '柴崎岳', '写真整理', 'チョップ', '奥座敷', '平家の落人', '敦盛', 'リトルワールド', '大阪桐蔭', '争覇', '引き下がる', '赤絹', 'オーバーロード', '武神', '久志', '落ち零れ', 'アインズ', 'ウール', 'ゴウン', '出迎え', '六文銭', 'ダレカルビ', 'LED', '白色', 'リーグ優勝', '公式戦', '麦芽', '豆乳', 'グラノーラ', '高田純二', '最低気温', '鯱', '直角', 'ブルームーン', '月光浴', 'バイデン', '投票権', '握り', '炙る', '穴子寿司', 'ごつ盛り', 'スパイク', 'MIZUNO', 'ショーン・コネリー', '湯婆', 'たんぽ', '湯たんぽ', 'ブロスタ', 'ヤマナカ', '絶品', '白バラコーヒー', 'アポロン', 'ミレービスケットカロリー', '犬種', '_φ(･_･', 'レアル', 'トリックスター', 'シマムラ', '王府', '台湾風', '蒸し鳥', '海水', '鷹の爪', '上位互換', '武田', '真田幸村', '橙', '奥州', '関東甲信越', '大阪市', '高橋', '瑠美子', '紫綬褒章', '子役時代', 'ハナちゃん', '婚約', 'ビブリア', '古書', '記念撮影', '焼きリンゴ', 'ウォーターオーブン', '留守番', '冒険少年', 'タケコプター', 'briku', 'ココナッツ', '実習生', 'オット', '小さな旅', 'みんみん蝉', 'フローリング', '蛇口', 'ぽたり', '文鳥', 'ガレット', '割安', '西荻窪', 'ことりや', '内装', '鶉', 'ノックアウト', 'パニーニ', '収穫', '緒川たまき', '大正', '機器', '怪奇恋愛作戦', '赤羽', 'まつもと市民芸術館', '狂人', '往生', '北区赤羽', 'スチャダラパー', '当方', '江戸川乱歩', '天知茂', '明智小五郎', '怖々', 'パノラマ', '奇談', '日の出', 'サンショウクイ', '見間違え', '尉鶲', '揖保', '燕', 'ベック', 'tropicalia', 'ゲス', '黄鶲', '大町', 'クランペット', 'either', 'XO', 'エリオット・スミス', 'DVD化', '蜩', 'ミルサー', '千代', '揺籃', 'ラタン', '搾乳', '発達心理学', '授乳', '電気料金', '桶谷', '天声人語', 'デビッド・ボウイ', '奥泉光', '芥川賞', '巧み', 'サパンジ', 'イチジク', '柴漬け', '紅生姜', '卵焼き', 'デニッシュ', '農作業', '全国一', '農林業', '盛ん', '障子', '立ち聞き', '和洋折衷', '戸', '日暮れ', '生活時間', '曲げ輪っぱ', 'データ改竄', '経歴詐称', '扠置く', '則る', '当該', '容姿', 'ボンポワン', 'ベビー服', 'スモッキング', 'セムラ', '舞う', 'めざす', '狩野', '多形日光疹', 'ハスミ', 'ジェネレーター', '切り抜く', '三島由紀夫賞', '野良', '活写', 'したり顔', '良識', 'ブラックユーモア', '切り離す', '黒沢健一', '茫然', 'FM横浜', 'ステレオ', '前のめり', 'ソロライブ', '公開録音', '苛立ち', '募る', '健一', '秀樹', 'ガール', '先延ばし', '内面化', 'タプリクリップ', '母子', '電灯', '指差し', '司書', 'クール・ビズ', '軽装', 'テンホウ', '幟', 'メッシュ', 'エルゴ', 'ぼうし', '親子関係', '擬する', '童謡', 'TMBG', 'MAN', 'イッツ', 'SO', 'LOUD', 'ヒア', 'ブックレット', '白地', 'ボタニカル柄', '防虫剤', '一連', '本題', '野鳥', '御存知', '緑鳩', '住宅地', '尺八', 'HARIO', '玻璃', '姿形', 'テントウムシ', '幼虫', '蛹', '堆肥', 'コンポスト', 'ドータクン', '夏至', '勝者', '日能研', '四谷', '大塚', '地域性', 'ビクトリア', 'バナー', 'ララビギン', '名車', '名鑑', 'パオ', 'フィガロ', '反訳', '速記', '平安堂', '工房', '明点', 'さわやか自然百景', 'BTS', 'とばっちり', 'ライネル', 'ジャスガ', '外国語', '上級者', 'チンチャ', 'progate', '有料会員', '吉日', 'チュソク', '韓国人', 'テロ', '生椎茸', '黴びる', 'topik', 'エッッッッギズモード', '十', 'baba', 'YOU', '滅入る', '大和田', '一人勝ち', 'トムジェリ', 'なんば', 'ユザワヤ', '心斎橋', '東急ハンズ', 'ABCマート', 'btow', 'firetv', 'オンオフ', 'Fire TV', '食い繋ぐ', '瀬戸際', '岐路', '立たす', '生す', '居丈', '韓国企業', 'ディレクター', '乱心', '軟式globe', 'じゅう', '存在意義', 'RIP', 'インテル', '自作PC', '遺伝子', '選', '値下げ', 'キャッシュカード', '生焼け', '策略', 'XR', 'おも', 'オレンジデイズ', 'notes', 'ブロガー', 'クロー', '神宮', 'CA', '旅行業', '助成金', '無地', 'ヨーグリーナ', 'K2', '差別的', 'メリットデメリット', '支', 'るんるん', 'むしむし', '門司港', '白玉', 'ぽけー', 'はれる', '日誌', '特化', '毛虫', '踊り', '寝入る', '延岡', 'テッド', '臨む', 'フルート', '福岡マラソン', '肉眼', 'むかむか', '博多座', '放浪記', 'レミゼ', '本城', '思い遣る', '金土', 'しおり', 'しゅわしゅわ', 'あした', '甘美', 'アシタサンカンビ', '園庭', '初任', '日向灘', 'れこ', '見入る', '公休', '電子黒板', 'コニカミノルケルタプラネタリウム', 'アロマ', '災難', 'パラリンピック', '瀬戸', '芸術祭', '夏服', '都城', 'たにぞう', '研修会', 'ばさ', '予行', '園長', '威圧', 'ラムネ', '計画性', '誕生会', 'ワーク・ライフ・バランス', 'ラミネーター', '資さん', '作り物', '染め', '虱', '絶好', 'セルフカラ', '栗木', '主任', 'マラソン大会', 'そめる', 'まみ', '七', '備', '卒園式', '御陰様', 'どたばた', '泣き疲れる', '休出', 'こける', 'ヨーガ', 'SONGS', '消防', 'つぶれる', 'さらっさら', '奄美', '反撃', '夏祭り', '部会', '掃除道具', '私語', 'ロッキング', 'ごき', 'しくじり', '電子掲示板', 'ワロス', '必殺', '複線', '芋蔓式', '擽る', '別冊', '秋冬物', '大乱闘スマッシュブラザーズ', '木製', '尻拭い', 'スイマー', '嘗め取る', '名刺交換', '代表取締役', 'モール', '室長', '与那原', 'ググッタラ', 'ソーキ', '(´Д⊂ヽ', '免罪符', 'マイミュージック', '溢れ出す', 'クレイジー', 'アイアン', 'メタルギア', 'キック', '携帯小説', 'ウェッジウッド', '攻撃力', 'けらけら', 'パンウメエヽノ', 'neee', '取り掛かり', '品質工学', '口出し', '情報開示', '進め方', '辞表', '新体制', '部門長', '地位', '相対的', 'インダストリー', 'インダストリアル', 'イリュージョン', 'デース', 'ダウンスイング', '右脇', 'adamas', 'ヴィンランドサガ', '客先', '掻い潜る', 'ざりがに', 'バルタン', '阪急電車', 'クジラの彼', '迷路', '館', '京都弁', '撫で撫で', 'ヤッタネ', '汚染', 'STAR OCEAN', 'スパロボOG', '雨音', 'ランボー', 'パナソニック', 'オーディオ', 'フォーマット', 'SDXC', '597', '66.333', '67', '伊勢丹', '誓い', '雪国', '棟', 'こそこそ', '末路', '悄然', '種族', 'ヨカーン', '泉', '評する', '今日明日', '古本屋', '差し当たり', '患部', '発令', '献身', '車好き', 'プリウス', 'ちゃち', 'カーボン', '仙台駅', 'KPC', 'gl', '死人', '銭', 'のと', '会社内', '激走', '藤原氏', '最盛期', '平安時代', '鳴子', '日帰り出張', '植物図鑑', '人形館', 'セナ', '背骨', '無軌道', '戦果', 'キャッチミーイフユーキャン', 'タイタンの戦い', '役人', '日本人社員', '情報操作', '新聞記事', '肯定的', '団塊世代', 'ハイドーン', 'ベニス', '商人', 'ヒックとドラゴン', 'ベックマンポチ', '自機', 'STG', '練習場', '山岸', '元専務', '出る杭は打たれる', '福島', '履き心地', 'ベックマン', 'わけがわからないよ', 'ショーシャンクの空に', '殿堂', 'モーガン・フリーマン', 'ジム・キャリー', 'トム・ハンクス', 'hachi', 'バジル', '常長', 'チェリー', '岡', '1933', 'コレジャナイロボ', 'サモン', 'デビルサバイバー', '女神', '転生', 'ピアニスト', 'インセプション', 'トゥルー・グリット', 'マイレージマイライフ', '並び順', 'スヌーピー', 'いがいが', '空飛ぶペンギン', '渡辺謙', 'LL', 'ホスィ', '向井理', 'ヤク', 'パブロン', 'さわら', '勇者', 'ラナルータ', '転がす', '然程', '包帯', '労災', '概ね', 'GI', 'ビョンホン', '無為', 'メッメッメガンテ', '交代制', 'konozama', 'ライアー', 'ジムキャリー', '野原ひろし', '盛り上がり', '手打ち', '変則', '麒麟の翼', 'エターナル・サンシャイン', 'ワショーイ', '東京インテリア', 'WiMAX', 'LTE', '映画版', '爛々', 'ネバー', '馬鹿馬鹿しい', 'セーフモード', '凡そ', 'パケット', '通信料', 'パケ死', '情報教育', '寝袋', 'キタ', '(゜∀゜)', '巨悪', '大噴火', '水浸し', '茣蓙', '候', 'あめあめ', '日勤', 'マリオシリーズ', 'ルイージ', 'ゲスヤロウ', 'デデデ', 'WIN', 'OS', '現行', 'ノーパソ', 'ブラウザ', 'too', 'パトリック', '全英オープン', 'チキンカレー', 'タマタマ', '大追跡', '時間給', '0800', '1700', 'ライドオーン', 'しっとり', 'genten', 'キーケース', '仙台港', 'タイトルマッチ', 'KO', 'クルー', '夜更け', 'パズドラログイン', '作業者', 'ドドリア', 'ザーボン', '飲料品', 'チャレンジスピリット', '舵', '切り方', '渓流', '疑心暗鬼', '軽トラ', 'あまちゃん', '役所仕事', 'dsll', '壮行会', '小関', 'バックスクリーン', '槙原', '嫌らしい', 'クイックルワイパー', '激おこぷんぷん丸', 'スパムメール', 'ダナー', 'hv', 'ロレックス', '弱火', '試作', '各人', '向上心', '芽生える', '生産現場', '駝鳥', '軽車両', '校舎', '落っことす', 'コーン', 'ポタージュ', '拾得者', 'extremevs', 'ガンダムゲー', 'てけない', '司会者', '英単語', 'ギャザ', 'パラレル大回転', '弁慶', '大阪城', 'ディスガイア', '05', 'メガンテ', '伊藤美来', '伊藤未来', 'メカトロ', '改組', '送電', '電気回路', '電子回路', 'm2', 'どっしり', '常人', 'ディープラーニング', '募金詐欺', 'ぼきん', '桂歌丸', 'ショメイ', '伊藤彩沙', '谷地', '聡い', '麻薬', 'やさ', '風紀', '引っ込む', '弦巻こころ', '稲垣吾郎', 'プレミアムエブリデイ', '故意', '電磁気', 'interference', '教習', '赤信号', '鶫', '主要', '安室奈美恵', '判定基準', '手違い', 'ハロハピ', 'ゲーム理論', 'アゴー', '直観的', '抽象', '前島亜美', 'エックシー', '時間割り', '試', '近似', '箱庭', '書き上がる', 'アホガール', 'ボルテージフォロワ', '気取る', '現像液', 'どぼどぼ', 'ブロックノイズ', 'Neural Network', '打ち上げ', '博士課程', 'OVA', 'リーマー', 'バンドリー', '櫻川', 'めぐさん', '記す', '見下ろす', 'ポンコツマスコットキャラ', 'Side Story', '石炭', '可採', '年数', 'コンパイラー', 'ネルミヤ', 'アイフォーン', '工学科', 'ローレンツ', 'qvb', '半導体', 'ラウダー', 'ハッキング', 'The Game', '幕間', 'スターマイン', '日溜まり', 'グリザイア', '適正価格', 'ムービーメーカー', '浪', '堕天', '精神病', 'ネオサ', 'C4', '極座標', '燃料タンク', '漏れ出る', 'フィッシング', '翻訳ソフト', '出稼ぎ', '古く', '仕来り', '美来', '攻略サイト', '野獣', '水性', 'カラーペン', 'オークション', 'フィンガー', 'コリオリの力', '有機', 'シミュレーター', '偏微分', 'ワルトナ', '冗長性', 'マニピュレーター', '協調', 'ポテンシャル', '時間微分', 'ブレット', 'オーム', '手計算', '数量', '中国語の部屋', '思考実験', '合否', '修士', '資格取得', '寝笹', 'プラカード', '専門学校', 'トエイク', 'カーニング', 'をば', '伝授', '花園神社', 'ヒカルの碁', 'ミッフィー', 'じゃんじゃん', 'ミッフィーペン', '誤謬', '論考', 'ミニオン', 'アトラクション', '海老せんべい', '前置き', '年頭', 'なつ', 'ボンボン', '必殺技', '萌絵', '触', '粗い', 'アイサック', 'アイ', 'スピーク', 'イングリッシュ', 'ウェル', 'ひょんな', '回路', 'つり', 'MDF', '緩衝材', '聖教新聞', '看護', '見取る', 'ホームルーム', 'ハンドスピナー', 'BTOB', 'スパイシー丸山', '生計', '巻き上げる', 'ラファエル', '移動教室', '沢庵', '失敗談', 'コジマ', '固有名詞', '呼び名', 'エリーチカ', '命題', '知能', 'ノイマン', 'クオリア', '生物学', '体系', 'リアクター', '進相', '大差', 'レンダリング', 'ぼんくら', '下線', '成熟', 'センシング', 'メソッド', 'ハーモニック', '慣性モーメント', 'チューター', 'ピンはね', 'kV', 'mA', '英和', '辞書', 'ノーマネー', 'エホバ', '眼差し', 'キャリブレーション', 'センサー', 'PA', '聖ウルスラ学院', 'セイント', 'ウルスラ', '学院', 'トーカ', '三森', '筋子', '血液', '大阪上本町', 'パワディレ', '接戦', '対数', '天使大学', '学位記', '補給', 'アァシズキ', 'マワシズキ', 'アクセント', 'ウィニングラン!', '入学金', '余剰', '福井', '大塚紗英', '気負う', 'のぞむ', '外務省', '事務次官', '自由研究', '拘束', 'Newton', '解法', '効率化', '謝辞', '最適化', '紫苑', '取り手', '対称', '一様', '剛体', 'マーカー', '物体', '小節', 'カタルシス', 'ジムノペディ', '花瓶', '古代ギリシャ', 'ラキスト', '志望', '質疑応答', 'あやめ', '習熟度', '認知科学', '浜口あやめ', 'ダイナミクス', 'キネマティクス', '差異', '本文', '実情', '学外', '生体', '准', '売り出す', 'カリスマ', '執事', '執事喫茶', '性質', 'キスマーク', '重み付け', '角速度', '角加速度', '加速度', '哀れ', 'チリチリ', 'レゲエ', '製図', '改竄', 'よしもとばなな', '涼宮ハルヒ', '安物', 'ノベル', 'いい大学', '嗜む', '塩津', '製麺機', 'メス', 'モンスター', '太陽光パネル', '関与', 'ジップ', 'YKK', '魔境', '希望者', 'カバーアルバム', '恋に落ちて', 'jebfes', '初任給', 'ゴア', 'スクリーミング', 'ショウ', 'ファイ', 'ハッピーマテリアル', 'オフレポ', 'テザリング', '奇譚', '東京奇譚集', '上坂', 'すみれ', 'アナスタシア', '千聖', 'relu', 'ミル', 'ボラー', '読み替える', 'すと', '泥酔', '法規', '制定', '禁止薬物', 'チョコレートフォンデュ', 'チーズフォンデュ', '右折', '工', '理科大', '理学', '抱え込む', '前山田健一', 'パスパレ', '入院費用', '異質', '喋り声', '世紀末', 'ORANGINA', 'バイトレ', '装置', 'isuk', '大川隆法', '破', 'デスティニー', '領収', '書き残す', '220', '有意', '模擬試験', '階数', '中抜き', '新瑞橋', '洗面器', '美竹蘭', '弦巻', '粘性', '給付型', 'メ', '割烹', '着々', 'ラズパイ', '傾斜', '泥濘む', '盆踊り', '櫓', 'バータックス', '遣らす', 'ちんちろ', '西木', '汎化', '著しい', 'クソシステム', 'ニューラル', 'ユーチュー', '類似', '参照先', 'ソメ', '留学', '櫻川めぐ', '宇田川', '吾子', 'フルハウス', '多幸感', 'TA', '公開中', 'Lenovo', '書き込む', 'ごっこ遊び', '見誤る', '業務上過失', 'ハーレム', 'もろもろ', '吹き飛ばす', '書き入れ', '取り付け騒ぎ', '中京大学', '宇野昌磨', '計算機', 'ガウス', 'FFT', 'アルゴリズム', '高速化', '上げ足', '深夜労働', '吹き替える', 'Roselia', 'MAD', '仕付ける', '奥沢', '美咲', 'アムウェイ', 'カジノ', '入場料', 'レゴランド', 'パスパレファン', '呼び親しむ', 'スチューデント', '巡回', 'バックプロパゲーション', '畳み込む', 'ディープ', 'ラーニング', 'タノシイ', '論理的', '放尿', '便器', '壁面', 'ベルヌーイの定理', '金属', '日銭', 'アフリカ人', 'アコム', '落とし込む', '連立', '過渡', '特性', '代数的', 'バンドパスフィルタ', '修了', '平衡', '近傍', 'マナカ', '残金', 'ぶんじ', '用途', '抽象化', 'レーン', '初心者マーク', '自己防衛', 'ロボットアーム', 'イージー', 'THAT', '自然数', 'A-Z', '群集', 'ヴァン', 'ガード', '大須', 'ジンジャエール', 'キャズム', 'ゆうちょダイレクト', '纏まり', '赤線', '交通手段', 'べったべた', '敵対者', '法的手段', '新興宗教', '被験者', '自己顕示欲', 'シフトキー', 'リファクタリング', 'ブログ記事', 'スルガ銀行', '保有資産', '水増し', 'クソコラ', '満州', 'キルミーベイベー', '放映', 'リーマン・ブラザーズ', '柱上変圧器', 'ジャーナル', 'ステッピングモータ', '取って置き', 'FORTRAN', '3650', '宮本', '君が笑む夕暮れ', 'SUUMO', '習性', '欠陥', 'パスパレオセロパーティ', '条件式', '書き間違える', '粘度', '橘田', 'ハナゾノランド', 'デビルスティック', '日本刀', 'ブラックスワン', 'SWAN SONG', '東大生', '広告効果', '面取り', 'vier', '̈unf', 'SEVEN STAR', '自制心', 'guangun', '安売り', '解脱', '急逝', '左肺', 'マルチタスク', 'デュアル', 'アキバナウ', '神田明神', 'スンズク', 'ロシア語', 'RYO', 'オイタ', 'フェザーズ', '最後列', '最後尾', '夏の秘密', '初回特典', '跳ね上がる', 'ユメユメエキスプレス', 'スマホシレン', '操作性', 'チート', 'sigfin', '雨避け', '踊らす', '選挙特番', '愛美', 'ベジエ', '送配電', '院卒', '電柱', 'ポピパサイサイ', 'トーキョ', '西部', 'ドーム', '前評判', 'Lark', '桑原先生', 'sice', 'ファナック', '新卒入社', '水準', '窪', 'iPad Pro', 'チームリーダー', '除名', '万能', 'コントレックス', '食中り', '経済犯罪', '安川電機', '介護職', 'Taxi Driver', 'saizen', '下呂', '投票者', '有権者', 'twicas', 'Apple Pay', '素通り', '学割', 'ラインペイ', '詐欺師', '反社', 'フルッタフルッタ', 'アサイー', '上場', '武蔵境', '開演', '香港デモ', 'UACJ', '機械力学', '形而上学', '軍事情報', '協定破棄', '介入', '両成敗', 'ロータス', '邸', '不登校', '教育心理学', '概説', '仁川', 'Hotmail', '流体力学', '明朝', 'タワー', '教育学部', '専攻', '金元寿子', '由貴', '東岡崎', '健康優良児', 'インボイス', '超電導', '高温', '半券', 'セーバー', '容易い', '運ゲー', '希望退職者', '試飲', '基本情報', '申込期限', '電子版', 'katts', 'グリチップ', '家系図', '瀬田薫', '同軸', '世界記録', '技術力', '史学', '走馬燈', '永久脱毛', '目利き', 'フーコー', '重力加速度', '船賃', '船舶', '硫黄', '排出規制', '脱硫', 'メモ書き', '残留', 'ウンケ', '踏み越える', 'ニムト', 'チュッパチャップス', 'グランクラス', '成金', 'ボージョレ・ヌーボー', '屈折率', '代入', 'ヌーボー', '呼び習わす', '香嵐渓', 'ダミーサークル', '参加費', 'qr', 'ブラケット', '井戸型ポテンシャル', '短信', '次期', '矢場とん', '貧民', 'オンス', 'トロイオンス', '助教', '和える', '西武ドーム', '手癖', '255', '襤褸布', '抗鬱剤', '食間', 'Black Friday', 'Cyber Monday', '切り落とす', 'Minecraft', 'ブランド力', 'IPPEI', 'ラプラシアン', '強化学習', 'TensorFlow', 'しみけん', 'ゼブフェス', 'リターン', '逐次', '抽出', '爆散', '針鼠', '盆栽', '攻略法', '安倍政権', 'ジェブ', '一転', '法螺貝', '特融', 'アッベの原理', 'シャフィーボ', 'LaTeX', 'アルファ', '取り急ぎ', 'じぶん銀行', 'yj', '計量経済学', '単純化', '回り道', '変量', '重回帰分析', 'ケプラー', '天体', '円形', '経済学者', '困り事', '見解', '相違', '国家元首', '張作霖', 'ソレイマニ', '横幅', '同一', '司令官', '対比', '大統領', '円満', '弥勒', '下生', '倫理', '体系的', '医療機器', 'ワンセット', '販促', 'シワッシワ', '赤福', 'ハル', '露呈', 'ギリシャ文字', '回路設計', 'ふやかす', '橋本環奈', '厳島', '工事中', '米原', 'UR', '目視', '羽沢', 'つぐみ', '定規', '通信ケーブル', 'ジーウィー', 'Slack', '関西弁キャラ', '褐色', '事業所', 'バーバ', 'マインド', '精神科', 'Brainfuck', '森嶋秀太', '勉強会', '召集', '見せ付ける', 'クソオシャ', '付箋', 'ゆるふわ', 'CAE', 'エラトステネスの篩', '素因数分解', 'ドゥー', 'ウォントゥ', '応用情報', '人工知能', '会計士', '監査', '祝儀袋', '表書き', '慶弔', 'サインペン', '変声期', '甲高い', '郷ひろみ', '男の子女の子', '牧歌', 'ブリュレ', 'ORIENTAL TRAFFIC', '告げ口', '事柄', '頻脈', '二徹', '新潮文庫', '三島由紀夫', 'ミシマ', 'いいひと。', 'タウリン', 'トマト鍋', 'しめ', 'ヴィル', '春琴抄', '感想文', '睡眠障害', 'ネーレーナーイー', 'いかす', '諸きゅう', 'オレンジジュース', 'ふせる', 'ワーカホリック', '前倒し', '気掛かり', '決まり事', '泉鏡花', '初版', 'podcast', '卑屈', 'どついたれ', '白鱚', 'キス', '想像力', '家訓', 'ミニマリスト', '資源塵', '空虚', 'バッターボックス', 'ホームベース', '験', '担ぎ', '野手', '吉本ばなな', 'ラノベ', '血液型', 'ピャッ', 'キウイ', '近県', '同然', '荒れ荒れ', 'note', '梅雨明け', '狆', '躊躇い', 'エスパー', '駿河', 'まんだらけ', '傷心', '打ち拉ぐ', 'カラヤン', 'チョコラBB', 'ねと', '梨泰院', '選び方', '委ねる', '8823', 'オクシモロン', 'さぶ', '愛撫', 'ネコチャン', '意外性', 'ディスカウントストア', '840', 'パンツの日', '贈る', 'ぶく', '大正解', 'Dr.', 'ハウス', '顔文字', '御邪魔', '顧みる', '戻り橋', '旅先', 'ハインツ', '星の金貨', '持続性', '経験則', 'ダヨ', '不労', '所得者', '一堂', '記憶術', '掠れる', 'そり', '底上げ', '二鳥', 'オネシャス', '大海', '曇天', '黄砂', '真っ白', '引き潮', 'フォトジェニック', '長々', 'アベック', 'ツイッタラー', '慇懃無礼', 'ザマァ', '馬鹿と鋏は使いよう', 'プログラマー', '外面', '分け隔てる', '本性', 'さん付け', '素っ気ない', '謝罪文', '乍ら', '船便', '鱚', '温泉に行きたい', 'KUSO', 'シンジ', '失業保険', 'シンジマインド', '脱落', '合皮', 'じゃーん', '人生ゲーム', '時差', 'スタバァ', 'サロベツ', '湯布院', '硫黄泉', '中津', '空き腹', 'メガラテ', '御中元', 'ライセンス', '滾る', '和裁', '訪ねる', '隣り町', 'ツイハイ', 'yogibo', '明け方', 'グルメ番組', 'ヒーローモノ', '善悪', 'フランスベッド', '返信用封筒', '座り心地', '柔らか', '冷やかし', 'バーゲン', 'キャットフィッシュ', 'ショー', '復讐', '異口同音', 'ジーニアス', '不況', 'パソコンケース', 'NASA', '共同研究', 'ナンタラ', '頑丈', '中布', '深紅', '浮世絵', '版権', 'ツーカーレーター', '身空', '打ち合わせる', '見積もる', '年長者', 'キツ', 'モヤァ', 'タダイマー', '乳がん検診', 'チョレギサラダ', 'ノーテク', '4500', '捨て垢', 'RMK', 'アイシャドー', 'ルートビア', 'ガラクタイチ', 'バーガーキング', '店先', '長田弘', '書き手', '陶酔', 'アマプラセール', '練り物', '打ち切る', '他社', '思い馳せる', 'キャンドゥ', '読み捨て', 'ノンアルコール', 'ゲコ', '小技', 'Excel', '節穴', '見抜く', '跡形', '端的', 'プレーボール', '烏の行水', '溌剌', 'インプレッション', 'リムブロミュート', '見城徹', 'アウトルック', '脈', 'ドアノック', 'IMAP', 'がっこ', 'PIC', 'Pig', 'マークイズ', '極めて', '貧窮問答歌', 'ちりり', '仰る', 'マリノア', '冷やかす', 'はてな', '渦巻く', '積', 'ジェシー', '垂れ幕', 'サポセン', 'メール設定', '目玉', 'センキュー', '高額納税者', 'ノンアルコールビール', '英彦山', '習字', '習わせる', '蜜月', '愚直', '勤勉', 'モンタージュ', 'コッチ', 'ぞっこん', 'チョコレートドーナツ', '悪役', '番外編', '業界用語', '一丁前', '無賃', '只働き', '禾', 'キャサリン', 'ハムレット', '目々', '一眠り', 'Uber', 'カリー', 'ちゅう', '除光液', '混入', '粗忽', '厄除け', '嵐山', 'めかす', '杞憂', 'コースター', '発禁本', '横合い', '弘法', '強風', '薙ぎ倒す', 'ピクシブ', '上の空', '泥鰌', '雨除け', '講じる', 'エェー', '限定グッズ', 'コンプリート', '羞恥心', '眠り姫', '休眠', 'クラフト', '墨刷り', '蔵出し', 'ギャラリー', '白川', '使い倒す', 'アンティーク', '祇園', '嬢', '錦市場', 'ロンドン', 'カステラ', 'どろん', '埒が明かない', 'コールセンター', 'しまる', 'ジャーン', 'きしきし', 'オワラセナイト', '名誉', 'テミス', 'ブロンズ', '目隠し', '自己都合', '歯痛', '性癖', '万年筆', 'リクロー', '冬将軍', '延ばす', '歯科', '皮肉', '抜歯', 'リライト', 'ラブロマンス', 'ボヤー', '記憶にございません', '園子', '情死', '鉢', '刺青', '在学中', '芥川', '欄干', '勾欄', '図星', '文章読本', '懇切', '既刊', '表明', 'がっぽり', '印税生活', '申し出る', '罵る', 'てかり', '友田', '松永', '拗れる', 'もう半分', '念ずる', '英国', 'ポエミー', 'デパ地下', '一服', 'マルセイ', '168', 'キロカロリー', 'ちくま文庫', '新潮', '強請る', '文豪', '校閲', '続行', '広辞苑', '公認', 'ァァァ', 'ごたつく', 'カニちゃん', '毛先', 'ぱっつん', '天災', '一次創作', 'スタンス', '流用', '谷川', '俊太郎', '倦怠', '人生観', '起き出す', '虚言', '天網', '恢恢', 'パリン', '読後感', '恥部', '懐疑的', '駄作', '癖字', 'ユニーク', 'イエー', '辛抱', '筒井康隆', '苛立つ', '小者', '辛辣', 'ぱら', '画像データ', 'クソダサイ', 'Evernote', '見てくれ', 'Word', 'とまり', '後追い', '起こし', '予約制', '電子カルテ', '手作業', 'かち', '柔い', 'するする', '市井', '事件性', '漢文', 'うろ覚え', '地理', '公民', '六法', 'クラシック', '保健', 'コスメ', 'ローション', '11000', 'タックス', '関節痛', '腕組み', 'リューマチ', '免疫性', '因子', '今風', '妖怪', '日本放送', '出勤日', '自虐的', '物言い', '目移り', 'スコーン', 'スパイラル', 'だれる', '政治家', 'あばよ', 'ChatWork', 'スラック', 'ガラスペン', '呪術', '正す', '同業者', '東大卒', '医学生', '薬剤師', '国試', '無芸大食', 'ログアウト', '学力', '孤独死', 'エアロバイク', 'プレス', 'あまおう', '東京バナナ', '近しい', 'にしかわ', '怒り狂う', '美貌', '歌手デビュー', '早逝', '憤怒', '冬眠', 'アメドラ', 'ドライブスルー', '米軍', '迷彩', 'インテ', '校長先生', '宿泊税', 'カード決済', '釈然', '河原町', 'ドゥミ', 'ごちゃごちゃ', 'ヨシヨシヨシヨシ', '都そば', '傲慢', '括る', 'リラ', 'リラックマ', '宝飾', 'ジャンポールエヴァン', '茶請け', 'アマレビュ', 'バッグインバッグ', 'ペイパル', 'BS日テレ', 'レコーダー', '税別', '京都迎賓館', 'ノープラン', 'ネトフリドラマ', '堕胎', '黄体ホルモン', '認可', '安全性', '仙洞', 'コウベ', '滅映', 'プリーズ', 'ME', '自殺願望', '自死', '不可解', 'tripadvisor', '厄落とし', 'ハッカー', 'モーニン', '膨れ上がる', 'トランク', '冬服', '骨董', '感冒', '小僧の神様', 'エアリプ', '箪笥', '尼', 'てん', '引き出す', '篦棒', '腿', '東横イン', '別払い', 'インターコンチネンタル', '祟る', '未就学', '嘆ずる', '鬼退治', 'あやかし', '振る舞う', '出来心', '片耳', 'モジャッ', 'モジャ', '面する', '暴走族', '一松', '丸める', '高槻', '中央口', '松坂屋', '三宮駅', '石畳', '好ましい', 'サルセン', '大統領選', 'ヒラリー', '蛸薬師', '場所代', '失笑', '頼り無い', '形状', '汚れ物', '泡立ち', 'LoveLiner', 'スッゲー', 'ぼや', 'テレビ大阪', 'もんじゃ', 'ガガガ', '試用期間', '筆力', 'なあなあ', '意思表示', '宛て先', '投じる', 'テヘペロ', '羊毛フェルト', '神経質', 'ボトル', '間に合わせ', 'ぽつん', '傾げる', 'シェパード', 'The World', 'イーブン', '桃李', '西岸', '唯一無二', 'ブサイク', '呼ばわり', 'シークレット', '商標', '不動', '精算', '画層', '使役', 'ヤオイソ', '肩透かし', '厚手', 'パーラー', '草食系', '頭脳派', '見飽きる', '島原', '見物', 'ラッコ', '局', 'オネーサン', 'チンアナゴ', '京都水族館', '酒豪', '驀地', '錦', '異', '上島', 'シーチキン', '撃沈', '出前館', '中村晃', 'グラシアル', 'レフト', 'レフティー', 'スナイパー', '放る', '指示語', 'あわす', '内野', 'にょきにょき', 'ネーミング', '文庫', '990', 'マグネット', '色味', '道順', '遠退く', '巧拙', 'トリップアドバイザー', '料亭', '気後れ', 'セルフサービス', '守り神', '英語字幕', 'SAL', '航路', '金蔓', '不親切', 'ざます', '手落ち', '士気', '連想', '内川', '退団', '高須クリニック', 'クランクアップ', '物々しい', '厳戒', '態勢', 'ポーズ', '土産物', '化野', '賽の河原', '幽体離脱', '西院', '川原', '極める', '太秦', '水戸黄門', '愉快', '冷やっ', '念仏寺', '無縁仏', '供養', '風葬', 'ぽい捨て', '大覚寺', '高級住宅街', 'ガイドブック', '匂わす', '三浦しをん', '長野まゆみ', '敷居', '黒毛', 'ぎゅう', 'ビーフカツサンド', '内税', '美食家', 'ネロ・ウルフ', '玉石混淆', '博打', '喫茶', 'パーチ', '行き当たり', '闇雲', 'ヘタリア', '上京', '干涸びる', '片手間', '睡眠剤', '身分', '上部', '表記ブレ', 'イチゲルゲ', '十四松', 'ヘビロテ', '算段', '薄笑う', '源泉徴収', '伊藤健太郎', '轢き逃げ', '露出', '東向き', 'ブラインド', '春雨', '脱色', '手酷い', '外国製', '外国産', 'チャージ金額', '夕暮れ', '寺町', 'げこげこ', '洋酒', 'ぎをん', '小森', '身持ち', '快楽', '対岸の火事', '文庫落ち', '阿部智里', 'YLANG YLANG', 'ビジネスセンター', 'JavaScript', '修める', 'かた', '買い手', '座り込む', '変梃', '奥方', '大騒ぎ', '明言', '将軍', '勇む', '真っさら', 'へばり付く', '売り手市場', 'フロリダ', '進々堂', 'クロッカン', 'UFJ', 'イーバンク', 'エースナンバー', '十八銀行', '過激', '同居', '血縁', '全盛期', '年会費', 'ウィルキンソン', '移し替える', '炭酸', '中華粥', 'されど', 'レッド', '料理屋', 'ちょろい', '金毘羅', 'ネットストーカー', 'アンブレイカブル', 'キミー', 'イエスマン', '本アカ', 'リトバス', 'Key', '集団いじめ', '(´<_` )', 'ずーん', '仲介役', '御節介', '弁える', '_(°_°_)_', '客引き', '悪質', '偽善者', '被災者', '重症', '格式', '́д', '怪奇現象', 'レアチーズケーキ', 'ローカル線', '義捐', '年頃', '此方側', 'ピクセル', 'ρ', '(・_・?)', 'アリス', '一挙', '虚脱', 'マリベル', 'ラブライブー', 'LP', 'オワッテル', '落とし物', '(;-;)', 'ケイト', '久野', '嫌悪感', 'cm', '(｡-_-｡)', '慰める', 'LIZ LISA', '遠い目', 'かつら', 'レニー', 'ブラウン', '打っ掛ける', '素足', 'オイスターソース', 'タイバニ', 'りっちゃん', '夢の続き', '雨降り', '波平', 'ジモドルフェスタ', 'ネックレス', '荒らし', 'バシャ', 'ガッシャーン', 'ビチャッ', 'ドジっ子', '点線', '切り取り', '女性用', '大外れ', 'やぶれる', '生誕祭', '!☜_(', '_☜_)', '友チョコ', 'ハイヒールモモコ', 'か弱い', 'ラブライバー', '雨水', 'bsnhk', '夜目', '肉食', '赤面', 'girls talk', '下種', '物語る', '煮立つ', '取っ手', 'もちょ', 'ブルーレイ', 'パンスプ', '〈', 'ガコン', '飛空', '士', '(*^^*)', '税込表示', '税抜き表示', '挟まる', 'ふさふさ', '゜ヘ', 'クールダウン', '暴', 'サリー', '撮り溜め', '味付け', 'ナルド', 'クバーガー', '玉取り', 'くし', '吸水', 'タイヘンダー', '(゜∀。)', '死亡フラグ', '́φ', 'φ', 'さらり', 'ナニモミテナインダー', '暗証番号', '同類', 'プレパレード', 'ドクロちゃん', 'maimai', '入れ替わり', 'ニャル', '自転', '不特定多数', '害する', 'ごめんなさいね', '恐怖心', '震え', 'ゲーム機', '歌姫', 'デビリット', 'エンジェリット', 'ドリア', 'オトモダチ', '相席', '引っ付く', '駅員', '育成', 'ガチャイベ', 'ロナ', 'ヽ(`Д´)ノ', 'ぷち', '後先', '打ちまける', 'SWEET LOVE SHOWER', '押さえ', '雨女', '雪女', '縞', 'ベガス', 'ロナイベ', '体力的', '(。-ω-)zzz', '́ー', '4.5', '著作権', '奥義', '光り輝く', '(* >ω<)', '紙芝居', 'レズ', 'レジュメ', 'プリントアウト', 'お年寄り', 'ふあ', '乙女', '法学部', '出しゃばる', '責任感', '独裁政治', 'ウィクロス', 'WIXOSS', '外税', '善意', '過失', '仕分ける', 'hshs', 'リア充爆発しろ', '変質者', '17000', '別アカ', 'ClariS', '劣等', 'K.', 'みゆきち', 'フラレ', 'ピーチ', 'マキ', 'ゴッドフェス', '知恵', 'つんつん', 'でれでれ', '(*´д`*)', '飾り', '(*´ー`*)', '765', '意気投合', '工具', 'バキュームカー', '無関心', '幕末', '着方', '狡賢い', '夏フェス', 'DQN', '_(_____)_', '(*´▽`*)', '*_)_*).。.:*♡', 'ドキュン', 'ブラックリスト', 'ジョッキ', '7.8', '富士山', '恋愛小説', 'シャル', '魔女', '(^ω^;)', 'ディズニー映画', 'ぼやく', 'マインドコントロール', 'アニサマテンション', '∴', '羞恥プレイ', 'о', '年月', 'EX', 'ギャルゲー', 'ぎとぎと', 'シャフト', '扇ぐ', '出展', 'アニカプ', 'がぶ', '長風呂', 'ψ', '整理整頓', '酔い潰れる', '無双', '久の', 'がたふぇす', 'サキナ', '彡', '┏(', ')┛', '取り締まる', '脱衣場', '無防備', '持ち主', '̅ー', '長門', '大和', '妖精さん', 'ラブホの上野さん', '銭の戦争', 'ブレーブ', '改定', '゜ま', '(*´艸`*)', '失踪', '異性関係', 'ガチレイプ', '赤髪の白雪姫', '山田くん', 'プリズン', '東のエデン', 'steins', 'CLANNAD', 'OPED', 'モー娘', '大型アップデート', '緋色', 'ボルテ', '阿良々木', '突き指', '曾', 'シャナ', 'プラメモ', 'あき', 'リズリサ', '!!', '(｡>﹏<｡)', 'ノコラボ', '゛あぁぁぁぁあぁあ', '鈴木このみ', 'ぶっ', '細工', 'ヲタ芸', 'ミカサ', 'ミク', '漏れ聞く', 'ラバスト', 'ヲタクガチ', '〃', 'ティアラ', '片す', '成田童夢', '三代', '豊作', 'Seraph', 'PSVita', 'ReLIFE', '仲介業者', 'アニメアニメアニメー', '精神的ダメージ', '労', '後回し', 'ストフェス', '白装束', '長髪', 'angelicpretty', '(*_)_*).。.:*♡', 'フリージング', '結婚式場', 'ナルト', 'grayman', 'レーベル', 'がくん', '初恋モンスター', 'がっこうぐらし', 'カードキャプターさくら', '仕様変更', '昔話', 'LINE LIVE', '気配り', '悩み事', '業務上', '関係悪化', '気遣う', 'すっぽり', 'ッキライ', '痛苦', '讓', '( ´-`)', 'アスナ', '_(_『__)', '閉じ籠もる', '体たらく', 'ハンドバッグ', 'ヘアアクセサリー', '1129', 'てぃんくる', 'Loppi', '忘れ去る', 'ガン無視', 'TICK', 'flyer', 'こんがり', 'レバトレード', 'ハネ', '売り時', '910000', '買い集める', '大髭', 'bitmex', '両建て', '原油', 'bitbank', '五', 'ゴーゴービットコイン', '不動産投資', '資本', 'アルゴ', 'ノーウェイト', '要所', '主導', 'ファンダ', '風説', '地合い', '860000', '下髭', '助兵衛', '負債', '1930000', '缶コーヒー', 'アホトレード', 'ドル円', 'SMA', '実体', '上抜け', '授', '建玉', '即座', '吹き上げる', '減資', 'XCP', '誤発注', '目次', '居合わせる', '1.4', '暴騰', '動き出る', 'ドドスコスコスコ', 'バンク', 'ドテンロング', '765000', '急変', 'LS', '733000', '傍観', 'min', 'フルレバ', 'エリオット波動', '両極端', '740000', 'ラインギリギリ', '頭頃', 'ボラヨコヨコ', 'ハートフル', 'サクセスストーリー', '厚板', 'ヒロセ', 'botter', '連動', '阻害', '流入', '見込む', 'kx', 'スッカスカ', '静観', 'ロスカヒゲ', 'trydiff', '売り圧力', 'バカスカ', '買い上げる', '欠く', '無自覚', '難平', '作為的相場形成', '朽ち掛ける', '販売所', 'qtly', 'okex', 'SQ', '売玉', 'レバショート', '案出', '借り物', 'TM', 'ローソク足', 'テックス', 'アトム', '被弾', '承認欲求', '全敗', 'バイナンス', '新手', '130', 'ど下手', 'びり', '担ぐ', 'ロスカ', '答え合わせ', 'NPP', 'シグナル', '引き分け', '押し目', '養分', '陰線', '改正', 'インサイダー', 'オシレータ', 'ユーゾーキャノン', 'ユーゾー', 'トレーディング', 'エリオット', '決め込む', 'アタック', '収支', 'LION', '援助', 'bitflyer', '差し上げる', '6800', '胆力', '726000', '強靭', '消化器官', 'トレードガチ', '大損', 'スプレッド', 'xem', '6000000', '裁量', 'ViX', '荒ぶる', 'ぞろ目', '逆乖離', 'ath', 'リップル', 'トレンドライン', '縮尺', 'へな', '土竜叩き', 'ジェネレート', 'トランザクション', '6370', '6340', 'ゼロカット', 'マイ転', 'ジェミニ', 'コメント欄', '大先生', 'ぷよぷよテトリス', 'Vita', '税率', '鳴り止む', '0.02', 'ダスト', '分身', 'ヒドゥン', '札束', 'フルレバトレード', '足並み', 'FINE', '陽線', 'ペ', '書籍', 'ETF', '可否', '下降', '間接', 'ハット', 'ノートレ', 'ミリオン', 'フリーマン', '縮緬', '砲', '断言', '縮小', 'ジャスティス', 'ぎざぎざ', '溶かす', 'sec', '射幸心', '順張り', '転換', 'BET', 'trx', 'SAT', '補填', 'エンターテイナー', 'クソポジ', 'プラテン', '板寄せ', '南ア', 'オーパーシュート', '580', 'チャトボ', 'エマージェンシー', '夏の終わり', '口座残高', '益', 'Atom', 'arert', '朔日餅', 'アビトラ', 'アビトラマン', 'ヘッジ', '仮装売買', '増し玉', '燃料', 'フィネ', 'PDF', 'LIGHTNING', 'スワップ', 'フィボナッチ', '鍵山', '頼み込む', 'gdax', 'イーサスキャ', '法整備', 'クラウチング', '売り方', '汗水', '邪悪', '鉄火場', 'インジ', '一纏め', '一撃', 'イキスギ', '運用実績', 'にっ', '無敗', '検知', 'イキスギシグナル', '凄腕', '所得', 'もぎ取る', 'シューカツ', 'ジオシティーズ', '265000', '堀北真希', 'クッパ', 'バブル崩壊', '微', 'みやき', '無心', '6600', '査定', 'テック', 'ビューロー', 'プラスファンダ', '下げ幅', '歴史的', 'イケハヤ', 'カルマ', 'サチグッズ', 'フランス料理', '段ボール肉まん', '根幹', 'カウントアップ', '不用意', '持ち前', '就職祝い', '素晴らしき日々', '指数', '新規登録', 'ダウロング', 'デリバティブ', 'ヤッバイヨォ', '清算', '寄り付き', '襲撃', '推移', '託する', 'ビットコイン', 'エンターテインメント', 'スキャン', '累積', '返礼', '病名', '熟睡', '実生活', 'エンターキー', 'バックスペースキー', '日時', '熊取', '出川', 'かんずる', '360000', '残弾', '荒稼ぎ', 'ダスキン', '課税額', 'モンテカルロ法', '興じる', '相当額', '錬金', '金儲け', 'デシニカル', '岐阜', '暴威', '退場', 'ダンガンロンパ', 'センキューグラッチェ', '熊取町', '高野町', '承継', '椅', '子取り', '引かす', '同額', 'シンプソン', 'カチ', 'アポトーシス', '検出', 'ロングヒゲ', 'エントリーポイント', '大学卒業', '叩き落とす', '揺さぶり', '乖離率', 'ハイロ', '380000', '微量', 'ロングナウ', '休学', '端数', 'アイホン', '残量', '東建コーポレーション', '爆速', '買い場', '値動き', '祭壇', 'ストップ安', '嬉々', '富豪', '揺する', '祈祷師', '掘れる', 'ちゅっ', '追いコン', 'rekt', '堅調', 'ワンショット', 'ゆうちょ銀行', 'アンロック', '一般男性', 'bybit', '一有', '熊谷', '在籍', '在学証明書', '累進課税', 'ぽっと出', '一発屋', 'マッチ棒', 'パズル', 'チーズバーガー', '火炎放射器', 'アベノマスクユーザー', 'メル友', '朝山', 'asayama', 'coinexchange', '撫子', 'kimetu', 'YAIBA', '縛り付ける', 'platformio', 'IDE', '掠り傷', '目尻', '斜視', 'ゴマキ', 'ホテトル', '管理費', '木偶の坊', 'サウイフモノニワタシハナリタイ', 'ファンビー', 'プラリア', '縮毛矯正', '盟友', 'ばっさばさ', '好物', '諸悪の根源', '蒸留酒', 'トリマー', 'やんごとない', '東京医大', '凶器', '凶行', '大回り', '本気出す', '酔歩', '強敵', '潮干狩', '踊ってばかりの国', '後頭部', '失神', '簀巻き', '鉄アレイ', '括り付ける', '駿河湾', '沈める', '消え行く', '稚魚', '炎鵬', '177', 'ステロイド', '投与', '176', '78', '審査員', '大量虐殺', 'インディーズ', 'なるい', '二人称', '虚構', '戦前', '反戦', '大全', 'ネットショップ', '不審死', 'efo', 'sgt', 'Indy', 'temples', 'beachwoods', 'ソフトロック', '一年生', 'HUAWEI', '一区', 'ケンちゃん', '裏返す', 'メードインジャパン', 'ユースホステル', '小火騒ぎ', '解れる', 'ボルケーノ', '様相', 'ソーセーズ', '卒業文集', '接点', '内々', '納本', 'アムス', 'ユース', '口論', 'ガンギマリ', 'リヨン', 'フランス人', '摩る', 'キーロガー', '真っ白い', '昭和歌謡', 'ウェーブ', '療養', '療養中', '日向ぼっこ', '減量', 'ロヒ', '厚生労働大臣', 'ピエール瀧', '記憶の海', '初恋', '鷲掴む', '真っ赤っか', 'ライトニング', '充電時間', '社外', 'ショーン', 'Kさん', 'ブラックミラー', 'シャキーン', '飲酒運転', '身代金', '断酒', '梗概', '叙述トリック', '当たって砕けろ', '新機能', '栄進', 'ゼミナール', '熱る', 'マヒトゥザピーポー', '下津', '分家', '現代社会', '選挙人名簿', 'パイプ椅子', '暗黒星雲賞', 'ロビー活動', '進研ゼミ', '谷崎潤一郎', 'カクヨム', 'ミサキ', '常々', 'ロマンス', '薔薇', '官能', '純文', 'レーフラー', 'わあわあ', '海パン', 'ずれ下がる', '団鬼六', '勝目梓', '決する', '恭一', '園内', 'オジ', 'メリーゴーラウンド', '全裸監督', 'ハシヤスメアツコ', 'ディスコ', '探偵小説', '奇書', '足場', '零れ落ちる', '帯びる', '徳永英明', '興行', '文化会館', 'スミス', 'bigmouth', 'STRIKES', 'againand', 've', 'GOT', 'テーク', 'placewith', '星新一賞', 'プライオリティー', '要項', '嘘偽り', '言い張る', 'ファタジー', '呉々', '返り討ち', '看護婦', '稼ぎ時', '血気', '巻き戻る', '起訴', '接見', '判事', '却下', '警官', '悪徳', 'パブ', 'シックス', 'サマナ', '日本グランプリ', '松阪', 'アンソロ', '校正者', '総数', '扉絵', '愛子', '読み解く', 'ハギワラ', '粗捜し', 'イヤホンーブル', 'キ', '読み飛ばす', 'オルタニア', '休み休み', 'サイフアイア', 'ハギワラサン', '淡野', '斎賀', '深澤', '物怖じ', '余儀', 'キュン死', 'ジュブナイル', 'イノセント', 'BOY MEETS GIRL', '中編', 'ダダー', 'グワー', 'ショートショート', 'グワワッ', 'フリマ', '高圧的', '一希', '赤坂天王山古墳', '崇峻天皇', '陵墓', '天皇陵', '宮内庁', '匍匐', '石棺', '幻魔大戦', '中間テスト', '答案', 'ぶっちぎり', '最下位', '地底人', 'noveljam', 'グランプリ', 'アワード', '新人賞', '満', 'チェス', 'テクノロジー', '殺意', '監視カメラ', 'amazonprimevideo', '凍配', '独眼', 'ベトナム人', 'オカネナイ', 'オカネナイカラ', 'カエラナイ', '嗜虐', 'グロテスク', '差し替える', '魔空空間', 'エメーリヤエンコ', 'ノミネート', 'SLIPKNOT', '逆行', 'デュランデュラン', '年齢層', '2005', 'サマソ', '125', '半田', '弦', 'DAW', 'デロンデロン', '丸見え', '塩ラーメン', 'べろんべろん', 'ヤベ', '36.5', 'BIOS', '幻覚', 'クローズドサークル', '精神病院', '山荘', 'ブラックニッカ', '連続殺人事件', '感染症', '溶連菌', '議題', '企画書', 'サイファイ', 'ララバイズ', 'ユダヤ教', 'レビ記', '禁じる', '正統派', 'ユダヤ教徒', '蓄える', '律法', '伝統的', '剃刀', 'はさみ', '勢力図', '加筆', 'ザワークラウト', '廃校', '売人', '鬼怒', 'メシア', 'ハンターカブ', 'ほほう', 'テスト結果', '不覚', '鮎喰', '響', '淵', '傑作', '牧野修', '公司', '剥奪', '20000000000', 'FIA', 'コンストラクター', '自己免疫疾患', '機構', 'MOTO', '舞城王太郎', '五芒星', '芒', 'ノナグラム', 'オーディナリー', 'マクラーレン', 'サウジアラビア', '2000000000', 'バーレーン', '夕間', '暮れ', '木枯らし', '綿毛', '線路', '黄昏', 'インスラ', '防護服', '毛皮', 'マリーズ', 'コーズ', 'esport', '震わす', '鈴鹿', '大仏', '茅渟', '平癒', 'プラズマ', '対戦相手', '厄災', '豪華客船', '時勢', '地球の歩き方', '三人称', 'スタンドアップ', '政治ネタ', 'JUJU', '首相', '怪', '哲学の道', '売り歩く', 'アーティスティック', '再発行', 'アコギ', '領収書', 'パパと踊ろう', '前野健太', '原油価格', '闇市', 'ガリ', '詰め物', 'アガサ', 'クリスティー', '反省会', 'キンドル', '絶海', 'リゾート施設', 'AUDI', 'DTM', 'BMW', 'スーパーGT', '康彦', 'はて', 'ロシアンルーレット', '読書メーター', '転嫁', '擦り抜ける', '椎茸', '舞茸', 'エノキダケ', 'ボッタス', 'ベッテル', 'ルノー', 'アロンソ', 'オコン', '那智勝浦', '発展途上国', '発射', '小説推理新人賞', '次行', '装丁', '家宝', 'ミント', 'アスピリン', '絨毯爆撃', '激論', '誤用', 'You Tube', '政見放送', 'タンメン', '怪文書', '補充', 'ぐびぐび', 'マジョルカ', 'オーディオインターフェース', '諏訪氏', '九十九', '十九', 'ガンマ', '190', '9.8', '調剤薬局', '改稿', '読後', '叩き付ける', 'ubereats', '入力欄', '希代', '無国籍', '逆鱗に触れる', 'アプリオリ', '我孫子武丸', '北野勇作', '小林泰三', '田中哲弥', '田中啓文', '勇次郎', '食レポ', '玉葱', '飴色', 'カレールー', '野次', '更ける', 'シャンパン', 'wonderwall', 'ピット', '絶対王者', 'けり', '真偽', '程', '一行', 'スーパーライセンス', '女児', 'フェルスタッペン', 'アルボン', 'クビアト', 'γ', 'スタンバイ', '俳句', 'ブランキーキタ', 'ベンジー', 'カッチェエ', '標', '詰め替え', '佐藤琢磨', 'フロントロースタート', 'インディー', '書かす', '燕三条', '岩海苔', '背脂', 'イスタンブール', 'もり', '上質', '映像作品', 'アンフェア', 'ミスリード', 'さり気無い', 'レターパックライト', 'レターパックプラス', '取り散らかる', '駆け足', '仲村', '琴', '天皇', '皇太子', '皇太孫', '初い', 'トスカーナ', 'ムジェロ', 'サーキット', 'カサノバ', 'アラビアータ', '文学的', '枳殻', '表彰台', '務め', '団塊ジュニア', 'だん', '男根', 'シニア', 'NAPALM DEATH', 'イップス', 'ざざ', '伯父', 'myheritage', '読み直す', 'ハイパーカー', '大阪王将', 'オール読物新人賞', '人体', 'ハギシン', 'バゲット', 'ラケット', 'amazonmusic', 'DAC', '排他', 'リップス', '片', 'ドリーム・ポップ', 'パルチザン', 'セルパブランキング', '入門', '解読', 'ハプニングバー', 'gotoeat', '焼肉定食', 'ポンド', '福音', 'テレカ', 'モータースポーツ', 'HONDA', '感情的', '足立区', 'ヤンキー', 'susuru', '全年齢対象', '玩具修理者', '用具', 'ナイアルホテプ', 'クトゥルフ', 'ファイター', 'ヒュルケンベルグ', 'ゴートゥーイート', 'セガ', 'yakuza', '砕ける', 'カレーうどん', '加ト吉', '冷凍うどん', '人偏', 'セイユー', '御墨付き', 'マエケン', '作詩', '盗作', 'ポルティマオサーキット', 'ホームストーレト', 'sugo', 'seiyu', 'ガパオ', 'BFC', '予選通過', '吉澤さん', 'ドット', 'コム', '酒代', 'リストラ', 'バノックバーン', 'ネーミングライツ', 'Amazon Music', 'HD', 'リッピング', 'ASIO', 'wasapi', 'ロスレス', '御徒町', '診療科', 'スクリーム', 'ぼろ泣き', 'すぽると', '打ち切り', '純喫茶', '会議室', 'Sally Scott', 'Onitsuka Tiger', 'コンテ', 'ブリングスマイル', 'マークバイマークジェイコブス', 'イルビゾンテ', '紙袋', 'いつかこの恋を思い出してきっと泣いてしまう', '穂', '散り散り', 'すべすべ', '昼時', 'チーズトースト', 'シナモントースト', '女学生', 'ルック', 'THE NOVEMBERS', 'リアルラブ', 'souls', 'コースト', 'シーナ', '銚釐', 'たち', '肩上', 'てくてく', 'ロケバス', 'みな', 'ベルト', 'たも', '運命的', '外出中', 'ぱぱ', 'ユッケジャン', '早技', 'ロイヤルミルクティー', 'だだ', '会いたいから', 'BAILA', '使い心地', '満室', 'へこへこ', '買い出す', 'フィナンシェ', '川谷', '禁句', '試供品', '病弱', '撮影前', 'saxobeat', 'アレキサンドラ', '天真爛漫', '取り柄', '全部好き。', 'LOFT', 'エンゼルフチ', '無表情', 'キティ', '(*`へ´*)', '追加購入', 'ウルトラス', 'お御籤', 'フルコンプ', 'じゅん', '(*^_^*)', 'ブレンディ', '゛でも', 'トミー', 'もちっ', '自分磨き', '微糖', 'ふりふり', 'やい', 'アイノネ', '簡易', 'あさって', 'YEN TOWN BAND', '新曲発売', '押しかけ女房', '鉄則', '妻子', '攣る', 'マリメッコ', 'NARS', 'むぎゅ', '憎', 'どれほど~', '肩身', '映像資料', '楽ちん', '心の問題', '柔道', '競泳', '(o_o)', 'ぼわぼわ', '東銀座', '梵', 'Cocco', '上面', '抱きしめたい', '導き', 'アントラーズ', '姦しい', '恋心', '関ジャニ', 'ふにゃ', 'もが', 'ダゾーン', '伊香保温泉', '不条理', 'レオシルバ', 'クォンスンテ', 'ソガ', '掛け替え', 'よも', '羽衣', '労る', 'スンテー', '酒井高徳', 'センターバック', '控え', '森重', 'ボランチ', '動き回る', '寄せ', '久保原', 'ボールキープ', '出足', 'スーパーサブ', '浅野', 'トップ下', 'さばける', 'タイ戦', 'マイゴッド', '隆行', '死力', '定時退勤', '無失点', '西川', '決定力', '原口', '遠藤', '土居', '永木', '赤崎', '天晴', '2001', '東京V', 'コカコーラ', '埼玉ダービー', 'レッズ', '横浜FC', '都倉', '戦術', '気弱い', '気怠い', '理性', 'シカゴ', 'ファンタジスタ', 'KJ', '口悪', '痛い痛い', '実る', 'ずけずけ', 'ムキー', '石井', 'チョレイー', 'チョレイ', '素人目', '照れ', '久慈', '久冨', '弘中', '花屋', '野草', 'ロケハン', 'はっちゃける', 'フリースタイルダンジョン', 'カズレーザー', 'もく', '走り去る', '焼け野が原', 'あっちゃん', '和やか', '自画自賛', 'LITTLE MERMAID', '白桃', 'レモネード', 'くすみ', '思い違い', '上等', 'アートスクール', 'EVIL', 'シティー', 'cool', '喃先', '喃', 'キリコ', 'FRED PERRY', '(T . T)', 'ネバヤン', '石川直宏', 'ナオ', '向井秀徳', 'ひさ子', 'ナカケン', 'アヒト', 'BURGER NUDS', 'LIXIL', '神々しい', 'HAKU', '増田誓志', '田代', '野沢', '興梠', 'マルキーニョス', '左サイド', '新井場', 'サニブラウン', '冷ややか', 'GINZA', 'sixkalen', 'ウォーカー', 'うっとり', '下ろし立て', 'PAR ICI', '等々力', '競技場', '聖真', '言わずもがな', '末恐ろしい', '画策', 'ニッパツ', '首位', '決戦', '長居スタジアム', 'ずばり', '台頭', 'ちょちょ切れる', '宣告', '薄汚れる', '自棄糞', 'もんぺ', '雨粒', 'mhl', 'ブルックス', '愛敬', 'ハイチ', '不細工', '蔓延る', '死守', '塗り直し', 'エンジェル', 'テキスタイル', 'カドル', '大人の女性', '軽蔑', '幸福論', '裂固', 'ムートン', 'クドカン', '夏帆', 'ねた作り', '千代田線', 'タクシー運転手', '反体制派', '宗派', '在日', '東京モーターショー', 'MACKINTOSH PHILOSOPHY', 'つるとんたん', 'ハトムギ', 'ソウルフード', 'ジュエリー', 'ete', '華奢', '天然石', 'ブレスレット', 'アクアマリン', '愛さない', 'レフェリー', '手強い', 'ビハーレン', 'ゼイワン', 'バーガー', 'ダウナー', 'ノーベンバーズ', 'PiCNiC', '名盤', '強要', '初頭', 'フーリッシュ', 'ツチダ', '可奈子', 'オダジョー', 'ハギオ', '立ち飲み屋', '沖田修一', 'オバ', 'o(`ω´ )o', '天辺', '働き詰め', '吉岡里帆', 'セトウツミ', '池松', '中条あやみ', '山田孝之', '俊輔', 'ネイルサロン', '空気感', '張り裂ける', 'おめでた', '川口能活', 'どかどか', 'カーリング', 'コンクール', 'ペドロ', 'COLORS', 'グッ', 'bshop', 'シンゾーン', '数人', '役者さん', '二階堂ふみ', '微笑む', 'オドモ', '面々', '色数', 'ハリル', '構想', '土居聖真', '掃き溜め', 'コンフィデンスマン', '古沢', '長澤まさみ', '小日向', 'Tacata', 'バカ丸出し', 'ユニバーサル', 'タカタ', 'アダムとイブ', '点取り', '好成績', '飲み屋街', 'キャラメルリボン', '蒟蒻', '残留争い', '43.5', 'チャットモンチートリビュート', 'きのこ帝国', '追い上げる', '美誠', '城戸賞', 'WOWOW', 'lim', 'FC東京', '上位対決', '新婚さん', 'キティラー', '崎山', 'HEAVEN', 'リリース', 'ノエスタ', 'アウェー戦', '勝ち進む', 'トーレス', '鳥栖', 'タカミスキンピール', '急造', '未来のために', '日韓', 'トルシエJAPAN', 'トルシエ', 'ムードメーカー', 'ダバディ', 'ジーコJAPAN', '中田', 'ポリバレント', 'スペシャリスト', 'virth', '猫ちゃん', '話し声', '柳沢', '小ネタ', '万引き', 'コロンビア戦', '酒井宏樹', '混戦', '欲張り', '次戦', '覇気', '東口', '賛否両論', '策士', '勝負師', '61', '正論', '瞬時', '重要性', '一発勝負', '下剋上', '言霊', '開催国', 'OG', 'クロアチア', 'デンマーク', '有望株', 'アイナナライブ', 'アイナナ', 'ポゼション', 'クルトワ', '(°▽°)', 'パスセンス', '汗染み', 'ずっとずっと', '送別会', '読み違い', 'ダイガエ', '市民権', 'オオタニサン', 'マロンクリーム', 'ステーキ肉', '身軽', 'グリーン車', '♪(_____)♪', 'POPUPSHOP', '鮮やか', '脚本家', '地盤', '村上春樹', '速達', '陸上', 'フルメンバー', 'アウトサイダーズ', '其方側', 'サニー', '高崎', 'グラフィティー', '芝居', '効', '演劇', '小劇場', '金足', '誇らしい', 'オパール', '味スタ', 'う', 'キックオフ', '伊東純也', '冨安', '伊藤達哉', '若手組', '吉田昌子', '口軽い', '敢行', '́o', '先制点', 'YOU MAY DREAM', '鮎川', '石橋静河', '潮来', 'IC', '神宮橋', '鬼門', '中学聖日記', '夏木マリ', '町田', '黒岩', '聖', '顔立ち', '魔女の条件', '松嶋菜々子', 'タッキー', '水原', '胸下', '曽ヶ端', 'ウルグアイ戦', '酒井', '南野', 'サチコ', 'ゆうこ', 'こんこん', 'ぼろ負け', '八代目', '市川染五郎', '切れ長', '凛々しい', '準決勝進出', '準々', '前節', '総力', '(о´∀`о)', '闘志', 'マチ', '晶', '羽', '松任谷', '夢子', 'もそ', '行き所', 'モンパチ', \"I'LL BE\", '金崎', 'ベンチ外', '世良', '書記', 'オフィス街', '鈍い', 'DFライン', '安西', '誤算', '出場機会', '有望', '篤人', '大伍', '今冬', '帯同', 'ストライカー', '君臨', '補強', 'モドリッチ', 'キティちゃん', '山口裕子', '大親友', '年忘れ', '韋駄天', '占い師', 'アタル', '罵声', '板倉', '海外移籍', 'フローニンゲン', 'ウズベキスタン戦', 'フリークス', 'サポーター', 'ワシャワシャ', '池江璃花子', '朝焼け', 'ヤマハスタジアム', '倦怠感', 'ドント', 'ノウ', '伊藤翔', '銀座', '倹約', 'Repetto', '繰り上げる', 'アローン', '美術', '食野', '凍える', '自暴自棄', '母性', 'ロシア戦', 'ベルギー戦', 'SUPER SOCCER', 'トゥーロン', 'まざまざ', 'Copa América', '機動力', 'むぎゅー', '萎む', '消え入る', '先々', 'ことちゃん', '低レベル', '目まぐるしい', '愛情', '小池', '白崎', '相馬', '月刊', '長旅', '前触れ', '合計額', 'ハットトリック', 'hondafc', 'ジャイキリ', '田中碧', 'ゴラッソ', '佐々木', 'スカーレット', '時効警察', 'フラッド', 'ニューシングル', 'オーバーラップ', '国立競技場', '戦線離脱', '身震い', '西大', '伍', 'fmvsfc', 'ゴール裏', '自力優勝', '政治的', '退任', '最終戦', '花道', '十二分', '埼スタ', '頂', 'もつ煮', '名古', '新国立競技場', '時たま', '心機一転', 'FINLANDS', '敗戦', 'タイムスケジュール', 'ジャンキー', '乾麵', 'ふかふか', '相談所', '決定機', '正確性', 'ゴール前', '撮り方', 'トラックイン', 'バイオレンス', 'ジョーク', '38.8', 'ラブシャッフル', '香里奈', '面白み', 'パラサイト', 'アカデミー賞', '期待感', '寄生', '貧富の差', '日本的', 'ひるおび!', 'コメンテーター', '賛成', '精神論', '小倉優子', 'こじるり', 'ドーム公演', '43.4', '時差出勤', '脂肪吸引', '浮腫', '腫れ', '術前', '和久田', '才色兼備', '惚れ惚れ', 'イグジット', 'バラエティ番組', '富川', '漢検', 'THEE MICHELLE GUN ELEPHANT', 'ゴールシーン', '松田直樹', 'マリノス', '1993', 'サントリー', 'ワンヒットワンダー', 'ひゅん', 'テツ', 'カリスマ性', '愛していると言ってくれ', '晃次', '紘子', '底抜けに', 'TVer', 'CMソング', '竹原ピストル', '伊参', '映画祭', '幸せの形', '二股', '鎮痛剤', '北杜市', 'シナリオコンクール', 'ナギサ', 'アンサングシンデレラ', '2009', 'シャーレ', '掲げる', 'カメラアングル', '物の怪', '姫観', '佐藤渉', 'ディアペイシェント', '白書', 'アンサング', '桜井ユキ', '真矢みき', '福田組', '眠れない夜', '尺', 'I LOVE YOU', 'イルミナ', '根性論', '浸食', '賑やか', '(^ω^', 'シゲカオースキー', 'MASTER HITS', 'ч', '601', 'お下がり', 'びしょびしょ', 'プロデュース', 'ウェッティケース', 'フラミンゴ', 'スリッポン', '靴底', 'キナリ', '歌ネタ', 'パンカパーナ', 'いちゃつく', '重み', 'Dean Fujioka', 'しゃれおつ', 'きに', '新聞屋', '心乱', '小山慶一郎', 'メダルゲーム', 'ぎんぎん', '和む', '伊野尾', '麗しい', 'サカナクションオシャンティヤナ', 'タツヤフジワラ', 'もたもた', '音楽祭', 'ハロウィン音楽祭', '小声', 'ダビッドソン', '語感', 'DIS', '社交辞令', '替え歌', 'ライフワーク', '摩訶不思議', '(^◇^)', '所作', 'けしからん', 'シゲタイプ', 'ソレダメ', 'えい', '割かし', 'トイプ', '繰り回す', 'カツカレー', 'チュムチュム', 'ぐうの音', '住み分け', 'シゲテンション', 'くい', 'コヤテゴ', 'イケシゲ', '名指し', '楽屋', '中島健人', 'ぬう', '親しむ', '博識', 'めく', '上白石萌音', 'しらいし', '最高峰', 'メガロマニア', 'リピートキメテタ', 'ぷりぷり', '鼬ごっこ', '‘', '成宮', '隔て', 'くむ', '少クラ', 'アラサーアイドル', '言葉遣い', 'ずん', 'ひん曲がる', 'うんざり', 'クリスマスデレメッセージ', '零れ話', '慶三郎', '束縛', 'ファッ!?', '鼠男', '世界遺産', 'テゴちゃん', '同点ゴール', '審判', 'リーディング', 'lis', '和訳', 'オブラート', '喉ちんこ', '(ー_ー)', '♢', '大人の事情', '海星', '地デジ', 'ビューアー', 'トキオ', 'xwwwwww', '÷', '茶の間', 'ヮ', '夜会', '合点', '壁打ち', '厠', '文字盤', 'うん十', '吉井和哉', '野沢雅子', '森川', 'としゆき', 'ともゆき', '奇策', '戒め', '空調', 'たあ', '久', '滲み出る', 'ネオパルパ', 'ドナルドトランピ', 'リーテ', 'ラトバリタ', '体得', '反復', '健', 'フルオンエア', 'リ', 'ガッチャガチャ', 'エロス', '慶', 'むっつり', 'ハラ', '深読み', '延いては', 'MiWa', 'ソングロボ', '天沢聖司', 'ヒロイズム', '侍', 'ヽ(;▽;)ノ', 'シゲスタンプ', 'DR', '64', '剛', 'シゲさん', 'スノー', 'ブレブレ', '天の邪鬼', 'ハスハス', 'ハードボイルド', '鈍感', 'キャッチー', 'kawaii', 'NA', 'shige', 'しげ', '戯事', '末っ子', '須藤元気', '押っ魂消る', 'ш', '引き下げる', '乗っ取り', '運動神経', 'ヒャダイン', 'キャラパレ', '舞い込む', 'スーパーモデル', 'ケイイチロウコヤマ', 'パリコレ', 'クズの本懐', 'newneu.', 'ブイ', 'ぐんぐん', 'ジャニオタ', 'SHUN', '凝らす', '入れ直す', 'キェァァァェェェェァァ', 'MUSIC FAIR', 'リトグリ', '多数決', '書き起こす', '格付け', '嫌われる勇気', 'オカリナ', 'ゴールデンタイム', '罪を憎んで人を憎まず', 'わだ', 'ゴンザード', 'どい', '動勢', 'ベコサス', 'おせん', 'ぷつぷつ', '鈴木おさむ', '赤髪', '信号機', '手越祐也', 'フムフムヌクヌクアパー', '素っ恍ける', '秘境', '薄目', 'あさこ', 'フォーエバー', 'MINE', '通常盤', '零れる', '増田貴久', 'ファンサ', '嵌める', 'テゴパート', '女性ボーカル', '汲み取る', 'いと', 'マイン', '折れ', 'タイムマシン', '消極的', '大器', 'マラ', 'なにやってんの', '水飲み', '等しい', '歯車', '張り上げる', '低音', 'マント', '小僧', 'キラーパス', 'Wonder', 'プランク', 'しげちゃん', '満足感', '少年倶楽部', 'ぐんま', '自転車泥棒', 'レギュラー番組', '特番', 'ベクトル', 'アドラー心理学', 'ネタパレ', '頓服薬', 'うっかりミス', 'フルスイング', '同等', '破壊力', 'スーパーフライデー', '弱肉強食', '役名', '覚', 'シゲアキ', 'カムバック', '百箇', '食べ納め', 'チリツモ', '人任せ', '変ラボ', '湊かなえ', '水神社', 'パイレーツ', 'カリビアン', 'リンパマッサージ', 'ベビーオイル', '油染み', 'キョウ', 'フンダーリケターリ', 'ゔわ゛あ゛あ゛あ゛あ゛あ゛ん゛ん゛ん゛', '゛や゛だ゛あ゛あ゛あ゛あ゛っ゛', '゛れ゛', 'ダオ゛ル', '゛ぐっ゛ざい゛よ゛お゛お゛お゛お゛', '゛る゛の゛め゛ん゛ど゛ぐっ゛ざい゛よ゛お゛お゛お゛お゛お゛', '些か', '゛あ゛あ゛あ゛あ゛', '゛の゛み゛ゅ', '゛じ゛っ゛ぐで゛い゛', '゛じ', '゛れ゛でま゛じだあ゛あ゛あ゛っ゛ぶ゛ね゛え゛え゛え゛あ゛あ゛あ゛あ゛あ゛', 'ぎる', 'サイマジョ', 'コンセプト', '進行形', 'モスキート', '家壁蝨', '阿鼻叫喚', 'ぼっこぼこ', 'プリンプリン物語', 'デルーデル', '疲労困憊', '手付け', '草むしり', 'シャイマス', '安眠', '¬', '配色', 'YAZAWA', 'ちえみ', '◆', '追い出る', '頭寒足熱', '体作り', '栄養失調', '苦言', '゛っ゛ず', '゛ゔめ゛ぎご゛え゛', '一朝', '__________(_', 'しあわせになるために', '閉', 'シタンタン', '塩対応', 'アルプラゾラム', '確かめる', '薬漬け', '八方塞り', 'mauta', '万事', '><', 'ナンプレ', 'ハッフルパフ', '家鴨口', 'センナ', '色遣い', '取々', '否定的', '青文字', '青文字系', '那月', 'カミュ', 'セッシー', 'プリツイ', '到着時刻', '鵜呑み', 'セクゾ', 'ポンパ', 'ボーイ', '雑貨屋さん', '白湯', 'スターター', 'レディー', '貝', '閉院', 'テゴママ', 'ガリットチュウ', '昴', 'ライターズ', 'なるはや', 'つとめる', '久方振り', '点鼻薬', '冫', '動乱', 'チートデー', 'チートス', '嘔吐恐怖', '過食嘔吐', '代役', '片頭痛', 'ずきずき', 'どたキャン', '入退院', '生涯現役', '歌丸', '嵩増し', '音程', '跳ね返す', 'イジ', '金八先生', '゛ん゛じ゛ゃ゛ゔよ゛お゛お゛お゛お゛お゛お゛', '゛って', '熱帯', '犯', 'STILL', 'フルコンボ', '⌒┻━┻', '薬剤', '販', 'カリッカリ', '冷や麦', '心持ち', '筋肉体操', '挫く', '戯言', '宇多田', '悟空', 'フライデー', 'はな', '御自分', '一筆', '待ち惚け', '疎通', 'マイ・ファミリー', '胃薬', '横たわる', '〜__(', '丘', 'epcotia', '高輪ゲートウェイ', '高輪駅', 'マモ', 'やっとこ', '色選び', '≡', '精査', 'クソネミ', '(~(~))~))', 'ノノ', 'ホームアローン', 'イノッチ', 'ダ・パンプ', 'ムラ', '明石市', '辞職', 'hihi', 'jets', 'ゆりやん', 'ピースナウ', '百貨', '大中', 'アルゴンキン', '蛭', '浅野温子', '誤作動', 'カメレオン', 'まさき', '喉風邪', '卑下', '自虐', '源さん', '紙媒体', '山崎賢人', '坂本冬美', '小枝', 'DOES', '四ノ宮', '尊', '淋', 'チャリパク', 'パク', 'ミギハヤミコハクヌシ', '終', '思い入れる', '日米', '条約', 'ガチャチケ', 'ジョニー', '北村匠海', '浮き沈み', '不眠症', '垣根', 'まもちゃん', '小胆', 'UVER', '大流行', 'ソロチャンネル', 'ダースー', 'めきめき', 'まちがいさがし', 'ジャポニカ', 'SixTONES', 'ピエールエルメコラボドーナッツ', '北風と太陽', '後遺症', '伊勢谷友介', '山羊', 'ダボジャビゴギギギ', 'はなちゃん', 'メッサージュ', 'メロサビ', 'DB', 'クアッカワラビー', '塵屋敷', 'ミカヅキモモコ', '紅音', '退所', '絶する', 'タイムテーブル', '今市', 'ロンゲ', 'ミカナカシマ', '愛のかたまり', 'あっちゅうま', '一幕', 'アイド', 'ピーズ', 'Kimonos', 'オワコン', '木久', '首都圏', '立て直す', '差し掛かる', 'ディドロ', 'ポジショントーク', '有り触れる', '躁鬱病', '(汗)', '無作為', '法人化', 'ラジオドラマ', 'NISSAN', '安部礼司', 'アベレージ', '長寿番組', '糸鋸', '粗大塵', 'ピカソ', '147800', 'ガーシュイン', '衣食住', '住', 'デジタルネイティブ', 'つぼ八', '坪', '大金', 'サイレントマジョリティー', '中立的', '編集長', '日本全国', 'ドメイン名', '社外秘', '全世界', '0.0002', '注意点', '文字起こし', '最終更新日', '題する', '売り言葉', 'ノーカット', '試作品', '望ましい', 'フィードバック', 'β', '渡航者', '言わば', 'マネタイズ', '会得', '誹謗中傷', 'インターネット上', 'ニッチ', '取り揃える', '権力', 'インフラ', '定期点検', 'PDCAサイクル', '海外移住', '受け継ぐ', '解決案', '口語', '体言', '感情表現', 'メルマガ', '配信中', '成果物', '個人的見解', '注記', '低減', 'パワーバランス', '運営側', '這い上がる', '海外メディア', 'ランチェスター', '弱者の戦略', '見せ所', '無宗教', '独学', 'デフォルト', '解決方法', '人間の業', '精進', 'イスラム教', 'コーラン', '定命', '定める', '14160000', 'インチ', '根無し草', 'はやす', '三者間', '文化人類学', '自動運転', '広告費', '締め付ける', '温厚', '百姓一揆', '海外展開', 'Google Maps', 'ストリートビュー', '7390000', '1700000', '参加率', '格安SIM', '検索機能', 'セミリタイア', 'キリスト教', '物質主義', '青年期', '老年期', '心境の変化', 'アイデンティティー', 'マイノリティー', '専門用語', '反論', '痛手', '散文', 'LIVEHOUSE DRUM', '野球場', 'サッカースタジアム', '一切皆苦', '統計的', '焼き増す', '安楽死', '安楽', '連鎖的', 'メニコン', 'メルスプラン', '1800', '甘酒', '聞き手', '完読', '実用', '走馬灯', '人生100年時代', '砂時計', 'ジューシー', 'ゴクリッ', '豚バラ肉', 'トピック', 'ストリーミング', '全盛', 'フロイド', '広角レンズ', '大部分', '利益率', '音域', '味醂', 'みりん風調味料', '代案', '大手企業', '日本国内', '金融危機', '定額制', '囲い込む', '必然', '鶏むね肉', '脂身', 'ぱさつく', 'ボイル', 'ビートルズ', '全体像', 'テロップ', '話し言葉', '秒数', 'プレゼンテーション', '結起', '承', '結', '延び', '路上ライブ', '削ぎ落とす', '規約', '±', '爆発力', '年老いる', '養生', '干し竿', 'プランター', '満タン', '鮮度', '2008', 'youtub', 'にほんブログ村', '明るめ', '試行錯誤', '静止画', '視', '透かし', 'ウォーターマーク', 'キリッパワポ', '集客力', '例外的', '条令', '順守', '道路交通法', 'ニュートン', '極大', 'ジグソーパズル', '断片', '持ち寄る', 'ノンフィクション', 'ymyl', '賃貸契約', '前払い', '節税', '零細', '情報公開', '組織化', 'ランチェスター戦略', '管理下', '商用', '埋め込む', 'オープンソース', '出処', '開発元', '診断メーカー', 'Life Is', 'VERY', '樹立', '中期', '慢心', 'Σ(・∀・;)', 'コン', '苦笑', '食事会', '主催者', '取り分', 'イージーモード', 'goo', '同義', '営業妨害', '労働人口', 'ウェブサイト', '等価交換', '部数', '良案', 'トレンドニュース', 'ボノボ', '一役', '公益性', 'Google Search', 'コンソール', '一般公開', 'チャールズ皇太子', 'ラフロイグ', 'キャッチコピー', '何それ', '(・∀・;)', '過信', '適性テスト', '悪名', '悪評', '一理', 'デジタルタトゥー', '単純接触効果', 'ランクイン', 'プログレ', '何十', '熾烈', 'ピンマイク', '単一', '指向性', 'リアカメラ', '自分撮り', '分配', '利点', '厚生', '年金制度', '厚生年金', '言論', 'トゥ', '自己資本比率', '建て直す', '語り掛ける', 'レシーブ', '坂本龍馬', 'レアケース', 'クリスマスソング', '分け与える', 'ひのきのぼう', 'ロバート', 'チェルディーニ', '著', '色弱', '補色', '一時停止', '仕入れ先', 'Galaxy', 'フォールド', '240000', '請け負う', '謝礼', '見定める', '商法', '法令', 'ギブ', '酒蔵', '新潟県', '妨げ', '入選', '鶴嘴', '売り文句', '動機付け', '細分化', 'カテゴリー', '工業規格', '実名', 'bast', 'チャップリン', '喜劇', '(≧▽≦)', '伝記映画', '脱する', 'キャッシュ', '儒教', '例え話', '作物', '飢え', 'アンディ・ウォーホル', '坂本龍一', '労働局', '仲裁', '赤兎馬', '呂布', 'マーフィーの法則', '併用', 'シンクロ', 'コア', '動画配信', '鏤める', 'ハウツー', '同一労働同一賃金', '罰則規定', 'white noise', '噛み', '暴く', '大資本', '小資本', '低品質', 'カメ', '江戸時代', '親しみ', '感じ取る', '資産管理', 'トロフィー', 'ワイフ', '信念', '心理学', '戦い方', '居飛車', '飛車', 'サムネイル', 'AB', 'ドメイン', '後手', '評論', '検索キーワード', 'アンサーソング', '似せる', 'アンサー', 'PAD', 'アンプ', 'davinci', 'resolve', '波形', 'デバイス', 'アダプター', 'AMD', '話題性', 'ツァイガルニク', '心理効果', '映画解説', 'キーワード検索', '未経験者', '牛飯', '290', '会社名', '詐欺被害', '形成', 'ドンキホーテ', '事後報告', 'アニメアイコン', '商品紹介', '生き残り', '初める', '9000000', '後退', '反感', '南半球', '146000', '2433', '101', 'ブラックボックス', '多湿', '太陽光', 'フレア', '蜜蜂', 'アインシュタイン', '食物連鎖', '生産量', '円高', '107', 'スティーブ・ジョブズ', '(~O~;)', '吾輩は猫である', 'エクセル', 'インポート', '社会的証明', '吟味', '年問題', '香川県民', 'ドイツ銀行', '悪手', '重要視', '円安', '株安', '複利', 'COCOON', '東証', '年初来高値', '災い', '飛蝗', '400000000000', '税務署', '(ノ∀`)', '書面', '大安', '熟成', '福沢諭吉', '複式簿記', '偉人', '9.71', 'フリマアプリ', '激化', '1.41', 'やよい', 'クライド', '税理士', 'ボーイング', 'マヤ文明', '皇室', '四民', '黙す', '自由恋愛', '株高', '2.69', '権利落ち', '上げ相場', 'リーマンショック', 'ネット通販', '懸念', '入国', 'ホワイトカラー', 'ブルーカラー', '4.51', '後場', 'ビギナーズ', '築', '飲料水', '特効薬', '予定日', '織り込み済み', 'ボートレース', '必勝法', 'オッズ', '高配', '記者会見', '2.83', '3.19', 'sbisl', 'バイヤーズ', '19500', '提出期限', '都市封鎖', 'オーバーシュート', '爆発的', '世界的大流行', '集団感染', '倍々', '廃業率', '1.84', '0.05', 'JR九州', '2900', '勝負事', '食糧', '自給率', 'カロリーベース', '電子機器', '伝染病', '為替リスク', 'BLOGGER', 'Google AdSense', '独自ドメイン', 'クラウドバンク', 'オーナー', '1918', 'スペイン風邪', '1923', '1929', '昭和恐慌', '1939', '世界大戦', '激動', 'レンタサイクル', 'ドッペルギャンガー', 'TIGER WOODS', 'パット', '打率', '都市', 'ソーシャルディスタンス', 'トルコ', 'テラス', 'ハッチバック', 'リスクヘッジ', '軽視', 'アメリカ同時多発テロ事件', '(^o^;', '決算期', '18100', '絵本作家', '伸し掛かる', '絞り込み検索', '畜産', '提言', '賃料', '通信費', '金融', '株価暴落', '機械化', '健康状態', '経営悪化', '地理的', '機転', 'シェアリングエコノミー', '入門書', 'IPアドレス', '優勢', '寄付金詐欺', '157', '2025', '炙り出す', 'リスキー', '証券口座', '店頭販売', 'クソムズ', '無料コンテンツ', '保険会社', 'ディフェンシブ株', '不景気', 'AdSense', 'ポリシー', '音楽活動', '古民家', '車輪の再発明', '空き巣', 'あしらう', \"—(;'∀')\", '北九州市', '松本清張記念館', 'パワースポット', '休場', '就職活動', 'オンライン面接', '全業', '物理エンジン', '空想科学', '免許の更新', '(^-^;', '住宅ローン', '0.9', '軒先', '御茶屋', '破り捨てる', '都市圏', 'ロックンロール', 'ミック', 'ジャガー', '発祥', 'エチオピア', 'コーヒー・セレモニー', '西友', '醸造アルコール', 'PageRank', '非公表', '潜在需要', 'GAFA', '頭脳戦', '無料配布', '尾道ラーメン', '中古レコード', '被', '富', '草木', 'funds', '日常茶飯事', '新ジャンル', 'クリーニング屋', 'クリーニング', '長期出張', '続伸', '民間資格', '議決権行使', '男性脳', '女性脳', '公会堂', '手形', '茶漉し', '重ね', 'オールド', 'New World', 'コンテナハウス', 'ライフスタイル', 'インデックス投資', '前年', '見え隠れ', 'TOPIX', 'モノレート', 'パッケージデザイン', 'コト消費', 'モノ消費', '土俵', 'マーケット', '失敗学', '人型', '労働環境', '改善案', '膨大', '参入障壁', '定説', '資本主義', '海抜', '吸収合併', '福岡市', '資本金', '損益計算書', '投資家', '自問自答', '災害時', 'ボート', \"Let's Note\", 'キーピッチ', 'ディフェンシブ', '猛暑', 'ゼロサム', 'システムトレード', '勘ピューター', '安定化', '半信半疑', '陳列', '工業製品', '応力', '業界再編', 'ワーム', 'JTB', '公社', '格言', '半値', '割り引く', '潤う', '漁師', 'アパレル', '統計', 'コワーキング', 'ビジネスモデル', '大儲け', '廃業', 'ホイール', '意匠権', 'インフレ率', '長期入院', 'バウンス', '藩政', 'フロントエンド', 'バックエンド', '無糖', '最上階', '角部屋', 'Nice', 'Garbage', 'ゆうゆう', '切り分ける', '依存性', '増強', 'ade', '取り外し', '1200000', '24000000', '職歴', 'SARS', 'MARS', '教育費', '住宅', '購入費', '麦御飯', '鮭', '生もち', '駄菓子', '一平ちゃん', '慰安旅行', 'ドッペルゲンガー', 'ディセンバー', '吉本', 'ナナ', 'ハイスタ', '南太平洋', 'ニューカレドニア', 'マクポ', 'ユーミン', 'ダンダントダンダンダダダント', '知多市', '夕焼け', '異臭', '混ぜ御飯', '他愛', 'アイコ', 'オールウェイズインマイハートステイゴールド', '喫煙率', 'プチオムライス', '古典的', '縫い物', 'センタートーカイ', 'ステーキソース', '吸い物', '火の玉', '水漏れ', '隕石', '新年の挨拶', 'ポコパン', 'オイルヒーター', '薬箱', '去勢', 'あたたかさ', 'ダイヤル', 'トンテキ', 'お笑い', '健康管理', 'チュルリー', 'オセロニア', '蓄膿', '舌苔', 'ツナ', 'ハラショ', 'ホモチョコ', '新井', 'ウーチャン', '富山', 'リュウグウノツカイ', 'お日様', '販売禁止', '三寒四温', '雁擬き', '猫さん', '斜陽', '月明かり', 'バニラシェイク', 'LINEマンガ', 'フルーチェ', '奔放', 'ベイシティ', '観覧車', 'おぼえてる。', 'ウォーク', 'こやま', 'オンバト', '躑躅', '蜜吸', '送り主', 'パコ', 'ロケンロール', '幸福度', 'クルーズ', '蛇行', '空気圧', '薄羽', '蜉蝣', 'アリジゴク', 'トランス', 'ポーター', 'ジェイソンステイサムカッコ', 'ミリオンダラーベイビー', 'ホビット', 'ラッシー', 'フランス映画', '心霊写真', '冷やしラーメン', '関わり合い', 'ラッコズ', 'スーパーカップ', 'バニラ', 'タイタニック', 'ディカプリオ', '粽', 'ドリス', 'ドロー', 'ドロフォー', 'デート商法', '貴理子', '貴理', '廃虚', '竹串', 'ナイロビの蜂', '雨脚', 'BIRTH', 'ちょっくら', '外郎', 'ムッチムチノ', '原田龍二', '松本明子', '塩辛い', 'カギカッコ', 'raiu', 'バレイ', '免許返納', 'エリーゼ', 'ルマンド', 'アムールプレート', 'ピルクル', 'アメトークホト', 'ロンブー', 'あつし', 'あなたがいれば', 'ナミヤ雑貨店の奇蹟', '林遣都', 'ぽつんぽつん', '名古屋弁', '市長', '経血', 'ジャニーさん', '音楽の日', 'インドネシア', '除湿剤', '個人事務所', 'スギちゃん', 'トータルテンボス', '土用', '熱帯低気圧', 'ファンキーガッツマン', '吉本新喜劇', '蚯蚓', 'こま', 'セッ', '煽り運転', '三崎', 'みさき', 'マドレーヌ', 'まこっちゃん', 'ぽっくり', '警戒レベル', 'ポート', 'シーモンキー', 'メープル', 'イカツイオウム', 'ジェティ', '診療所', 'ぽっくん', 'アンゼリカ', '資産家', '蜘蛛の巣', 'ノッティングヒルの恋人', 'ジュリア・ロバーツ', 'セップテンバーラブ', 'bitte', '燦々', 'フロム', '血液クレンジング', '豊明', 'ぱじゃま', '小室哲哉', 'レディボーデン', 'カラースプレー', '活動自粛', 'オザ', '老猫', 'Copicat', 'アウトオブサイト', '怒号', 'イジングスパイダーマン', '爆問', '太田', '不起訴', 'ババシャツ', '英考', '女シリーズ', 'Dlife', '海外ドラマ', '俎板', '鹵簿', 'しがみ付く', 'エリカ', '合成麻薬', 'エリカ様', '無罪モラトリアム', '色褪せる', 'モルヒネ', '病的', 'noki', 'NAOKI', 'マキロン', 'リモコンキー', '踠く', 'ジャガーさん', 'ぴゅう', '炭', 'ポコパンタウン', '燻らす', 'うちの猫', 'ガーナ', 'ピラフ', 'グラコロ', '匿名', '結束', '除夜の鐘', '風情', '検索ちゃん', 'ニューヨーク', '大地震', '緊急会見', 'フット岩尾', 'たけのこの里', 'ホッカイロ', 'ガキ使', '喋くる', 'がやがや', 'レイジ', '平和ぼけ', '島国', 'カツレツ', 'ボーコレン', 'ミサイル', '墜落', 'マフィン', 'ナオコーラ', '不二家', '天白', '火葬', 'サイコメトラーEIJI', 'リッツ', 'チバニアン', '壮大', 'ミステリー小説', '江戸むらさき', 'ショートコント', '針金', 'がみがみ', '鬱憤', 'スピードワゴン', 'ペナルティー', 'アルファルファ', '田上よしえ', 'プラスドライバー', 'アメディオ', '郡司', 'アスレチック', '加藤紗里', 'クエスチョンマーク', 'イヌヌワン', '那覇', '下船', '武漢', 'ちくり', 'CICADA', '暖簾', '向こう側', 'せき', '高須', 'サーベーサーベサーベレジーナ', '蘇', '佐藤浩市', 'チャイニーズ', '菜の花', 'セクシーコマンドー', '外伝', 'プチダブルキャラメルプリン', 'にじいろジーン', 'つくり', 'ビーム', 'カトちゃん', 'アイラブユー', '厚生労働省', '都庁', '福祉', 'ステイヒア', '理美容', 'グレッチ', '肝斑', 'パニック映画', 'くわえる', '底抜け', 'エアライン', '古坂大魔王', 'ピコ', '中岡', '脅迫', 'こうゆう', '志那', '金正恩', 'fishmans', '岡村', '070', '厚労省', 'yt', '山芋', 'LOVE PSYCHEDELICO', 'PIZZA OF DEATH', '浜崎', 'あゆみ', '硼酸', 'ダンゴセブンオッケ', 'カラスノエンドウ', 'メンタ', '寝覚め', 'ギフト券', 'STAY GOLD', '火花', 'まきちゃん', '胃潰瘍', '娼年', '港区中川本町', '立て籠もり', 'パトネット', '狂犬病', '木の実', '飛騨', 'NNN', '西尾', 'アンジャ', 'アンジャッシュ', '爆笑オンエアバトル', '桃太郎', '文春', '乱交', 'サッポロ一番みそラーメン', '豆苗', '時間旅行', '金環食', 'カセット', 'さやか', 'Is this love', '老人と海', '笑顔の行方', '狂気', 'DIFFERENCE', '村上ショージ', '集う', 'ミリオンキッシーズ', '琥珀の月', 'ジグザグジギー', '木下優樹菜', '頭文字', '再インストール', 'メルカリアプリ', '丁', '包み込む', '内蔵', '君に届け', '風早', '注視', 'ダブル浅野', 'イスパニア', 'ぐっさん', '又吉', '純文学', 'さける', 'あいすまんじゅう', 'ナウプレイング', 'パーパー', 'ニッキューナナ', '家庭教師', 'アーユーセックスマシン', 'オゾック', '平針', 'なんだ', 'ハーデンダッツ', '熱田神宮', '寝台列車', 'ロマンチック', '外熱', '亀梨', '水道管', 'シャカラビッツ', 'イーブンイフ', '新喜劇', '鮎', 'リアリティ番組', '藤野可織', '爪と目', 'ちょっちゅね', '豊川', 'パティシエ', 'ハチクロ', 'ネコポス', 'ベイベ', '高橋由美子', 'ラブレターズ', 'ウォールフラワー', 'アンダーソン', 'フィービー', '朋', 'ブラッディー', 'マンデー', 'ヒスブル', 'くりくり', '空気階段', 'ジャンポケ', 'フラカン', '深夜高速', '江國香織', '形式的', 'アポパイ', '異臭騒ぎ', 'ゲコゲコ', '弓', 'イケオジ', '吉川', '晃司', '西本願寺', '伏見区', 'シンデルヨオ', '五条', '事業所得', '雑所得', '持続化給付金', '支援策', '低所得', '減収', '進言', '適用範囲', '施策', '脱毛', 'mogmog', 'かんな', 'ニャンズ', 'ベルマート', 'カズチー', '還付金', '猶予', '給与所得者', '休業手当', 'リモートデスクトップ', '通信速度', '経産省', '手順', '桶狭間', '減免割合', '玄関先', '米子駅', '左衛門', '焼き鯖寿司', 'カリオストロの城', 'ガンバリウス', 'うさぎや', 'パッカーズ', 'さいとう', '手羽先', 'ジョージフォアマングリル', '小松菜', '煮浸し', '和え', '天橋立', '意味深', 'トクロン', '立腹', '誤読', 'ヤシオリ', '最終組', '蛸部屋', '押し込める', '下っ端', '部下', 'まじ切れ', '環境構築', '温泉ホテル', '川久', '伊根', '舟屋', '伊予灘ものがたり', 'しまなみ海道', '下呂温泉', '乳頭温泉', 'クレープリーチロル', '遊山箱', 'さわ', 'クリン', '讃岐うどん', '浦上', 'フルーツパーラー', '岩魚', '由比', '桜海老', '掻き揚げ', '利久', '牛たん', '肥薩', 'おれんじ', 'コース料理', '大虐殺', '陽性', '普通電車', '特急列車', '成る丈', 'ドキュメント', '設計書', '日食', '計算式', '致命傷', 'リーメント', '高木先生', '目鼻', 'センタン', 'すくり', 'タロットカード', '虫眼鏡', 'そげえ', 'せせり', '部位', '所さん', 'ジョンソンアンドジョンソン', 'パンパース', '引換券', '満鉄', 'タロット', 'アルカナ', 'タンク', '断末魔', '朱華', '脊髄反射', '品質向上', '中傷', 'helltoyou', 'ソウルジェム', '大葉', '刻み入れる', 'たえ', 'xz', '区民', '広島市', '葬儀', '混み合う', 'にる', '時田', '博士', '平沢進', '小口', 'KATO', 'ココリーメント', 'odoria', 'ho', '鼻息', 'UNIX', 'UX', '3050', 'ワイングラス', 'モーグリ', 'チョコボ', '時効', '( ^ω^)', 'ひじきの煮物', 'モイ', '小型犬', 'おけい', '深度', 'シャウエッセン', 'サラミ', 'ウーロン茶', 'パワポダメ', '先祖', '彼の世', '終点', 'フォション', 'アップルティー', '区内', '324288470', '通じ合う', '永劫', '梃入れ', '鳥取市', '米子市', '皆生温泉', '言い当てる', 'ビデオチャット', '現象学', '主演', '柴咲コウ', 'おんな城主直虎', 'HITAC', 'ナツカシス', '水無月', '緩', '厚切り', 'ビンカンペットボトル', '船場', 'センタービル', '個人商店', '集合体', '号館', '問屋街', '南洲', '用語集', 'ハイタック', 'ビットマップ', 'アセンブラ', 'COBOL', '機械語', '宣う', 'イーグル', 'vosk', 'ウインドー', 'FD', '入出力', 'DAEMON', 'プロセス制御', '研究所', '調査報告書', '駆り出す', '高専卒', '松藻', '略号', '本部長', '省略', '湯婆婆', '珠', 'ネコタ', '狭間', '侵食', '船井総研', 'NAVERまとめ', '忖度', 'GT', 'テキストエディタ', '摘出', 'まどろっこしい', '現役引退', '買い物カゴ', 'モーター', '一掃', 'everybady', 'キョウカショ', 'モッテマスカー', 'モッテナイヒトハ', 'plese', 'カリテクダサーイ', 'AT', 'オンライン授業', '西浦', '酷暑', '雲行き', 'WEST', '山陰', '昼行', '松江', '代用', '天地', '運行', '李', 'アイスクリーム', '宝石箱', 'バニラアイス', 'ぷちぷち', 'オナシャス', '降り止む', '人吉', '青井阿蘇神社', '日帰り温泉', '同月', '落ち込み', '素振り', '踏ん切り', '自伝', '二部', '大学教員', '不死鳥', 'トクロンティヌス', '総量', 'フォト', '引き抜く', '天王山', '自家製', 'レモンスカッシュ', 'よつ葉', '加塩', '修正依頼', '口座振替', '依頼書', '徴収', '可聴', '嫌がらせ', '眠りこける', '追い出す', '快活', 'AOKI', '見込み額', '試算', '支給要件', '老若男女', '異常者', '代表格', '学生さん', '薄切り', '塩揉み', '生麩', '半兵衛', '麩', '嘉', '瞬発力', '転がり込む', '二の足', '大名', '越後', '千石', '柴田屋敷', '出羽', '不釣り合い', 'つうかあ', '宅地', '建売住宅', 'アパマン', 'ガンバリウスプラン', 'OTA', '古語', 'かご', '川合', '孝', '楕円形', '盛り', 'ブチャラティ', '酒乱', 'PUREPURE', '入信', '卒業論文', '打ちかます', 'あま', 'グルル', 'デビルマン', 'クライ', 'ピザトースト', '薬売り', 'セメント', '陥没', '対象外', '旅行代金', '還付', '実費', '目通り', 'michiro', '請う', '両面テープ', 'デッス', '長辺', '1024', '不平', 'KBS', '蛭子', '関西圏', '異物', '範囲指定', 'マグニチュード', 'crybaby', '午後の紅茶', 'おいしい季節', '男爵', 'ハッシュドビーフ', '餅屋', '魚屋', 'サンキュー', '別枠', '1973', '年版', '丹波哲郎', '小林桂樹', '二谷英明', '国土', '仄か', '祇園祭', '真っ盛り', '農作物', '698', '改葬', 'クラゲゾーン', '腐海', '雑学', 'チーズティ', '期初', '志津屋', 'カルネ', 'スイカパン', 'ボローニャ', '京都府', '予断', '密', '絶句', '直親', '塾代', 'ポヤァッ', 'シャカイ', '証明書', 'オーバーフロー', '学生支援', '定額給付金', '750000', '420000', '230000', '不透明', '近鉄奈良駅', '大和八木駅', '母方', '取り合う', '国立', '見逃し三振', '(●´ω`●)', '抗癌剤', '若年', '化学療法', 'ハーセプチン', 'ムネアツ', '根管', '仮止め', '10500', '地表', 'カーチャン', '絶縁', 'バズツイート', 'ぶら下がる', '絵図', '立誠', '建造物', '商家', '出し合う', '洋館', '自彊', '典型的', '見計らう', '渡辺橋駅', '渡辺橋', '淀屋橋', '真夏日', '汚物', '組み上げる', '記事化', '分業', '枝葉', '末節', '泥臭い', '勘所', '寿司職人', '擬装', '巧妙', 'ゾラ', '注', '訴え', '狙い目', 'キャプチャー', '現役時代', 'ジュリ', '堪忍袋', 'シャー', 'ora', 'フェリー', '丸洗い', '虐待', 'ギャァギャァ', '鎖骨', '鎖', '突き刺さる', 'ビアレストラン', '三脚', 'スタジオマジ', 'dsc', 'hx', '720', 'さそり座', '蠍', 'ファサード', 'ウエーイ', 'シェラメール', '滋賀県大津市', 'マジカーマジカー', '四条河原町', '志布志港', '鹿児島市', 'レバレッジ', '鳩尾', '駆け抜ける', '浅蜊', '蛤', '踏襲', '芸術', '医療センター', '涼しい顔', 'CTRL', '泣きべそ', '打ち直す', '施す', '向日葵畑', 'SES', 'ウマウマ', 'AQUAPAZZA', 'トマト缶', '合い挽き肉', 'ゲプー', '398', '198', '山下達郎', '拾得', 'データベース', '巨大企業', '乾き', '吊るす', '種子', '主キー', '意訳', 'アンデルセン', '1970', 'シェープ', 'メタファー', '満ち満ちる', 'イエエ', '寝静まる', '無症状', '大丸', '定型句', '組織内', '東海林', '六郎', '葬儀屋', '木林', '宍戸さん', '一種独特', 'ミー', 'ゴールズベリ', '大切り', '立ち向かう', '忌野清志郎', 'パンフォーカス', 'ガチピン', '被害状況', '吉村', 'カバネリ', '乱', '千田町', '付', '教育実習', '教員免許', 'テヘ', 'フリーライド', 'さんじゅう', '震え声', 'ボットン', '便所', '路地', 'パングラタン', '油蝉', '出汐', '爆心地', '3.6', '比治山', '北西', '緑井', '生々しい', 'ジョブ型雇用', '安佐南区', '府中町', '大洲', '海田市', '広島市内', '黄金山', '麓', '東千田', '三篠', '御幸橋', '遊び場', '密集', '郊外', '持ち家', 'コンパイル', 'シベリア抑留', '手記', '自費出版', '琺瑯', 'mimoza', 'デビュー戦', '汁物', '人選', '新聞記者', '戦況', '一郎', 'スペ', '舞台裏', '六角精児', '殺戮', 'セミファイナル', '立秋', '忍び寄る', '上流', '下流', '顕在化', '1981', '青葉学園物語', 'シッター', 'ポン', '精神的負担', '御漏らし', '寝方', 'ど突く', 'ソルベ', '刑', '輪切り', 'べったり', 'ペンション', '流れ弾', '注意喚起', '青函トンネル', '森駅', '下灘駅', '山陽本線', '山口県', '臨床', '対義語', 'レファレンス', '参照', '前頭葉', '外見', '斜め上', '11980', '時系列', '1.1', '伯耆町', '事後', '破格', '交通機関', '足立美術館', '出雲大社', 'フルーツカフェサエキ', '焼き魚', '煮魚', '流動的', 'チームバチスタシリーズ', '烈子', '仲村トオル', 'チーム・バチスタ', 'ユージ', '乗り移る', 'ビルゲイツ', 'バフェット', '書き換わる', '辞意表明', '商社株', '点火', 'のほほん', 'インターン', '放浪', '大人びる', 'ネットパス', 'キャンセル料', '損金', 'ちぐはぐ', '京町家', '楽園', 'ハッシュドポテト', '胡麻団子', '中道', '飛散', 'ケツスリスリダンス', 'フッルーイ', '売り家', '隣家', '走り抜ける', '最大限', '活性化', '腐心', 'ハンジ', 'エルビン', '調査兵団', '飛行艇', 'インターネットバンキング', 'みずほ', 'セキュリティ事故', '天草', '鞭打つ', '底辺', '(; ・`д・´)', 'コルネ', '北京', '本通り', '路面電車', '広島弁', '南区', 'カタ', 'いい生活', '八丁堀', '福屋', '松葉', 'カツ丼', '瞬断', 'クレイア', 'フレイヤ', 'モニョ', '胸突き', 'Paypal', '14000', 'ローンチ', '松重豊', '窪田', '社会保険料', '税込み', '可処分所得', '賑わい', '揺り戻し', '反吐', '向井', 'ブロークン', 'しゃんしゃん', '血流', '電化', 'すっぽん', '肉球', '画角', 'スナ', 'フジタ', 'batis', 'ぶん回す', '広島太郎', '竹中直人', '似', 'レオパレス', '入居者', '四条烏丸', '乗換案内', '住道', '難読地名', '八尾', '布施', '繁華街', '移動量', '突き当たる', '木霊', 'デザイン性', 'マクロ', '広角', '刑期', '中崎町', 'クリームシチュー', 'ヨドバシ梅田', '馬介', '左馬助', '側近', '対称性', '広大', '会館', 'シェラトン', '浅はか', '亭', 'トランプ大統領', '夫妻', 'didi', 'みゅうみゅう', '一軒家', '廃屋', '無情', '高島屋', '見回り', 'オバチャン', '引きちぎる', '憤慨', '花輪', '訥々', '牛筋', '仕入れ', '複合商業施設', 'チェーン店', '佃煮', '下鴨', '枚挙', '割引チケット', '割引率', '食用', '酸漿', '宿る', '先行き', '暗示', 'ハードディスク', '香取神宮', 'ロイターポーセリン', '無利子', '元金', '蒸し', '区切り', '高利貸し', '談義', '見立', '下体', '滑らか', '蒸かし芋', '安納芋', '弘乳舎', 'パエリア', 'ガンガントルコリラ', '急落', '再始動', 'ナイナイ岡村', '最年長', '営業開始', '城崎', '湯巡り', '兄子', 'ひよっこ', '既成', '食品サンプル', '本社', 'tjo']\n"
     ]
    }
   ],
   "source": [
    "# 出現頻度が少ない単語をstopwordとする\n",
    "def stopwords_occur(textlist, threshold):\n",
    "    morphemelist = [tokenizer_obj.tokenize(text, mode) for text in textlist]\n",
    "    words = []\n",
    "    for morpheme in morphemelist:\n",
    "        for word in morpheme:\n",
    "            words.append(word.normalized_form())\n",
    "    dic = collections.Counter(words)\n",
    "    dic = {key:value for key, value in dic.items() if value<= threshold}\n",
    "    return list(dic.keys())\n",
    "\n",
    "clear_part_of_speech_list = [[\"助詞\", \"助動詞\"],[\"数詞\"]]\n",
    "\n",
    "with open(datapath + \"stopwords.txt\") as f:\n",
    "    stopword_list = f.read().splitlines()\n",
    "\n",
    "stopword_occur = stopwords_occur(train_text, 2)\n",
    "\n",
    "stopword_list.extend(stopword_occur)\n",
    "print(stopword_list)\n",
    "\n",
    "train_data = text_cleaning(train_text, mode, clear_part_of_speech_list, stopword_list)\n",
    "dev_data = text_cleaning(dev_text, mode, clear_part_of_speech_list, stopword_list)\n",
    "test_data = text_cleaning(test_text, mode, clear_part_of_speech_list, stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.9.3)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.24.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = (30000, 9801)\n",
      "trainlabel = (30000,)\n",
      "dev = (2500, 9801)\n",
      "devlabel = (2500,)\n",
      "test = (2500, 9801)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "train_tfidf = vectorizer.fit_transform(train_data)\n",
    "dev_tfidf = vectorizer.transform(dev_data)\n",
    "test_tfidf = vectorizer.transform(test_data)\n",
    "\n",
    "train_vec = train_tfidf.toarray()\n",
    "dev_vec = dev_tfidf.toarray()\n",
    "test_vec = test_tfidf.toarray()\n",
    "\n",
    "print(\"train = \" + str(train_vec.shape))\n",
    "print(\"trainlabel = \" + str(train_label.shape))\n",
    "print(\"dev = \" + str(dev_vec.shape))\n",
    "print(\"devlabel = \" + str(dev_label.shape))\n",
    "print(\"test = \" + str(test_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 500 candidates, totalling 1000 fits\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9959372753607982, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9959372753607982\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5479896290647852, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5479896290647852\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.544379430610996, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.544379430610996\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7084051625013859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7084051625013859\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 1.50513\n",
      "[CV 1/2] END bagging_fraction=0.5479896290647852, bagging_freq=9, feature_fraction=0.7084051625013859, lambda_l1=3.9959372753607982, lambda_l2=3.544379430610996, learning_rate=0.05, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=50, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.326 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9959372753607982, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9959372753607982\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5479896290647852, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5479896290647852\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.544379430610996, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.544379430610996\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7084051625013859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7084051625013859\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.49901\n",
      "[CV 2/2] END bagging_fraction=0.5479896290647852, bagging_freq=9, feature_fraction=0.7084051625013859, lambda_l1=3.9959372753607982, lambda_l2=3.544379430610996, learning_rate=0.05, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=50, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.331 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.934598189798967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.934598189798967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.688911601204926, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.688911601204926\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10602053900659741, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.10602053900659741\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7221194754786714, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7221194754786714\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's multi_logloss: 1.49797\n",
      "[CV 1/2] END bagging_fraction=0.688911601204926, bagging_freq=7, feature_fraction=0.7221194754786714, lambda_l1=2.934598189798967, lambda_l2=0.10602053900659741, learning_rate=0.01, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=227, objective=i, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=4;, score=0.330 total time=   9.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.962420690019447, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.962420690019447\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48734046972006345, subsample=0.5 will be ignored. Current value: bagging_fraction=0.48734046972006345\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.970749862037039, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.970749862037039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6211833441003494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6211833441003494\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.49574\n",
      "[CV 1/2] END bagging_fraction=0.48734046972006345, bagging_freq=3, feature_fraction=0.6211833441003494, lambda_l1=7.962420690019447, lambda_l2=9.970749862037039, learning_rate=0.2, metric=multi_logloss, min_child_samples=17, num_class=5, num_leaves=270, objective=c, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.328 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.895490272513732, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.895490272513732\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6317838284721253, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6317838284721253\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.764609217357015, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.764609217357015\n",
      "[LightGBM] [Warning] feature_fraction is set=0.849623143205043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.849623143205043\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's multi_logloss: 1.49716\n",
      "[CV 2/2] END bagging_fraction=0.6317838284721253, bagging_freq=6, feature_fraction=0.849623143205043, lambda_l1=6.895490272513732, lambda_l2=2.764609217357015, learning_rate=0.2, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=473, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=256;, score=0.328 total time=   6.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.1424997495376, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.1424997495376\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6888893903801346, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6888893903801346\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.728967081186351, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.728967081186351\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47801318217632716, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47801318217632716\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 1.5149\n",
      "[CV 1/2] END bagging_fraction=0.6888893903801346, bagging_freq=4, feature_fraction=0.47801318217632716, lambda_l1=8.1424997495376, lambda_l2=9.728967081186351, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=408, objective=l, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=128;, score=0.323 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.1424997495376, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.1424997495376\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6888893903801346, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6888893903801346\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.728967081186351, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.728967081186351\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47801318217632716, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47801318217632716\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 1.50127\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.234311750954802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.234311750954802\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46809308313618975, subsample=0.7 will be ignored. Current value: bagging_fraction=0.46809308313618975\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7206340463327505, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.7206340463327505\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9458023938331066, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9458023938331066\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's multi_logloss: 1.50034\n",
      "[CV 1/2] END bagging_fraction=0.46809308313618975, bagging_freq=9, feature_fraction=0.9458023938331066, lambda_l1=8.234311750954802, lambda_l2=3.7206340463327505, learning_rate=0.2, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=73, objective=u, reg_lambda=1e-05, subsample=0.7, subsample_freq=4;, score=0.315 total time=   7.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.094025588678599, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.094025588678599\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9503161294225088, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9503161294225088\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.059180025855623, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.059180025855623\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8181378168175275, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8181378168175275\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's multi_logloss: 1.49652\n",
      "[CV 2/2] END bagging_fraction=0.9503161294225088, bagging_freq=9, feature_fraction=0.8181378168175275, lambda_l1=5.094025588678599, lambda_l2=8.059180025855623, learning_rate=0.05, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=216, objective=u, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=256;, score=0.329 total time=   6.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.9320036167568, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9320036167568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6171177266973288, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6171177266973288\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8610635629932628, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.8610635629932628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7191732907901032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7191732907901032\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's multi_logloss: 1.5023\n",
      "[CV 1/2] END bagging_fraction=0.6171177266973288, bagging_freq=5, feature_fraction=0.7191732907901032, lambda_l1=2.9320036167568, lambda_l2=1.8610635629932628, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=50, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.329 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.9320036167568, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9320036167568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6171177266973288, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6171177266973288\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8610635629932628, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.8610635629932628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7191732907901032, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7191732907901032\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.49891\n",
      "[CV 2/2] END bagging_fraction=0.6171177266973288, bagging_freq=5, feature_fraction=0.7191732907901032, lambda_l1=2.9320036167568, lambda_l2=1.8610635629932628, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=50, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.329 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.962420690019447, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.962420690019447\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48734046972006345, subsample=0.5 will be ignored. Current value: bagging_fraction=0.48734046972006345\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.970749862037039, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.970749862037039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6211833441003494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6211833441003494\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's multi_logloss: 1.49216\n",
      "[CV 2/2] END bagging_fraction=0.48734046972006345, bagging_freq=3, feature_fraction=0.6211833441003494, lambda_l1=7.962420690019447, lambda_l2=9.970749862037039, learning_rate=0.2, metric=multi_logloss, min_child_samples=17, num_class=5, num_leaves=270, objective=c, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.330 total time=   6.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.855881763917828, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.855881763917828\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8702548964507482, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8702548964507482\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6303873294121812, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.6303873294121812\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9819275927264565, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9819275927264565\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.4984\n",
      "[CV 1/2] END bagging_fraction=0.8702548964507482, bagging_freq=8, feature_fraction=0.9819275927264565, lambda_l1=5.855881763917828, lambda_l2=0.6303873294121812, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=179, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.329 total time=   9.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.170558761641159, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.170558761641159\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44245024243723224, subsample=0.6 will be ignored. Current value: bagging_fraction=0.44245024243723224\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1688352036536975, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.1688352036536975\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9401878094818684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9401878094818684\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=8 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's multi_logloss: 1.49459\n",
      "[CV 2/2] END bagging_fraction=0.44245024243723224, bagging_freq=4, feature_fraction=0.9401878094818684, lambda_l1=9.170558761641159, lambda_l2=2.1688352036536975, learning_rate=0.05, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=269, objective=l, reg_lambda=1e-05, subsample=0.6, subsample_freq=8;, score=0.330 total time=   8.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.234311750954802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.234311750954802\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46809308313618975, subsample=0.7 will be ignored. Current value: bagging_fraction=0.46809308313618975\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7206340463327505, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.7206340463327505\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9458023938331066, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9458023938331066\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 1.49829\n",
      "[CV 2/2] END bagging_fraction=0.46809308313618975, bagging_freq=9, feature_fraction=0.9458023938331066, lambda_l1=8.234311750954802, lambda_l2=3.7206340463327505, learning_rate=0.2, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=73, objective=u, reg_lambda=1e-05, subsample=0.7, subsample_freq=4;, score=0.325 total time=   7.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.094025588678599, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.094025588678599\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9503161294225088, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9503161294225088\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.059180025855623, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.059180025855623\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8181378168175275, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8181378168175275\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 1.50013\n",
      "[CV 1/2] END bagging_fraction=0.9503161294225088, bagging_freq=9, feature_fraction=0.8181378168175275, lambda_l1=5.094025588678599, lambda_l2=8.059180025855623, learning_rate=0.05, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=216, objective=u, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=256;, score=0.327 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.934598189798967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.934598189798967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.688911601204926, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.688911601204926\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10602053900659741, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.10602053900659741\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7221194754786714, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7221194754786714\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid_0's multi_logloss: 1.49722\n",
      "[CV 2/2] END bagging_fraction=0.688911601204926, bagging_freq=7, feature_fraction=0.7221194754786714, lambda_l1=2.934598189798967, lambda_l2=0.10602053900659741, learning_rate=0.01, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=227, objective=i, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=4;, score=0.331 total time=  10.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.895490272513732, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.895490272513732\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6317838284721253, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6317838284721253\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.764609217357015, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.764609217357015\n",
      "[LightGBM] [Warning] feature_fraction is set=0.849623143205043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.849623143205043\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 1.49778\n",
      "[CV 1/2] END bagging_fraction=0.6317838284721253, bagging_freq=6, feature_fraction=0.849623143205043, lambda_l1=6.895490272513732, lambda_l2=2.764609217357015, learning_rate=0.2, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=473, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=256;, score=0.331 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.855881763917828, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.855881763917828\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8702548964507482, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8702548964507482\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6303873294121812, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.6303873294121812\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9819275927264565, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9819275927264565\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.49294\n",
      "[CV 2/2] END bagging_fraction=0.8702548964507482, bagging_freq=8, feature_fraction=0.9819275927264565, lambda_l1=5.855881763917828, lambda_l2=0.6303873294121812, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=179, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.329 total time=  10.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.580185807188986, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.580185807188986\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8077330734846755, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8077330734846755\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.571664879919302, reg_lambda=0 will be ignored. Current value: lambda_l2=8.571664879919302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.588152994235987, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.588152994235987\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's multi_logloss: 1.50923\n",
      "[CV 1/2] END bagging_fraction=0.8077330734846755, bagging_freq=8, feature_fraction=0.588152994235987, lambda_l1=7.580185807188986, lambda_l2=8.571664879919302, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=240, objective=a, reg_lambda=0, subsample=0.5, subsample_freq=64;, score=0.324 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.960548299094741, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.960548299094741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9679332883898306, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9679332883898306\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7991926769347266, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.7991926769347266\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8850013821517814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8850013821517814\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1008]\tvalid_0's multi_logloss: 1.49733\n",
      "[CV 1/2] END bagging_fraction=0.9679332883898306, bagging_freq=2, feature_fraction=0.8850013821517814, lambda_l1=7.960548299094741, lambda_l2=2.7991926769347266, learning_rate=0.01, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=404, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=32;, score=0.333 total time=  27.6s[CV 2/2] END bagging_fraction=0.6888893903801346, bagging_freq=4, feature_fraction=0.47801318217632716, lambda_l1=8.1424997495376, lambda_l2=9.728967081186351, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=408, objective=l, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=128;, score=0.329 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.170558761641159, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.170558761641159\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44245024243723224, subsample=0.6 will be ignored. Current value: bagging_fraction=0.44245024243723224\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1688352036536975, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.1688352036536975\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9401878094818684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9401878094818684\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=8 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 1.49892\n",
      "[CV 1/2] END bagging_fraction=0.44245024243723224, bagging_freq=4, feature_fraction=0.9401878094818684, lambda_l1=9.170558761641159, lambda_l2=2.1688352036536975, learning_rate=0.05, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=269, objective=l, reg_lambda=1e-05, subsample=0.6, subsample_freq=8;, score=0.328 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.580185807188986, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.580185807188986\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8077330734846755, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8077330734846755\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.571664879919302, reg_lambda=0 will be ignored. Current value: lambda_l2=8.571664879919302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.588152994235987, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.588152994235987\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 1.49764\n",
      "[CV 2/2] END bagging_fraction=0.8077330734846755, bagging_freq=8, feature_fraction=0.588152994235987, lambda_l1=7.580185807188986, lambda_l2=8.571664879919302, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=240, objective=a, reg_lambda=0, subsample=0.5, subsample_freq=64;, score=0.330 total time=   5.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6718691497742766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6718691497742766\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4356560143255849, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.4356560143255849\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.847009883300423, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.847009883300423\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7911682647986727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7911682647986727\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[455]\tvalid_0's multi_logloss: 1.49803\n",
      "[CV 1/2] END bagging_fraction=0.4356560143255849, bagging_freq=8, feature_fraction=0.7911682647986727, lambda_l1=3.6718691497742766, lambda_l2=8.847009883300423, learning_rate=0.01, metric=multi_logloss, min_child_samples=27, num_class=5, num_leaves=329, objective=l, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=256;, score=0.331 total time=  14.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6718691497742766, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6718691497742766\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4356560143255849, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.4356560143255849\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.847009883300423, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.847009883300423\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7911682647986727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7911682647986727\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[546]\tvalid_0's multi_logloss: 1.4945\n",
      "[CV 2/2] END bagging_fraction=0.4356560143255849, bagging_freq=8, feature_fraction=0.7911682647986727, lambda_l1=3.6718691497742766, lambda_l2=8.847009883300423, learning_rate=0.01, metric=multi_logloss, min_child_samples=27, num_class=5, num_leaves=329, objective=l, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=256;, score=0.330 total time=  17.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.699712914714301, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.699712914714301\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9381553684067849, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9381553684067849\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.275039891773685, reg_lambda=0 will be ignored. Current value: lambda_l2=5.275039891773685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5733984111193471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5733984111193471\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 1.49675\n",
      "[CV 2/2] END bagging_fraction=0.9381553684067849, bagging_freq=3, feature_fraction=0.5733984111193471, lambda_l1=1.699712914714301, lambda_l2=5.275039891773685, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=252, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=4;, score=0.328 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21983487663739282, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21983487663739282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8349813565282047, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8349813565282047\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.553141570990163, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.553141570990163\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7788989362070493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7788989362070493\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.49538\n",
      "[CV 1/2] END bagging_fraction=0.8349813565282047, bagging_freq=7, feature_fraction=0.7788989362070493, lambda_l1=0.21983487663739282, lambda_l2=3.553141570990163, learning_rate=0.2, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=63, objective=l, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.334 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21983487663739282, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21983487663739282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8349813565282047, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8349813565282047\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.553141570990163, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.553141570990163\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7788989362070493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7788989362070493\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.960548299094741, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.960548299094741\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9679332883898306, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9679332883898306\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7991926769347266, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.7991926769347266\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8850013821517814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8850013821517814\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[636]\tvalid_0's multi_logloss: 1.49483\n",
      "[CV 2/2] END bagging_fraction=0.9679332883898306, bagging_freq=2, feature_fraction=0.8850013821517814, lambda_l1=7.960548299094741, lambda_l2=2.7991926769347266, learning_rate=0.01, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=404, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=32;, score=0.330 total time=  21.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.511761338556545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.511761338556545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9860558804390043, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9860558804390043\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7922972999232536, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.7922972999232536\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8445477161765744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8445477161765744\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 1.50556\n",
      "[CV 1/2] END bagging_fraction=0.9860558804390043, bagging_freq=6, feature_fraction=0.8445477161765744, lambda_l1=6.511761338556545, lambda_l2=1.7922972999232536, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=336, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=32;, score=0.326 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.511761338556545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.511761338556545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9860558804390043, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9860558804390043\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7922972999232536, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.7922972999232536\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8445477161765744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8445477161765744\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 1.49857\n",
      "[CV 2/2] END bagging_fraction=0.9860558804390043, bagging_freq=6, feature_fraction=0.8445477161765744, lambda_l1=6.511761338556545, lambda_l2=1.7922972999232536, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=336, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=32;, score=0.331 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.018458413197948, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.018458413197948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.785721214792171, subsample=0.7 will be ignored. Current value: bagging_fraction=0.785721214792171\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4796806027342626, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.4796806027342626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7089324327382405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7089324327382405\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's multi_logloss: 1.49546\n",
      "[CV 2/2] END bagging_fraction=0.785721214792171, bagging_freq=3, feature_fraction=0.7089324327382405, lambda_l1=9.018458413197948, lambda_l2=1.4796806027342626, learning_rate=0.05, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=113, objective=u, reg_lambda=1e-07, subsample=0.7, subsample_freq=4;, score=0.330 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2312529476673015, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2312529476673015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8974145622310399, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8974145622310399\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.459352513826135, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.459352513826135\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7831137141969211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7831137141969211\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[579]\tvalid_0's multi_logloss: 1.50157\n",
      "[CV 1/2] END bagging_fraction=0.8974145622310399, bagging_freq=6, feature_fraction=0.7831137141969211, lambda_l1=4.2312529476673015, lambda_l2=7.459352513826135, learning_rate=0.01, metric=multi_logloss, min_child_samples=87, num_class=5, num_leaves=410, objective=a, reg_lambda=1e-07, subsample=0.7, subsample_freq=128;, score=0.328 total time=  13.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.83884437942165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.83884437942165\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.685142852801411, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.685142852801411\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.28267212583555, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.28267212583555\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9777237820314806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9777237820314806\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[470]\tvalid_0's multi_logloss: 1.51281\n",
      "[CV 1/2] END bagging_fraction=0.685142852801411, bagging_freq=5, feature_fraction=0.9777237820314806, lambda_l1=8.83884437942165, lambda_l2=7.28267212583555, learning_rate=0.05, metric=multi_logloss, min_child_samples=94, num_class=5, num_leaves=265, objective=u, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=32;, score=0.322 total time=   6.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.83884437942165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.83884437942165\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.685142852801411, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.685142852801411\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.28267212583555, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.28267212583555\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9777237820314806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9777237820314806\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's multi_logloss: 1.49974\n",
      "\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.018458413197948, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.018458413197948\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.785721214792171, subsample=0.7 will be ignored. Current value: bagging_fraction=0.785721214792171\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4796806027342626, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.4796806027342626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7089324327382405, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7089324327382405\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 1.50371\n",
      "[CV 1/2] END bagging_fraction=0.785721214792171, bagging_freq=3, feature_fraction=0.7089324327382405, lambda_l1=9.018458413197948, lambda_l2=1.4796806027342626, learning_rate=0.05, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=113, objective=u, reg_lambda=1e-07, subsample=0.7, subsample_freq=4;, score=0.329 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.699712914714301, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.699712914714301\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9381553684067849, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9381553684067849\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.275039891773685, reg_lambda=0 will be ignored. Current value: lambda_l2=5.275039891773685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5733984111193471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5733984111193471\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_logloss: 1.50086\n",
      "[CV 1/2] END bagging_fraction=0.9381553684067849, bagging_freq=3, feature_fraction=0.5733984111193471, lambda_l1=1.699712914714301, lambda_l2=5.275039891773685, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=252, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=4;, score=0.330 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2312529476673015, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2312529476673015\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8974145622310399, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8974145622310399\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.459352513826135, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.459352513826135\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7831137141969211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7831137141969211\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[425]\tvalid_0's multi_logloss: 1.49822\n",
      "[CV 2/2] END bagging_fraction=0.8974145622310399, bagging_freq=6, feature_fraction=0.7831137141969211, lambda_l1=4.2312529476673015, lambda_l2=7.459352513826135, learning_rate=0.01, metric=multi_logloss, min_child_samples=87, num_class=5, num_leaves=410, objective=a, reg_lambda=1e-07, subsample=0.7, subsample_freq=128;, score=0.330 total time=  11.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.153892753101344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.153892753101344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9670151437518608, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9670151437518608\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8983635832317197, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.8983635832317197\n",
      "[LightGBM] [Warning] feature_fraction is set=0.43231073048263363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43231073048263363\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[501]\tvalid_0's multi_logloss: 1.50003\n",
      "[CV 1/2] END bagging_fraction=0.9670151437518608, bagging_freq=9, feature_fraction=0.43231073048263363, lambda_l1=3.153892753101344, lambda_l2=0.8983635832317197, learning_rate=0.01, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=214, objective=s, reg_lambda=0.001, subsample=0.7, subsample_freq=2;, score=0.330 total time=  13.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.669193472947416, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.669193472947416\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44748139905214945, subsample=0.6 will be ignored. Current value: bagging_fraction=0.44748139905214945\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6464984733811888, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.6464984733811888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4088842576617991, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4088842576617991\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[608]\tvalid_0's multi_logloss: 1.50914\n",
      "[CV 2/2] END bagging_fraction=0.44748139905214945, bagging_freq=8, feature_fraction=0.4088842576617991, lambda_l1=9.669193472947416, lambda_l2=0.6464984733811888, learning_rate=0.01, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=89, objective=c, reg_lambda=1e-07, subsample=0.6, subsample_freq=4;, score=0.328 total time=   7.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.017349603018822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.017349603018822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7075542857810624, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7075542857810624\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.485169350400997, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.485169350400997\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8010046187178721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8010046187178721\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 1.49698\n",
      "[CV 2/2] END bagging_fraction=0.7075542857810624, bagging_freq=4, feature_fraction=0.8010046187178721, lambda_l1=4.017349603018822, lambda_l2=5.485169350400997, learning_rate=0.05, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=142, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=64;, score=0.331 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.995777208221898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.995777208221898\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9515038425827126, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9515038425827126\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8406062219887764, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.8406062219887764\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4801088226507616, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4801088226507616\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 1.49627\n",
      "[CV 1/2] END bagging_fraction=0.9515038425827126, bagging_freq=9, feature_fraction=0.4801088226507616, lambda_l1=7.995777208221898, lambda_l2=2.8406062219887764, learning_rate=0.2, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=362, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.332 total time=   4.0s\n",
      "[CV 2/2] END bagging_fraction=0.685142852801411, bagging_freq=5, feature_fraction=0.9777237820314806, lambda_l1=8.83884437942165, lambda_l2=7.28267212583555, learning_rate=0.05, metric=multi_logloss, min_child_samples=94, num_class=5, num_leaves=265, objective=u, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=32;, score=0.330 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.25968394339221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.25968394339221\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5554804914757069, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5554804914757069\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.583350102946449, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.583350102946449\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9280678154231559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9280678154231559\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 1.51235\n",
      "[CV 1/2] END bagging_fraction=0.5554804914757069, bagging_freq=4, feature_fraction=0.9280678154231559, lambda_l1=8.25968394339221, lambda_l2=9.583350102946449, learning_rate=0.05, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=234, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.323 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.25968394339221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.25968394339221\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5554804914757069, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5554804914757069\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.583350102946449, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.583350102946449\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9280678154231559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9280678154231559\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's multi_logloss: 1.4995\n",
      "[CV 2/2] END bagging_fraction=0.5554804914757069, bagging_freq=4, feature_fraction=0.9280678154231559, lambda_l1=8.25968394339221, lambda_l2=9.583350102946449, learning_rate=0.05, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=234, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.326 total time=   5.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.744097097411486, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.744097097411486\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5997022404894556, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5997022404894556\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6824659480701305, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.6824659480701305\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6865350280384643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6865350280384643\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[672]\tvalid_0's multi_logloss: 1.50668\n",
      "[CV 1/2] END bagging_fraction=0.5997022404894556, bagging_freq=7, feature_fraction=0.6865350280384643, lambda_l1=4.744097097411486, lambda_l2=3.6824659480701305, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=136, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.326 total time=  11.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.144972833510556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.144972833510556\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8731738304064697, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8731738304064697\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4970010165602643, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.4970010165602643\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5958037799160196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5958037799160196\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1515]\tvalid_0's multi_logloss: 1.50032\n",
      "[CV 1/2] END bagging_fraction=0.8731738304064697, bagging_freq=3, feature_fraction=0.5958037799160196, lambda_l1=8.144972833510556, lambda_l2=3.4970010165602643, learning_rate=0.01, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=365, objective=i, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=8;, score=0.329 total time=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=7.995777208221898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.995777208221898\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9515038425827126, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9515038425827126\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8406062219887764, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.8406062219887764\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4801088226507616, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4801088226507616\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.49446\n",
      "[CV 2/2] END bagging_fraction=0.9515038425827126, bagging_freq=9, feature_fraction=0.4801088226507616, lambda_l1=7.995777208221898, lambda_l2=2.8406062219887764, learning_rate=0.2, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=362, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.330 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.417007160598748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.417007160598748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.831154866364008, subsample=0.6 will be ignored. Current value: bagging_fraction=0.831154866364008\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7347730879099323, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.7347730879099323\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8085956602180395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8085956602180395\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 1.49825\n",
      "[CV 1/2] END bagging_fraction=0.831154866364008, bagging_freq=7, feature_fraction=0.8085956602180395, lambda_l1=1.417007160598748, lambda_l2=1.7347730879099323, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=405, objective=a, reg_lambda=0.0001, subsample=0.6, subsample_freq=2;, score=0.331 total time=  11.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3818558102730008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3818558102730008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4655823361861897, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4655823361861897\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.178763852245845, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.178763852245845\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7852881367690293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7852881367690293\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.52527\n",
      "[CV 1/2] END bagging_fraction=0.4655823361861897, bagging_freq=5, feature_fraction=0.7852881367690293, lambda_l1=1.3818558102730008, lambda_l2=9.178763852245845, learning_rate=0.2, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=377, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=8;, score=0.322 total time=   2.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3818558102730008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3818558102730008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4655823361861897, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4655823361861897\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.178763852245845, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.178763852245845\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7852881367690293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7852881367690293\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.51254\n",
      "[CV 2/2] END bagging_fraction=0.4655823361861897, bagging_freq=5, feature_fraction=0.7852881367690293, lambda_l1=1.3818558102730008, lambda_l2=9.178763852245845, learning_rate=0.2, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=377, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=8;, score=0.317 total time=   2.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.218349606147688, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.218349606147688\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5702980621669361, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5702980621669361\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.134572108113401, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.134572108113401\n",
      "[LightGBM] [Warning] feature_fraction is set=0.619316787881051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.619316787881051\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 1.51053\n",
      "[CV 1/2] END bagging_fraction=0.5702980621669361, bagging_freq=4, feature_fraction=0.619316787881051, lambda_l1=9.218349606147688, lambda_l2=9.134572108113401, learning_rate=0.05, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=403, objective=i, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=1;, score=0.323 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.218349606147688, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.218349606147688\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5702980621669361, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5702980621669361\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.134572108113401, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.134572108113401\n",
      "[LightGBM] [Warning] feature_fraction is set=0.619316787881051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.619316787881051\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's multi_logloss: 1.49882\n",
      "[CV 2/2] END bagging_fraction=0.5702980621669361, bagging_freq=4, feature_fraction=0.619316787881051, lambda_l1=9.218349606147688, lambda_l2=9.134572108113401, learning_rate=0.05, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=403, objective=i, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=1;, score=0.331 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.850019278717117, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.850019278717117\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.661771136320625, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.661771136320625\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0026512249238600013, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.0026512249238600013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5326286441097239, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5326286441097239\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's multi_logloss: 1.50929\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.49316\n",
      "[CV 2/2] END bagging_fraction=0.8349813565282047, bagging_freq=7, feature_fraction=0.7788989362070493, lambda_l1=0.21983487663739282, lambda_l2=3.553141570990163, learning_rate=0.2, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=63, objective=l, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.328 total time=   5.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.153892753101344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.153892753101344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9670151437518608, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9670151437518608\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8983635832317197, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.8983635832317197\n",
      "[LightGBM] [Warning] feature_fraction is set=0.43231073048263363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43231073048263363\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's multi_logloss: 1.49574\n",
      "[CV 2/2] END bagging_fraction=0.9670151437518608, bagging_freq=9, feature_fraction=0.43231073048263363, lambda_l1=3.153892753101344, lambda_l2=0.8983635832317197, learning_rate=0.01, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=214, objective=s, reg_lambda=0.001, subsample=0.7, subsample_freq=2;, score=0.328 total time=  10.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.669193472947416, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.669193472947416\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44748139905214945, subsample=0.6 will be ignored. Current value: bagging_fraction=0.44748139905214945\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6464984733811888, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.6464984733811888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4088842576617991, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4088842576617991\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[768]\tvalid_0's multi_logloss: 1.51573\n",
      "[CV 1/2] END bagging_fraction=0.44748139905214945, bagging_freq=8, feature_fraction=0.4088842576617991, lambda_l1=9.669193472947416, lambda_l2=0.6464984733811888, learning_rate=0.01, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=89, objective=c, reg_lambda=1e-07, subsample=0.6, subsample_freq=4;, score=0.326 total time=   7.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.017349603018822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.017349603018822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7075542857810624, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7075542857810624\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.485169350400997, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.485169350400997\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8010046187178721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8010046187178721\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's multi_logloss: 1.50172\n",
      "[CV 1/2] END bagging_fraction=0.7075542857810624, bagging_freq=4, feature_fraction=0.8010046187178721, lambda_l1=4.017349603018822, lambda_l2=5.485169350400997, learning_rate=0.05, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=142, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=64;, score=0.329 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.744097097411486, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.744097097411486\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5997022404894556, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5997022404894556\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6824659480701305, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.6824659480701305\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6865350280384643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6865350280384643\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's multi_logloss: 1.49803\n",
      "[CV 2/2] END bagging_fraction=0.5997022404894556, bagging_freq=7, feature_fraction=0.6865350280384643, lambda_l1=4.744097097411486, lambda_l2=3.6824659480701305, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=136, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.332 total time=   9.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.417007160598748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.417007160598748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.831154866364008, subsample=0.6 will be ignored. Current value: bagging_fraction=0.831154866364008\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7347730879099323, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.7347730879099323\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8085956602180395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8085956602180395\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 1.49991\n",
      "[CV 2/2] END bagging_fraction=0.831154866364008, bagging_freq=7, feature_fraction=0.8085956602180395, lambda_l1=1.417007160598748, lambda_l2=1.7347730879099323, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=405, objective=a, reg_lambda=0.0001, subsample=0.6, subsample_freq=2;, score=0.330 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.144972833510556, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.144972833510556\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8731738304064697, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8731738304064697\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4970010165602643, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.4970010165602643\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5958037799160196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5958037799160196\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1098]\tvalid_0's multi_logloss: 1.49474\n",
      "[CV 2/2] END bagging_fraction=0.8731738304064697, bagging_freq=3, feature_fraction=0.5958037799160196, lambda_l1=8.144972833510556, lambda_l2=3.4970010165602643, learning_rate=0.01, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=365, objective=i, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=8;, score=0.331 total time=  22.8s\n",
      "[CV 1/2] END bagging_fraction=0.661771136320625, bagging_freq=3, feature_fraction=0.5326286441097239, lambda_l1=6.850019278717117, lambda_l2=0.0026512249238600013, learning_rate=0.05, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=454, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=2;, score=0.327 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.667245253084037, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.667245253084037\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8261013363042167, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8261013363042167\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.5531904246421764, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.5531904246421764\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75945015515379, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75945015515379\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's multi_logloss: 1.49905\n",
      "[CV 1/2] END bagging_fraction=0.8261013363042167, bagging_freq=9, feature_fraction=0.75945015515379, lambda_l1=9.667245253084037, lambda_l2=3.5531904246421764, learning_rate=0.05, metric=multi_logloss, min_child_samples=45, num_class=5, num_leaves=50, objective=m, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.332 total time=   6.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6311827104175034, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6311827104175034\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7758087588574247, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7758087588574247\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2010940178061493, reg_lambda=0 will be ignored. Current value: lambda_l2=1.2010940178061493\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7880931817597923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7880931817597923\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.5002\n",
      "[CV 2/2] END bagging_fraction=0.7758087588574247, bagging_freq=7, feature_fraction=0.7880931817597923, lambda_l1=2.6311827104175034, lambda_l2=1.2010940178061493, learning_rate=0.2, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=438, objective=l, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.330 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5354378825859873, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5354378825859873\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7708765998329838, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7708765998329838\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.257882722825228, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.257882722825228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8804068871828895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8804068871828895\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 1.49593\n",
      "[CV 2/2] END bagging_fraction=0.7708765998329838, bagging_freq=5, feature_fraction=0.8804068871828895, lambda_l1=2.5354378825859873, lambda_l2=9.257882722825228, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=430, objective=t, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.326 total time=   8.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.510724689889251, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.510724689889251\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8535829745179502, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8535829745179502\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.974672560156452, reg_lambda=0 will be ignored. Current value: lambda_l2=2.974672560156452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968843187121733, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968843187121733\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's multi_logloss: 1.49985\n",
      "[CV 1/2] END bagging_fraction=0.8535829745179502, bagging_freq=7, feature_fraction=0.8968843187121733, lambda_l1=9.510724689889251, lambda_l2=2.974672560156452, learning_rate=0.2, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=120, objective=t, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=2;, score=0.329 total time=   4.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0039730238731353115, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0039730238731353115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6508954292553986, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6508954292553986\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.494667279949291, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.494667279949291\n",
      "[LightGBM] [Warning] feature_fraction is set=0.764891375750377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.764891375750377\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's multi_logloss: 1.49758\n",
      "[CV 1/2] END bagging_fraction=0.6508954292553986, bagging_freq=9, feature_fraction=0.764891375750377, lambda_l1=0.0039730238731353115, lambda_l2=6.494667279949291, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=105, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=4;, score=0.332 total time=  13.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2507112743214934, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2507112743214934\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7738873274787412, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7738873274787412\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9028808646534392, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.9028808646534392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.633689378012019, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.633689378012019\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's multi_logloss: 1.49275\n",
      "[CV 2/2] END bagging_fraction=0.7738873274787412, bagging_freq=5, feature_fraction=0.633689378012019, lambda_l1=2.2507112743214934, lambda_l2=1.9028808646534392, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=389, objective=a, reg_lambda=1e-07, subsample=0.6, subsample_freq=8;, score=0.332 total time=  20.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.599537612172696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.599537612172696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5074864322792544, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5074864322792544\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.241710456426566, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.241710456426566\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6824675961505076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6824675961505076\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.850019278717117, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.850019278717117\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.661771136320625, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.661771136320625\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0026512249238600013, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.0026512249238600013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5326286441097239, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5326286441097239\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's multi_logloss: 1.49867\n",
      "[CV 2/2] END bagging_fraction=0.661771136320625, bagging_freq=3, feature_fraction=0.5326286441097239, lambda_l1=6.850019278717117, lambda_l2=0.0026512249238600013, learning_rate=0.05, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=454, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=2;, score=0.329 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6311827104175034, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6311827104175034\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7758087588574247, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7758087588574247\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2010940178061493, reg_lambda=0 will be ignored. Current value: lambda_l2=1.2010940178061493\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7880931817597923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7880931817597923\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.50472\n",
      "[CV 1/2] END bagging_fraction=0.7758087588574247, bagging_freq=7, feature_fraction=0.7880931817597923, lambda_l1=2.6311827104175034, lambda_l2=1.2010940178061493, learning_rate=0.2, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=438, objective=l, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.326 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5354378825859873, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5354378825859873\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7708765998329838, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7708765998329838\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.257882722825228, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.257882722825228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8804068871828895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8804068871828895\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's multi_logloss: 1.49192\n",
      "[CV 1/2] END bagging_fraction=0.7708765998329838, bagging_freq=5, feature_fraction=0.8804068871828895, lambda_l1=2.5354378825859873, lambda_l2=9.257882722825228, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=430, objective=t, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.331 total time=  10.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.510724689889251, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.510724689889251\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8535829745179502, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8535829745179502\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.974672560156452, reg_lambda=0 will be ignored. Current value: lambda_l2=2.974672560156452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8968843187121733, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8968843187121733\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_logloss: 1.49477\n",
      "[CV 2/2] END bagging_fraction=0.8535829745179502, bagging_freq=7, feature_fraction=0.8968843187121733, lambda_l1=9.510724689889251, lambda_l2=2.974672560156452, learning_rate=0.2, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=120, objective=t, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=2;, score=0.329 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0039730238731353115, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0039730238731353115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6508954292553986, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6508954292553986\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.494667279949291, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.494667279949291\n",
      "[LightGBM] [Warning] feature_fraction is set=0.764891375750377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.764891375750377\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's multi_logloss: 1.49917\n",
      "[CV 2/2] END bagging_fraction=0.6508954292553986, bagging_freq=9, feature_fraction=0.764891375750377, lambda_l1=0.0039730238731353115, lambda_l2=6.494667279949291, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=105, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=4;, score=0.328 total time=  16.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7016491743696518, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7016491743696518\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4786083520170945, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4786083520170945\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.49264185846524, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.49264185846524\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5989923370585566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5989923370585566\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[507]\tvalid_0's multi_logloss: 1.48893\n",
      "[CV 1/2] END bagging_fraction=0.4786083520170945, bagging_freq=5, feature_fraction=0.5989923370585566, lambda_l1=1.7016491743696518, lambda_l2=8.49264185846524, learning_rate=0.01, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=199, objective=s, reg_lambda=0.0001, subsample=0.5, subsample_freq=256;, score=0.333 total time=  36.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4937147250550888, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4937147250550888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5721255461915254, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5721255461915254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.937442343743426, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.937442343743426\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5839280132502196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5839280132502196\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 1.51795\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.667245253084037, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.667245253084037\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8261013363042167, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8261013363042167\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.5531904246421764, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.5531904246421764\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75945015515379, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75945015515379\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's multi_logloss: 1.49544\n",
      "[CV 2/2] END bagging_fraction=0.8261013363042167, bagging_freq=9, feature_fraction=0.75945015515379, lambda_l1=9.667245253084037, lambda_l2=3.5531904246421764, learning_rate=0.05, metric=multi_logloss, min_child_samples=45, num_class=5, num_leaves=50, objective=m, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.331 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.887015715414048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.887015715414048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5258157995472695, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5258157995472695\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7036366470828965, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.7036366470828965\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8587834881563259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8587834881563259\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[657]\tvalid_0's multi_logloss: 1.51556\n",
      "[CV 1/2] END bagging_fraction=0.5258157995472695, bagging_freq=9, feature_fraction=0.8587834881563259, lambda_l1=8.887015715414048, lambda_l2=3.7036366470828965, learning_rate=0.01, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=319, objective=l, reg_lambda=0.001, subsample=0.6, subsample_freq=64;, score=0.325 total time=   7.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.887015715414048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.887015715414048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5258157995472695, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5258157995472695\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7036366470828965, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.7036366470828965\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8587834881563259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8587834881563259\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[704]\tvalid_0's multi_logloss: 1.50413\n",
      "[CV 2/2] END bagging_fraction=0.5258157995472695, bagging_freq=9, feature_fraction=0.8587834881563259, lambda_l1=8.887015715414048, lambda_l2=3.7036366470828965, learning_rate=0.01, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=319, objective=l, reg_lambda=0.001, subsample=0.6, subsample_freq=64;, score=0.325 total time=   8.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2507112743214934, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2507112743214934\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7738873274787412, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7738873274787412\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9028808646534392, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.9028808646534392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.633689378012019, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.633689378012019\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's multi_logloss: 1.49021\n",
      "[CV 1/2] END bagging_fraction=0.7738873274787412, bagging_freq=5, feature_fraction=0.633689378012019, lambda_l1=2.2507112743214934, lambda_l2=1.9028808646534392, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=389, objective=a, reg_lambda=1e-07, subsample=0.6, subsample_freq=8;, score=0.336 total time=  23.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7016491743696518, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7016491743696518\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4786083520170945, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4786083520170945\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.49264185846524, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.49264185846524\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5989923370585566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5989923370585566\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's multi_logloss: 1.49078\n",
      "[CV 2/2] END bagging_fraction=0.4786083520170945, bagging_freq=5, feature_fraction=0.5989923370585566, lambda_l1=1.7016491743696518, lambda_l2=8.49264185846524, learning_rate=0.01, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=199, objective=s, reg_lambda=0.0001, subsample=0.5, subsample_freq=256;, score=0.331 total time=  28.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4937147250550888, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4937147250550888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5721255461915254, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5721255461915254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.937442343743426, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.937442343743426\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5839280132502196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5839280132502196\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 1.50511\n",
      "[CV 2/2] END bagging_fraction=0.5721255461915254, bagging_freq=8, feature_fraction=0.5839280132502196, lambda_l1=1.4937147250550888, lambda_l2=9.937442343743426, learning_rate=0.05, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=344, objective=a, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.325 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2754464425972345, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2754464425972345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5309657744344197, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5309657744344197\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.908751129193368, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.908751129193368\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6454162716609424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6454162716609424\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[387]\tvalid_0's multi_logloss: 1.4954\n",
      "[CV 2/2] END bagging_fraction=0.5309657744344197, bagging_freq=3, feature_fraction=0.6454162716609424, lambda_l1=2.2754464425972345, lambda_l2=8.908751129193368, learning_rate=0.01, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=399, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=1;, score=0.332 total time=  13.6s\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's multi_logloss: 1.52106\n",
      "[CV 1/2] END bagging_fraction=0.5074864322792544, bagging_freq=2, feature_fraction=0.6824675961505076, lambda_l1=9.599537612172696, lambda_l2=7.241710456426566, learning_rate=0.05, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=218, objective=u, reg_lambda=1e-06, subsample=0.7, subsample_freq=2;, score=0.327 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.599537612172696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.599537612172696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5074864322792544, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5074864322792544\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.241710456426566, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.241710456426566\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6824675961505076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6824675961505076\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's multi_logloss: 1.50478\n",
      "[CV 2/2] END bagging_fraction=0.5074864322792544, bagging_freq=2, feature_fraction=0.6824675961505076, lambda_l1=9.599537612172696, lambda_l2=7.241710456426566, learning_rate=0.05, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=218, objective=u, reg_lambda=1e-06, subsample=0.7, subsample_freq=2;, score=0.323 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.6082445684903337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6082445684903337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9954464740668845, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9954464740668845\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.9980549866251, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.9980549866251\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6321166706478226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321166706478226\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.49455\n",
      "[CV 1/2] END bagging_fraction=0.9954464740668845, bagging_freq=2, feature_fraction=0.6321166706478226, lambda_l1=1.6082445684903337, lambda_l2=8.9980549866251, learning_rate=0.2, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=155, objective=l, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=4;, score=0.332 total time=   6.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.6082445684903337, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6082445684903337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9954464740668845, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9954464740668845\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.9980549866251, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.9980549866251\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6321166706478226, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321166706478226\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.49542\n",
      "[CV 2/2] END bagging_fraction=0.9954464740668845, bagging_freq=2, feature_fraction=0.6321166706478226, lambda_l1=1.6082445684903337, lambda_l2=8.9980549866251, learning_rate=0.2, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=155, objective=l, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=4;, score=0.327 total time=   7.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.139625901573662, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.139625901573662\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.627993061720445, subsample=0.6 will be ignored. Current value: bagging_fraction=0.627993061720445\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.444704031733943, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.444704031733943\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5165272126209609, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5165272126209609\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 1.50705\n",
      "[CV 1/2] END bagging_fraction=0.627993061720445, bagging_freq=4, feature_fraction=0.5165272126209609, lambda_l1=7.139625901573662, lambda_l2=7.444704031733943, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=150, objective=u, reg_lambda=1e-07, subsample=0.6, subsample_freq=1;, score=0.325 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2754464425972345, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2754464425972345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5309657744344197, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5309657744344197\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.908751129193368, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.908751129193368\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6454162716609424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6454162716609424\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[546]\tvalid_0's multi_logloss: 1.49856\n",
      "[CV 1/2] END bagging_fraction=0.5309657744344197, bagging_freq=3, feature_fraction=0.6454162716609424, lambda_l1=2.2754464425972345, lambda_l2=8.908751129193368, learning_rate=0.01, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=399, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=1;, score=0.331 total time=  16.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.4451667635053305, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.4451667635053305\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7079607442153233, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7079607442153233\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.061791894032849, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.061791894032849\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8102715515123804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8102715515123804\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 1.51137\n",
      "[CV 1/2] END bagging_fraction=0.7079607442153233, bagging_freq=5, feature_fraction=0.8102715515123804, lambda_l1=4.4451667635053305, lambda_l2=8.061791894032849, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=271, objective=s, reg_lambda=0.0001, subsample=0.6, subsample_freq=8;, score=0.325 total time=   2.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.4451667635053305, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.4451667635053305\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7079607442153233, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7079607442153233\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.061791894032849, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.061791894032849\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8102715515123804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8102715515123804\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "[CV 1/2] END bagging_fraction=0.5721255461915254, bagging_freq=8, feature_fraction=0.5839280132502196, lambda_l1=1.4937147250550888, lambda_l2=9.937442343743426, learning_rate=0.05, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=344, objective=a, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.323 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.139625901573662, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.139625901573662\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.627993061720445, subsample=0.6 will be ignored. Current value: bagging_fraction=0.627993061720445\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.444704031733943, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.444704031733943\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5165272126209609, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5165272126209609\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 1.50078\n",
      "[CV 2/2] END bagging_fraction=0.627993061720445, bagging_freq=4, feature_fraction=0.5165272126209609, lambda_l1=7.139625901573662, lambda_l2=7.444704031733943, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=150, objective=u, reg_lambda=1e-07, subsample=0.6, subsample_freq=1;, score=0.331 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.716101594701775, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.716101594701775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179051407877854, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9179051407877854\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.961365513517034, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.961365513517034\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7362466057112735, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7362466057112735\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's multi_logloss: 1.50127\n",
      "[CV 1/2] END bagging_fraction=0.9179051407877854, bagging_freq=2, feature_fraction=0.7362466057112735, lambda_l1=6.716101594701775, lambda_l2=2.961365513517034, learning_rate=0.05, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=171, objective=t, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=64;, score=0.328 total time=   6.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.716101594701775, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.716101594701775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179051407877854, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9179051407877854\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.961365513517034, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.961365513517034\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7362466057112735, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7362466057112735\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 1.49511\n",
      "[CV 2/2] END bagging_fraction=0.9179051407877854, bagging_freq=2, feature_fraction=0.7362466057112735, lambda_l1=6.716101594701775, lambda_l2=2.961365513517034, learning_rate=0.05, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=171, objective=t, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=64;, score=0.329 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.283826866638534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.283826866638534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7734196804017774, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7734196804017774\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.756503683493875, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.756503683493875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9881151666495208, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9881151666495208\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 1.49677\n",
      "[CV 2/2] END bagging_fraction=0.7734196804017774, bagging_freq=7, feature_fraction=0.9881151666495208, lambda_l1=4.283826866638534, lambda_l2=8.756503683493875, learning_rate=0.05, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=464, objective=s, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.331 total time=   5.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7487901598675295, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7487901598675295\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5103883974864591, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5103883974864591\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.232019231830245, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.232019231830245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6240313852166754, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6240313852166754\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 1.50853\n",
      "[CV 2/2] END bagging_fraction=0.5103883974864591, bagging_freq=4, feature_fraction=0.6240313852166754, lambda_l1=2.7487901598675295, lambda_l2=1.232019231830245, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=497, objective=u, reg_lambda=1e-07, subsample=0.7, subsample_freq=128;, score=0.323 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.180584467948731, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.180584467948731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6662393586862563, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6662393586862563\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.901162118811325, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.901162118811325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9805216577834536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9805216577834536\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[587]\tvalid_0's multi_logloss: 1.50294\n",
      "[CV 1/2] END bagging_fraction=0.6662393586862563, bagging_freq=6, feature_fraction=0.9805216577834536, lambda_l1=4.180584467948731, lambda_l2=8.901162118811325, learning_rate=0.01, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=384, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.329 total time=  13.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.180584467948731, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.180584467948731\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6662393586862563, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6662393586862563\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.901162118811325, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.901162118811325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9805216577834536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9805216577834536\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.283826866638534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.283826866638534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7734196804017774, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7734196804017774\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.756503683493875, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.756503683493875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9881151666495208, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9881151666495208\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's multi_logloss: 1.50093\n",
      "[CV 1/2] END bagging_fraction=0.7734196804017774, bagging_freq=7, feature_fraction=0.9881151666495208, lambda_l1=4.283826866638534, lambda_l2=8.756503683493875, learning_rate=0.05, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=464, objective=s, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.330 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7487901598675295, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7487901598675295\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5103883974864591, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5103883974864591\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.232019231830245, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.232019231830245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6240313852166754, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6240313852166754\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's multi_logloss: 1.52062\n",
      "[CV 1/2] END bagging_fraction=0.5103883974864591, bagging_freq=4, feature_fraction=0.6240313852166754, lambda_l1=2.7487901598675295, lambda_l2=1.232019231830245, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=497, objective=u, reg_lambda=1e-07, subsample=0.7, subsample_freq=128;, score=0.323 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.828349453716575, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.828349453716575\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9933174491122561, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9933174491122561\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522836266507319, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.522836266507319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.902033042038273, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.902033042038273\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's multi_logloss: 1.49612\n",
      "[CV 2/2] END bagging_fraction=0.9933174491122561, bagging_freq=8, feature_fraction=0.902033042038273, lambda_l1=5.828349453716575, lambda_l2=2.522836266507319, learning_rate=0.01, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=511, objective=a, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.330 total time=  19.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3642777588293125, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3642777588293125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.545731795949955, subsample=0.7 will be ignored. Current value: bagging_fraction=0.545731795949955\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.752311804912098, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.752311804912098\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7683027122470557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7683027122470557\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 1.50942\n",
      "[CV 2/2] END bagging_fraction=0.545731795949955, bagging_freq=8, feature_fraction=0.7683027122470557, lambda_l1=0.3642777588293125, lambda_l2=7.752311804912098, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=199, objective=c, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.324 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.81399322255484, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.81399322255484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42131524412228305, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.42131524412228305\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.991725770352744, reg_lambda=0 will be ignored. Current value: lambda_l2=6.991725770352744\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8225928018971873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8225928018971873\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=128 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[360]\tvalid_0's multi_logloss: 1.50666\n",
      "[CV 2/2] END bagging_fraction=0.42131524412228305, bagging_freq=5, feature_fraction=0.8225928018971873, lambda_l1=0.81399322255484, lambda_l2=6.991725770352744, learning_rate=0.01, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=15, objective=s, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=128;, score=0.322 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4909545097810974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4909545097810974\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7233227839005887, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7233227839005887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27353837395821784, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.27353837395821784\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7735220566703878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7735220566703878\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.49095\n",
      "[CV 1/2] END bagging_fraction=0.7233227839005887, bagging_freq=3, feature_fraction=0.7735220566703878, lambda_l1=1.4909545097810974, lambda_l2=0.27353837395821784, learning_rate=0.05, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=303, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=4;, score=0.334 total time=  11.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.1978787310543435, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.1978787310543435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8108496154561644, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8108496154561644\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.76832201114896, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.76832201114896\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8710307432633806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8710307432633806\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[734]\tvalid_0's multi_logloss: 1.49709\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's multi_logloss: 1.50051\n",
      "[CV 2/2] END bagging_fraction=0.7079607442153233, bagging_freq=5, feature_fraction=0.8102715515123804, lambda_l1=4.4451667635053305, lambda_l2=8.061791894032849, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=271, objective=s, reg_lambda=0.0001, subsample=0.6, subsample_freq=8;, score=0.329 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.828349453716575, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.828349453716575\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9933174491122561, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9933174491122561\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522836266507319, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.522836266507319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.902033042038273, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.902033042038273\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[548]\tvalid_0's multi_logloss: 1.49677\n",
      "[CV 1/2] END bagging_fraction=0.9933174491122561, bagging_freq=8, feature_fraction=0.902033042038273, lambda_l1=5.828349453716575, lambda_l2=2.522836266507319, learning_rate=0.01, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=511, objective=a, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.331 total time=  19.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3642777588293125, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3642777588293125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.545731795949955, subsample=0.7 will be ignored. Current value: bagging_fraction=0.545731795949955\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.752311804912098, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.752311804912098\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7683027122470557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7683027122470557\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 1.51885\n",
      "[CV 1/2] END bagging_fraction=0.545731795949955, bagging_freq=8, feature_fraction=0.7683027122470557, lambda_l1=0.3642777588293125, lambda_l2=7.752311804912098, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=199, objective=c, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.324 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.81399322255484, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.81399322255484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42131524412228305, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.42131524412228305\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.991725770352744, reg_lambda=0 will be ignored. Current value: lambda_l2=6.991725770352744\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8225928018971873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8225928018971873\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=128 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's multi_logloss: 1.51946\n",
      "[CV 1/2] END bagging_fraction=0.42131524412228305, bagging_freq=5, feature_fraction=0.8225928018971873, lambda_l1=0.81399322255484, lambda_l2=6.991725770352744, learning_rate=0.01, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=15, objective=s, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=128;, score=0.326 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.050799747458465, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.050799747458465\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757021520545887, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9757021520545887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07705618905984674, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.07705618905984674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8295399129084541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8295399129084541\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 1.4942\n",
      "[CV 2/2] END bagging_fraction=0.9757021520545887, bagging_freq=7, feature_fraction=0.8295399129084541, lambda_l1=4.050799747458465, lambda_l2=0.07705618905984674, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=392, objective=u, reg_lambda=1e-07, subsample=0.6, subsample_freq=2;, score=0.333 total time=   8.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.1978787310543435, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.1978787310543435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8108496154561644, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8108496154561644\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.76832201114896, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.76832201114896\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8710307432633806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8710307432633806\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[868]\tvalid_0's multi_logloss: 1.50288\n",
      "[CV 1/2] END bagging_fraction=0.8108496154561644, bagging_freq=2, feature_fraction=0.8710307432633806, lambda_l1=7.1978787310543435, lambda_l2=7.76832201114896, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=310, objective=c, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.329 total time=  15.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.926081199420593, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.926081199420593\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5770437501163082, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5770437501163082\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3562073513954833, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.3562073513954833\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9484549689084358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9484549689084358\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's multi_logloss: 1.4937\n",
      "[CV 2/2] END bagging_fraction=0.5770437501163082, bagging_freq=3, feature_fraction=0.9484549689084358, lambda_l1=2.926081199420593, lambda_l2=1.3562073513954833, learning_rate=0.01, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=162, objective=l, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=4;, score=0.330 total time=  16.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3668156977373682, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3668156977373682\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5529721306737907, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5529721306737907\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.203723634314287, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.203723634314287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6617651934575374, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6617651934575374\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 1.51324\n",
      "[CV 1/2] END bagging_fraction=0.5529721306737907, bagging_freq=3, feature_fraction=0.6617651934575374, lambda_l1=1.3668156977373682, lambda_l2=5.203723634314287, learning_rate=0.05, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=33, objective=m, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.326 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3668156977373682, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3668156977373682\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5529721306737907, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5529721306737907\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.203723634314287, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.203723634314287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6617651934575374, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6617651934575374\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 1.50156\n",
      "[CV 2/2] END bagging_fraction=0.5529721306737907, bagging_freq=3, feature_fraction=0.6617651934575374, lambda_l1=1.3668156977373682, lambda_l2=5.203723634314287, learning_rate=0.05, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=33, objective=m, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.328 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.160411158842539, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.160411158842539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4160750378438361, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4160750378438361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.143920453719979, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.143920453719979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6644854111423126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6644854111423126\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's multi_logloss: 1.5258\n",
      "[CV 1/2] END bagging_fraction=0.4160750378438361, bagging_freq=6, feature_fraction=0.6644854111423126, lambda_l1=2.160411158842539, lambda_l2=8.143920453719979, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=37, objective=l, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=256;, score=0.318 total time=   2.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.160411158842539, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.160411158842539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4160750378438361, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4160750378438361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.143920453719979, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.143920453719979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6644854111423126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6644854111423126\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_logloss: 1.51812\n",
      "[CV 2/2] END bagging_fraction=0.4160750378438361, bagging_freq=6, feature_fraction=0.6644854111423126, lambda_l1=2.160411158842539, lambda_l2=8.143920453719979, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=37, objective=l, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=256;, score=0.307 total time=   2.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.144926723362577, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.144926723362577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6480928437214125, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6480928437214125\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1203410732646164, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.1203410732646164\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7274466578795762, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7274466578795762\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.49472\n",
      "[CV 1/2] END bagging_fraction=0.6480928437214125, bagging_freq=3, feature_fraction=0.7274466578795762, lambda_l1=2.144926723362577, lambda_l2=3.1203410732646164, learning_rate=0.05, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=182, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=256;, score=0.331 total time=   8.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.347371025769811, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.347371025769811\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5502590213774448, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5502590213774448\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.716779191076133, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.716779191076133\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5451379801869898, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5451379801869898\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.50419\n",
      "[CV 2/2] END bagging_fraction=0.5502590213774448, bagging_freq=5, feature_fraction=0.5451379801869898, lambda_l1=3.347371025769811, lambda_l2=8.716779191076133, learning_rate=0.2, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=179, objective=i, reg_lambda=1e-07, subsample=0.5, subsample_freq=256;, score=0.327 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1487142455325141, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1487142455325141\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.959443017514302, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.959443017514302\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.036125210006934, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.036125210006934\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8762891188670263, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8762891188670263\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's multi_logloss: 1.50257\n",
      "[CV 2/2] END bagging_fraction=0.959443017514302, bagging_freq=5, feature_fraction=0.8762891188670263, lambda_l1=1.1487142455325141, lambda_l2=4.036125210006934, learning_rate=0.01, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=161, objective=a, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=256;, score=0.331 total time=   9.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4390770348453774, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4390770348453774\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5456372965686787, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5456372965686787\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0493551053487846, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.0493551053487846\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's multi_logloss: 1.4986\n",
      "[CV 2/2] END bagging_fraction=0.6662393586862563, bagging_freq=6, feature_fraction=0.9805216577834536, lambda_l1=4.180584467948731, lambda_l2=8.901162118811325, learning_rate=0.01, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=384, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.330 total time=  11.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.050799747458465, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.050799747458465\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9757021520545887, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9757021520545887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07705618905984674, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.07705618905984674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8295399129084541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8295399129084541\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.49171\n",
      "[CV 1/2] END bagging_fraction=0.9757021520545887, bagging_freq=7, feature_fraction=0.8295399129084541, lambda_l1=4.050799747458465, lambda_l2=0.07705618905984674, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=392, objective=u, reg_lambda=1e-07, subsample=0.6, subsample_freq=2;, score=0.333 total time=   7.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4909545097810974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4909545097810974\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7233227839005887, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7233227839005887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27353837395821784, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.27353837395821784\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7735220566703878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7735220566703878\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_logloss: 1.4969\n",
      "[CV 2/2] END bagging_fraction=0.7233227839005887, bagging_freq=3, feature_fraction=0.7735220566703878, lambda_l1=1.4909545097810974, lambda_l2=0.27353837395821784, learning_rate=0.05, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=303, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=4;, score=0.328 total time=  11.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.926081199420593, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.926081199420593\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5770437501163082, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5770437501163082\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3562073513954833, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.3562073513954833\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9484549689084358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9484549689084358\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's multi_logloss: 1.49295\n",
      "[CV 1/2] END bagging_fraction=0.5770437501163082, bagging_freq=3, feature_fraction=0.9484549689084358, lambda_l1=2.926081199420593, lambda_l2=1.3562073513954833, learning_rate=0.01, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=162, objective=l, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=4;, score=0.331 total time=  16.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8220298933670267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8220298933670267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9115559831541065, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9115559831541065\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6471094034132037, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.6471094034132037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7341601147084118, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7341601147084118\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 1.49409\n",
      "[CV 2/2] END bagging_fraction=0.9115559831541065, bagging_freq=8, feature_fraction=0.7341601147084118, lambda_l1=1.8220298933670267, lambda_l2=3.6471094034132037, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=178, objective=a, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.331 total time=  24.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.347371025769811, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.347371025769811\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5502590213774448, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5502590213774448\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.716779191076133, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.716779191076133\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5451379801869898, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5451379801869898\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_logloss: 1.51013\n",
      "[CV 1/2] END bagging_fraction=0.5502590213774448, bagging_freq=5, feature_fraction=0.5451379801869898, lambda_l1=3.347371025769811, lambda_l2=8.716779191076133, learning_rate=0.2, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=179, objective=i, reg_lambda=1e-07, subsample=0.5, subsample_freq=256;, score=0.324 total time=   2.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1487142455325141, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1487142455325141\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.959443017514302, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.959443017514302\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.036125210006934, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.036125210006934\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8762891188670263, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8762891188670263\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[295]\tvalid_0's multi_logloss: 1.50074\n",
      "[CV 1/2] END bagging_fraction=0.959443017514302, bagging_freq=5, feature_fraction=0.8762891188670263, lambda_l1=1.1487142455325141, lambda_l2=4.036125210006934, learning_rate=0.01, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=161, objective=a, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=256;, score=0.329 total time=  12.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.833749606144027, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.833749606144027\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8354589927310097, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8354589927310097\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.581689988978966, reg_lambda=0 will be ignored. Current value: lambda_l2=7.581689988978966\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6479635317011769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6479635317011769\n",
      "[CV 2/2] END bagging_fraction=0.8108496154561644, bagging_freq=2, feature_fraction=0.8710307432633806, lambda_l1=7.1978787310543435, lambda_l2=7.76832201114896, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=310, objective=c, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.331 total time=  14.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8220298933670267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8220298933670267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9115559831541065, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9115559831541065\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6471094034132037, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.6471094034132037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7341601147084118, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7341601147084118\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid_0's multi_logloss: 1.48866\n",
      "[CV 1/2] END bagging_fraction=0.9115559831541065, bagging_freq=8, feature_fraction=0.7341601147084118, lambda_l1=1.8220298933670267, lambda_l2=3.6471094034132037, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=178, objective=a, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.333 total time=  28.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.144926723362577, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.144926723362577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6480928437214125, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6480928437214125\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1203410732646164, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.1203410732646164\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7274466578795762, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7274466578795762\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's multi_logloss: 1.49653\n",
      "[CV 2/2] END bagging_fraction=0.6480928437214125, bagging_freq=3, feature_fraction=0.7274466578795762, lambda_l1=2.144926723362577, lambda_l2=3.1203410732646164, learning_rate=0.05, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=182, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=256;, score=0.328 total time=   7.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.619049266916718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.619049266916718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6537901936715881, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6537901936715881\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.982042946232363, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.982042946232363\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8444270207195301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8444270207195301\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 1.51256\n",
      "[CV 1/2] END bagging_fraction=0.6537901936715881, bagging_freq=8, feature_fraction=0.8444270207195301, lambda_l1=6.619049266916718, lambda_l2=2.982042946232363, learning_rate=0.05, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=210, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=32;, score=0.324 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.619049266916718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.619049266916718\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6537901936715881, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6537901936715881\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.982042946232363, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.982042946232363\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8444270207195301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8444270207195301\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 1.50035\n",
      "[CV 2/2] END bagging_fraction=0.6537901936715881, bagging_freq=8, feature_fraction=0.8444270207195301, lambda_l1=6.619049266916718, lambda_l2=2.982042946232363, learning_rate=0.05, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=210, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=32;, score=0.331 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4390770348453774, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4390770348453774\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5456372965686787, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5456372965686787\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0493551053487846, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.0493551053487846\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8798495618980415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8798495618980415\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's multi_logloss: 1.50243\n",
      "[CV 2/2] END bagging_fraction=0.5456372965686787, bagging_freq=9, feature_fraction=0.8798495618980415, lambda_l1=3.4390770348453774, lambda_l2=3.0493551053487846, learning_rate=0.2, metric=multi_logloss, min_child_samples=37, num_class=5, num_leaves=324, objective=t, reg_lambda=1e-06, subsample=0.6, subsample_freq=256;, score=0.324 total time=   4.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.5432460332322036, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.5432460332322036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8786276624690292, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8786276624690292\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.57695133941436, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.57695133941436\n",
      "[LightGBM] [Warning] feature_fraction is set=0.905784268670293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.905784268670293\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.49322\n",
      "[CV 1/2] END bagging_fraction=0.8786276624690292, bagging_freq=2, feature_fraction=0.905784268670293, lambda_l1=7.5432460332322036, lambda_l2=4.57695133941436, learning_rate=0.2, metric=multi_logloss, min_child_samples=32, num_class=5, num_leaves=48, objective=c, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=32;, score=0.333 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.5432460332322036, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.5432460332322036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8786276624690292, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8786276624690292\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.57695133941436, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.57695133941436\n",
      "[LightGBM] [Warning] feature_fraction is set=0.905784268670293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.905784268670293\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[868]\tvalid_0's multi_logloss: 1.50199\n",
      "[CV 1/2] END bagging_fraction=0.8354589927310097, bagging_freq=2, feature_fraction=0.6479635317011769, lambda_l1=4.833749606144027, lambda_l2=7.581689988978966, learning_rate=0.01, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=118, objective=l, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=4;, score=0.328 total time=  17.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7253810082152845, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7253810082152845\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9475324694731937, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9475324694731937\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.600827581132637, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.600827581132637\n",
      "[LightGBM] [Warning] feature_fraction is set=0.634940262396025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.634940262396025\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 1.49306\n",
      "[CV 2/2] END bagging_fraction=0.9475324694731937, bagging_freq=6, feature_fraction=0.634940262396025, lambda_l1=1.7253810082152845, lambda_l2=6.600827581132637, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=131, objective=s, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.332 total time=  12.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.559092136769822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.559092136769822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5066830957506432, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5066830957506432\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.103311913043156, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.103311913043156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8225377945936752, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8225377945936752\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid_0's multi_logloss: 1.49839\n",
      "[CV 1/2] END bagging_fraction=0.5066830957506432, bagging_freq=8, feature_fraction=0.8225377945936752, lambda_l1=9.559092136769822, lambda_l2=4.103311913043156, learning_rate=0.05, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=390, objective=m, reg_lambda=1e-05, subsample=0.7, subsample_freq=4;, score=0.328 total time=   7.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.559092136769822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.559092136769822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5066830957506432, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5066830957506432\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.103311913043156, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.103311913043156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8225377945936752, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8225377945936752\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid_0's multi_logloss: 1.49784\n",
      "[CV 2/2] END bagging_fraction=0.5066830957506432, bagging_freq=8, feature_fraction=0.8225377945936752, lambda_l1=9.559092136769822, lambda_l2=4.103311913043156, learning_rate=0.05, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=390, objective=m, reg_lambda=1e-05, subsample=0.7, subsample_freq=4;, score=0.329 total time=   7.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.926132486034981, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.926132486034981\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8551749765184977, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8551749765184977\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.77764759108186, reg_lambda=0 will be ignored. Current value: lambda_l2=3.77764759108186\n",
      "[LightGBM] [Warning] feature_fraction is set=0.915370209917586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.915370209917586\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.50104\n",
      "[CV 2/2] END bagging_fraction=0.8551749765184977, bagging_freq=9, feature_fraction=0.915370209917586, lambda_l1=7.926132486034981, lambda_l2=3.77764759108186, learning_rate=0.2, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=509, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.328 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.749401990903637, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.749401990903637\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9064763572604698, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9064763572604698\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5161222293664958, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.5161222293664958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5758901228435975, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5758901228435975\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 1.49567\n",
      "[CV 2/2] END bagging_fraction=0.9064763572604698, bagging_freq=2, feature_fraction=0.5758901228435975, lambda_l1=8.749401990903637, lambda_l2=2.5161222293664958, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=24, objective=a, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=256;, score=0.330 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4418245216001786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4418245216001786\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5456740245109893, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5456740245109893\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3079430831754433, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.3079430831754433\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5182837122169096, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5182837122169096\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 1.50326\n",
      "[CV 2/2] END bagging_fraction=0.5456740245109893, bagging_freq=6, feature_fraction=0.5182837122169096, lambda_l1=3.4418245216001786, lambda_l2=2.3079430831754433, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=90, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=1;, score=0.327 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7671297310294154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7671297310294154\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9449349237081772, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9449349237081772\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7870145766214476, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.7870145766214476\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528097448642585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528097448642585\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8798495618980415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8798495618980415\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_logloss: 1.5057\n",
      "[CV 1/2] END bagging_fraction=0.5456372965686787, bagging_freq=9, feature_fraction=0.8798495618980415, lambda_l1=3.4390770348453774, lambda_l2=3.0493551053487846, learning_rate=0.2, metric=multi_logloss, min_child_samples=37, num_class=5, num_leaves=324, objective=t, reg_lambda=1e-06, subsample=0.6, subsample_freq=256;, score=0.325 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.833749606144027, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.833749606144027\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8354589927310097, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8354589927310097\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.581689988978966, reg_lambda=0 will be ignored. Current value: lambda_l2=7.581689988978966\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6479635317011769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6479635317011769\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[650]\tvalid_0's multi_logloss: 1.49641\n",
      "[CV 2/2] END bagging_fraction=0.8354589927310097, bagging_freq=2, feature_fraction=0.6479635317011769, lambda_l1=4.833749606144027, lambda_l2=7.581689988978966, learning_rate=0.01, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=118, objective=l, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=4;, score=0.331 total time=  14.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.903242151324807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.903242151324807\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8966214424896686, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8966214424896686\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.001723399144486, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.001723399144486\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6814092414301187, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6814092414301187\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1180]\tvalid_0's multi_logloss: 1.49971\n",
      "[CV 1/2] END bagging_fraction=0.8966214424896686, bagging_freq=2, feature_fraction=0.6814092414301187, lambda_l1=9.903242151324807, lambda_l2=5.001723399144486, learning_rate=0.01, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=126, objective=u, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=4;, score=0.332 total time=  24.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.926132486034981, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.926132486034981\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8551749765184977, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8551749765184977\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.77764759108186, reg_lambda=0 will be ignored. Current value: lambda_l2=3.77764759108186\n",
      "[LightGBM] [Warning] feature_fraction is set=0.915370209917586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.915370209917586\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 1.50598\n",
      "[CV 1/2] END bagging_fraction=0.8551749765184977, bagging_freq=9, feature_fraction=0.915370209917586, lambda_l1=7.926132486034981, lambda_l2=3.77764759108186, learning_rate=0.2, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=509, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.329 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.749401990903637, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.749401990903637\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9064763572604698, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9064763572604698\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5161222293664958, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.5161222293664958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5758901228435975, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5758901228435975\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 1.50124\n",
      "[CV 1/2] END bagging_fraction=0.9064763572604698, bagging_freq=2, feature_fraction=0.5758901228435975, lambda_l1=8.749401990903637, lambda_l2=2.5161222293664958, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=24, objective=a, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=256;, score=0.329 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4418245216001786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4418245216001786\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5456740245109893, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5456740245109893\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3079430831754433, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.3079430831754433\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5182837122169096, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5182837122169096\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's multi_logloss: 1.50732\n",
      "[CV 1/2] END bagging_fraction=0.5456740245109893, bagging_freq=6, feature_fraction=0.5182837122169096, lambda_l1=3.4418245216001786, lambda_l2=2.3079430831754433, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=90, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=1;, score=0.328 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7671297310294154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7671297310294154\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9449349237081772, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9449349237081772\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7870145766214476, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.7870145766214476\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528097448642585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528097448642585\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's multi_logloss: 1.49483\n",
      "[CV 1/2] END bagging_fraction=0.9449349237081772, bagging_freq=7, feature_fraction=0.8528097448642585, lambda_l1=2.7671297310294154, lambda_l2=2.7870145766214476, learning_rate=0.01, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=345, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=16;, score=0.331 total time=  20.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.478061179263953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.478061179263953\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6804450170265424, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6804450170265424\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_logloss: 1.48963\n",
      "[CV 2/2] END bagging_fraction=0.8786276624690292, bagging_freq=2, feature_fraction=0.905784268670293, lambda_l1=7.5432460332322036, lambda_l2=4.57695133941436, learning_rate=0.2, metric=multi_logloss, min_child_samples=32, num_class=5, num_leaves=48, objective=c, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=32;, score=0.331 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7253810082152845, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7253810082152845\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9475324694731937, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9475324694731937\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.600827581132637, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.600827581132637\n",
      "[LightGBM] [Warning] feature_fraction is set=0.634940262396025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.634940262396025\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 1.4896\n",
      "[CV 1/2] END bagging_fraction=0.9475324694731937, bagging_freq=6, feature_fraction=0.634940262396025, lambda_l1=1.7253810082152845, lambda_l2=6.600827581132637, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=131, objective=s, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.329 total time=  14.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.903242151324807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.903242151324807\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8966214424896686, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8966214424896686\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.001723399144486, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.001723399144486\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6814092414301187, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6814092414301187\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1166]\tvalid_0's multi_logloss: 1.4947\n",
      "[CV 2/2] END bagging_fraction=0.8966214424896686, bagging_freq=2, feature_fraction=0.6814092414301187, lambda_l1=9.903242151324807, lambda_l2=5.001723399144486, learning_rate=0.01, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=126, objective=u, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=4;, score=0.331 total time=  27.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.758319254371375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.758319254371375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6129563902070163, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6129563902070163\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8944548733050032, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.8944548733050032\n",
      "[LightGBM] [Warning] feature_fraction is set=0.422671946447966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.422671946447966\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 1.4971\n",
      "[CV 1/2] END bagging_fraction=0.6129563902070163, bagging_freq=6, feature_fraction=0.422671946447966, lambda_l1=5.758319254371375, lambda_l2=0.8944548733050032, learning_rate=0.2, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=124, objective=t, reg_lambda=0.001, subsample=0.6, subsample_freq=16;, score=0.329 total time=   6.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.758319254371375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.758319254371375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6129563902070163, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6129563902070163\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8944548733050032, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.8944548733050032\n",
      "[LightGBM] [Warning] feature_fraction is set=0.422671946447966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.422671946447966\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 1.49427\n",
      "[CV 2/2] END bagging_fraction=0.6129563902070163, bagging_freq=6, feature_fraction=0.422671946447966, lambda_l1=5.758319254371375, lambda_l2=0.8944548733050032, learning_rate=0.2, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=124, objective=t, reg_lambda=0.001, subsample=0.6, subsample_freq=16;, score=0.333 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.327419361429856, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.327419361429856\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6370181206137442, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6370181206137442\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8153458382311403, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.8153458382311403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6398938226084798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6398938226084798\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[558]\tvalid_0's multi_logloss: 1.50799\n",
      "[CV 1/2] END bagging_fraction=0.6370181206137442, bagging_freq=2, feature_fraction=0.6398938226084798, lambda_l1=8.327419361429856, lambda_l2=2.8153458382311403, learning_rate=0.05, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=224, objective=t, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.326 total time=   8.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.478061179263953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.478061179263953\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6804450170265424, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6804450170265424\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.627975866052689, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.627975866052689\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9306692103988377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9306692103988377\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's multi_logloss: 1.49389\n",
      "[CV 2/2] END bagging_fraction=0.6804450170265424, bagging_freq=9, feature_fraction=0.9306692103988377, lambda_l1=8.478061179263953, lambda_l2=5.627975866052689, learning_rate=0.01, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=300, objective=s, reg_lambda=1e-06, subsample=0.5, subsample_freq=32;, score=0.329 total time=  24.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0719878815982384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0719878815982384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6623880001469633, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6623880001469633\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.996984995647977, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.996984995647977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8707243739176839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8707243739176839\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's multi_logloss: 1.4964\n",
      "[CV 2/2] END bagging_fraction=0.9449349237081772, bagging_freq=7, feature_fraction=0.8528097448642585, lambda_l1=2.7671297310294154, lambda_l2=2.7870145766214476, learning_rate=0.01, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=345, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=16;, score=0.330 total time=  18.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.327419361429856, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.327419361429856\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6370181206137442, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6370181206137442\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8153458382311403, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.8153458382311403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6398938226084798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6398938226084798\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's multi_logloss: 1.49972\n",
      "[CV 2/2] END bagging_fraction=0.6370181206137442, bagging_freq=2, feature_fraction=0.6398938226084798, lambda_l1=8.327419361429856, lambda_l2=2.8153458382311403, learning_rate=0.05, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=224, objective=t, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.333 total time=   5.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.221393576466686, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.221393576466686\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5825908434716746, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5825908434716746\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7061184886750486, reg_lambda=0 will be ignored. Current value: lambda_l2=0.7061184886750486\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9554839072749367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9554839072749367\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's multi_logloss: 1.50201\n",
      "[CV 1/2] END bagging_fraction=0.5825908434716746, bagging_freq=6, feature_fraction=0.9554839072749367, lambda_l1=6.221393576466686, lambda_l2=0.7061184886750486, learning_rate=0.2, metric=multi_logloss, min_child_samples=26, num_class=5, num_leaves=500, objective=u, reg_lambda=0, subsample=0.6, subsample_freq=8;, score=0.311 total time=   6.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.221393576466686, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.221393576466686\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5825908434716746, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5825908434716746\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7061184886750486, reg_lambda=0 will be ignored. Current value: lambda_l2=0.7061184886750486\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9554839072749367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9554839072749367\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_logloss: 1.5002\n",
      "[CV 2/2] END bagging_fraction=0.5825908434716746, bagging_freq=6, feature_fraction=0.9554839072749367, lambda_l1=6.221393576466686, lambda_l2=0.7061184886750486, learning_rate=0.2, metric=multi_logloss, min_child_samples=26, num_class=5, num_leaves=500, objective=u, reg_lambda=0, subsample=0.6, subsample_freq=8;, score=0.329 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.92842962745211, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.92842962745211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.522251508580128, subsample=0.6 will be ignored. Current value: bagging_fraction=0.522251508580128\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9381623098283179, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.9381623098283179\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5999565682186954, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5999565682186954\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's multi_logloss: 1.49883\n",
      "[CV 1/2] END bagging_fraction=0.522251508580128, bagging_freq=6, feature_fraction=0.5999565682186954, lambda_l1=6.92842962745211, lambda_l2=0.9381623098283179, learning_rate=0.2, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=45, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=256;, score=0.328 total time=   5.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.020531894511560962, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020531894511560962\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8176659942595439, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8176659942595439\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2716565017964045, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.2716565017964045\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7502015734589399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7502015734589399\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's multi_logloss: 1.50078\n",
      "[CV 1/2] END bagging_fraction=0.8176659942595439, bagging_freq=5, feature_fraction=0.7502015734589399, lambda_l1=0.020531894511560962, lambda_l2=2.2716565017964045, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=498, objective=a, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.328 total time=   7.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.0719878815982384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0719878815982384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6623880001469633, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6623880001469633\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.996984995647977, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.996984995647977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8707243739176839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8707243739176839\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.50274\n",
      "[CV 2/2] END bagging_fraction=0.6623880001469633, bagging_freq=7, feature_fraction=0.8707243739176839, lambda_l1=3.0719878815982384, lambda_l2=4.996984995647977, learning_rate=0.2, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=342, objective=m, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=32;, score=0.328 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7279745926107717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7279745926107717\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5474355598359907, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5474355598359907\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.281503912185448, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.281503912185448\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 1.50018\n",
      "[CV 1/2] END bagging_fraction=0.6623880001469633, bagging_freq=7, feature_fraction=0.8707243739176839, lambda_l1=3.0719878815982384, lambda_l2=4.996984995647977, learning_rate=0.2, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=342, objective=m, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=32;, score=0.329 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.246509525645353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.246509525645353\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.763224130166952, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.763224130166952\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4848245279760155, reg_lambda=0 will be ignored. Current value: lambda_l2=5.4848245279760155\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6054839020131881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6054839020131881\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 1.50518\n",
      "[CV 1/2] END bagging_fraction=0.763224130166952, bagging_freq=9, feature_fraction=0.6054839020131881, lambda_l1=7.246509525645353, lambda_l2=5.4848245279760155, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=219, objective=m, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=2;, score=0.328 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7279745926107717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7279745926107717\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5474355598359907, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5474355598359907\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.281503912185448, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.281503912185448\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719593126811306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719593126811306\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's multi_logloss: 1.49391\n",
      "[CV 2/2] END bagging_fraction=0.5474355598359907, bagging_freq=8, feature_fraction=0.7719593126811306, lambda_l1=2.7279745926107717, lambda_l2=9.281503912185448, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=217, objective=s, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=8;, score=0.329 total time=  21.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.780847639065259, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.780847639065259\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079024260805177, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8079024260805177\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.955442616265743, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.955442616265743\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7971592565742627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7971592565742627\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 1.49883\n",
      "[CV 1/2] END bagging_fraction=0.8079024260805177, bagging_freq=6, feature_fraction=0.7971592565742627, lambda_l1=4.780847639065259, lambda_l2=3.955442616265743, learning_rate=0.2, metric=multi_logloss, min_child_samples=55, num_class=5, num_leaves=486, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.333 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.780847639065259, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.780847639065259\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079024260805177, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8079024260805177\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.955442616265743, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.955442616265743\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7971592565742627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7971592565742627\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.49529\n",
      "[CV 2/2] END bagging_fraction=0.8079024260805177, bagging_freq=6, feature_fraction=0.7971592565742627, lambda_l1=4.780847639065259, lambda_l2=3.955442616265743, learning_rate=0.2, metric=multi_logloss, min_child_samples=55, num_class=5, num_leaves=486, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.328 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4746676306604092, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4746676306604092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5452989019622699, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5452989019622699\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.639025583634878, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.639025583634878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7774186158301726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7774186158301726\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.51811\n",
      "[CV 1/2] END bagging_fraction=0.5452989019622699, bagging_freq=4, feature_fraction=0.7774186158301726, lambda_l1=1.4746676306604092, lambda_l2=7.639025583634878, learning_rate=0.2, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=390, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.323 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0120855841611096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0120855841611096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7517434667659433, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7517434667659433\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.786344855694699, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.786344855694699\n",
      "[LightGBM] [Warning] feature_fraction is set=0.691743630257089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.691743630257089\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's multi_logloss: 1.50618\n",
      "[CV 1/2] END bagging_fraction=0.7517434667659433, bagging_freq=3, feature_fraction=0.691743630257089, lambda_l1=2.0120855841611096, lambda_l2=8.786344855694699, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=46, objective=l, reg_lambda=1e-05, subsample=0.6, subsample_freq=8;, score=0.327 total time=  12.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6185107562304824, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6185107562304824\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.668515867959313, subsample=0.5 will be ignored. Current value: bagging_fraction=0.668515867959313\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7579485669391692, reg_lambda=0 will be ignored. Current value: lambda_l2=3.7579485669391692\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7679805035616039, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7679805035616039\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.627975866052689, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.627975866052689\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9306692103988377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9306692103988377\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's multi_logloss: 1.4993\n",
      "[CV 1/2] END bagging_fraction=0.6804450170265424, bagging_freq=9, feature_fraction=0.9306692103988377, lambda_l1=8.478061179263953, lambda_l2=5.627975866052689, learning_rate=0.01, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=300, objective=s, reg_lambda=1e-06, subsample=0.5, subsample_freq=32;, score=0.333 total time=  20.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.92842962745211, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.92842962745211\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.522251508580128, subsample=0.6 will be ignored. Current value: bagging_fraction=0.522251508580128\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9381623098283179, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.9381623098283179\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5999565682186954, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5999565682186954\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 1.49788\n",
      "[CV 2/2] END bagging_fraction=0.522251508580128, bagging_freq=6, feature_fraction=0.5999565682186954, lambda_l1=6.92842962745211, lambda_l2=0.9381623098283179, learning_rate=0.2, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=45, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=256;, score=0.329 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.020531894511560962, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020531894511560962\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8176659942595439, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8176659942595439\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2716565017964045, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.2716565017964045\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7502015734589399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7502015734589399\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.50552\n",
      "[CV 2/2] END bagging_fraction=0.8176659942595439, bagging_freq=5, feature_fraction=0.7502015734589399, lambda_l1=0.020531894511560962, lambda_l2=2.2716565017964045, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=498, objective=a, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.321 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.246509525645353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.246509525645353\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.763224130166952, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.763224130166952\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4848245279760155, reg_lambda=0 will be ignored. Current value: lambda_l2=5.4848245279760155\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6054839020131881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6054839020131881\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's multi_logloss: 1.49635\n",
      "[CV 2/2] END bagging_fraction=0.763224130166952, bagging_freq=9, feature_fraction=0.6054839020131881, lambda_l1=7.246509525645353, lambda_l2=5.4848245279760155, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=219, objective=m, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=2;, score=0.330 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.934807260324866, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.934807260324866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9447645033556015, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9447645033556015\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.964912283729306, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.964912283729306\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8501374789741157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8501374789741157\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[660]\tvalid_0's multi_logloss: 1.4923\n",
      "[CV 1/2] END bagging_fraction=0.9447645033556015, bagging_freq=6, feature_fraction=0.8501374789741157, lambda_l1=4.934807260324866, lambda_l2=5.964912283729306, learning_rate=0.01, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=54, objective=a, reg_lambda=1e-05, subsample=0.5, subsample_freq=256;, score=0.336 total time=  29.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4746676306604092, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4746676306604092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5452989019622699, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5452989019622699\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.639025583634878, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.639025583634878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7774186158301726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7774186158301726\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 1.50684\n",
      "[CV 2/2] END bagging_fraction=0.5452989019622699, bagging_freq=4, feature_fraction=0.7774186158301726, lambda_l1=1.4746676306604092, lambda_l2=7.639025583634878, learning_rate=0.2, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=390, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.323 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0120855841611096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0120855841611096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7517434667659433, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7517434667659433\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.786344855694699, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.786344855694699\n",
      "[LightGBM] [Warning] feature_fraction is set=0.691743630257089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.691743630257089\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's multi_logloss: 1.49919\n",
      "[CV 2/2] END bagging_fraction=0.7517434667659433, bagging_freq=3, feature_fraction=0.691743630257089, lambda_l1=2.0120855841611096, lambda_l2=8.786344855694699, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=46, objective=l, reg_lambda=1e-05, subsample=0.6, subsample_freq=8;, score=0.332 total time=  11.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.392600998365389, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.392600998365389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872324004683034, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8872324004683034\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's multi_logloss: 1.49203\n",
      "[CV 2/2] END bagging_fraction=0.668515867959313, bagging_freq=7, feature_fraction=0.7679805035616039, lambda_l1=3.6185107562304824, lambda_l2=3.7579485669391692, learning_rate=0.05, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=357, objective=u, reg_lambda=0, subsample=0.5, subsample_freq=8;, score=0.330 total time=   9.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5419298335609115, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5419298335609115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.468508878170447, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.468508878170447\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.743858213302385, reg_lambda=0 will be ignored. Current value: lambda_l2=6.743858213302385\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4517019263321337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4517019263321337\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's multi_logloss: 1.51097\n",
      "[CV 1/2] END bagging_fraction=0.468508878170447, bagging_freq=2, feature_fraction=0.4517019263321337, lambda_l1=5.5419298335609115, lambda_l2=6.743858213302385, learning_rate=0.05, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=379, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.321 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5419298335609115, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5419298335609115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.468508878170447, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.468508878170447\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.743858213302385, reg_lambda=0 will be ignored. Current value: lambda_l2=6.743858213302385\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4517019263321337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4517019263321337\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's multi_logloss: 1.49882\n",
      "[CV 2/2] END bagging_fraction=0.468508878170447, bagging_freq=2, feature_fraction=0.4517019263321337, lambda_l1=5.5419298335609115, lambda_l2=6.743858213302385, learning_rate=0.05, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=379, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.329 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.672387017000558, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.672387017000558\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6877763987954011, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6877763987954011\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.674329018889602, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.674329018889602\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9131303013805575, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9131303013805575\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's multi_logloss: 1.5132\n",
      "[CV 1/2] END bagging_fraction=0.6877763987954011, bagging_freq=6, feature_fraction=0.9131303013805575, lambda_l1=5.672387017000558, lambda_l2=4.674329018889602, learning_rate=0.01, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=371, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=16;, score=0.325 total time=   9.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.477182226894283, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.477182226894283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6335946167058893, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6335946167058893\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.356479845887939, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.356479845887939\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8928590722658677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8928590722658677\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[587]\tvalid_0's multi_logloss: 1.50604\n",
      "[CV 1/2] END bagging_fraction=0.6335946167058893, bagging_freq=6, feature_fraction=0.8928590722658677, lambda_l1=5.477182226894283, lambda_l2=4.356479845887939, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=174, objective=t, reg_lambda=1e-07, subsample=0.6, subsample_freq=16;, score=0.327 total time=  10.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.558429122769644, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.558429122769644\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8768759225218713, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8768759225218713\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.250959993471994, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.250959993471994\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6311922379327999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6311922379327999\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's multi_logloss: 1.49754\n",
      "[CV 2/2] END bagging_fraction=0.8768759225218713, bagging_freq=6, feature_fraction=0.6311922379327999, lambda_l1=9.558429122769644, lambda_l2=8.250959993471994, learning_rate=0.05, metric=multi_logloss, min_child_samples=88, num_class=5, num_leaves=506, objective=l, reg_lambda=1e-05, subsample=0.6, subsample_freq=1;, score=0.330 total time=   6.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.8335479636341, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.8335479636341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6011221401450461, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6011221401450461\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.474336355099329, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.474336355099329\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9419816195100249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9419816195100249\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 1.50759\n",
      "[CV 1/2] END bagging_fraction=0.6011221401450461, bagging_freq=2, feature_fraction=0.9419816195100249, lambda_l1=9.8335479636341, lambda_l2=9.474336355099329, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=283, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=8;, score=0.326 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.8335479636341, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.8335479636341\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6011221401450461, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6011221401450461\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.474336355099329, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.474336355099329\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9419816195100249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9419816195100249\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.370012349975616, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.370012349975616\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5028614483471164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5028614483471164\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[688]\tvalid_0's multi_logloss: 1.49629\n",
      "[CV 1/2] END bagging_fraction=0.8872324004683034, bagging_freq=9, feature_fraction=0.5028614483471164, lambda_l1=4.392600998365389, lambda_l2=6.370012349975616, learning_rate=0.01, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=232, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=1;, score=0.332 total time=  21.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.672387017000558, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.672387017000558\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6877763987954011, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6877763987954011\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.674329018889602, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.674329018889602\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9131303013805575, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9131303013805575\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's multi_logloss: 1.50009\n",
      "[CV 2/2] END bagging_fraction=0.6877763987954011, bagging_freq=6, feature_fraction=0.9131303013805575, lambda_l1=5.672387017000558, lambda_l2=4.674329018889602, learning_rate=0.01, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=371, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=16;, score=0.327 total time=   8.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.558429122769644, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.558429122769644\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8768759225218713, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8768759225218713\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.250959993471994, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.250959993471994\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6311922379327999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6311922379327999\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's multi_logloss: 1.50307\n",
      "[CV 1/2] END bagging_fraction=0.8768759225218713, bagging_freq=6, feature_fraction=0.6311922379327999, lambda_l1=9.558429122769644, lambda_l2=8.250959993471994, learning_rate=0.05, metric=multi_logloss, min_child_samples=88, num_class=5, num_leaves=506, objective=l, reg_lambda=1e-05, subsample=0.6, subsample_freq=1;, score=0.329 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.176759031647618, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.176759031647618\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43691909879166974, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.43691909879166974\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.252200722654433, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.252200722654433\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6111226660939925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6111226660939925\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[969]\tvalid_0's multi_logloss: 1.50951\n",
      "[CV 1/2] END bagging_fraction=0.43691909879166974, bagging_freq=3, feature_fraction=0.6111226660939925, lambda_l1=8.176759031647618, lambda_l2=2.252200722654433, learning_rate=0.01, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=392, objective=a, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.326 total time=  12.8s\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719593126811306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719593126811306\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid_0's multi_logloss: 1.49484\n",
      "[CV 1/2] END bagging_fraction=0.5474355598359907, bagging_freq=8, feature_fraction=0.7719593126811306, lambda_l1=2.7279745926107717, lambda_l2=9.281503912185448, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=217, objective=s, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=8;, score=0.331 total time=  17.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.934807260324866, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.934807260324866\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9447645033556015, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9447645033556015\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.964912283729306, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.964912283729306\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8501374789741157, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8501374789741157\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's multi_logloss: 1.48958\n",
      "[CV 2/2] END bagging_fraction=0.9447645033556015, bagging_freq=6, feature_fraction=0.8501374789741157, lambda_l1=4.934807260324866, lambda_l2=5.964912283729306, learning_rate=0.01, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=54, objective=a, reg_lambda=1e-05, subsample=0.5, subsample_freq=256;, score=0.334 total time=  22.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6185107562304824, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6185107562304824\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.668515867959313, subsample=0.5 will be ignored. Current value: bagging_fraction=0.668515867959313\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7579485669391692, reg_lambda=0 will be ignored. Current value: lambda_l2=3.7579485669391692\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7679805035616039, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7679805035616039\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's multi_logloss: 1.49391\n",
      "[CV 1/2] END bagging_fraction=0.668515867959313, bagging_freq=7, feature_fraction=0.7679805035616039, lambda_l1=3.6185107562304824, lambda_l2=3.7579485669391692, learning_rate=0.05, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=357, objective=u, reg_lambda=0, subsample=0.5, subsample_freq=8;, score=0.329 total time=  12.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.392600998365389, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.392600998365389\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8872324004683034, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8872324004683034\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.370012349975616, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.370012349975616\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5028614483471164, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5028614483471164\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[621]\tvalid_0's multi_logloss: 1.49259\n",
      "[CV 2/2] END bagging_fraction=0.8872324004683034, bagging_freq=9, feature_fraction=0.5028614483471164, lambda_l1=4.392600998365389, lambda_l2=6.370012349975616, learning_rate=0.01, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=232, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=1;, score=0.328 total time=  24.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.477182226894283, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.477182226894283\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6335946167058893, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6335946167058893\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.356479845887939, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.356479845887939\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8928590722658677, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8928590722658677\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[557]\tvalid_0's multi_logloss: 1.49854\n",
      "[CV 2/2] END bagging_fraction=0.6335946167058893, bagging_freq=6, feature_fraction=0.8928590722658677, lambda_l1=5.477182226894283, lambda_l2=4.356479845887939, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=174, objective=t, reg_lambda=1e-07, subsample=0.6, subsample_freq=16;, score=0.329 total time=  10.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.176759031647618, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.176759031647618\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43691909879166974, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.43691909879166974\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.252200722654433, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.252200722654433\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6111226660939925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6111226660939925\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[705]\tvalid_0's multi_logloss: 1.50135\n",
      "[CV 2/2] END bagging_fraction=0.43691909879166974, bagging_freq=3, feature_fraction=0.6111226660939925, lambda_l1=8.176759031647618, lambda_l2=2.252200722654433, learning_rate=0.01, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=392, objective=a, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.331 total time=  10.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.32400054898637204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.32400054898637204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.526341406066656, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.526341406066656\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.231029697264958, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.231029697264958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5603235808715212, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5603235808715212\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.51267\n",
      "[CV 1/2] END bagging_fraction=0.526341406066656, bagging_freq=6, feature_fraction=0.5603235808715212, lambda_l1=0.32400054898637204, lambda_l2=9.231029697264958, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=336, objective=i, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=4;, score=0.325 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.975879365573173, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.975879365573173\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9951207120887698, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9951207120887698\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's multi_logloss: 1.50116\n",
      "[CV 2/2] END bagging_fraction=0.6011221401450461, bagging_freq=2, feature_fraction=0.9419816195100249, lambda_l1=9.8335479636341, lambda_l2=9.474336355099329, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=283, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=8;, score=0.330 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.975879365573173, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.975879365573173\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9951207120887698, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9951207120887698\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.450475382083611, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.450475382083611\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5833909227730194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5833909227730194\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[703]\tvalid_0's multi_logloss: 1.50612\n",
      "[CV 1/2] END bagging_fraction=0.9951207120887698, bagging_freq=3, feature_fraction=0.5833909227730194, lambda_l1=8.975879365573173, lambda_l2=7.450475382083611, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=225, objective=s, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=128;, score=0.327 total time=   6.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.28251023591743, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.28251023591743\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7990945023544596, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7990945023544596\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6974184142013155, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.6974184142013155\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6197346854330861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6197346854330861\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[635]\tvalid_0's multi_logloss: 1.49221\n",
      "[CV 2/2] END bagging_fraction=0.7990945023544596, bagging_freq=5, feature_fraction=0.6197346854330861, lambda_l1=7.28251023591743, lambda_l2=0.6974184142013155, learning_rate=0.01, metric=multi_logloss, min_child_samples=27, num_class=5, num_leaves=182, objective=i, reg_lambda=1e-06, subsample=0.6, subsample_freq=2;, score=0.332 total time=  27.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8797765056353105, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8797765056353105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5194963726738601, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5194963726738601\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.313490355439138, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.313490355439138\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5995063855640098, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5995063855640098\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.50454\n",
      "[CV 2/2] END bagging_fraction=0.5194963726738601, bagging_freq=7, feature_fraction=0.5995063855640098, lambda_l1=0.8797765056353105, lambda_l2=0.313490355439138, learning_rate=0.2, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=420, objective=l, reg_lambda=1e-07, subsample=0.6, subsample_freq=2;, score=0.323 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.077408620921157, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.077408620921157\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.961220935042153, subsample=0.5 will be ignored. Current value: bagging_fraction=0.961220935042153\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3018156905721954, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.3018156905721954\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6763975917033986, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6763975917033986\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 1.49045\n",
      "[CV 1/2] END bagging_fraction=0.961220935042153, bagging_freq=7, feature_fraction=0.6763975917033986, lambda_l1=4.077408620921157, lambda_l2=2.3018156905721954, learning_rate=0.05, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=86, objective=i, reg_lambda=1e-06, subsample=0.5, subsample_freq=4;, score=0.334 total time=   9.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.211636142019335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.211636142019335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.783261413552711, subsample=0.7 will be ignored. Current value: bagging_fraction=0.783261413552711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3540967266890265, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.3540967266890265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953281447058008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953281447058008\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's multi_logloss: 1.49585\n",
      "[CV 1/2] END bagging_fraction=0.783261413552711, bagging_freq=8, feature_fraction=0.8953281447058008, lambda_l1=9.211636142019335, lambda_l2=3.3540967266890265, learning_rate=0.05, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=371, objective=t, reg_lambda=1e-06, subsample=0.7, subsample_freq=32;, score=0.330 total time=   7.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0590996495551117, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0590996495551117\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9112481297707631, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9112481297707631\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.850925430410908, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.850925430410908\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4660146216681053, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4660146216681053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.4948\n",
      "[CV 1/2] END bagging_fraction=0.9112481297707631, bagging_freq=7, feature_fraction=0.4660146216681053, lambda_l1=2.0590996495551117, lambda_l2=2.850925430410908, learning_rate=0.05, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=415, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=256;, score=0.334 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7941497587349717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7941497587349717\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5400204344483375, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5400204344483375\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2787491818882104, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.2787491818882104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6758281015236165, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6758281015236165\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.450475382083611, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.450475382083611\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5833909227730194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5833909227730194\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[484]\tvalid_0's multi_logloss: 1.49627\n",
      "[CV 2/2] END bagging_fraction=0.9951207120887698, bagging_freq=3, feature_fraction=0.5833909227730194, lambda_l1=8.975879365573173, lambda_l2=7.450475382083611, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=225, objective=s, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=128;, score=0.329 total time=   6.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.031279283297156, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.031279283297156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6208136080664286, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6208136080664286\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7637130728185674, reg_lambda=0 will be ignored. Current value: lambda_l2=0.7637130728185674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7054840742105712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7054840742105712\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid_0's multi_logloss: 1.51268\n",
      "[CV 1/2] END bagging_fraction=0.6208136080664286, bagging_freq=6, feature_fraction=0.7054840742105712, lambda_l1=8.031279283297156, lambda_l2=0.7637130728185674, learning_rate=0.01, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=30, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=128;, score=0.325 total time=   7.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.031279283297156, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.031279283297156\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6208136080664286, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6208136080664286\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7637130728185674, reg_lambda=0 will be ignored. Current value: lambda_l2=0.7637130728185674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7054840742105712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7054840742105712\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1116]\tvalid_0's multi_logloss: 1.49914\n",
      "[CV 2/2] END bagging_fraction=0.6208136080664286, bagging_freq=6, feature_fraction=0.7054840742105712, lambda_l1=8.031279283297156, lambda_l2=0.7637130728185674, learning_rate=0.01, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=30, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=128;, score=0.327 total time=  15.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8797765056353105, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8797765056353105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5194963726738601, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5194963726738601\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.313490355439138, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.313490355439138\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5995063855640098, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5995063855640098\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.5147\n",
      "[CV 1/2] END bagging_fraction=0.5194963726738601, bagging_freq=7, feature_fraction=0.5995063855640098, lambda_l1=0.8797765056353105, lambda_l2=0.313490355439138, learning_rate=0.2, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=420, objective=l, reg_lambda=1e-07, subsample=0.6, subsample_freq=2;, score=0.324 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.217934232576537, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.217934232576537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7816107335042664, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7816107335042664\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.766367246310097, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.766367246310097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.45032216229542305, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.45032216229542305\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's multi_logloss: 1.48911\n",
      "[CV 2/2] END bagging_fraction=0.7816107335042664, bagging_freq=6, feature_fraction=0.45032216229542305, lambda_l1=3.217934232576537, lambda_l2=9.766367246310097, learning_rate=0.05, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=47, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=64;, score=0.335 total time=  11.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.211636142019335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.211636142019335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.783261413552711, subsample=0.7 will be ignored. Current value: bagging_fraction=0.783261413552711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3540967266890265, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.3540967266890265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8953281447058008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8953281447058008\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's multi_logloss: 1.49566\n",
      "[CV 2/2] END bagging_fraction=0.783261413552711, bagging_freq=8, feature_fraction=0.8953281447058008, lambda_l1=9.211636142019335, lambda_l2=3.3540967266890265, learning_rate=0.05, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=371, objective=t, reg_lambda=1e-06, subsample=0.7, subsample_freq=32;, score=0.332 total time=   8.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7941497587349717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7941497587349717\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5400204344483375, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5400204344483375\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2787491818882104, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.2787491818882104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6758281015236165, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6758281015236165\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=128 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 1.49042\n",
      "[CV 1/2] END bagging_fraction=0.5400204344483375, bagging_freq=5, feature_fraction=0.6758281015236165, lambda_l1=2.7941497587349717, lambda_l2=1.2787491818882104, learning_rate=0.05, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=76, objective=u, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=128;, score=0.333 total time=  10.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.397243630884294, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.397243630884294\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.32400054898637204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.32400054898637204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.526341406066656, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.526341406066656\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.231029697264958, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.231029697264958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5603235808715212, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5603235808715212\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 1.50485\n",
      "[CV 2/2] END bagging_fraction=0.526341406066656, bagging_freq=6, feature_fraction=0.5603235808715212, lambda_l1=0.32400054898637204, lambda_l2=9.231029697264958, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=336, objective=i, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=4;, score=0.326 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.28251023591743, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.28251023591743\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7990945023544596, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7990945023544596\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6974184142013155, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.6974184142013155\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6197346854330861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6197346854330861\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[830]\tvalid_0's multi_logloss: 1.49428\n",
      "[CV 1/2] END bagging_fraction=0.7990945023544596, bagging_freq=5, feature_fraction=0.6197346854330861, lambda_l1=7.28251023591743, lambda_l2=0.6974184142013155, learning_rate=0.01, metric=multi_logloss, min_child_samples=27, num_class=5, num_leaves=182, objective=i, reg_lambda=1e-06, subsample=0.6, subsample_freq=2;, score=0.333 total time=  30.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.217934232576537, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.217934232576537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7816107335042664, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7816107335042664\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.766367246310097, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.766367246310097\n",
      "[LightGBM] [Warning] feature_fraction is set=0.45032216229542305, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.45032216229542305\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 1.48865\n",
      "[CV 1/2] END bagging_fraction=0.7816107335042664, bagging_freq=6, feature_fraction=0.45032216229542305, lambda_l1=3.217934232576537, lambda_l2=9.766367246310097, learning_rate=0.05, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=47, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=64;, score=0.336 total time=  11.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.077408620921157, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.077408620921157\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.961220935042153, subsample=0.5 will be ignored. Current value: bagging_fraction=0.961220935042153\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3018156905721954, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.3018156905721954\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6763975917033986, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6763975917033986\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 1.49237\n",
      "[CV 2/2] END bagging_fraction=0.961220935042153, bagging_freq=7, feature_fraction=0.6763975917033986, lambda_l1=4.077408620921157, lambda_l2=2.3018156905721954, learning_rate=0.05, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=86, objective=i, reg_lambda=1e-06, subsample=0.5, subsample_freq=4;, score=0.334 total time=   9.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0590996495551117, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0590996495551117\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9112481297707631, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9112481297707631\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.850925430410908, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.850925430410908\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4660146216681053, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4660146216681053\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's multi_logloss: 1.49341\n",
      "[CV 2/2] END bagging_fraction=0.9112481297707631, bagging_freq=7, feature_fraction=0.4660146216681053, lambda_l1=2.0590996495551117, lambda_l2=2.850925430410908, learning_rate=0.05, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=415, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=256;, score=0.324 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.397243630884294, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.397243630884294\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6680339967382115, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6680339967382115\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.741216408250022, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.741216408250022\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4025967781968185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4025967781968185\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1180]\tvalid_0's multi_logloss: 1.51087\n",
      "[CV 1/2] END bagging_fraction=0.6680339967382115, bagging_freq=5, feature_fraction=0.4025967781968185, lambda_l1=8.397243630884294, lambda_l2=9.741216408250022, learning_rate=0.01, metric=multi_logloss, min_child_samples=73, num_class=5, num_leaves=107, objective=s, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=8;, score=0.328 total time=  13.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.736256400712493, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.736256400712493\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8529850699486496, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8529850699486496\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.67692009885967, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.67692009885967\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5662514580277691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5662514580277691\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1304]\tvalid_0's multi_logloss: 1.49215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6680339967382115, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6680339967382115\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.741216408250022, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.741216408250022\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4025967781968185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4025967781968185\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1121]\tvalid_0's multi_logloss: 1.50002\n",
      "[CV 2/2] END bagging_fraction=0.6680339967382115, bagging_freq=5, feature_fraction=0.4025967781968185, lambda_l1=8.397243630884294, lambda_l2=9.741216408250022, learning_rate=0.01, metric=multi_logloss, min_child_samples=73, num_class=5, num_leaves=107, objective=s, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=8;, score=0.330 total time=  13.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.365869251767821, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.365869251767821\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47502179438870357, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.47502179438870357\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.299696037529459, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.299696037529459\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4634013592607501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4634013592607501\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[768]\tvalid_0's multi_logloss: 1.50094\n",
      "[CV 1/2] END bagging_fraction=0.47502179438870357, bagging_freq=8, feature_fraction=0.4634013592607501, lambda_l1=6.365869251767821, lambda_l2=7.299696037529459, learning_rate=0.01, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=372, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.330 total time=  19.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.107928680766473, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.107928680766473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612424941302374, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9612424941302374\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.157261286034348, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.157261286034348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7884151898981875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7884151898981875\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 1.49889\n",
      "[CV 1/2] END bagging_fraction=0.9612424941302374, bagging_freq=6, feature_fraction=0.7884151898981875, lambda_l1=5.107928680766473, lambda_l2=6.157261286034348, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=325, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.327 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.107928680766473, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.107928680766473\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612424941302374, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9612424941302374\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.157261286034348, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.157261286034348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7884151898981875, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7884151898981875\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's multi_logloss: 1.49673\n",
      "[CV 2/2] END bagging_fraction=0.9612424941302374, bagging_freq=6, feature_fraction=0.7884151898981875, lambda_l1=5.107928680766473, lambda_l2=6.157261286034348, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=325, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.330 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5031187512398665, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5031187512398665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.848785569882786, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.848785569882786\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.394514985117858, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.394514985117858\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4960505774324795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4960505774324795\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's multi_logloss: 1.49551\n",
      "[CV 2/2] END bagging_fraction=0.848785569882786, bagging_freq=8, feature_fraction=0.4960505774324795, lambda_l1=3.5031187512398665, lambda_l2=9.394514985117858, learning_rate=0.05, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=227, objective=i, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=64;, score=0.330 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3858280903942002, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3858280903942002\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8635804097892865, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8635804097892865\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.5796016175907557, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.5796016175907557\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8258794771170315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8258794771170315\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 1.50088\n",
      "[CV 2/2] END bagging_fraction=0.8635804097892865, bagging_freq=3, feature_fraction=0.8258794771170315, lambda_l1=1.3858280903942002, lambda_l2=3.5796016175907557, learning_rate=0.05, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=406, objective=i, reg_lambda=1e-05, subsample=0.5, subsample_freq=2;, score=0.331 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.329971998992779, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.329971998992779\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9205822707179778, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9205822707179778\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.813889487824754, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.813889487824754\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6613027959163129, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6613027959163129\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 1.50789\n",
      "[CV 1/2] END bagging_fraction=0.9205822707179778, bagging_freq=7, feature_fraction=0.6613027959163129, lambda_l1=3.329971998992779, lambda_l2=7.813889487824754, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=458, objective=u, reg_lambda=0.0001, subsample=0.7, subsample_freq=256;, score=0.327 total time=   4.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=128 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.49369\n",
      "[CV 2/2] END bagging_fraction=0.5400204344483375, bagging_freq=5, feature_fraction=0.6758281015236165, lambda_l1=2.7941497587349717, lambda_l2=1.2787491818882104, learning_rate=0.05, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=76, objective=u, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=128;, score=0.329 total time=   8.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.736256400712493, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.736256400712493\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8529850699486496, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8529850699486496\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.67692009885967, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.67692009885967\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5662514580277691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5662514580277691\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1160]\tvalid_0's multi_logloss: 1.49839\n",
      "[CV 1/2] END bagging_fraction=0.8529850699486496, bagging_freq=4, feature_fraction=0.5662514580277691, lambda_l1=7.736256400712493, lambda_l2=9.67692009885967, learning_rate=0.01, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=32, objective=l, reg_lambda=1e-07, subsample=0.7, subsample_freq=32;, score=0.332 total time=  24.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.365869251767821, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.365869251767821\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47502179438870357, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.47502179438870357\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.299696037529459, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.299696037529459\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4634013592607501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4634013592607501\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[984]\tvalid_0's multi_logloss: 1.49407\n",
      "[CV 2/2] END bagging_fraction=0.47502179438870357, bagging_freq=8, feature_fraction=0.4634013592607501, lambda_l1=6.365869251767821, lambda_l2=7.299696037529459, learning_rate=0.01, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=372, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.331 total time=  27.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4111732009838312, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4111732009838312\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9343752849674788, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9343752849674788\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.619423937574643, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.619423937574643\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49881321504041676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49881321504041676\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's multi_logloss: 1.49783\n",
      "[CV 2/2] END bagging_fraction=0.9343752849674788, bagging_freq=8, feature_fraction=0.49881321504041676, lambda_l1=0.4111732009838312, lambda_l2=3.619423937574643, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=196, objective=t, reg_lambda=0.001, subsample=0.6, subsample_freq=1;, score=0.329 total time=  13.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1776368798889125, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1776368798889125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9682048683574492, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9682048683574492\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4512574869357247, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.4512574869357247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6182019527203603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6182019527203603\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.49344\n",
      "[CV 2/2] END bagging_fraction=0.9682048683574492, bagging_freq=4, feature_fraction=0.6182019527203603, lambda_l1=3.1776368798889125, lambda_l2=0.4512574869357247, learning_rate=0.2, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=371, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=128;, score=0.329 total time=  14.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.329971998992779, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.329971998992779\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9205822707179778, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9205822707179778\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.813889487824754, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.813889487824754\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6613027959163129, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6613027959163129\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's multi_logloss: 1.49951\n",
      "[CV 2/2] END bagging_fraction=0.9205822707179778, bagging_freq=7, feature_fraction=0.6613027959163129, lambda_l1=3.329971998992779, lambda_l2=7.813889487824754, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=458, objective=u, reg_lambda=0.0001, subsample=0.7, subsample_freq=256;, score=0.331 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1776368798889125, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1776368798889125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9682048683574492, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9682048683574492\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4512574869357247, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.4512574869357247\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6182019527203603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6182019527203603\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.49599\n",
      "[CV 1/2] END bagging_fraction=0.9682048683574492, bagging_freq=4, feature_fraction=0.6182019527203603, lambda_l1=3.1776368798889125, lambda_l2=0.4512574869357247, learning_rate=0.2, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=371, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=128;, score=0.332 total time=  15.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6535712265413011, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6535712265413011\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46170863629308695, subsample=0.6 will be ignored. Current value: bagging_fraction=0.46170863629308695\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.748022292700876, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.748022292700876\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9267744917616825, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9267744917616825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's multi_logloss: 1.49843\n",
      "[CV 2/2] END bagging_fraction=0.46170863629308695, bagging_freq=8, feature_fraction=0.9267744917616825, lambda_l1=0.6535712265413011, lambda_l2=9.748022292700876, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=185, objective=u, reg_lambda=0.001, subsample=0.6, subsample_freq=128;, score=0.331 total time=  16.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.118104117989427, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.118104117989427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5450776584694227, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5450776584694227\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.464137678044892, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.464137678044892\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84458113495155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84458113495155\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's multi_logloss: 1.50276\n",
      "[CV 1/2] END bagging_fraction=0.5450776584694227, bagging_freq=7, feature_fraction=0.84458113495155, lambda_l1=8.118104117989427, lambda_l2=9.464137678044892, learning_rate=0.2, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=169, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.329 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.118104117989427, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.118104117989427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5450776584694227, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5450776584694227\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.464137678044892, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.464137678044892\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84458113495155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84458113495155\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's multi_logloss: 1.50427\n",
      "[CV 2/2] END bagging_fraction=0.5450776584694227, bagging_freq=7, feature_fraction=0.84458113495155, lambda_l1=8.118104117989427, lambda_l2=9.464137678044892, learning_rate=0.2, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=169, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.327 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9191182664172013, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9191182664172013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6537863435689251, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6537863435689251\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05549330459127117, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.05549330459127117\n",
      "[LightGBM] [Warning] feature_fraction is set=0.554615248992432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554615248992432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[393]\tvalid_0's multi_logloss: 1.51304\n",
      "[CV 1/2] END bagging_fraction=0.6537863435689251, bagging_freq=4, feature_fraction=0.554615248992432, lambda_l1=3.9191182664172013, lambda_l2=0.05549330459127117, learning_rate=0.01, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=353, objective=i, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=16;, score=0.324 total time=   9.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9191182664172013, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9191182664172013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6537863435689251, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6537863435689251\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05549330459127117, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.05549330459127117\n",
      "[LightGBM] [Warning] feature_fraction is set=0.554615248992432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554615248992432\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[554]\tvalid_0's multi_logloss: 1.50016\n",
      "[CV 2/2] END bagging_fraction=0.8529850699486496, bagging_freq=4, feature_fraction=0.5662514580277691, lambda_l1=7.736256400712493, lambda_l2=9.67692009885967, learning_rate=0.01, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=32, objective=l, reg_lambda=1e-07, subsample=0.7, subsample_freq=32;, score=0.331 total time=  31.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5031187512398665, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5031187512398665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.848785569882786, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.848785569882786\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.394514985117858, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.394514985117858\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4960505774324795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4960505774324795\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 1.4984\n",
      "[CV 1/2] END bagging_fraction=0.848785569882786, bagging_freq=8, feature_fraction=0.4960505774324795, lambda_l1=3.5031187512398665, lambda_l2=9.394514985117858, learning_rate=0.05, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=227, objective=i, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=64;, score=0.329 total time=   7.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3858280903942002, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3858280903942002\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8635804097892865, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8635804097892865\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.5796016175907557, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.5796016175907557\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8258794771170315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8258794771170315\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.50202\n",
      "[CV 1/2] END bagging_fraction=0.8635804097892865, bagging_freq=3, feature_fraction=0.8258794771170315, lambda_l1=1.3858280903942002, lambda_l2=3.5796016175907557, learning_rate=0.05, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=406, objective=i, reg_lambda=1e-05, subsample=0.5, subsample_freq=2;, score=0.329 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4111732009838312, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4111732009838312\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9343752849674788, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9343752849674788\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.619423937574643, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.619423937574643\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49881321504041676, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49881321504041676\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's multi_logloss: 1.498\n",
      "[CV 1/2] END bagging_fraction=0.9343752849674788, bagging_freq=8, feature_fraction=0.49881321504041676, lambda_l1=0.4111732009838312, lambda_l2=3.619423937574643, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=196, objective=t, reg_lambda=0.001, subsample=0.6, subsample_freq=1;, score=0.329 total time=  15.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6535712265413011, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6535712265413011\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46170863629308695, subsample=0.6 will be ignored. Current value: bagging_fraction=0.46170863629308695\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.748022292700876, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.748022292700876\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9267744917616825, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9267744917616825\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's multi_logloss: 1.50157\n",
      "[CV 1/2] END bagging_fraction=0.46170863629308695, bagging_freq=8, feature_fraction=0.9267744917616825, lambda_l1=0.6535712265413011, lambda_l2=9.748022292700876, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=185, objective=u, reg_lambda=0.001, subsample=0.6, subsample_freq=128;, score=0.331 total time=  13.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.278965798280066, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.278965798280066\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8855131715544103, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8855131715544103\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.503595634703589, reg_lambda=0 will be ignored. Current value: lambda_l2=6.503595634703589\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5495443360175153, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5495443360175153\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[654]\tvalid_0's multi_logloss: 1.49103\n",
      "[CV 1/2] END bagging_fraction=0.8855131715544103, bagging_freq=4, feature_fraction=0.5495443360175153, lambda_l1=5.278965798280066, lambda_l2=6.503595634703589, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=419, objective=i, reg_lambda=0, subsample=0.6, subsample_freq=2;, score=0.332 total time= 1.2min\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5850369675645535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5850369675645535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43948830525239496, subsample=0.6 will be ignored. Current value: bagging_fraction=0.43948830525239496\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.7022136062600675, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.7022136062600675\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4032485437147339, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4032485437147339\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's multi_logloss: 1.51723\n",
      "[CV 1/2] END bagging_fraction=0.43948830525239496, bagging_freq=9, feature_fraction=0.4032485437147339, lambda_l1=4.5850369675645535, lambda_l2=7.7022136062600675, learning_rate=0.05, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=108, objective=l, reg_lambda=1e-06, subsample=0.6, subsample_freq=128;, score=0.323 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9764611752929745, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9764611752929745\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7283602095868847, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7283602095868847\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.979666620221022, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.979666620221022\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5552861348324051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5552861348324051\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.49574\n",
      "[CV 2/2] END bagging_fraction=0.6537863435689251, bagging_freq=4, feature_fraction=0.554615248992432, lambda_l1=3.9191182664172013, lambda_l2=0.05549330459127117, learning_rate=0.01, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=353, objective=i, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=16;, score=0.328 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.378793588809959, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.378793588809959\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9666689265462823, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9666689265462823\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3055041077042002, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.3055041077042002\n",
      "[LightGBM] [Warning] feature_fraction is set=0.44274606786606874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44274606786606874\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[825]\tvalid_0's multi_logloss: 1.50019\n",
      "[CV 1/2] END bagging_fraction=0.9666689265462823, bagging_freq=3, feature_fraction=0.44274606786606874, lambda_l1=9.378793588809959, lambda_l2=3.3055041077042002, learning_rate=0.05, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=412, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=128;, score=0.329 total time=  12.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.378793588809959, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.378793588809959\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9666689265462823, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9666689265462823\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3055041077042002, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.3055041077042002\n",
      "[LightGBM] [Warning] feature_fraction is set=0.44274606786606874, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44274606786606874\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[445]\tvalid_0's multi_logloss: 1.49464\n",
      "[CV 2/2] END bagging_fraction=0.9666689265462823, bagging_freq=3, feature_fraction=0.44274606786606874, lambda_l1=9.378793588809959, lambda_l2=3.3055041077042002, learning_rate=0.05, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=412, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=128;, score=0.329 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.252610684121786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.252610684121786\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.802997295921787, subsample=0.7 will be ignored. Current value: bagging_fraction=0.802997295921787\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.490058624575299, reg_lambda=0 will be ignored. Current value: lambda_l2=5.490058624575299\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6982139878793365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6982139878793365\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's multi_logloss: 1.49525\n",
      "[CV 2/2] END bagging_fraction=0.802997295921787, bagging_freq=9, feature_fraction=0.6982139878793365, lambda_l1=6.252610684121786, lambda_l2=5.490058624575299, learning_rate=0.05, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=446, objective=i, reg_lambda=0, subsample=0.7, subsample_freq=64;, score=0.329 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.661575763702685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.661575763702685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6295342039608791, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6295342039608791\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.709867189584837, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.709867189584837\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9086324088813329, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9086324088813329\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 1.49958\n",
      "[CV 2/2] END bagging_fraction=0.6295342039608791, bagging_freq=6, feature_fraction=0.9086324088813329, lambda_l1=4.661575763702685, lambda_l2=5.709867189584837, learning_rate=0.05, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=165, objective=a, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.330 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9764611752929745, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9764611752929745\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7283602095868847, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7283602095868847\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.979666620221022, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.979666620221022\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5552861348324051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5552861348324051\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.49199\n",
      "[CV 1/2] END bagging_fraction=0.7283602095868847, bagging_freq=7, feature_fraction=0.5552861348324051, lambda_l1=0.9764611752929745, lambda_l2=7.979666620221022, learning_rate=0.2, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=75, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=1;, score=0.331 total time=   9.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.288364495735395, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.288364495735395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.955096997261573, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.955096997261573\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.62879993109767, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.62879993109767\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47919201035820935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47919201035820935\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's multi_logloss: 1.48834\n",
      "[CV 2/2] END bagging_fraction=0.955096997261573, bagging_freq=7, feature_fraction=0.47919201035820935, lambda_l1=6.288364495735395, lambda_l2=9.62879993109767, learning_rate=0.2, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=389, objective=c, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.329 total time=   8.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3381472961846663, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3381472961846663\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474337093017459, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9474337093017459\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.333249141365995, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.333249141365995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4605564664120035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4605564664120035\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[346]\tvalid_0's multi_logloss: 1.48692\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.278965798280066, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.278965798280066\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8855131715544103, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8855131715544103\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.503595634703589, reg_lambda=0 will be ignored. Current value: lambda_l2=6.503595634703589\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5495443360175153, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5495443360175153\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's multi_logloss: 1.49001\n",
      "[CV 2/2] END bagging_fraction=0.8855131715544103, bagging_freq=4, feature_fraction=0.5495443360175153, lambda_l1=5.278965798280066, lambda_l2=6.503595634703589, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=419, objective=i, reg_lambda=0, subsample=0.6, subsample_freq=2;, score=0.333 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.252610684121786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.252610684121786\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.802997295921787, subsample=0.7 will be ignored. Current value: bagging_fraction=0.802997295921787\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.490058624575299, reg_lambda=0 will be ignored. Current value: lambda_l2=5.490058624575299\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6982139878793365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6982139878793365\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 1.49871\n",
      "[CV 1/2] END bagging_fraction=0.802997295921787, bagging_freq=9, feature_fraction=0.6982139878793365, lambda_l1=6.252610684121786, lambda_l2=5.490058624575299, learning_rate=0.05, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=446, objective=i, reg_lambda=0, subsample=0.7, subsample_freq=64;, score=0.331 total time=   7.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.661575763702685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.661575763702685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6295342039608791, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6295342039608791\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.709867189584837, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.709867189584837\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9086324088813329, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9086324088813329\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 1.50529\n",
      "[CV 1/2] END bagging_fraction=0.6295342039608791, bagging_freq=6, feature_fraction=0.9086324088813329, lambda_l1=4.661575763702685, lambda_l2=5.709867189584837, learning_rate=0.05, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=165, objective=a, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.328 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5850369675645535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5850369675645535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43948830525239496, subsample=0.6 will be ignored. Current value: bagging_fraction=0.43948830525239496\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.7022136062600675, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.7022136062600675\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4032485437147339, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4032485437147339\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's multi_logloss: 1.50381\n",
      "[CV 2/2] END bagging_fraction=0.43948830525239496, bagging_freq=9, feature_fraction=0.4032485437147339, lambda_l1=4.5850369675645535, lambda_l2=7.7022136062600675, learning_rate=0.05, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=108, objective=l, reg_lambda=1e-06, subsample=0.6, subsample_freq=128;, score=0.324 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.288364495735395, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.288364495735395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.955096997261573, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.955096997261573\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.62879993109767, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.62879993109767\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47919201035820935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47919201035820935\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's multi_logloss: 1.49398\n",
      "[CV 1/2] END bagging_fraction=0.955096997261573, bagging_freq=7, feature_fraction=0.47919201035820935, lambda_l1=6.288364495735395, lambda_l2=9.62879993109767, learning_rate=0.2, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=389, objective=c, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.328 total time=   9.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.54311544127466, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.54311544127466\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7208159078191445, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7208159078191445\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.052170177307571, reg_lambda=0 will be ignored. Current value: lambda_l2=4.052170177307571\n",
      "[LightGBM] [Warning] feature_fraction is set=0.631610532215036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.631610532215036\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[882]\tvalid_0's multi_logloss: 1.49642\n",
      "[CV 2/2] END bagging_fraction=0.7208159078191445, bagging_freq=2, feature_fraction=0.631610532215036, lambda_l1=7.54311544127466, lambda_l2=4.052170177307571, learning_rate=0.01, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=207, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=8;, score=0.332 total time=  15.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3381472961846663, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3381472961846663\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474337093017459, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9474337093017459\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.333249141365995, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.333249141365995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4605564664120035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4605564664120035\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's multi_logloss: 1.4929\n",
      "[CV 2/2] END bagging_fraction=0.9474337093017459, bagging_freq=5, feature_fraction=0.4605564664120035, lambda_l1=2.3381472961846663, lambda_l2=3.333249141365995, learning_rate=0.01, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=390, objective=m, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.331 total time=  38.9s\n",
      "[CV 2/2] END bagging_fraction=0.7283602095868847, bagging_freq=7, feature_fraction=0.5552861348324051, lambda_l1=0.9764611752929745, lambda_l2=7.979666620221022, learning_rate=0.2, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=75, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=1;, score=0.334 total time=   8.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.54311544127466, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.54311544127466\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7208159078191445, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7208159078191445\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.052170177307571, reg_lambda=0 will be ignored. Current value: lambda_l2=4.052170177307571\n",
      "[LightGBM] [Warning] feature_fraction is set=0.631610532215036, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.631610532215036\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1439]\tvalid_0's multi_logloss: 1.50336\n",
      "[CV 1/2] END bagging_fraction=0.7208159078191445, bagging_freq=2, feature_fraction=0.631610532215036, lambda_l1=7.54311544127466, lambda_l2=4.052170177307571, learning_rate=0.01, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=207, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=8;, score=0.329 total time=  23.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.738276545354461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.738276545354461\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5703611958568519, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5703611958568519\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.098691437039359, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.098691437039359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6802457714962834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6802457714962834\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid_0's multi_logloss: 1.4932\n",
      "[CV 1/2] END bagging_fraction=0.5703611958568519, bagging_freq=2, feature_fraction=0.6802457714962834, lambda_l1=9.738276545354461, lambda_l2=6.098691437039359, learning_rate=0.05, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=370, objective=a, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.331 total time=  16.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.738276545354461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.738276545354461\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5703611958568519, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5703611958568519\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.098691437039359, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.098691437039359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6802457714962834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6802457714962834\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's multi_logloss: 1.49267\n",
      "[CV 2/2] END bagging_fraction=0.5703611958568519, bagging_freq=2, feature_fraction=0.6802457714962834, lambda_l1=9.738276545354461, lambda_l2=6.098691437039359, learning_rate=0.05, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=370, objective=a, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.327 total time=  10.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9389962435440772, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9389962435440772\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43194808645459737, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.43194808645459737\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.580186536752287, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.580186536752287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5643500063896343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5643500063896343\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[333]\tvalid_0's multi_logloss: 1.52236\n",
      "[CV 1/2] END bagging_fraction=0.43194808645459737, bagging_freq=9, feature_fraction=0.5643500063896343, lambda_l1=0.9389962435440772, lambda_l2=5.580186536752287, learning_rate=0.01, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=351, objective=c, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=128;, score=0.323 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3598342317021404, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3598342317021404\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7664782223291567, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7664782223291567\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.775647401448402, reg_lambda=0 will be ignored. Current value: lambda_l2=5.775647401448402\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5999992883445197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5999992883445197\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 1.49821\n",
      "[CV 1/2] END bagging_fraction=0.7664782223291567, bagging_freq=3, feature_fraction=0.5999992883445197, lambda_l1=2.3598342317021404, lambda_l2=5.775647401448402, learning_rate=0.2, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=192, objective=i, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.328 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.724479564245892, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.724479564245892\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.69112591441848, subsample=0.6 will be ignored. Current value: bagging_fraction=0.69112591441848\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.326200655854006, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.326200655854006\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6629334314117072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6629334314117072\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's multi_logloss: 1.49841\n",
      "[CV 2/2] END bagging_fraction=0.69112591441848, bagging_freq=2, feature_fraction=0.6629334314117072, lambda_l1=5.724479564245892, lambda_l2=3.326200655854006, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=310, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=256;, score=0.330 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5642711831487963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5642711831487963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7826907305548548, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7826907305548548\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1580961998200292, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.1580961998200292\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6419975199764374, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6419975199764374\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 1.50716\n",
      "[CV 1/2] END bagging_fraction=0.9474337093017459, bagging_freq=5, feature_fraction=0.4605564664120035, lambda_l1=2.3381472961846663, lambda_l2=3.333249141365995, learning_rate=0.01, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=390, objective=m, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.331 total time=  44.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9389962435440772, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9389962435440772\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43194808645459737, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.43194808645459737\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.580186536752287, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.580186536752287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5643500063896343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5643500063896343\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[595]\tvalid_0's multi_logloss: 1.50933\n",
      "[CV 2/2] END bagging_fraction=0.43194808645459737, bagging_freq=9, feature_fraction=0.5643500063896343, lambda_l1=0.9389962435440772, lambda_l2=5.580186536752287, learning_rate=0.01, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=351, objective=c, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=128;, score=0.318 total time=   9.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.724479564245892, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.724479564245892\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.69112591441848, subsample=0.6 will be ignored. Current value: bagging_fraction=0.69112591441848\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.326200655854006, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.326200655854006\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6629334314117072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6629334314117072\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 1.51379\n",
      "[CV 1/2] END bagging_fraction=0.69112591441848, bagging_freq=2, feature_fraction=0.6629334314117072, lambda_l1=5.724479564245892, lambda_l2=3.326200655854006, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=310, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=256;, score=0.326 total time=   3.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.115948957233598, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.115948957233598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6556980051027583, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6556980051027583\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.333995018373379, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.333995018373379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8654522632706827, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8654522632706827\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[707]\tvalid_0's multi_logloss: 1.49952\n",
      "[CV 1/2] END bagging_fraction=0.6556980051027583, bagging_freq=7, feature_fraction=0.8654522632706827, lambda_l1=6.115948957233598, lambda_l2=9.333995018373379, learning_rate=0.01, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=171, objective=l, reg_lambda=1e-07, subsample=0.5, subsample_freq=64;, score=0.330 total time=  16.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.944341953358578, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.944341953358578\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9383568098660537, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9383568098660537\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.032651488356412, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.032651488356412\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4182037674315501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4182037674315501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 1.48842\n",
      "[CV 2/2] END bagging_fraction=0.9383568098660537, bagging_freq=3, feature_fraction=0.4182037674315501, lambda_l1=9.944341953358578, lambda_l2=5.032651488356412, learning_rate=0.05, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=298, objective=i, reg_lambda=1e-06, subsample=0.5, subsample_freq=64;, score=0.334 total time=  24.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.123763761449323, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.123763761449323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.948324283639643, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.948324283639643\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0037748197445993, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.0037748197445993\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5180475552869038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5180475552869038\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.48731\n",
      "[CV 2/2] END bagging_fraction=0.948324283639643, bagging_freq=9, feature_fraction=0.5180475552869038, lambda_l1=7.123763761449323, lambda_l2=2.0037748197445993, learning_rate=0.2, metric=multi_logloss, min_child_samples=17, num_class=5, num_leaves=136, objective=a, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.334 total time=  10.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.628931776501889, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.628931776501889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44664823575917917, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.44664823575917917\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.41279969832217517, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.41279969832217517\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6234272522356382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6234272522356382\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.50636\n",
      "[CV 2/2] END bagging_fraction=0.44664823575917917, bagging_freq=9, feature_fraction=0.6234272522356382, lambda_l1=0.628931776501889, lambda_l2=0.41279969832217517, learning_rate=0.05, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=136, objective=t, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=1;, score=0.321 total time=   3.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.4983003949963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.4983003949963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9556330282873381, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9556330282873381\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0681674125952758, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.0681674125952758\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5347578971148552, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5347578971148552\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3598342317021404, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3598342317021404\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7664782223291567, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7664782223291567\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.775647401448402, reg_lambda=0 will be ignored. Current value: lambda_l2=5.775647401448402\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5999992883445197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5999992883445197\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.49516\n",
      "[CV 2/2] END bagging_fraction=0.7664782223291567, bagging_freq=3, feature_fraction=0.5999992883445197, lambda_l1=2.3598342317021404, lambda_l2=5.775647401448402, learning_rate=0.2, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=192, objective=i, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.328 total time=   7.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.115948957233598, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.115948957233598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6556980051027583, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6556980051027583\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.333995018373379, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.333995018373379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8654522632706827, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8654522632706827\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[644]\tvalid_0's multi_logloss: 1.49599\n",
      "[CV 2/2] END bagging_fraction=0.6556980051027583, bagging_freq=7, feature_fraction=0.8654522632706827, lambda_l1=6.115948957233598, lambda_l2=9.333995018373379, learning_rate=0.01, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=171, objective=l, reg_lambda=1e-07, subsample=0.5, subsample_freq=64;, score=0.330 total time=  18.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3021345741623216, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3021345741623216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8648512212245827, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8648512212245827\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.948451491302519, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.948451491302519\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9378624107999025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9378624107999025\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's multi_logloss: 1.5089\n",
      "[CV 1/2] END bagging_fraction=0.8648512212245827, bagging_freq=9, feature_fraction=0.9378624107999025, lambda_l1=1.3021345741623216, lambda_l2=9.948451491302519, learning_rate=0.01, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=358, objective=c, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=32;, score=0.327 total time=  10.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3021345741623216, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3021345741623216\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8648512212245827, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8648512212245827\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.948451491302519, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.948451491302519\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9378624107999025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9378624107999025\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's multi_logloss: 1.50367\n",
      "[CV 2/2] END bagging_fraction=0.8648512212245827, bagging_freq=9, feature_fraction=0.9378624107999025, lambda_l1=1.3021345741623216, lambda_l2=9.948451491302519, learning_rate=0.01, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=358, objective=c, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=32;, score=0.331 total time=  10.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.123763761449323, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.123763761449323\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.948324283639643, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.948324283639643\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0037748197445993, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.0037748197445993\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5180475552869038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5180475552869038\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.49364\n",
      "[CV 1/2] END bagging_fraction=0.948324283639643, bagging_freq=9, feature_fraction=0.5180475552869038, lambda_l1=7.123763761449323, lambda_l2=2.0037748197445993, learning_rate=0.2, metric=multi_logloss, min_child_samples=17, num_class=5, num_leaves=136, objective=a, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.327 total time=  11.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.628931776501889, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.628931776501889\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44664823575917917, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.44664823575917917\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.41279969832217517, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.41279969832217517\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6234272522356382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6234272522356382\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 1.51971\n",
      "[CV 1/2] END bagging_fraction=0.44664823575917917, bagging_freq=9, feature_fraction=0.6234272522356382, lambda_l1=0.628931776501889, lambda_l2=0.41279969832217517, learning_rate=0.05, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=136, objective=t, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=1;, score=0.325 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.698314720596513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.698314720596513\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8992303919648282, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8992303919648282\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.289489129439109, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.289489129439109\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5847989931558841, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5847989931558841\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's multi_logloss: 1.49054\n",
      "[CV 1/2] END bagging_fraction=0.7826907305548548, bagging_freq=8, feature_fraction=0.6419975199764374, lambda_l1=2.5642711831487963, lambda_l2=1.1580961998200292, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=378, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=32;, score=0.326 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5642711831487963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5642711831487963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7826907305548548, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7826907305548548\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1580961998200292, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.1580961998200292\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6419975199764374, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6419975199764374\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 1.49926\n",
      "[CV 2/2] END bagging_fraction=0.7826907305548548, bagging_freq=8, feature_fraction=0.6419975199764374, lambda_l1=2.5642711831487963, lambda_l2=1.1580961998200292, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=378, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=32;, score=0.328 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.944341953358578, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.944341953358578\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9383568098660537, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9383568098660537\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.032651488356412, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.032651488356412\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4182037674315501, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4182037674315501\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's multi_logloss: 1.49137\n",
      "[CV 1/2] END bagging_fraction=0.9383568098660537, bagging_freq=3, feature_fraction=0.4182037674315501, lambda_l1=9.944341953358578, lambda_l2=5.032651488356412, learning_rate=0.05, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=298, objective=i, reg_lambda=1e-06, subsample=0.5, subsample_freq=64;, score=0.330 total time=  31.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.092852796985421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.092852796985421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5444914984109044, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5444914984109044\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12962265496870545, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.12962265496870545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810225331643233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810225331643233\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 1.5107\n",
      "[CV 1/2] END bagging_fraction=0.5444914984109044, bagging_freq=9, feature_fraction=0.8810225331643233, lambda_l1=1.092852796985421, lambda_l2=0.12962265496870545, learning_rate=0.05, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=438, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.322 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.092852796985421, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.092852796985421\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5444914984109044, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5444914984109044\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12962265496870545, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.12962265496870545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810225331643233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810225331643233\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 1.50564\n",
      "[CV 2/2] END bagging_fraction=0.5444914984109044, bagging_freq=9, feature_fraction=0.8810225331643233, lambda_l1=1.092852796985421, lambda_l2=0.12962265496870545, learning_rate=0.05, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=438, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.327 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.698314720596513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.698314720596513\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8992303919648282, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8992303919648282\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.289489129439109, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.289489129439109\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5847989931558841, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5847989931558841\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[389]\tvalid_0's multi_logloss: 1.48907\n",
      "[CV 1/2] END bagging_fraction=0.8992303919648282, bagging_freq=7, feature_fraction=0.5847989931558841, lambda_l1=7.698314720596513, lambda_l2=4.289489129439109, learning_rate=0.05, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=67, objective=m, reg_lambda=0.001, subsample=0.6, subsample_freq=32;, score=0.333 total time=  20.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.610185277379205, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.610185277379205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6035385585459253, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6035385585459253\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22148701110574015, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.22148701110574015\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720872429442206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720872429442206\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's multi_logloss: 1.4985\n",
      "[CV 2/2] END bagging_fraction=0.6035385585459253, bagging_freq=3, feature_fraction=0.9720872429442206, lambda_l1=9.610185277379205, lambda_l2=0.22148701110574015, learning_rate=0.01, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=61, objective=l, reg_lambda=0.0001, subsample=0.7, subsample_freq=4;, score=0.330 total time=  16.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.9749142527249344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9749142527249344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079006125156198, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8079006125156198\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.695929747080739, reg_lambda=0 will be ignored. Current value: lambda_l2=6.695929747080739\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6203678268005723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6203678268005723\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 1.4956\n",
      "[CV 1/2] END bagging_fraction=0.8079006125156198, bagging_freq=3, feature_fraction=0.6203678268005723, lambda_l1=2.9749142527249344, lambda_l2=6.695929747080739, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=165, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=128;, score=0.330 total time=   5.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.9749142527249344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9749142527249344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079006125156198, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8079006125156198\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.695929747080739, reg_lambda=0 will be ignored. Current value: lambda_l2=6.695929747080739\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6203678268005723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6203678268005723\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.49562\n",
      "[CV 2/2] END bagging_fraction=0.8079006125156198, bagging_freq=3, feature_fraction=0.6203678268005723, lambda_l1=2.9749142527249344, lambda_l2=6.695929747080739, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=165, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=128;, score=0.327 total time=   5.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0858881772463977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0858881772463977\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4353518046324127, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4353518046324127\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.055526353578317, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.055526353578317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871522556826876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871522556826876\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 1.50603\n",
      "[CV 1/2] END bagging_fraction=0.4353518046324127, bagging_freq=3, feature_fraction=0.5871522556826876, lambda_l1=2.0858881772463977, lambda_l2=9.055526353578317, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=228, objective=l, reg_lambda=1e-07, subsample=0.6, subsample_freq=1;, score=0.325 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0858881772463977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0858881772463977\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4353518046324127, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4353518046324127\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.055526353578317, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.055526353578317\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871522556826876, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871522556826876\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_logloss: 1.50003\n",
      "[CV 2/2] END bagging_fraction=0.4353518046324127, bagging_freq=3, feature_fraction=0.5871522556826876, lambda_l1=2.0858881772463977, lambda_l2=9.055526353578317, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=228, objective=l, reg_lambda=1e-07, subsample=0.6, subsample_freq=1;, score=0.326 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.847978785196767, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.847978785196767\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5957526268794845, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5957526268794845\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.462783914303878, reg_lambda=0 will be ignored. Current value: lambda_l2=3.462783914303878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6223757160469913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6223757160469913\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 1.49346\n",
      "[CV 1/2] END bagging_fraction=0.5957526268794845, bagging_freq=2, feature_fraction=0.6223757160469913, lambda_l1=7.847978785196767, lambda_l2=3.462783914303878, learning_rate=0.2, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=495, objective=t, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.309 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.847978785196767, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.847978785196767\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5957526268794845, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5957526268794845\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.462783914303878, reg_lambda=0 will be ignored. Current value: lambda_l2=3.462783914303878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6223757160469913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6223757160469913\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 1.49534\n",
      "[CV 2/2] END bagging_fraction=0.5957526268794845, bagging_freq=2, feature_fraction=0.6223757160469913, lambda_l1=7.847978785196767, lambda_l2=3.462783914303878, learning_rate=0.2, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=495, objective=t, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.329 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5287267947529424, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5287267947529424\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.713462160051048, subsample=0.6 will be ignored. Current value: bagging_fraction=0.713462160051048\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8834151687519898, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.8834151687519898\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7726051769987401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7726051769987401\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1530]\tvalid_0's multi_logloss: 1.48868\n",
      "[CV 1/2] END bagging_fraction=0.713462160051048, bagging_freq=2, feature_fraction=0.7726051769987401, lambda_l1=2.5287267947529424, lambda_l2=1.8834151687519898, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=7, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=8;, score=0.339 total time=  26.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.652355813002586, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.652355813002586\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8188145438571286, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8188145438571286\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7466240122385914, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.7466240122385914\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104202745496852, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104202745496852\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[CV 2/2] END bagging_fraction=0.8992303919648282, bagging_freq=7, feature_fraction=0.5847989931558841, lambda_l1=7.698314720596513, lambda_l2=4.289489129439109, learning_rate=0.05, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=67, objective=m, reg_lambda=0.001, subsample=0.6, subsample_freq=32;, score=0.332 total time=  15.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.4983003949963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.4983003949963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9556330282873381, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9556330282873381\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0681674125952758, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.0681674125952758\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5347578971148552, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5347578971148552\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[792]\tvalid_0's multi_logloss: 1.49778\n",
      "[CV 2/2] END bagging_fraction=0.9556330282873381, bagging_freq=6, feature_fraction=0.5347578971148552, lambda_l1=7.4983003949963, lambda_l2=1.0681674125952758, learning_rate=0.01, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=274, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.331 total time=  14.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.265230034928876, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.265230034928876\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8670195483301348, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8670195483301348\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.800533739303762, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.800533739303762\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7735719667996415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7735719667996415\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid_0's multi_logloss: 1.49105\n",
      "[CV 2/2] END bagging_fraction=0.8670195483301348, bagging_freq=7, feature_fraction=0.7735719667996415, lambda_l1=6.265230034928876, lambda_l2=5.800533739303762, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=413, objective=t, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.335 total time=  50.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.652355813002586, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.652355813002586\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8188145438571286, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8188145438571286\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7466240122385914, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.7466240122385914\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104202745496852, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104202745496852\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's multi_logloss: 1.4947\n",
      "[CV 1/2] END bagging_fraction=0.8188145438571286, bagging_freq=5, feature_fraction=0.9104202745496852, lambda_l1=8.652355813002586, lambda_l2=1.7466240122385914, learning_rate=0.05, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=277, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=1;, score=0.331 total time=  11.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.610179452473621, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.610179452473621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6626792688750012, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6626792688750012\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0939338036243713, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.0939338036243713\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5669810822721968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5669810822721968\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's multi_logloss: 1.49718\n",
      "[CV 1/2] END bagging_fraction=0.6626792688750012, bagging_freq=7, feature_fraction=0.5669810822721968, lambda_l1=3.610179452473621, lambda_l2=3.0939338036243713, learning_rate=0.2, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=333, objective=t, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=1;, score=0.315 total time=  13.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.764381914837521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.764381914837521\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5015160442151553, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5015160442151553\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.042353760626031, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.042353760626031\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4720152834889135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4720152834889135\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[558]\tvalid_0's multi_logloss: 1.49606\n",
      "[CV 2/2] END bagging_fraction=0.5015160442151553, bagging_freq=2, feature_fraction=0.4720152834889135, lambda_l1=9.764381914837521, lambda_l2=4.042353760626031, learning_rate=0.05, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=217, objective=s, reg_lambda=0.0001, subsample=0.5, subsample_freq=1;, score=0.332 total time=   9.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.646170321690571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.646170321690571\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5971833108707897, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5971833108707897\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.872220053751026, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.872220053751026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7333120618528586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7333120618528586\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's multi_logloss: 1.49017\n",
      "[CV 1/2] END bagging_fraction=0.5971833108707897, bagging_freq=2, feature_fraction=0.7333120618528586, lambda_l1=4.646170321690571, lambda_l2=2.872220053751026, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=221, objective=c, reg_lambda=0.001, subsample=0.7, subsample_freq=128;, score=0.332 total time=  56.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9668702129559362, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9668702129559362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415459209506708, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9415459209506708\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.118422860510683, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.118422860510683\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7942414959505216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7942414959505216\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 1.49377\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 1.49152\n",
      "[CV 2/2] END bagging_fraction=0.8188145438571286, bagging_freq=5, feature_fraction=0.9104202745496852, lambda_l1=8.652355813002586, lambda_l2=1.7466240122385914, learning_rate=0.05, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=277, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=1;, score=0.331 total time=   9.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.610179452473621, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.610179452473621\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6626792688750012, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6626792688750012\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0939338036243713, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.0939338036243713\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5669810822721968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5669810822721968\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.49842\n",
      "[CV 2/2] END bagging_fraction=0.6626792688750012, bagging_freq=7, feature_fraction=0.5669810822721968, lambda_l1=3.610179452473621, lambda_l2=3.0939338036243713, learning_rate=0.2, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=333, objective=t, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=1;, score=0.332 total time=  12.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.876956058632299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.876956058632299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9173266405689371, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9173266405689371\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.736210442794613, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.736210442794613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9567596985060717, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9567596985060717\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's multi_logloss: 1.49199\n",
      "[CV 2/2] END bagging_fraction=0.9173266405689371, bagging_freq=3, feature_fraction=0.9567596985060717, lambda_l1=8.876956058632299, lambda_l2=9.736210442794613, learning_rate=0.05, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=146, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.332 total time=  11.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2157034523211246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2157034523211246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9892303368887593, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9892303368887593\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6843291087668595, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.6843291087668595\n",
      "[LightGBM] [Warning] feature_fraction is set=0.732403731128316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732403731128316\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.50376\n",
      "[CV 1/2] END bagging_fraction=0.9892303368887593, bagging_freq=7, feature_fraction=0.732403731128316, lambda_l1=0.2157034523211246, lambda_l2=3.6843291087668595, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=390, objective=u, reg_lambda=1e-07, subsample=0.5, subsample_freq=64;, score=0.331 total time=  41.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5103294920646165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5103294920646165\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5330373371401274, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5330373371401274\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.888638741435248, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.888638741435248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6376887102995608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6376887102995608\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.51282\n",
      "[CV 1/2] END bagging_fraction=0.5330373371401274, bagging_freq=9, feature_fraction=0.6376887102995608, lambda_l1=0.5103294920646165, lambda_l2=9.888638741435248, learning_rate=0.2, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=92, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=256;, score=0.329 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5103294920646165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5103294920646165\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5330373371401274, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5330373371401274\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.888638741435248, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.888638741435248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6376887102995608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6376887102995608\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.50507\n",
      "[CV 2/2] END bagging_fraction=0.5330373371401274, bagging_freq=9, feature_fraction=0.6376887102995608, lambda_l1=0.5103294920646165, lambda_l2=9.888638741435248, learning_rate=0.2, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=92, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=256;, score=0.326 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9668702129559362, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9668702129559362\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9415459209506708, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9415459209506708\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.118422860510683, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.118422860510683\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7942414959505216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7942414959505216\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 1.4973\n",
      "[CV 2/2] END bagging_fraction=0.9415459209506708, bagging_freq=3, feature_fraction=0.7942414959505216, lambda_l1=0.9668702129559362, lambda_l2=4.118422860510683, learning_rate=0.05, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=254, objective=l, reg_lambda=1e-06, subsample=0.6, subsample_freq=8;, score=0.328 total time=  12.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.625994269719487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.625994269719487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43127153396936235, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.43127153396936235\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.895178024464105, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.895178024464105\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7273096498820051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7273096498820051\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Early stopping, best iteration is:\n",
      "[918]\tvalid_0's multi_logloss: 1.50333\n",
      "[CV 1/2] END bagging_fraction=0.9556330282873381, bagging_freq=6, feature_fraction=0.5347578971148552, lambda_l1=7.4983003949963, lambda_l2=1.0681674125952758, learning_rate=0.01, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=274, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=128;, score=0.329 total time=  15.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.610185277379205, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.610185277379205\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6035385585459253, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6035385585459253\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22148701110574015, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.22148701110574015\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720872429442206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720872429442206\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's multi_logloss: 1.51104\n",
      "[CV 1/2] END bagging_fraction=0.6035385585459253, bagging_freq=3, feature_fraction=0.9720872429442206, lambda_l1=9.610185277379205, lambda_l2=0.22148701110574015, learning_rate=0.01, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=61, objective=l, reg_lambda=0.0001, subsample=0.7, subsample_freq=4;, score=0.325 total time=   7.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.265230034928876, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.265230034928876\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8670195483301348, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8670195483301348\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.800533739303762, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.800533739303762\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7735719667996415, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7735719667996415\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[532]\tvalid_0's multi_logloss: 1.4918\n",
      "[CV 1/2] END bagging_fraction=0.8670195483301348, bagging_freq=7, feature_fraction=0.7735719667996415, lambda_l1=6.265230034928876, lambda_l2=5.800533739303762, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=413, objective=t, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.330 total time=  55.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5287267947529424, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5287267947529424\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.713462160051048, subsample=0.6 will be ignored. Current value: bagging_fraction=0.713462160051048\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8834151687519898, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.8834151687519898\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7726051769987401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7726051769987401\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1312]\tvalid_0's multi_logloss: 1.48934\n",
      "[CV 2/2] END bagging_fraction=0.713462160051048, bagging_freq=2, feature_fraction=0.7726051769987401, lambda_l1=2.5287267947529424, lambda_l2=1.8834151687519898, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=7, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=8;, score=0.340 total time=  22.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.764381914837521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.764381914837521\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5015160442151553, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5015160442151553\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.042353760626031, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.042353760626031\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4720152834889135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4720152834889135\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[554]\tvalid_0's multi_logloss: 1.50403\n",
      "[CV 1/2] END bagging_fraction=0.5015160442151553, bagging_freq=2, feature_fraction=0.4720152834889135, lambda_l1=9.764381914837521, lambda_l2=4.042353760626031, learning_rate=0.05, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=217, objective=s, reg_lambda=0.0001, subsample=0.5, subsample_freq=1;, score=0.327 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.876956058632299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.876956058632299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9173266405689371, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9173266405689371\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.736210442794613, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.736210442794613\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9567596985060717, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9567596985060717\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 1.49496\n",
      "[CV 1/2] END bagging_fraction=0.9173266405689371, bagging_freq=3, feature_fraction=0.9567596985060717, lambda_l1=8.876956058632299, lambda_l2=9.736210442794613, learning_rate=0.05, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=146, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.331 total time=  11.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.646170321690571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.646170321690571\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5971833108707897, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5971833108707897\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.872220053751026, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.872220053751026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7333120618528586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7333120618528586\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[360]\tvalid_0's multi_logloss: 1.49132\n",
      "[CV 2/2] END bagging_fraction=0.5971833108707897, bagging_freq=2, feature_fraction=0.7333120618528586, lambda_l1=4.646170321690571, lambda_l2=2.872220053751026, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=221, objective=c, reg_lambda=0.001, subsample=0.7, subsample_freq=128;, score=0.333 total time=  39.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2157034523211246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2157034523211246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9892303368887593, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9892303368887593\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6843291087668595, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.6843291087668595\n",
      "[LightGBM] [Warning] feature_fraction is set=0.732403731128316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.732403731128316\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.50232\n",
      "[CV 2/2] END bagging_fraction=0.9892303368887593, bagging_freq=7, feature_fraction=0.732403731128316, lambda_l1=0.2157034523211246, lambda_l2=3.6843291087668595, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=390, objective=u, reg_lambda=1e-07, subsample=0.5, subsample_freq=64;, score=0.330 total time=  39.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.810976831767878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.810976831767878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48819495371475136, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.48819495371475136\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.791010701103987, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.791010701103987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.882702390676987, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.882702390676987\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 1.48939\n",
      "[CV 1/2] END bagging_fraction=0.48819495371475136, bagging_freq=2, feature_fraction=0.882702390676987, lambda_l1=7.810976831767878, lambda_l2=5.791010701103987, learning_rate=0.05, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=247, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=128;, score=0.330 total time=  17.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.810976831767878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.810976831767878\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48819495371475136, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.48819495371475136\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.791010701103987, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.791010701103987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.882702390676987, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.882702390676987\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 1.48996\n",
      "[CV 2/2] END bagging_fraction=0.48819495371475136, bagging_freq=2, feature_fraction=0.882702390676987, lambda_l1=7.810976831767878, lambda_l2=5.791010701103987, learning_rate=0.05, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=247, objective=c, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=128;, score=0.331 total time=  22.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9036430016736433, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9036430016736433\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9278470555438681, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9278470555438681\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.022266286159667, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.022266286159667\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9508365951288593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9508365951288593\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.50603\n",
      "[CV 1/2] END bagging_fraction=0.9278470555438681, bagging_freq=3, feature_fraction=0.9508365951288593, lambda_l1=0.9036430016736433, lambda_l2=9.022266286159667, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=327, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=64;, score=0.329 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.844388501318657, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.844388501318657\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8660529575483764, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8660529575483764\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.910171460490986, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.910171460490986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5710559141368577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5710559141368577\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=256 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's multi_logloss: 1.49886\n",
      "[CV 2/2] END bagging_fraction=0.8660529575483764, bagging_freq=4, feature_fraction=0.5710559141368577, lambda_l1=4.844388501318657, lambda_l2=2.910171460490986, learning_rate=0.01, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=200, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=256;, score=0.332 total time=  10.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5387376716334655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5387376716334655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.715172417593855, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.715172417593855\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0523839497081897, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.0523839497081897\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8457292212681895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8457292212681895\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.51007\n",
      "[CV 1/2] END bagging_fraction=0.715172417593855, bagging_freq=2, feature_fraction=0.8457292212681895, lambda_l1=3.5387376716334655, lambda_l2=3.0523839497081897, learning_rate=0.05, metric=multi_logloss, min_child_samples=89, num_class=5, num_leaves=380, objective=s, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.325 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5387376716334655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5387376716334655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.715172417593855, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.715172417593855\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0523839497081897, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.0523839497081897\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8457292212681895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8457292212681895\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's multi_logloss: 1.5019\n",
      "[CV 2/2] END bagging_fraction=0.715172417593855, bagging_freq=2, feature_fraction=0.8457292212681895, lambda_l1=3.5387376716334655, lambda_l2=3.0523839497081897, learning_rate=0.05, metric=multi_logloss, min_child_samples=89, num_class=5, num_leaves=380, objective=s, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.330 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.807627535648802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.807627535648802\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9140266371239886, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9140266371239886\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10036010839983206, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.10036010839983206\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7491046370142345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7491046370142345\n",
      "[CV 1/2] END bagging_fraction=0.9415459209506708, bagging_freq=3, feature_fraction=0.7942414959505216, lambda_l1=0.9668702129559362, lambda_l2=4.118422860510683, learning_rate=0.05, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=254, objective=l, reg_lambda=1e-06, subsample=0.6, subsample_freq=8;, score=0.332 total time=  11.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.625994269719487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.625994269719487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43127153396936235, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.43127153396936235\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.895178024464105, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.895178024464105\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7273096498820051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7273096498820051\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's multi_logloss: 1.49145\n",
      "[CV 1/2] END bagging_fraction=0.43127153396936235, bagging_freq=4, feature_fraction=0.7273096498820051, lambda_l1=7.625994269719487, lambda_l2=8.895178024464105, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=209, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=4;, score=0.313 total time=  12.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.96777046770598, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.96777046770598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.773031591137346, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.773031591137346\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.031260054521382, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.031260054521382\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5074234633558625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5074234633558625\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1159]\tvalid_0's multi_logloss: 1.49358\n",
      "[CV 1/2] END bagging_fraction=0.773031591137346, bagging_freq=7, feature_fraction=0.5074234633558625, lambda_l1=7.96777046770598, lambda_l2=4.031260054521382, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=352, objective=i, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=128;, score=0.331 total time=  45.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1360913267529698, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1360913267529698\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4557086861550001, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4557086861550001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27862298488231435, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.27862298488231435\n",
      "[LightGBM] [Warning] feature_fraction is set=0.651173677637141, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.651173677637141\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 1.52103\n",
      "[CV 1/2] END bagging_fraction=0.4557086861550001, bagging_freq=5, feature_fraction=0.651173677637141, lambda_l1=0.1360913267529698, lambda_l2=0.27862298488231435, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=404, objective=i, reg_lambda=1e-05, subsample=0.5, subsample_freq=4;, score=0.325 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9036430016736433, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9036430016736433\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9278470555438681, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9278470555438681\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.022266286159667, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.022266286159667\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9508365951288593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9508365951288593\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.50347\n",
      "[CV 2/2] END bagging_fraction=0.9278470555438681, bagging_freq=3, feature_fraction=0.9508365951288593, lambda_l1=0.9036430016736433, lambda_l2=9.022266286159667, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=327, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=64;, score=0.330 total time=   6.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.406771017242795, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.406771017242795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7209409012336221, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7209409012336221\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.461904464522564, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.461904464522564\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6353073713929251, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6353073713929251\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's multi_logloss: 1.50856\n",
      "[CV 1/2] END bagging_fraction=0.7209409012336221, bagging_freq=2, feature_fraction=0.6353073713929251, lambda_l1=9.406771017242795, lambda_l2=4.461904464522564, learning_rate=0.05, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=57, objective=i, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=4;, score=0.327 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.537389159176664, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.537389159176664\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.74774245274388, subsample=0.5 will be ignored. Current value: bagging_fraction=0.74774245274388\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.785633662885534, reg_lambda=0 will be ignored. Current value: lambda_l2=9.785633662885534\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9193018523240523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9193018523240523\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[686]\tvalid_0's multi_logloss: 1.50739\n",
      "[CV 1/2] END bagging_fraction=0.74774245274388, bagging_freq=7, feature_fraction=0.9193018523240523, lambda_l1=4.537389159176664, lambda_l2=9.785633662885534, learning_rate=0.01, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=16, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=2;, score=0.326 total time=   8.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.760958019264332, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.760958019264332\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5401339529393374, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5401339529393374\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.383394117281432, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.383394117281432\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9289538933436152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9289538933436152\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's multi_logloss: 1.49071\n",
      "[CV 2/2] END bagging_fraction=0.43127153396936235, bagging_freq=4, feature_fraction=0.7273096498820051, lambda_l1=7.625994269719487, lambda_l2=8.895178024464105, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=209, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=4;, score=0.330 total time=  12.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.96777046770598, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.96777046770598\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.773031591137346, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.773031591137346\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.031260054521382, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.031260054521382\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5074234633558625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5074234633558625\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[879]\tvalid_0's multi_logloss: 1.49016\n",
      "[CV 2/2] END bagging_fraction=0.773031591137346, bagging_freq=7, feature_fraction=0.5074234633558625, lambda_l1=7.96777046770598, lambda_l2=4.031260054521382, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=352, objective=i, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=128;, score=0.332 total time=  39.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1360913267529698, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1360913267529698\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4557086861550001, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4557086861550001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27862298488231435, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.27862298488231435\n",
      "[LightGBM] [Warning] feature_fraction is set=0.651173677637141, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.651173677637141\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 1.51267\n",
      "[CV 2/2] END bagging_fraction=0.4557086861550001, bagging_freq=5, feature_fraction=0.651173677637141, lambda_l1=0.1360913267529698, lambda_l2=0.27862298488231435, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=404, objective=i, reg_lambda=1e-05, subsample=0.5, subsample_freq=4;, score=0.318 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.844388501318657, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.844388501318657\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8660529575483764, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8660529575483764\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.910171460490986, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.910171460490986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5710559141368577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5710559141368577\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=256 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[408]\tvalid_0's multi_logloss: 1.5095\n",
      "[CV 1/2] END bagging_fraction=0.8660529575483764, bagging_freq=4, feature_fraction=0.5710559141368577, lambda_l1=4.844388501318657, lambda_l2=2.910171460490986, learning_rate=0.01, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=200, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=256;, score=0.327 total time=   8.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.406771017242795, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.406771017242795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7209409012336221, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7209409012336221\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.461904464522564, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.461904464522564\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6353073713929251, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6353073713929251\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's multi_logloss: 1.49778\n",
      "[CV 2/2] END bagging_fraction=0.7209409012336221, bagging_freq=2, feature_fraction=0.6353073713929251, lambda_l1=9.406771017242795, lambda_l2=4.461904464522564, learning_rate=0.05, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=57, objective=i, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=4;, score=0.330 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.537389159176664, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.537389159176664\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.74774245274388, subsample=0.5 will be ignored. Current value: bagging_fraction=0.74774245274388\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.785633662885534, reg_lambda=0 will be ignored. Current value: lambda_l2=9.785633662885534\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9193018523240523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9193018523240523\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's multi_logloss: 1.49761\n",
      "[CV 2/2] END bagging_fraction=0.74774245274388, bagging_freq=7, feature_fraction=0.9193018523240523, lambda_l1=4.537389159176664, lambda_l2=9.785633662885534, learning_rate=0.01, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=16, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=2;, score=0.331 total time=   8.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.760958019264332, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.760958019264332\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5401339529393374, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5401339529393374\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.383394117281432, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.383394117281432\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9289538933436152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9289538933436152\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's multi_logloss: 1.50148\n",
      "[CV 2/2] END bagging_fraction=0.5401339529393374, bagging_freq=4, feature_fraction=0.9289538933436152, lambda_l1=6.760958019264332, lambda_l2=5.383394117281432, learning_rate=0.01, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=199, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=128;, score=0.330 total time=   9.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.855153911060906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.855153911060906\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.588195216469842, subsample=0.6 will be ignored. Current value: bagging_fraction=0.588195216469842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3275145512803271, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.3275145512803271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6500835308544441, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6500835308544441\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 1.49828\n",
      "[CV 1/2] END bagging_fraction=0.9140266371239886, bagging_freq=5, feature_fraction=0.7491046370142345, lambda_l1=9.807627535648802, lambda_l2=0.10036010839983206, learning_rate=0.2, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=324, objective=a, reg_lambda=1e-06, subsample=0.5, subsample_freq=64;, score=0.331 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.807627535648802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.807627535648802\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9140266371239886, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9140266371239886\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10036010839983206, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.10036010839983206\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7491046370142345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7491046370142345\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 1.49361\n",
      "[CV 2/2] END bagging_fraction=0.9140266371239886, bagging_freq=5, feature_fraction=0.7491046370142345, lambda_l1=9.807627535648802, lambda_l2=0.10036010839983206, learning_rate=0.2, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=324, objective=a, reg_lambda=1e-06, subsample=0.5, subsample_freq=64;, score=0.331 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.855153911060906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.855153911060906\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.588195216469842, subsample=0.6 will be ignored. Current value: bagging_fraction=0.588195216469842\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3275145512803271, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.3275145512803271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6500835308544441, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6500835308544441\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[768]\tvalid_0's multi_logloss: 1.49391\n",
      "[CV 1/2] END bagging_fraction=0.588195216469842, bagging_freq=8, feature_fraction=0.6500835308544441, lambda_l1=9.855153911060906, lambda_l2=0.3275145512803271, learning_rate=0.01, metric=multi_logloss, min_child_samples=13, num_class=5, num_leaves=407, objective=t, reg_lambda=1e-05, subsample=0.6, subsample_freq=16;, score=0.331 total time=  34.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[740]\tvalid_0's multi_logloss: 1.48966\n",
      "[CV 2/2] END bagging_fraction=0.588195216469842, bagging_freq=8, feature_fraction=0.6500835308544441, lambda_l1=9.855153911060906, lambda_l2=0.3275145512803271, learning_rate=0.01, metric=multi_logloss, min_child_samples=13, num_class=5, num_leaves=407, objective=t, reg_lambda=1e-05, subsample=0.6, subsample_freq=16;, score=0.330 total time=  34.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.540579037413883, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.540579037413883\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7571460127937506, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7571460127937506\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.574754264736907, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.574754264736907\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9973075708158858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9973075708158858\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's multi_logloss: 1.49675\n",
      "[CV 2/2] END bagging_fraction=0.7571460127937506, bagging_freq=2, feature_fraction=0.9973075708158858, lambda_l1=3.540579037413883, lambda_l2=8.574754264736907, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=7, objective=s, reg_lambda=1e-07, subsample=0.5, subsample_freq=4;, score=0.333 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4542036137240471, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4542036137240471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.444506941938294, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.444506941938294\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.106409694907239, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.106409694907239\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6394585136018538, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6394585136018538\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[374]\tvalid_0's multi_logloss: 1.49729\n",
      "[CV 1/2] END bagging_fraction=0.444506941938294, bagging_freq=5, feature_fraction=0.6394585136018538, lambda_l1=0.4542036137240471, lambda_l2=8.106409694907239, learning_rate=0.01, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=136, objective=i, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.331 total time=  15.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.615735336836863, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.615735336836863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6318545471909687, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6318545471909687\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.630892736736111, reg_lambda=0 will be ignored. Current value: lambda_l2=9.630892736736111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7404031753650406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7404031753650406\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[827]\tvalid_0's multi_logloss: 1.49758\n",
      "[CV 2/2] END bagging_fraction=0.6318545471909687, bagging_freq=6, feature_fraction=0.7404031753650406, lambda_l1=7.615735336836863, lambda_l2=9.630892736736111, learning_rate=0.01, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=62, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=2;, score=0.330 total time=  15.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.666752626040817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.666752626040817\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.751223915469891, subsample=0.6 will be ignored. Current value: bagging_fraction=0.751223915469891\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3962557418472734, reg_lambda=0 will be ignored. Current value: lambda_l2=2.3962557418472734\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41670222801852724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41670222801852724\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_logloss: 1.50143\n",
      "[CV 1/2] END bagging_fraction=0.751223915469891, bagging_freq=3, feature_fraction=0.41670222801852724, lambda_l1=3.666752626040817, lambda_l2=2.3962557418472734, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=353, objective=i, reg_lambda=0, subsample=0.6, subsample_freq=256;, score=0.330 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.666752626040817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.666752626040817\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.751223915469891, subsample=0.6 will be ignored. Current value: bagging_fraction=0.751223915469891\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3962557418472734, reg_lambda=0 will be ignored. Current value: lambda_l2=2.3962557418472734\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41670222801852724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41670222801852724\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.49364\n",
      "[CV 2/2] END bagging_fraction=0.751223915469891, bagging_freq=3, feature_fraction=0.41670222801852724, lambda_l1=3.666752626040817, lambda_l2=2.3962557418472734, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=353, objective=i, reg_lambda=0, subsample=0.6, subsample_freq=256;, score=0.329 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.951811648131472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.951811648131472\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45880918187068304, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.45880918187068304\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.134210156470726, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.134210156470726\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7988401753793126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7988401753793126\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's multi_logloss: 1.50193\n",
      "[CV 1/2] END bagging_fraction=0.45880918187068304, bagging_freq=9, feature_fraction=0.7988401753793126, lambda_l1=1.951811648131472, lambda_l2=3.134210156470726, learning_rate=0.05, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=323, objective=t, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=4;, score=0.331 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.951811648131472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.951811648131472\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45880918187068304, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.45880918187068304\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.134210156470726, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.134210156470726\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7988401753793126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7988401753793126\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 1.50155\n",
      "Early stopping, best iteration is:\n",
      "[800]\tvalid_0's multi_logloss: 1.51082\n",
      "[CV 1/2] END bagging_fraction=0.5401339529393374, bagging_freq=4, feature_fraction=0.9289538933436152, lambda_l1=6.760958019264332, lambda_l2=5.383394117281432, learning_rate=0.01, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=199, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=128;, score=0.325 total time=  12.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.2352350514251795, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2352350514251795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42435608817241877, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.42435608817241877\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.844927635880791, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.844927635880791\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137269862291739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137269862291739\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[404]\tvalid_0's multi_logloss: 1.5009\n",
      "[CV 1/2] END bagging_fraction=0.42435608817241877, bagging_freq=4, feature_fraction=0.6137269862291739, lambda_l1=3.2352350514251795, lambda_l2=6.844927635880791, learning_rate=0.01, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=427, objective=u, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.331 total time=  12.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.2352350514251795, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2352350514251795\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42435608817241877, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.42435608817241877\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.844927635880791, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.844927635880791\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137269862291739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137269862291739\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[740]\tvalid_0's multi_logloss: 1.49344\n",
      "[CV 2/2] END bagging_fraction=0.42435608817241877, bagging_freq=4, feature_fraction=0.6137269862291739, lambda_l1=3.2352350514251795, lambda_l2=6.844927635880791, learning_rate=0.01, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=427, objective=u, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.331 total time=  23.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.203439147965135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.203439147965135\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8590301824464743, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8590301824464743\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.985653018006693, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.985653018006693\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7484984176613912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7484984176613912\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.49447\n",
      "[CV 1/2] END bagging_fraction=0.8590301824464743, bagging_freq=9, feature_fraction=0.7484984176613912, lambda_l1=9.203439147965135, lambda_l2=7.985653018006693, learning_rate=0.2, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=100, objective=l, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.331 total time=  10.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4542036137240471, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4542036137240471\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.444506941938294, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.444506941938294\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.106409694907239, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.106409694907239\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6394585136018538, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6394585136018538\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[380]\tvalid_0's multi_logloss: 1.49567\n",
      "[CV 2/2] END bagging_fraction=0.444506941938294, bagging_freq=5, feature_fraction=0.6394585136018538, lambda_l1=0.4542036137240471, lambda_l2=8.106409694907239, learning_rate=0.01, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=136, objective=i, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.328 total time=  16.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.521306207116064, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.521306207116064\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8582309433460398, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8582309433460398\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.282086657314716, reg_lambda=0 will be ignored. Current value: lambda_l2=3.282086657314716\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6955017427334078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6955017427334078\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 1.49931\n",
      "[CV 2/2] END bagging_fraction=0.8582309433460398, bagging_freq=5, feature_fraction=0.6955017427334078, lambda_l1=4.521306207116064, lambda_l2=3.282086657314716, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=193, objective=s, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.330 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2691854344857822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2691854344857822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5118248331029562, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5118248331029562\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.863251675249256, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.863251675249256\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9245103215745768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9245103215745768\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.5025\n",
      "[CV 2/2] END bagging_fraction=0.5118248331029562, bagging_freq=4, feature_fraction=0.9245103215745768, lambda_l1=2.2691854344857822, lambda_l2=6.863251675249256, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=278, objective=c, reg_lambda=1e-06, subsample=0.5, subsample_freq=1;, score=0.324 total time=  20.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.205985997127176, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.205985997127176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9120749605351817, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9120749605351817\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.908331978685488, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.908331978685488\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4818607373650417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4818607373650417\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.540579037413883, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.540579037413883\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7571460127937506, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7571460127937506\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.574754264736907, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.574754264736907\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9973075708158858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9973075708158858\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 1.50791\n",
      "[CV 1/2] END bagging_fraction=0.7571460127937506, bagging_freq=2, feature_fraction=0.9973075708158858, lambda_l1=3.540579037413883, lambda_l2=8.574754264736907, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=7, objective=s, reg_lambda=1e-07, subsample=0.5, subsample_freq=4;, score=0.328 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.203439147965135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.203439147965135\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8590301824464743, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8590301824464743\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.985653018006693, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.985653018006693\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7484984176613912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7484984176613912\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 1.48691\n",
      "[CV 2/2] END bagging_fraction=0.8590301824464743, bagging_freq=9, feature_fraction=0.7484984176613912, lambda_l1=9.203439147965135, lambda_l2=7.985653018006693, learning_rate=0.2, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=100, objective=l, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.330 total time=   9.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.615735336836863, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.615735336836863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6318545471909687, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6318545471909687\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.630892736736111, reg_lambda=0 will be ignored. Current value: lambda_l2=9.630892736736111\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7404031753650406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7404031753650406\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[785]\tvalid_0's multi_logloss: 1.50451\n",
      "[CV 1/2] END bagging_fraction=0.6318545471909687, bagging_freq=6, feature_fraction=0.7404031753650406, lambda_l1=7.615735336836863, lambda_l2=9.630892736736111, learning_rate=0.01, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=62, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=2;, score=0.331 total time=  12.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.521306207116064, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.521306207116064\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8582309433460398, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8582309433460398\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.282086657314716, reg_lambda=0 will be ignored. Current value: lambda_l2=3.282086657314716\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6955017427334078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6955017427334078\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's multi_logloss: 1.50762\n",
      "[CV 1/2] END bagging_fraction=0.8582309433460398, bagging_freq=5, feature_fraction=0.6955017427334078, lambda_l1=4.521306207116064, lambda_l2=3.282086657314716, learning_rate=0.05, metric=multi_logloss, min_child_samples=95, num_class=5, num_leaves=193, objective=s, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.325 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2691854344857822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2691854344857822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5118248331029562, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5118248331029562\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.863251675249256, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.863251675249256\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9245103215745768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9245103215745768\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.50656\n",
      "[CV 1/2] END bagging_fraction=0.5118248331029562, bagging_freq=4, feature_fraction=0.9245103215745768, lambda_l1=2.2691854344857822, lambda_l2=6.863251675249256, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=278, objective=c, reg_lambda=1e-06, subsample=0.5, subsample_freq=1;, score=0.311 total time=  22.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.205985997127176, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.205985997127176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9120749605351817, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9120749605351817\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.908331978685488, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.908331978685488\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4818607373650417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4818607373650417\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's multi_logloss: 1.49787\n",
      "[CV 1/2] END bagging_fraction=0.9120749605351817, bagging_freq=4, feature_fraction=0.4818607373650417, lambda_l1=9.205985997127176, lambda_l2=7.908331978685488, learning_rate=0.2, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=338, objective=m, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.331 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.569484581077303, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.569484581077303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5077071831104867, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5077071831104867\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.402798760160201, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.402798760160201\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5372363700045845, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5372363700045845\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's multi_logloss: 1.50653\n",
      "[CV 2/2] END bagging_fraction=0.45880918187068304, bagging_freq=9, feature_fraction=0.7988401753793126, lambda_l1=1.951811648131472, lambda_l2=3.134210156470726, learning_rate=0.05, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=323, objective=t, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=4;, score=0.326 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.569484581077303, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.569484581077303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5077071831104867, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5077071831104867\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.402798760160201, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.402798760160201\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5372363700045845, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5372363700045845\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's multi_logloss: 1.52016\n",
      "[CV 1/2] END bagging_fraction=0.5077071831104867, bagging_freq=6, feature_fraction=0.5372363700045845, lambda_l1=3.569484581077303, lambda_l2=4.402798760160201, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=424, objective=l, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.323 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.551609803218609, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.551609803218609\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8367017951533999, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8367017951533999\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.419185146678368, reg_lambda=0 will be ignored. Current value: lambda_l2=7.419185146678368\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6573647401895113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6573647401895113\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 1.49633\n",
      "[CV 1/2] END bagging_fraction=0.8367017951533999, bagging_freq=5, feature_fraction=0.6573647401895113, lambda_l1=7.551609803218609, lambda_l2=7.419185146678368, learning_rate=0.2, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=417, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=32;, score=0.328 total time=  15.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.231874217443053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.231874217443053\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611029887282251, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8611029887282251\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.751210096709095, reg_lambda=0 will be ignored. Current value: lambda_l2=5.751210096709095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5404009205078597, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5404009205078597\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1586]\tvalid_0's multi_logloss: 1.49462\n",
      "[CV 2/2] END bagging_fraction=0.8611029887282251, bagging_freq=7, feature_fraction=0.5404009205078597, lambda_l1=9.231874217443053, lambda_l2=5.751210096709095, learning_rate=0.01, metric=multi_logloss, min_child_samples=51, num_class=5, num_leaves=11, objective=t, reg_lambda=0, subsample=0.6, subsample_freq=32;, score=0.333 total time=  23.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.84372414342203, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.84372414342203\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47328279075288604, subsample=0.7 will be ignored. Current value: bagging_fraction=0.47328279075288604\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.822905917698176, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.822905917698176\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5743620962047815, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5743620962047815\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_logloss: 1.49515\n",
      "[CV 1/2] END bagging_fraction=0.47328279075288604, bagging_freq=8, feature_fraction=0.5743620962047815, lambda_l1=8.84372414342203, lambda_l2=8.822905917698176, learning_rate=0.2, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=505, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.310 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.84372414342203, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.84372414342203\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47328279075288604, subsample=0.7 will be ignored. Current value: bagging_fraction=0.47328279075288604\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.822905917698176, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.822905917698176\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5743620962047815, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5743620962047815\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's multi_logloss: 1.49851\n",
      "[CV 2/2] END bagging_fraction=0.47328279075288604, bagging_freq=8, feature_fraction=0.5743620962047815, lambda_l1=8.84372414342203, lambda_l2=8.822905917698176, learning_rate=0.2, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=505, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.328 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14548114853501964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14548114853501964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5634795927625417, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5634795927625417\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.789341647609404, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.789341647609404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4008704707125706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4008704707125706\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.50759\n",
      "[CV 1/2] END bagging_fraction=0.5634795927625417, bagging_freq=9, feature_fraction=0.4008704707125706, lambda_l1=0.14548114853501964, lambda_l2=4.789341647609404, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=347, objective=m, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=1;, score=0.327 total time=   9.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14548114853501964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14548114853501964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5634795927625417, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5634795927625417\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.789341647609404, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.789341647609404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4008704707125706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4008704707125706\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.50158\n",
      "[CV 2/2] END bagging_fraction=0.5634795927625417, bagging_freq=9, feature_fraction=0.4008704707125706, lambda_l1=0.14548114853501964, lambda_l2=4.789341647609404, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=347, objective=m, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=1;, score=0.323 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.687705206070024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.687705206070024\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4069697941419332, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4069697941419332\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.628820361769977, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.628820361769977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42035479939821185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42035479939821185\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's multi_logloss: 1.49913\n",
      "[CV 2/2] END bagging_fraction=0.4069697941419332, bagging_freq=7, feature_fraction=0.42035479939821185, lambda_l1=9.687705206070024, lambda_l2=2.628820361769977, learning_rate=0.2, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=222, objective=s, reg_lambda=0.001, subsample=0.5, subsample_freq=8;, score=0.327 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.8364707121287145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.8364707121287145\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9268638963115929, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9268638963115929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9529211212107017, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.9529211212107017\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8689572025994536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8689572025994536\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 1.49789\n",
      "[CV 1/2] END bagging_fraction=0.9268638963115929, bagging_freq=9, feature_fraction=0.8689572025994536, lambda_l1=6.8364707121287145, lambda_l2=0.9529211212107017, learning_rate=0.05, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=9, objective=l, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=32;, score=0.335 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4852403841482484, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4852403841482484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9913403105165726, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9913403105165726\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.1901579521018455, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.1901579521018455\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9410397762031635, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9410397762031635\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.49966\n",
      "[CV 2/2] END bagging_fraction=0.9913403105165726, bagging_freq=4, feature_fraction=0.9410397762031635, lambda_l1=3.4852403841482484, lambda_l2=4.1901579521018455, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=334, objective=u, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=4;, score=0.327 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.558513755436222, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.558513755436222\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7152803982610464, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7152803982610464\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.096360269180733, reg_lambda=0 will be ignored. Current value: lambda_l2=5.096360269180733\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5921417708283692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5921417708283692\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.50079\n",
      "[CV 1/2] END bagging_fraction=0.7152803982610464, bagging_freq=3, feature_fraction=0.5921417708283692, lambda_l1=6.558513755436222, lambda_l2=5.096360269180733, learning_rate=0.2, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=117, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.328 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.558513755436222, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.558513755436222\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7152803982610464, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7152803982610464\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.096360269180733, reg_lambda=0 will be ignored. Current value: lambda_l2=5.096360269180733\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5921417708283692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5921417708283692\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.49724\n",
      "[CV 2/2] END bagging_fraction=0.7152803982610464, bagging_freq=3, feature_fraction=0.5921417708283692, lambda_l1=6.558513755436222, lambda_l2=5.096360269180733, learning_rate=0.2, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=117, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.328 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.619492580476143, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.619492580476143\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7546922685472115, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7546922685472115\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.5005273203388745, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.5005273203388745\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6400509332932767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6400509332932767\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 1.49269\n",
      "[CV 1/2] END bagging_fraction=0.7546922685472115, bagging_freq=3, feature_fraction=0.6400509332932767, lambda_l1=9.619492580476143, lambda_l2=4.5005273203388745, learning_rate=0.2, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=257, objective=m, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.331 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.619492580476143, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.619492580476143\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7546922685472115, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7546922685472115\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.5005273203388745, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.5005273203388745\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6400509332932767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6400509332932767\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "[CV 2/2] END bagging_fraction=0.5077071831104867, bagging_freq=6, feature_fraction=0.5372363700045845, lambda_l1=3.569484581077303, lambda_l2=4.402798760160201, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=424, objective=l, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.322 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6364560435755915, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6364560435755915\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8745974784378274, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8745974784378274\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.078431184376245, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.078431184376245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7875297190896824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7875297190896824\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.49801\n",
      "[CV 1/2] END bagging_fraction=0.8745974784378274, bagging_freq=9, feature_fraction=0.7875297190896824, lambda_l1=2.6364560435755915, lambda_l2=2.078431184376245, learning_rate=0.2, metric=multi_logloss, min_child_samples=51, num_class=5, num_leaves=41, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.335 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6364560435755915, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6364560435755915\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8745974784378274, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8745974784378274\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.078431184376245, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.078431184376245\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7875297190896824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7875297190896824\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49615\n",
      "[CV 2/2] END bagging_fraction=0.8745974784378274, bagging_freq=9, feature_fraction=0.7875297190896824, lambda_l1=2.6364560435755915, lambda_l2=2.078431184376245, learning_rate=0.2, metric=multi_logloss, min_child_samples=51, num_class=5, num_leaves=41, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.332 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.231874217443053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.231874217443053\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611029887282251, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8611029887282251\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.751210096709095, reg_lambda=0 will be ignored. Current value: lambda_l2=5.751210096709095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5404009205078597, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5404009205078597\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1155]\tvalid_0's multi_logloss: 1.50378\n",
      "[CV 1/2] END bagging_fraction=0.8611029887282251, bagging_freq=7, feature_fraction=0.5404009205078597, lambda_l1=9.231874217443053, lambda_l2=5.751210096709095, learning_rate=0.01, metric=multi_logloss, min_child_samples=51, num_class=5, num_leaves=11, objective=t, reg_lambda=0, subsample=0.6, subsample_freq=32;, score=0.336 total time=  14.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.8881830101966166, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8881830101966166\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5960408375598203, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5960408375598203\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.545352263028968, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.545352263028968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6710490064103134, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6710490064103134\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's multi_logloss: 1.48905\n",
      "[CV 2/2] END bagging_fraction=0.5960408375598203, bagging_freq=7, feature_fraction=0.6710490064103134, lambda_l1=2.8881830101966166, lambda_l2=5.545352263028968, learning_rate=0.01, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=111, objective=m, reg_lambda=1e-05, subsample=0.5, subsample_freq=1;, score=0.336 total time=  41.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.597112699983239, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.597112699983239\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49345283482259733, subsample=0.7 will be ignored. Current value: bagging_fraction=0.49345283482259733\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.173168627996354, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.173168627996354\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548060682984103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548060682984103\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's multi_logloss: 1.49724\n",
      "[CV 2/2] END bagging_fraction=0.49345283482259733, bagging_freq=7, feature_fraction=0.9548060682984103, lambda_l1=9.597112699983239, lambda_l2=8.173168627996354, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=231, objective=c, reg_lambda=1e-06, subsample=0.7, subsample_freq=128;, score=0.329 total time=   6.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4852403841482484, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4852403841482484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9913403105165726, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9913403105165726\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.1901579521018455, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.1901579521018455\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9410397762031635, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9410397762031635\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's multi_logloss: 1.50016\n",
      "[CV 1/2] END bagging_fraction=0.9913403105165726, bagging_freq=4, feature_fraction=0.9410397762031635, lambda_l1=3.4852403841482484, lambda_l2=4.1901579521018455, learning_rate=0.2, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=334, objective=u, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=4;, score=0.331 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.211187981248049, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.211187981248049\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8732191642023559, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8732191642023559\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.910470927145874, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.910470927145874\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7469565171100883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7469565171100883\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's multi_logloss: 1.49428\n",
      "[CV 2/2] END bagging_fraction=0.8732191642023559, bagging_freq=2, feature_fraction=0.7469565171100883, lambda_l1=9.211187981248049, lambda_l2=4.910470927145874, learning_rate=0.01, metric=multi_logloss, min_child_samples=44, num_class=5, num_leaves=330, objective=t, reg_lambda=1e-06, subsample=0.5, subsample_freq=4;, score=0.330 total time=  24.7s\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's multi_logloss: 1.49178\n",
      "[CV 2/2] END bagging_fraction=0.7546922685472115, bagging_freq=3, feature_fraction=0.6400509332932767, lambda_l1=9.619492580476143, lambda_l2=4.5005273203388745, learning_rate=0.2, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=257, objective=m, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.327 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.799996646657352, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.799996646657352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4860622018559391, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4860622018559391\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.72070997823228, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.72070997823228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8030577097431575, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8030577097431575\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[864]\tvalid_0's multi_logloss: 1.50098\n",
      "[CV 1/2] END bagging_fraction=0.4860622018559391, bagging_freq=9, feature_fraction=0.8030577097431575, lambda_l1=8.799996646657352, lambda_l2=9.72070997823228, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=492, objective=a, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.329 total time=  21.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 1.4928\n",
      "[CV 2/2] END bagging_fraction=0.9120749605351817, bagging_freq=4, feature_fraction=0.4818607373650417, lambda_l1=9.205985997127176, lambda_l2=7.908331978685488, learning_rate=0.2, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=338, objective=m, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.330 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.551609803218609, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.551609803218609\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8367017951533999, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8367017951533999\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.419185146678368, reg_lambda=0 will be ignored. Current value: lambda_l2=7.419185146678368\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6573647401895113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6573647401895113\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 1.48813\n",
      "[CV 2/2] END bagging_fraction=0.8367017951533999, bagging_freq=5, feature_fraction=0.6573647401895113, lambda_l1=7.551609803218609, lambda_l2=7.419185146678368, learning_rate=0.2, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=417, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=32;, score=0.330 total time=  15.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.8881830101966166, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8881830101966166\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5960408375598203, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5960408375598203\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.545352263028968, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.545352263028968\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6710490064103134, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6710490064103134\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's multi_logloss: 1.48734\n",
      "[CV 1/2] END bagging_fraction=0.5960408375598203, bagging_freq=7, feature_fraction=0.6710490064103134, lambda_l1=2.8881830101966166, lambda_l2=5.545352263028968, learning_rate=0.01, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=111, objective=m, reg_lambda=1e-05, subsample=0.5, subsample_freq=1;, score=0.336 total time=  43.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.597112699983239, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.597112699983239\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49345283482259733, subsample=0.7 will be ignored. Current value: bagging_fraction=0.49345283482259733\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.173168627996354, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.173168627996354\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9548060682984103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9548060682984103\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's multi_logloss: 1.49712\n",
      "[CV 1/2] END bagging_fraction=0.49345283482259733, bagging_freq=7, feature_fraction=0.9548060682984103, lambda_l1=9.597112699983239, lambda_l2=8.173168627996354, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=231, objective=c, reg_lambda=1e-06, subsample=0.7, subsample_freq=128;, score=0.329 total time=   9.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.687705206070024, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.687705206070024\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4069697941419332, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4069697941419332\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.628820361769977, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.628820361769977\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42035479939821185, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42035479939821185\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[489]\tvalid_0's multi_logloss: 1.50096\n",
      "[CV 1/2] END bagging_fraction=0.4069697941419332, bagging_freq=7, feature_fraction=0.42035479939821185, lambda_l1=9.687705206070024, lambda_l2=2.628820361769977, learning_rate=0.2, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=222, objective=s, reg_lambda=0.001, subsample=0.5, subsample_freq=8;, score=0.301 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.8364707121287145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.8364707121287145\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9268638963115929, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9268638963115929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9529211212107017, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.9529211212107017\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8689572025994536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8689572025994536\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's multi_logloss: 1.49207\n",
      "[CV 2/2] END bagging_fraction=0.9268638963115929, bagging_freq=9, feature_fraction=0.8689572025994536, lambda_l1=6.8364707121287145, lambda_l2=0.9529211212107017, learning_rate=0.05, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=9, objective=l, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=32;, score=0.331 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.211187981248049, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.211187981248049\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8732191642023559, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8732191642023559\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.910470927145874, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.910470927145874\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7469565171100883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7469565171100883\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1696]\tvalid_0's multi_logloss: 1.49632\n",
      "[CV 1/2] END bagging_fraction=0.8732191642023559, bagging_freq=2, feature_fraction=0.7469565171100883, lambda_l1=9.211187981248049, lambda_l2=4.910470927145874, learning_rate=0.01, metric=multi_logloss, min_child_samples=44, num_class=5, num_leaves=330, objective=t, reg_lambda=1e-06, subsample=0.5, subsample_freq=4;, score=0.332 total time=  43.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4968138515206488, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4968138515206488\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9238420147781361, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9238420147781361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.554352067197579, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.554352067197579\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4382041750359096, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4382041750359096\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.49909\n",
      "[CV 2/2] END bagging_fraction=0.9238420147781361, bagging_freq=7, feature_fraction=0.4382041750359096, lambda_l1=1.4968138515206488, lambda_l2=8.554352067197579, learning_rate=0.2, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=333, objective=u, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.325 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4948349111008685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4948349111008685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267554424843478, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9267554424843478\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.640309596876332, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.640309596876332\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5992294333713905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5992294333713905\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 1.50015\n",
      "[CV 1/2] END bagging_fraction=0.9267554424843478, bagging_freq=7, feature_fraction=0.5992294333713905, lambda_l1=2.4948349111008685, lambda_l2=8.640309596876332, learning_rate=0.05, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=461, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=8;, score=0.331 total time=   6.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.861112341192448, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.861112341192448\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229376618563298, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6229376618563298\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.275571532510612, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.275571532510612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7855198425146432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7855198425146432\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[501]\tvalid_0's multi_logloss: 1.50278\n",
      "[CV 2/2] END bagging_fraction=0.6229376618563298, bagging_freq=2, feature_fraction=0.7855198425146432, lambda_l1=2.861112341192448, lambda_l2=4.275571532510612, learning_rate=0.01, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=425, objective=u, reg_lambda=0.0001, subsample=0.7, subsample_freq=1;, score=0.327 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.221062476076663, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.221062476076663\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.866316588509381, subsample=0.5 will be ignored. Current value: bagging_fraction=0.866316588509381\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.076382347095103, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.076382347095103\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4451179287280974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4451179287280974\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.50575\n",
      "[CV 1/2] END bagging_fraction=0.866316588509381, bagging_freq=5, feature_fraction=0.4451179287280974, lambda_l1=3.221062476076663, lambda_l2=4.076382347095103, learning_rate=0.2, metric=multi_logloss, min_child_samples=80, num_class=5, num_leaves=378, objective=t, reg_lambda=1e-05, subsample=0.5, subsample_freq=32;, score=0.329 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.221062476076663, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.221062476076663\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.866316588509381, subsample=0.5 will be ignored. Current value: bagging_fraction=0.866316588509381\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.076382347095103, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.076382347095103\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4451179287280974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4451179287280974\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 1.49561\n",
      "[CV 2/2] END bagging_fraction=0.866316588509381, bagging_freq=5, feature_fraction=0.4451179287280974, lambda_l1=3.221062476076663, lambda_l2=4.076382347095103, learning_rate=0.2, metric=multi_logloss, min_child_samples=80, num_class=5, num_leaves=378, objective=t, reg_lambda=1e-05, subsample=0.5, subsample_freq=32;, score=0.331 total time=   3.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.791420507215207, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.791420507215207\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861221553896433, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5861221553896433\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.914957768530755, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.914957768530755\n",
      "[LightGBM] [Warning] feature_fraction is set=0.640418822219052, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.640418822219052\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 1.50036\n",
      "[CV 1/2] END bagging_fraction=0.5861221553896433, bagging_freq=3, feature_fraction=0.640418822219052, lambda_l1=8.791420507215207, lambda_l2=2.914957768530755, learning_rate=0.2, metric=multi_logloss, min_child_samples=55, num_class=5, num_leaves=211, objective=i, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.327 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.013897668222692, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.013897668222692\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5401776537019944, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5401776537019944\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2824876273354937, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.2824876273354937\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7542194002389956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7542194002389956\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=16 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 1.49331\n",
      "[CV 1/2] END bagging_fraction=0.5401776537019944, bagging_freq=2, feature_fraction=0.7542194002389956, lambda_l1=5.013897668222692, lambda_l2=1.2824876273354937, learning_rate=0.2, metric=multi_logloss, min_child_samples=26, num_class=5, num_leaves=297, objective=l, reg_lambda=1e-07, subsample=0.6, subsample_freq=16;, score=0.329 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.216901412539109, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.216901412539109\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5166323358091661, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5166323358091661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.091717084439559, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.091717084439559\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.799996646657352, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.799996646657352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4860622018559391, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4860622018559391\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.72070997823228, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.72070997823228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8030577097431575, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8030577097431575\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's multi_logloss: 1.49761\n",
      "[CV 2/2] END bagging_fraction=0.4860622018559391, bagging_freq=9, feature_fraction=0.8030577097431575, lambda_l1=8.799996646657352, lambda_l2=9.72070997823228, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=492, objective=a, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.331 total time=  20.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4796761321670495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4796761321670495\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8319300881516767, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8319300881516767\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.288853771975649, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.288853771975649\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4032629315126088, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4032629315126088\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.50524\n",
      "[CV 1/2] END bagging_fraction=0.8319300881516767, bagging_freq=7, feature_fraction=0.4032629315126088, lambda_l1=1.4796761321670495, lambda_l2=5.288853771975649, learning_rate=0.2, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=266, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=128;, score=0.332 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4948349111008685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4948349111008685\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9267554424843478, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9267554424843478\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.640309596876332, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.640309596876332\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5992294333713905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5992294333713905\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 1.49689\n",
      "[CV 2/2] END bagging_fraction=0.9267554424843478, bagging_freq=7, feature_fraction=0.5992294333713905, lambda_l1=2.4948349111008685, lambda_l2=8.640309596876332, learning_rate=0.05, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=461, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=8;, score=0.328 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.170700420687886, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.170700420687886\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9671783114373059, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9671783114373059\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.239195987147417, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.239195987147417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6675336375134489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6675336375134489\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[873]\tvalid_0's multi_logloss: 1.50166\n",
      "[CV 1/2] END bagging_fraction=0.9671783114373059, bagging_freq=3, feature_fraction=0.6675336375134489, lambda_l1=5.170700420687886, lambda_l2=8.239195987147417, learning_rate=0.01, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=439, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.328 total time=  18.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.791420507215207, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.791420507215207\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5861221553896433, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5861221553896433\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.914957768530755, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.914957768530755\n",
      "[LightGBM] [Warning] feature_fraction is set=0.640418822219052, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.640418822219052\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 1.4971\n",
      "[CV 2/2] END bagging_fraction=0.5861221553896433, bagging_freq=3, feature_fraction=0.640418822219052, lambda_l1=8.791420507215207, lambda_l2=2.914957768530755, learning_rate=0.2, metric=multi_logloss, min_child_samples=55, num_class=5, num_leaves=211, objective=i, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.328 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.216901412539109, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.216901412539109\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5166323358091661, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5166323358091661\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.091717084439559, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.091717084439559\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6569749206239419, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6569749206239419\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 1.49354\n",
      "[CV 1/2] END bagging_fraction=0.5166323358091661, bagging_freq=4, feature_fraction=0.6569749206239419, lambda_l1=8.216901412539109, lambda_l2=5.091717084439559, learning_rate=0.2, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=339, objective=m, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.311 total time=   7.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.494970631203743, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.494970631203743\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6198661559489365, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6198661559489365\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.790718644759049, reg_lambda=0 will be ignored. Current value: lambda_l2=7.790718644759049\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6389371646036555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6389371646036555\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[762]\tvalid_0's multi_logloss: 1.49588\n",
      "[CV 2/2] END bagging_fraction=0.6198661559489365, bagging_freq=6, feature_fraction=0.6389371646036555, lambda_l1=5.494970631203743, lambda_l2=7.790718644759049, learning_rate=0.01, metric=multi_logloss, min_child_samples=55, num_class=5, num_leaves=397, objective=i, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=128;, score=0.330 total time=  16.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4968138515206488, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4968138515206488\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9238420147781361, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9238420147781361\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.554352067197579, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.554352067197579\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4382041750359096, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4382041750359096\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 1.49952\n",
      "[CV 1/2] END bagging_fraction=0.9238420147781361, bagging_freq=7, feature_fraction=0.4382041750359096, lambda_l1=1.4968138515206488, lambda_l2=8.554352067197579, learning_rate=0.2, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=333, objective=u, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.328 total time=   7.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4796761321670495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4796761321670495\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8319300881516767, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8319300881516767\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.288853771975649, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.288853771975649\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4032629315126088, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4032629315126088\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.50072\n",
      "[CV 2/2] END bagging_fraction=0.8319300881516767, bagging_freq=7, feature_fraction=0.4032629315126088, lambda_l1=1.4796761321670495, lambda_l2=5.288853771975649, learning_rate=0.2, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=266, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=128;, score=0.327 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.861112341192448, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.861112341192448\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6229376618563298, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6229376618563298\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.275571532510612, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.275571532510612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7855198425146432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7855198425146432\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's multi_logloss: 1.51576\n",
      "[CV 1/2] END bagging_fraction=0.6229376618563298, bagging_freq=2, feature_fraction=0.7855198425146432, lambda_l1=2.861112341192448, lambda_l2=4.275571532510612, learning_rate=0.01, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=425, objective=u, reg_lambda=0.0001, subsample=0.7, subsample_freq=1;, score=0.323 total time=   9.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.170700420687886, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.170700420687886\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9671783114373059, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9671783114373059\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.239195987147417, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.239195987147417\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6675336375134489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6675336375134489\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's multi_logloss: 1.49812\n",
      "[CV 2/2] END bagging_fraction=0.9671783114373059, bagging_freq=3, feature_fraction=0.6675336375134489, lambda_l1=5.170700420687886, lambda_l2=8.239195987147417, learning_rate=0.01, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=439, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.331 total time=  14.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.013897668222692, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.013897668222692\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5401776537019944, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5401776537019944\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2824876273354937, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.2824876273354937\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7542194002389956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7542194002389956\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=16 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's multi_logloss: 1.49876\n",
      "[CV 2/2] END bagging_fraction=0.5401776537019944, bagging_freq=2, feature_fraction=0.7542194002389956, lambda_l1=5.013897668222692, lambda_l2=1.2824876273354937, learning_rate=0.2, metric=multi_logloss, min_child_samples=26, num_class=5, num_leaves=297, objective=l, reg_lambda=1e-07, subsample=0.6, subsample_freq=16;, score=0.329 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.494970631203743, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.494970631203743\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6198661559489365, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6198661559489365\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.790718644759049, reg_lambda=0 will be ignored. Current value: lambda_l2=7.790718644759049\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6389371646036555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6389371646036555\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[782]\tvalid_0's multi_logloss: 1.50283\n",
      "[CV 1/2] END bagging_fraction=0.6198661559489365, bagging_freq=6, feature_fraction=0.6389371646036555, lambda_l1=5.494970631203743, lambda_l2=7.790718644759049, learning_rate=0.01, metric=multi_logloss, min_child_samples=55, num_class=5, num_leaves=397, objective=i, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=128;, score=0.329 total time=  14.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2680774540231976, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2680774540231976\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48464005627674933, subsample=0.7 will be ignored. Current value: bagging_fraction=0.48464005627674933\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.176446642693982, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.176446642693982\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6621500583242965, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6621500583242965\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 1.49251\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6569749206239419, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6569749206239419\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.49643\n",
      "[CV 2/2] END bagging_fraction=0.5166323358091661, bagging_freq=4, feature_fraction=0.6569749206239419, lambda_l1=8.216901412539109, lambda_l2=5.091717084439559, learning_rate=0.2, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=339, objective=m, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.326 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.364399084863364, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.364399084863364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9717344340611418, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9717344340611418\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.436206800724158, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.436206800724158\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49490503364116384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49490503364116384\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[326]\tvalid_0's multi_logloss: 1.49946\n",
      "[CV 1/2] END bagging_fraction=0.9717344340611418, bagging_freq=5, feature_fraction=0.49490503364116384, lambda_l1=7.364399084863364, lambda_l2=8.436206800724158, learning_rate=0.2, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=15, objective=i, reg_lambda=1e-07, subsample=0.7, subsample_freq=4;, score=0.328 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.364399084863364, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.364399084863364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9717344340611418, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9717344340611418\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.436206800724158, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.436206800724158\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49490503364116384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49490503364116384\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 1.49318\n",
      "[CV 2/2] END bagging_fraction=0.9717344340611418, bagging_freq=5, feature_fraction=0.49490503364116384, lambda_l1=7.364399084863364, lambda_l2=8.436206800724158, learning_rate=0.2, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=15, objective=i, reg_lambda=1e-07, subsample=0.7, subsample_freq=4;, score=0.330 total time=   3.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.2680774540231976, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.2680774540231976\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48464005627674933, subsample=0.7 will be ignored. Current value: bagging_fraction=0.48464005627674933\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.176446642693982, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.176446642693982\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6621500583242965, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6621500583242965\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's multi_logloss: 1.49655\n",
      "[CV 1/2] END bagging_fraction=0.48464005627674933, bagging_freq=9, feature_fraction=0.6621500583242965, lambda_l1=2.2680774540231976, lambda_l2=8.176446642693982, learning_rate=0.05, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=35, objective=t, reg_lambda=1e-07, subsample=0.7, subsample_freq=8;, score=0.335 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.542345101402139, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.542345101402139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.776811552310583, subsample=0.7 will be ignored. Current value: bagging_fraction=0.776811552310583\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.620902833772687, reg_lambda=0 will be ignored. Current value: lambda_l2=6.620902833772687\n",
      "[LightGBM] [Warning] feature_fraction is set=0.451892255277377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.451892255277377\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 1.49709\n",
      "[CV 1/2] END bagging_fraction=0.776811552310583, bagging_freq=6, feature_fraction=0.451892255277377, lambda_l1=2.542345101402139, lambda_l2=6.620902833772687, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=75, objective=t, reg_lambda=0, subsample=0.7, subsample_freq=256;, score=0.333 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.3411531045433005, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3411531045433005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8434830662977575, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8434830662977575\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.649774977064434, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.649774977064434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6589517794932152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6589517794932152\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's multi_logloss: 1.49548\n",
      "[CV 2/2] END bagging_fraction=0.8434830662977575, bagging_freq=8, feature_fraction=0.6589517794932152, lambda_l1=5.3411531045433005, lambda_l2=3.649774977064434, learning_rate=0.01, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=424, objective=s, reg_lambda=1e-06, subsample=0.5, subsample_freq=16;, score=0.328 total time=  13.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.430891319479132, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.430891319479132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6584872857679924, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6584872857679924\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.993744256877434, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.993744256877434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9037276675387503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9037276675387503\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's multi_logloss: 1.49368\n",
      "[CV 2/2] END bagging_fraction=0.6584872857679924, bagging_freq=4, feature_fraction=0.9037276675387503, lambda_l1=1.430891319479132, lambda_l2=8.993744256877434, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=348, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=16;, score=0.330 total time=  24.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2224534400687945, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2224534400687945\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6314581207197945, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6314581207197945\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7092883042578135, reg_lambda=0 will be ignored. Current value: lambda_l2=1.7092883042578135\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.542345101402139, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.542345101402139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.776811552310583, subsample=0.7 will be ignored. Current value: bagging_fraction=0.776811552310583\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.620902833772687, reg_lambda=0 will be ignored. Current value: lambda_l2=6.620902833772687\n",
      "[LightGBM] [Warning] feature_fraction is set=0.451892255277377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.451892255277377\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49509\n",
      "[CV 2/2] END bagging_fraction=0.776811552310583, bagging_freq=6, feature_fraction=0.451892255277377, lambda_l1=2.542345101402139, lambda_l2=6.620902833772687, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=75, objective=t, reg_lambda=0, subsample=0.7, subsample_freq=256;, score=0.327 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.159542233756963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.159542233756963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43146963304846314, subsample=0.5 will be ignored. Current value: bagging_fraction=0.43146963304846314\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6291954664052444, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.6291954664052444\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6451284832130301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6451284832130301\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=8 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[404]\tvalid_0's multi_logloss: 1.51462\n",
      "[CV 1/2] END bagging_fraction=0.43146963304846314, bagging_freq=4, feature_fraction=0.6451284832130301, lambda_l1=6.159542233756963, lambda_l2=2.6291954664052444, learning_rate=0.01, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=149, objective=m, reg_lambda=1e-05, subsample=0.5, subsample_freq=8;, score=0.325 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.159542233756963, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.159542233756963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43146963304846314, subsample=0.5 will be ignored. Current value: bagging_fraction=0.43146963304846314\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6291954664052444, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.6291954664052444\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6451284832130301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6451284832130301\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=8 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[920]\tvalid_0's multi_logloss: 1.49966\n",
      "[CV 2/2] END bagging_fraction=0.43146963304846314, bagging_freq=4, feature_fraction=0.6451284832130301, lambda_l1=6.159542233756963, lambda_l2=2.6291954664052444, learning_rate=0.01, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=149, objective=m, reg_lambda=1e-05, subsample=0.5, subsample_freq=8;, score=0.328 total time=  11.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.644705938171787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.644705938171787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8238200050681408, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8238200050681408\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9635383845912715, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.9635383845912715\n",
      "[LightGBM] [Warning] feature_fraction is set=0.787553243240114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.787553243240114\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 1.50005\n",
      "[CV 1/2] END bagging_fraction=0.8238200050681408, bagging_freq=5, feature_fraction=0.787553243240114, lambda_l1=7.644705938171787, lambda_l2=5.9635383845912715, learning_rate=0.2, metric=multi_logloss, min_child_samples=53, num_class=5, num_leaves=288, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=64;, score=0.332 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.644705938171787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.644705938171787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8238200050681408, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8238200050681408\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9635383845912715, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.9635383845912715\n",
      "[LightGBM] [Warning] feature_fraction is set=0.787553243240114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.787553243240114\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 1.4933\n",
      "[CV 2/2] END bagging_fraction=0.8238200050681408, bagging_freq=5, feature_fraction=0.787553243240114, lambda_l1=7.644705938171787, lambda_l2=5.9635383845912715, learning_rate=0.2, metric=multi_logloss, min_child_samples=53, num_class=5, num_leaves=288, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=64;, score=0.328 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.2224534400687945, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.2224534400687945\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6314581207197945, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6314581207197945\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7092883042578135, reg_lambda=0 will be ignored. Current value: lambda_l2=1.7092883042578135\n",
      "[LightGBM] [Warning] feature_fraction is set=0.424446872459538, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.424446872459538\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[736]\tvalid_0's multi_logloss: 1.49718\n",
      "[CV 1/2] END bagging_fraction=0.6314581207197945, bagging_freq=4, feature_fraction=0.424446872459538, lambda_l1=4.2224534400687945, lambda_l2=1.7092883042578135, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=412, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=64;, score=0.331 total time=  17.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.182051797272244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.182051797272244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6055264112564908, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6055264112564908\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.95190596368921, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.95190596368921\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9310461547532927, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9310461547532927\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's multi_logloss: 1.49964\n",
      "[CV 2/2] END bagging_fraction=0.6055264112564908, bagging_freq=2, feature_fraction=0.9310461547532927, lambda_l1=3.182051797272244, lambda_l2=6.95190596368921, learning_rate=0.01, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=50, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=64;, score=0.331 total time=   9.7s\n",
      "[CV 2/2] END bagging_fraction=0.48464005627674933, bagging_freq=9, feature_fraction=0.6621500583242965, lambda_l1=2.2680774540231976, lambda_l2=8.176446642693982, learning_rate=0.05, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=35, objective=t, reg_lambda=1e-07, subsample=0.7, subsample_freq=8;, score=0.324 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.3411531045433005, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3411531045433005\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8434830662977575, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8434830662977575\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.649774977064434, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.649774977064434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6589517794932152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6589517794932152\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's multi_logloss: 1.50055\n",
      "[CV 1/2] END bagging_fraction=0.8434830662977575, bagging_freq=8, feature_fraction=0.6589517794932152, lambda_l1=5.3411531045433005, lambda_l2=3.649774977064434, learning_rate=0.01, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=424, objective=s, reg_lambda=1e-06, subsample=0.5, subsample_freq=16;, score=0.329 total time=  11.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.430891319479132, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.430891319479132\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6584872857679924, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6584872857679924\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.993744256877434, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.993744256877434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9037276675387503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9037276675387503\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[386]\tvalid_0's multi_logloss: 1.49003\n",
      "[CV 1/2] END bagging_fraction=0.6584872857679924, bagging_freq=4, feature_fraction=0.9037276675387503, lambda_l1=1.430891319479132, lambda_l2=8.993744256877434, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=348, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=16;, score=0.333 total time=  30.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.182051797272244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.182051797272244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6055264112564908, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6055264112564908\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.95190596368921, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.95190596368921\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9310461547532927, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9310461547532927\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[404]\tvalid_0's multi_logloss: 1.50997\n",
      "[CV 1/2] END bagging_fraction=0.6055264112564908, bagging_freq=2, feature_fraction=0.9310461547532927, lambda_l1=3.182051797272244, lambda_l2=6.95190596368921, learning_rate=0.01, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=50, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=64;, score=0.324 total time=   9.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.439834303157056, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.439834303157056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.867554687966795, subsample=0.7 will be ignored. Current value: bagging_fraction=0.867554687966795\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.957156575222929, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.957156575222929\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8960803773694854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8960803773694854\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 1.49896\n",
      "[CV 1/2] END bagging_fraction=0.867554687966795, bagging_freq=9, feature_fraction=0.8960803773694854, lambda_l1=9.439834303157056, lambda_l2=2.957156575222929, learning_rate=0.2, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=179, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.332 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.092075554205124, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.092075554205124\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686944837061769, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7686944837061769\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0998505459808552, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.0998505459808552\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5533968054772693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5533968054772693\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[445]\tvalid_0's multi_logloss: 1.51039\n",
      "[CV 1/2] END bagging_fraction=0.7686944837061769, bagging_freq=5, feature_fraction=0.5533968054772693, lambda_l1=9.092075554205124, lambda_l2=1.0998505459808552, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=240, objective=i, reg_lambda=0.0001, subsample=0.7, subsample_freq=8;, score=0.324 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.195847228396929, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.195847228396929\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.41472089997357625, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.41472089997357625\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.189140546564986, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.189140546564986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7084712811625389, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7084712811625389\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's multi_logloss: 1.50488\n",
      "[CV 1/2] END bagging_fraction=0.41472089997357625, bagging_freq=9, feature_fraction=0.7084712811625389, lambda_l1=8.195847228396929, lambda_l2=7.189140546564986, learning_rate=0.2, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=182, objective=s, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=64;, score=0.326 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.335039555821446, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.335039555821446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7419739227838844, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7419739227838844\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.580933663945995, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.580933663945995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4176050926872854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4176050926872854\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 1.4981\n",
      "[LightGBM] [Warning] feature_fraction is set=0.424446872459538, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.424446872459538\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's multi_logloss: 1.49275\n",
      "[CV 2/2] END bagging_fraction=0.6314581207197945, bagging_freq=4, feature_fraction=0.424446872459538, lambda_l1=4.2224534400687945, lambda_l2=1.7092883042578135, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=412, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=64;, score=0.328 total time=  14.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.439834303157056, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.439834303157056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.867554687966795, subsample=0.7 will be ignored. Current value: bagging_fraction=0.867554687966795\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.957156575222929, reg_lambda=0.001 will be ignored. Current value: lambda_l2=2.957156575222929\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8960803773694854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8960803773694854\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's multi_logloss: 1.49521\n",
      "[CV 2/2] END bagging_fraction=0.867554687966795, bagging_freq=9, feature_fraction=0.8960803773694854, lambda_l1=9.439834303157056, lambda_l2=2.957156575222929, learning_rate=0.2, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=179, objective=l, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.331 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.930898659519714, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.930898659519714\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6533862404318806, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6533862404318806\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.589215701359359, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.589215701359359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.44098170921336344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44098170921336344\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's multi_logloss: 1.50217\n",
      "[CV 1/2] END bagging_fraction=0.6533862404318806, bagging_freq=4, feature_fraction=0.44098170921336344, lambda_l1=5.930898659519714, lambda_l2=6.589215701359359, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=2, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=64;, score=0.329 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.930898659519714, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.930898659519714\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6533862404318806, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6533862404318806\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.589215701359359, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.589215701359359\n",
      "[LightGBM] [Warning] feature_fraction is set=0.44098170921336344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44098170921336344\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's multi_logloss: 1.49442\n",
      "[CV 2/2] END bagging_fraction=0.6533862404318806, bagging_freq=4, feature_fraction=0.44098170921336344, lambda_l1=5.930898659519714, lambda_l2=6.589215701359359, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=2, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=64;, score=0.332 total time=   2.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.254743562147702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.254743562147702\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8629491201990933, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8629491201990933\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.763424771896314, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.763424771896314\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5435811350439554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5435811350439554\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[825]\tvalid_0's multi_logloss: 1.50545\n",
      "[CV 1/2] END bagging_fraction=0.8629491201990933, bagging_freq=5, feature_fraction=0.5435811350439554, lambda_l1=9.254743562147702, lambda_l2=5.763424771896314, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=213, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=64;, score=0.332 total time=  13.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.282927824326513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.282927824326513\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4384852256905064, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4384852256905064\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.9406011604264, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.9406011604264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9151728779849343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9151728779849343\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 1.50063\n",
      "[CV 2/2] END bagging_fraction=0.4384852256905064, bagging_freq=3, feature_fraction=0.9151728779849343, lambda_l1=4.282927824326513, lambda_l2=8.9406011604264, learning_rate=0.2, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=308, objective=t, reg_lambda=1e-06, subsample=0.7, subsample_freq=1;, score=0.321 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.544212892768119, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.544212892768119\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5845080642123079, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5845080642123079\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.934057407252757, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.934057407252757\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4370445898249624, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4370445898249624\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[360]\tvalid_0's multi_logloss: 1.49179\n",
      "[CV 2/2] END bagging_fraction=0.5845080642123079, bagging_freq=2, feature_fraction=0.4370445898249624, lambda_l1=8.544212892768119, lambda_l2=7.934057407252757, learning_rate=0.05, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=136, objective=c, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=1;, score=0.329 total time=   9.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.901564464827215, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.901564464827215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7248298945794276, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7248298945794276\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.092075554205124, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.092075554205124\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7686944837061769, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7686944837061769\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0998505459808552, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.0998505459808552\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5533968054772693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5533968054772693\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[345]\tvalid_0's multi_logloss: 1.49791\n",
      "[CV 2/2] END bagging_fraction=0.7686944837061769, bagging_freq=5, feature_fraction=0.5533968054772693, lambda_l1=9.092075554205124, lambda_l2=1.0998505459808552, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=240, objective=i, reg_lambda=0.0001, subsample=0.7, subsample_freq=8;, score=0.330 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.195847228396929, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.195847228396929\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.41472089997357625, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.41472089997357625\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.189140546564986, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.189140546564986\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7084712811625389, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7084712811625389\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 1.50059\n",
      "[CV 2/2] END bagging_fraction=0.41472089997357625, bagging_freq=9, feature_fraction=0.7084712811625389, lambda_l1=8.195847228396929, lambda_l2=7.189140546564986, learning_rate=0.2, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=182, objective=s, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=64;, score=0.327 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.254743562147702, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.254743562147702\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8629491201990933, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8629491201990933\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.763424771896314, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.763424771896314\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5435811350439554, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5435811350439554\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1129]\tvalid_0's multi_logloss: 1.49585\n",
      "[CV 2/2] END bagging_fraction=0.8629491201990933, bagging_freq=5, feature_fraction=0.5435811350439554, lambda_l1=9.254743562147702, lambda_l2=5.763424771896314, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=213, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=64;, score=0.331 total time=  20.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.901564464827215, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.901564464827215\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7248298945794276, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7248298945794276\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.220044871841096, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.220044871841096\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5480522738434225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5480522738434225\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[644]\tvalid_0's multi_logloss: 1.50114\n",
      "[CV 1/2] END bagging_fraction=0.7248298945794276, bagging_freq=2, feature_fraction=0.5480522738434225, lambda_l1=9.901564464827215, lambda_l2=7.220044871841096, learning_rate=0.05, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=88, objective=s, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.329 total time=  10.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0715913211944075, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0715913211944075\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6231709918545415, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6231709918545415\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.634231045431621, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.634231045431621\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6292316184251993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6292316184251993\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.50467\n",
      "[CV 2/2] END bagging_fraction=0.6231709918545415, bagging_freq=9, feature_fraction=0.6292316184251993, lambda_l1=1.0715913211944075, lambda_l2=9.634231045431621, learning_rate=0.2, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=160, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.323 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.409588280897754, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.409588280897754\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8646045120042412, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8646045120042412\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4289875578837224, reg_lambda=0 will be ignored. Current value: lambda_l2=0.4289875578837224\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4608527950675943, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4608527950675943\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1116]\tvalid_0's multi_logloss: 1.49211\n",
      "[CV 2/2] END bagging_fraction=0.8646045120042412, bagging_freq=4, feature_fraction=0.4608527950675943, lambda_l1=8.409588280897754, lambda_l2=0.4289875578837224, learning_rate=0.01, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=105, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.330 total time=  34.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.4283820716861095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.4283820716861095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9173189677008149, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9173189677008149\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.054800908252817, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.054800908252817\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8686464933199686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8686464933199686\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[786]\tvalid_0's multi_logloss: 1.4996\n",
      "[CV 1/2] END bagging_fraction=0.7419739227838844, bagging_freq=6, feature_fraction=0.4176050926872854, lambda_l1=9.335039555821446, lambda_l2=1.580933663945995, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=106, objective=a, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.330 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.335039555821446, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.335039555821446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7419739227838844, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7419739227838844\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.580933663945995, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.580933663945995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4176050926872854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4176050926872854\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's multi_logloss: 1.49497\n",
      "[CV 2/2] END bagging_fraction=0.7419739227838844, bagging_freq=6, feature_fraction=0.4176050926872854, lambda_l1=9.335039555821446, lambda_l2=1.580933663945995, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=106, objective=a, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.330 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.282927824326513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.282927824326513\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4384852256905064, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4384852256905064\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.9406011604264, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.9406011604264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9151728779849343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9151728779849343\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.49928\n",
      "[CV 1/2] END bagging_fraction=0.4384852256905064, bagging_freq=3, feature_fraction=0.9151728779849343, lambda_l1=4.282927824326513, lambda_l2=8.9406011604264, learning_rate=0.2, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=308, objective=t, reg_lambda=1e-06, subsample=0.7, subsample_freq=1;, score=0.327 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.544212892768119, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.544212892768119\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5845080642123079, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5845080642123079\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.934057407252757, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.934057407252757\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4370445898249624, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4370445898249624\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[558]\tvalid_0's multi_logloss: 1.49404\n",
      "[CV 1/2] END bagging_fraction=0.5845080642123079, bagging_freq=2, feature_fraction=0.4370445898249624, lambda_l1=8.544212892768119, lambda_l2=7.934057407252757, learning_rate=0.05, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=136, objective=c, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=1;, score=0.332 total time=  13.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0715913211944075, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0715913211944075\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6231709918545415, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6231709918545415\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.634231045431621, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.634231045431621\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6292316184251993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6292316184251993\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 1.51234\n",
      "[CV 1/2] END bagging_fraction=0.6231709918545415, bagging_freq=9, feature_fraction=0.6292316184251993, lambda_l1=1.0715913211944075, lambda_l2=9.634231045431621, learning_rate=0.2, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=160, objective=a, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.324 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.409588280897754, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.409588280897754\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8646045120042412, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8646045120042412\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4289875578837224, reg_lambda=0 will be ignored. Current value: lambda_l2=0.4289875578837224\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4608527950675943, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4608527950675943\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1280]\tvalid_0's multi_logloss: 1.49598\n",
      "[CV 1/2] END bagging_fraction=0.8646045120042412, bagging_freq=4, feature_fraction=0.4608527950675943, lambda_l1=8.409588280897754, lambda_l2=0.4289875578837224, learning_rate=0.01, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=105, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.334 total time=  34.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.741875199737489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.741875199737489\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9163930830866589, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9163930830866589\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.617335151440198, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.617335151440198\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8479477709101789, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8479477709101789\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[918]\tvalid_0's multi_logloss: 1.49749\n",
      "[CV 1/2] END bagging_fraction=0.9163930830866589, bagging_freq=2, feature_fraction=0.8479477709101789, lambda_l1=7.741875199737489, lambda_l2=3.617335151440198, learning_rate=0.01, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=438, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=32;, score=0.331 total time=  24.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.777509326253499, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.777509326253499\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6172329852466827, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6172329852466827\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.159737973762218, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.159737973762218\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8192547190056944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8192547190056944\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.220044871841096, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.220044871841096\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5480522738434225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5480522738434225\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[422]\tvalid_0's multi_logloss: 1.49448\n",
      "[CV 2/2] END bagging_fraction=0.7248298945794276, bagging_freq=2, feature_fraction=0.5480522738434225, lambda_l1=9.901564464827215, lambda_l2=7.220044871841096, learning_rate=0.05, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=88, objective=s, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.329 total time=   8.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1634386670873322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1634386670873322\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680148154263122, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5680148154263122\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.510388657652861, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.510388657652861\n",
      "[LightGBM] [Warning] feature_fraction is set=0.747571770200782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.747571770200782\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\tvalid_0's multi_logloss: 1.49991\n",
      "[CV 1/2] END bagging_fraction=0.5680148154263122, bagging_freq=6, feature_fraction=0.747571770200782, lambda_l1=2.1634386670873322, lambda_l2=9.510388657652861, learning_rate=0.01, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=168, objective=u, reg_lambda=1e-06, subsample=0.6, subsample_freq=8;, score=0.329 total time=  15.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1634386670873322, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1634386670873322\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680148154263122, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5680148154263122\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.510388657652861, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.510388657652861\n",
      "[LightGBM] [Warning] feature_fraction is set=0.747571770200782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.747571770200782\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid_0's multi_logloss: 1.49609\n",
      "[CV 2/2] END bagging_fraction=0.5680148154263122, bagging_freq=6, feature_fraction=0.747571770200782, lambda_l1=2.1634386670873322, lambda_l2=9.510388657652861, learning_rate=0.01, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=168, objective=u, reg_lambda=1e-06, subsample=0.6, subsample_freq=8;, score=0.330 total time=  16.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.741875199737489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.741875199737489\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9163930830866589, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9163930830866589\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.617335151440198, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.617335151440198\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8479477709101789, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8479477709101789\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[772]\tvalid_0's multi_logloss: 1.49488\n",
      "[CV 2/2] END bagging_fraction=0.9163930830866589, bagging_freq=2, feature_fraction=0.8479477709101789, lambda_l1=7.741875199737489, lambda_l2=3.617335151440198, learning_rate=0.01, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=438, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=32;, score=0.331 total time=  22.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.777509326253499, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.777509326253499\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6172329852466827, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6172329852466827\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.159737973762218, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.159737973762218\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8192547190056944, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8192547190056944\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 1.51266\n",
      "[CV 1/2] END bagging_fraction=0.6172329852466827, bagging_freq=5, feature_fraction=0.8192547190056944, lambda_l1=8.777509326253499, lambda_l2=5.159737973762218, learning_rate=0.2, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=502, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=1;, score=0.323 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8668141105960584, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8668141105960584\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.791322017767101, subsample=0.5 will be ignored. Current value: bagging_fraction=0.791322017767101\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.360022245620987, reg_lambda=0 will be ignored. Current value: lambda_l2=7.360022245620987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977154668270491, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977154668270491\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.50668\n",
      "[CV 1/2] END bagging_fraction=0.791322017767101, bagging_freq=5, feature_fraction=0.8977154668270491, lambda_l1=0.8668141105960584, lambda_l2=7.360022245620987, learning_rate=0.2, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=78, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=256;, score=0.326 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.889324014161256, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.889324014161256\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9888087993108877, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9888087993108877\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.875819259616401, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.875819259616401\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8065440548784378, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8065440548784378\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[585]\tvalid_0's multi_logloss: 1.49787\n",
      "[CV 1/2] END bagging_fraction=0.9888087993108877, bagging_freq=9, feature_fraction=0.8065440548784378, lambda_l1=4.889324014161256, lambda_l2=7.875819259616401, learning_rate=0.01, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=260, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=32;, score=0.329 total time=  17.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5594180959828545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5594180959828545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.849006031577172, subsample=0.7 will be ignored. Current value: bagging_fraction=0.849006031577172\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 1.50182\n",
      "[CV 2/2] END bagging_fraction=0.6172329852466827, bagging_freq=5, feature_fraction=0.8192547190056944, lambda_l1=8.777509326253499, lambda_l2=5.159737973762218, learning_rate=0.2, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=502, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=1;, score=0.332 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8668141105960584, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8668141105960584\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.791322017767101, subsample=0.5 will be ignored. Current value: bagging_fraction=0.791322017767101\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.360022245620987, reg_lambda=0 will be ignored. Current value: lambda_l2=7.360022245620987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8977154668270491, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8977154668270491\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.50184\n",
      "[CV 2/2] END bagging_fraction=0.791322017767101, bagging_freq=5, feature_fraction=0.8977154668270491, lambda_l1=0.8668141105960584, lambda_l2=7.360022245620987, learning_rate=0.2, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=78, objective=i, reg_lambda=0, subsample=0.5, subsample_freq=256;, score=0.330 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.889324014161256, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.889324014161256\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9888087993108877, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9888087993108877\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.875819259616401, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.875819259616401\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8065440548784378, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8065440548784378\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid_0's multi_logloss: 1.49654\n",
      "[CV 2/2] END bagging_fraction=0.9888087993108877, bagging_freq=9, feature_fraction=0.8065440548784378, lambda_l1=4.889324014161256, lambda_l2=7.875819259616401, learning_rate=0.01, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=260, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=32;, score=0.328 total time=  14.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.315826716715045, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.315826716715045\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8874472023707887, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8874472023707887\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.160046054770785, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.160046054770785\n",
      "[LightGBM] [Warning] feature_fraction is set=0.45342604498589056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.45342604498589056\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's multi_logloss: 1.49417\n",
      "[CV 2/2] END bagging_fraction=0.8874472023707887, bagging_freq=4, feature_fraction=0.45342604498589056, lambda_l1=6.315826716715045, lambda_l2=9.160046054770785, learning_rate=0.05, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=65, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.330 total time=   7.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.721684686923307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.721684686923307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4715162009777536, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4715162009777536\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.028218364225185706, reg_lambda=0 will be ignored. Current value: lambda_l2=0.028218364225185706\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7086966247608992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086966247608992\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[589]\tvalid_0's multi_logloss: 1.52448\n",
      "[CV 1/2] END bagging_fraction=0.4715162009777536, bagging_freq=3, feature_fraction=0.7086966247608992, lambda_l1=8.721684686923307, lambda_l2=0.028218364225185706, learning_rate=0.01, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=458, objective=a, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.325 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.925588088650374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.925588088650374\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6374846483681191, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6374846483681191\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.135438902882132, reg_lambda=0 will be ignored. Current value: lambda_l2=7.135438902882132\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9517508112776949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9517508112776949\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 1.50519\n",
      "[CV 1/2] END bagging_fraction=0.6374846483681191, bagging_freq=4, feature_fraction=0.9517508112776949, lambda_l1=9.925588088650374, lambda_l2=7.135438902882132, learning_rate=0.2, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=500, objective=l, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=2;, score=0.328 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.318201276954893, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.318201276954893\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6494612790611082, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6494612790611082\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7873907566790725, reg_lambda=0 will be ignored. Current value: lambda_l2=6.7873907566790725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8337297535524327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8337297535524327\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.50161\n",
      "[CV 1/2] END bagging_fraction=0.6494612790611082, bagging_freq=6, feature_fraction=0.8337297535524327, lambda_l1=4.318201276954893, lambda_l2=6.7873907566790725, learning_rate=0.2, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=374, objective=s, reg_lambda=0, subsample=0.6, subsample_freq=128;, score=0.329 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.781140169731849, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.781140169731849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.792526482321338, subsample=0.5 will be ignored. Current value: bagging_fraction=0.792526482321338\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.747699441595628, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.747699441595628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5628055404168973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5628055404168973\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[CV 1/2] END bagging_fraction=0.9173189677008149, bagging_freq=6, feature_fraction=0.8686464933199686, lambda_l1=6.4283820716861095, lambda_l2=5.054800908252817, learning_rate=0.01, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=442, objective=t, reg_lambda=1e-06, subsample=0.5, subsample_freq=256;, score=0.328 total time=  19.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.4283820716861095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.4283820716861095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9173189677008149, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9173189677008149\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.054800908252817, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.054800908252817\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8686464933199686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8686464933199686\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[726]\tvalid_0's multi_logloss: 1.4953\n",
      "[CV 2/2] END bagging_fraction=0.9173189677008149, bagging_freq=6, feature_fraction=0.8686464933199686, lambda_l1=6.4283820716861095, lambda_l2=5.054800908252817, learning_rate=0.01, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=442, objective=t, reg_lambda=1e-06, subsample=0.5, subsample_freq=256;, score=0.331 total time=  18.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.315826716715045, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.315826716715045\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8874472023707887, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8874472023707887\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.160046054770785, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.160046054770785\n",
      "[LightGBM] [Warning] feature_fraction is set=0.45342604498589056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.45342604498589056\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[383]\tvalid_0's multi_logloss: 1.49688\n",
      "[CV 1/2] END bagging_fraction=0.8874472023707887, bagging_freq=4, feature_fraction=0.45342604498589056, lambda_l1=6.315826716715045, lambda_l2=9.160046054770785, learning_rate=0.05, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=65, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.331 total time=   8.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5594180959828545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5594180959828545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.849006031577172, subsample=0.7 will be ignored. Current value: bagging_fraction=0.849006031577172\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.36114283162003, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.36114283162003\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4752810021515816, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4752810021515816\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 1.49501\n",
      "[CV 2/2] END bagging_fraction=0.849006031577172, bagging_freq=3, feature_fraction=0.4752810021515816, lambda_l1=5.5594180959828545, lambda_l2=3.36114283162003, learning_rate=0.05, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=126, objective=m, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.329 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.721684686923307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.721684686923307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4715162009777536, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4715162009777536\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.028218364225185706, reg_lambda=0 will be ignored. Current value: lambda_l2=0.028218364225185706\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7086966247608992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7086966247608992\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[702]\tvalid_0's multi_logloss: 1.50876\n",
      "[CV 2/2] END bagging_fraction=0.4715162009777536, bagging_freq=3, feature_fraction=0.7086966247608992, lambda_l1=8.721684686923307, lambda_l2=0.028218364225185706, learning_rate=0.01, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=458, objective=a, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.322 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.925588088650374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.925588088650374\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6374846483681191, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6374846483681191\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.135438902882132, reg_lambda=0 will be ignored. Current value: lambda_l2=7.135438902882132\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9517508112776949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9517508112776949\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's multi_logloss: 1.50148\n",
      "[CV 2/2] END bagging_fraction=0.6374846483681191, bagging_freq=4, feature_fraction=0.9517508112776949, lambda_l1=9.925588088650374, lambda_l2=7.135438902882132, learning_rate=0.2, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=500, objective=l, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=2;, score=0.330 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.781140169731849, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.781140169731849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.792526482321338, subsample=0.5 will be ignored. Current value: bagging_fraction=0.792526482321338\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.747699441595628, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.747699441595628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5628055404168973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5628055404168973\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 1.51014\n",
      "[CV 1/2] END bagging_fraction=0.792526482321338, bagging_freq=9, feature_fraction=0.5628055404168973, lambda_l1=5.781140169731849, lambda_l2=9.747699441595628, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=421, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=256;, score=0.326 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.205958544592083, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.205958544592083\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.446280416237472, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.446280416237472\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.018561764524446, reg_lambda=0 will be ignored. Current value: lambda_l2=8.018561764524446\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7842056557225756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7842056557225756\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=2 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.50085\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.36114283162003, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.36114283162003\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4752810021515816, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4752810021515816\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 1.4991\n",
      "[CV 1/2] END bagging_fraction=0.849006031577172, bagging_freq=3, feature_fraction=0.4752810021515816, lambda_l1=5.5594180959828545, lambda_l2=3.36114283162003, learning_rate=0.05, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=126, objective=m, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.330 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.3241248587875605, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.3241248587875605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9029619790352009, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9029619790352009\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2000625408015573, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.2000625408015573\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340240039484911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340240039484911\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 1.49786\n",
      "[CV 1/2] END bagging_fraction=0.9029619790352009, bagging_freq=6, feature_fraction=0.7340240039484911, lambda_l1=4.3241248587875605, lambda_l2=3.2000625408015573, learning_rate=0.2, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=495, objective=m, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=256;, score=0.332 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.3241248587875605, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.3241248587875605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9029619790352009, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9029619790352009\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2000625408015573, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.2000625408015573\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340240039484911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340240039484911\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49402\n",
      "[CV 2/2] END bagging_fraction=0.9029619790352009, bagging_freq=6, feature_fraction=0.7340240039484911, lambda_l1=4.3241248587875605, lambda_l2=3.2000625408015573, learning_rate=0.2, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=495, objective=m, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=256;, score=0.328 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.318201276954893, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.318201276954893\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6494612790611082, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6494612790611082\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.7873907566790725, reg_lambda=0 will be ignored. Current value: lambda_l2=6.7873907566790725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8337297535524327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8337297535524327\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_logloss: 1.49885\n",
      "[CV 2/2] END bagging_fraction=0.6494612790611082, bagging_freq=6, feature_fraction=0.8337297535524327, lambda_l1=4.318201276954893, lambda_l2=6.7873907566790725, learning_rate=0.2, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=374, objective=s, reg_lambda=0, subsample=0.6, subsample_freq=128;, score=0.328 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.205958544592083, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.205958544592083\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.446280416237472, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.446280416237472\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.018561764524446, reg_lambda=0 will be ignored. Current value: lambda_l2=8.018561764524446\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7842056557225756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7842056557225756\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=2 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's multi_logloss: 1.50841\n",
      "[CV 1/2] END bagging_fraction=0.446280416237472, bagging_freq=8, feature_fraction=0.7842056557225756, lambda_l1=4.205958544592083, lambda_l2=8.018561764524446, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=118, objective=c, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=2;, score=0.325 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.972977787212743, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.972977787212743\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9695006396433128, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9695006396433128\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8875553747640811, reg_lambda=0 will be ignored. Current value: lambda_l2=0.8875553747640811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9878681946201693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9878681946201693\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 1.4981\n",
      "[CV 1/2] END bagging_fraction=0.9695006396433128, bagging_freq=3, feature_fraction=0.9878681946201693, lambda_l1=8.972977787212743, lambda_l2=0.8875553747640811, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=499, objective=s, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=4;, score=0.333 total time=   4.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.31360443943853095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31360443943853095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8005070750137664, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8005070750137664\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3975240993346425, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.3975240993346425\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6219152781948588, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6219152781948588\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's multi_logloss: 1.49752\n",
      "[CV 2/2] END bagging_fraction=0.8005070750137664, bagging_freq=5, feature_fraction=0.6219152781948588, lambda_l1=0.31360443943853095, lambda_l2=2.3975240993346425, learning_rate=0.01, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=302, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=256;, score=0.329 total time=   9.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.171138187491332, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.171138187491332\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8640722963791336, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8640722963791336\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.707176042095292, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.707176042095292\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7525308390221974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7525308390221974\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's multi_logloss: 1.49771\n",
      "[CV 1/2] END bagging_fraction=0.8640722963791336, bagging_freq=9, feature_fraction=0.7525308390221974, lambda_l1=6.171138187491332, lambda_l2=2.707176042095292, learning_rate=0.05, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=256, objective=m, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=2;, score=0.332 total time=   7.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.147114844709118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.147114844709118\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6002308767860562, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6002308767860562\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6773215566127844, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.6773215566127844\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8514208775882081, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8514208775882081\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 1.49321\n",
      "[CV 2/2] END bagging_fraction=0.6002308767860562, bagging_freq=4, feature_fraction=0.8514208775882081, lambda_l1=6.147114844709118, lambda_l2=1.6773215566127844, learning_rate=0.05, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=394, objective=u, reg_lambda=1e-06, subsample=0.7, subsample_freq=4;, score=0.330 total time=  19.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.964309873700377, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.964309873700377\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9323613273769479, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9323613273769479\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7459146546983924, reg_lambda=0 will be ignored. Current value: lambda_l2=3.7459146546983924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.43152667268267403, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43152667268267403\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[449]\tvalid_0's multi_logloss: 1.49003\n",
      "[CV 2/2] END bagging_fraction=0.9323613273769479, bagging_freq=2, feature_fraction=0.43152667268267403, lambda_l1=2.964309873700377, lambda_l2=3.7459146546983924, learning_rate=0.01, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=44, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=64;, score=0.336 total time=  22.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4811432423574549, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4811432423574549\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48898768175082324, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.48898768175082324\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.404725304826755, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.404725304826755\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7169330630963928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7169330630963928\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's multi_logloss: 1.51011\n",
      "[CV 1/2] END bagging_fraction=0.48898768175082324, bagging_freq=9, feature_fraction=0.7169330630963928, lambda_l1=0.4811432423574549, lambda_l2=6.404725304826755, learning_rate=0.01, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=243, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=32;, score=0.324 total time=   9.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4811432423574549, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4811432423574549\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48898768175082324, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.48898768175082324\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.404725304826755, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.404725304826755\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7169330630963928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7169330630963928\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's multi_logloss: 1.50083\n",
      "[CV 2/2] END bagging_fraction=0.48898768175082324, bagging_freq=9, feature_fraction=0.7169330630963928, lambda_l1=0.4811432423574549, lambda_l2=6.404725304826755, learning_rate=0.01, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=243, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=32;, score=0.330 total time=   8.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.869307040463482, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.869307040463482\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.923694843611045, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.923694843611045\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.8663592089262275, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.8663592089262275\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7653276351843861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7653276351843861\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid_0's multi_logloss: 1.50123\n",
      "[CV 1/2] END bagging_fraction=0.923694843611045, bagging_freq=3, feature_fraction=0.7653276351843861, lambda_l1=8.869307040463482, lambda_l2=7.8663592089262275, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=487, objective=u, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=4;, score=0.329 total time=   7.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.869307040463482, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.869307040463482\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.923694843611045, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.923694843611045\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.8663592089262275, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.8663592089262275\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7653276351843861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7653276351843861\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's multi_logloss: 1.49644\n",
      "[CV 2/2] END bagging_fraction=0.923694843611045, bagging_freq=3, feature_fraction=0.7653276351843861, lambda_l1=8.869307040463482, lambda_l2=7.8663592089262275, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=487, objective=u, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=4;, score=0.329 total time=   5.5s\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's multi_logloss: 1.49812\n",
      "[CV 2/2] END bagging_fraction=0.792526482321338, bagging_freq=9, feature_fraction=0.5628055404168973, lambda_l1=5.781140169731849, lambda_l2=9.747699441595628, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=421, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=256;, score=0.330 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.972977787212743, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.972977787212743\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9695006396433128, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9695006396433128\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8875553747640811, reg_lambda=0 will be ignored. Current value: lambda_l2=0.8875553747640811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9878681946201693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9878681946201693\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 1.49453\n",
      "[CV 2/2] END bagging_fraction=0.9695006396433128, bagging_freq=3, feature_fraction=0.9878681946201693, lambda_l1=8.972977787212743, lambda_l2=0.8875553747640811, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=499, objective=s, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=4;, score=0.329 total time=   5.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8639809627937787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8639809627937787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5388777916360865, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5388777916360865\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.0662497913813285, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.0662497913813285\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5590913978522188, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5590913978522188\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[511]\tvalid_0's multi_logloss: 1.50622\n",
      "[CV 1/2] END bagging_fraction=0.5388777916360865, bagging_freq=9, feature_fraction=0.5590913978522188, lambda_l1=3.8639809627937787, lambda_l2=4.0662497913813285, learning_rate=0.01, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=185, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=256;, score=0.327 total time=   9.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.171138187491332, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.171138187491332\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8640722963791336, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8640722963791336\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.707176042095292, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.707176042095292\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7525308390221974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7525308390221974\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 1.49449\n",
      "[CV 2/2] END bagging_fraction=0.8640722963791336, bagging_freq=9, feature_fraction=0.7525308390221974, lambda_l1=6.171138187491332, lambda_l2=2.707176042095292, learning_rate=0.05, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=256, objective=m, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=2;, score=0.329 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.147114844709118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.147114844709118\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6002308767860562, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6002308767860562\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6773215566127844, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.6773215566127844\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8514208775882081, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8514208775882081\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 1.4911\n",
      "[CV 1/2] END bagging_fraction=0.6002308767860562, bagging_freq=4, feature_fraction=0.8514208775882081, lambda_l1=6.147114844709118, lambda_l2=1.6773215566127844, learning_rate=0.05, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=394, objective=u, reg_lambda=1e-06, subsample=0.7, subsample_freq=4;, score=0.328 total time=  20.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.67965358086582, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.67965358086582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7190380047358191, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7190380047358191\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6784845344489113, reg_lambda=0 will be ignored. Current value: lambda_l2=0.6784845344489113\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7687123012401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7687123012401\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's multi_logloss: 1.50617\n",
      "[CV 1/2] END bagging_fraction=0.7190380047358191, bagging_freq=3, feature_fraction=0.7687123012401, lambda_l1=9.67965358086582, lambda_l2=0.6784845344489113, learning_rate=0.05, metric=multi_logloss, min_child_samples=80, num_class=5, num_leaves=149, objective=a, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.329 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.67965358086582, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.67965358086582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7190380047358191, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7190380047358191\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6784845344489113, reg_lambda=0 will be ignored. Current value: lambda_l2=0.6784845344489113\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7687123012401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7687123012401\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's multi_logloss: 1.49738\n",
      "[CV 2/2] END bagging_fraction=0.7190380047358191, bagging_freq=3, feature_fraction=0.7687123012401, lambda_l1=9.67965358086582, lambda_l2=0.6784845344489113, learning_rate=0.05, metric=multi_logloss, min_child_samples=80, num_class=5, num_leaves=149, objective=a, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.331 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.626771952202457, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.626771952202457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8186196353006887, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8186196353006887\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.258707198537566, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.258707198537566\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5622878908803961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5622878908803961\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[CV 2/2] END bagging_fraction=0.446280416237472, bagging_freq=8, feature_fraction=0.7842056557225756, lambda_l1=4.205958544592083, lambda_l2=8.018561764524446, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=118, objective=c, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=2;, score=0.327 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.31360443943853095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31360443943853095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8005070750137664, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8005070750137664\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3975240993346425, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.3975240993346425\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6219152781948588, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6219152781948588\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's multi_logloss: 1.5003\n",
      "[CV 1/2] END bagging_fraction=0.8005070750137664, bagging_freq=5, feature_fraction=0.6219152781948588, lambda_l1=0.31360443943853095, lambda_l2=2.3975240993346425, learning_rate=0.01, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=302, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=256;, score=0.330 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8639809627937787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8639809627937787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5388777916360865, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5388777916360865\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.0662497913813285, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.0662497913813285\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5590913978522188, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5590913978522188\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's multi_logloss: 1.49623\n",
      "[CV 2/2] END bagging_fraction=0.5388777916360865, bagging_freq=9, feature_fraction=0.5590913978522188, lambda_l1=3.8639809627937787, lambda_l2=4.0662497913813285, learning_rate=0.01, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=185, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=256;, score=0.329 total time=  13.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.964309873700377, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.964309873700377\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9323613273769479, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9323613273769479\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7459146546983924, reg_lambda=0 will be ignored. Current value: lambda_l2=3.7459146546983924\n",
      "[LightGBM] [Warning] feature_fraction is set=0.43152667268267403, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43152667268267403\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[580]\tvalid_0's multi_logloss: 1.48892\n",
      "[CV 1/2] END bagging_fraction=0.9323613273769479, bagging_freq=2, feature_fraction=0.43152667268267403, lambda_l1=2.964309873700377, lambda_l2=3.7459146546983924, learning_rate=0.01, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=44, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=64;, score=0.336 total time=  31.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.626771952202457, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.626771952202457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8186196353006887, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8186196353006887\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.258707198537566, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.258707198537566\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5622878908803961, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5622878908803961\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 1.49264\n",
      "[CV 2/2] END bagging_fraction=0.8186196353006887, bagging_freq=5, feature_fraction=0.5622878908803961, lambda_l1=2.626771952202457, lambda_l2=3.258707198537566, learning_rate=0.01, metric=multi_logloss, min_child_samples=13, num_class=5, num_leaves=204, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=64;, score=0.334 total time=  34.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.154469605850051, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.154469605850051\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9951104948446519, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9951104948446519\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.782737732507, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.782737732507\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7152567162044343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7152567162044343\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 1.49821\n",
      "[CV 1/2] END bagging_fraction=0.9951104948446519, bagging_freq=4, feature_fraction=0.7152567162044343, lambda_l1=6.154469605850051, lambda_l2=8.782737732507, learning_rate=0.2, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=33, objective=s, reg_lambda=1e-07, subsample=0.5, subsample_freq=16;, score=0.330 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.102538733566344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.102538733566344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7156397724275876, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7156397724275876\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.391077893890646, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.391077893890646\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5158615642394159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5158615642394159\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1016]\tvalid_0's multi_logloss: 1.49607\n",
      "[CV 1/2] END bagging_fraction=0.7156397724275876, bagging_freq=5, feature_fraction=0.5158615642394159, lambda_l1=4.102538733566344, lambda_l2=8.391077893890646, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=221, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=64;, score=0.331 total time=  31.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.682317853171636, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.682317853171636\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4486458914249612, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4486458914249612\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.179148937182035, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.179148937182035\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48232408296894147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48232408296894147\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[852]\tvalid_0's multi_logloss: 1.50944\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's multi_logloss: 1.48793\n",
      "[CV 1/2] END bagging_fraction=0.8186196353006887, bagging_freq=5, feature_fraction=0.5622878908803961, lambda_l1=2.626771952202457, lambda_l2=3.258707198537566, learning_rate=0.01, metric=multi_logloss, min_child_samples=13, num_class=5, num_leaves=204, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=64;, score=0.330 total time=  46.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.191478196437687, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.191478196437687\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7236299071112239, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7236299071112239\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.954102261465431, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.954102261465431\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7429658755918255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7429658755918255\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2964]\tvalid_0's multi_logloss: 1.51294\n",
      "[CV 1/2] END bagging_fraction=0.7236299071112239, bagging_freq=4, feature_fraction=0.7429658755918255, lambda_l1=9.191478196437687, lambda_l2=7.954102261465431, learning_rate=0.01, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=2, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=16;, score=0.330 total time=  10.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.191478196437687, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.191478196437687\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7236299071112239, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7236299071112239\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.954102261465431, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.954102261465431\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7429658755918255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7429658755918255\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2216]\tvalid_0's multi_logloss: 1.50759\n",
      "[CV 2/2] END bagging_fraction=0.7236299071112239, bagging_freq=4, feature_fraction=0.7429658755918255, lambda_l1=9.191478196437687, lambda_l2=7.954102261465431, learning_rate=0.01, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=2, objective=m, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=16;, score=0.331 total time=   8.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6642368440903477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6642368440903477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6592873463448142, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6592873463448142\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.924261188030173, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.924261188030173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6727861207948008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6727861207948008\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 1.50701\n",
      "[CV 1/2] END bagging_fraction=0.6592873463448142, bagging_freq=3, feature_fraction=0.6727861207948008, lambda_l1=2.6642368440903477, lambda_l2=5.924261188030173, learning_rate=0.05, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=453, objective=l, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=1;, score=0.326 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.461531821817612, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.461531821817612\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7224029633436029, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7224029633436029\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.275763741390918, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.275763741390918\n",
      "[LightGBM] [Warning] feature_fraction is set=0.681611420288475, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.681611420288475\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1098]\tvalid_0's multi_logloss: 1.50092\n",
      "[CV 2/2] END bagging_fraction=0.7224029633436029, bagging_freq=3, feature_fraction=0.681611420288475, lambda_l1=9.461531821817612, lambda_l2=9.275763741390918, learning_rate=0.05, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=2, objective=a, reg_lambda=0.0001, subsample=0.7, subsample_freq=32;, score=0.332 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9978170678200748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9978170678200748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9418625112187239, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9418625112187239\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.077734838902879, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.077734838902879\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5905102732987011, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5905102732987011\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49599\n",
      "[CV 1/2] END bagging_fraction=0.9418625112187239, bagging_freq=7, feature_fraction=0.5905102732987011, lambda_l1=1.9978170678200748, lambda_l2=5.077734838902879, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=379, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.333 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9978170678200748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9978170678200748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9418625112187239, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9418625112187239\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.077734838902879, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.077734838902879\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5905102732987011, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5905102732987011\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.49822\n",
      "[CV 2/2] END bagging_fraction=0.9418625112187239, bagging_freq=7, feature_fraction=0.5905102732987011, lambda_l1=1.9978170678200748, lambda_l2=5.077734838902879, learning_rate=0.2, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=379, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.324 total time=   6.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.035638878056263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.035638878056263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9779231208737217, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9779231208737217\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.696819626685253, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.696819626685253\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5866093425848047, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5866093425848047\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.154469605850051, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.154469605850051\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9951104948446519, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9951104948446519\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.782737732507, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.782737732507\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7152567162044343, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7152567162044343\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 1.49317\n",
      "[CV 2/2] END bagging_fraction=0.9951104948446519, bagging_freq=4, feature_fraction=0.7152567162044343, lambda_l1=6.154469605850051, lambda_l2=8.782737732507, learning_rate=0.2, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=33, objective=s, reg_lambda=1e-07, subsample=0.5, subsample_freq=16;, score=0.330 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.102538733566344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.102538733566344\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7156397724275876, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7156397724275876\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.391077893890646, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.391077893890646\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5158615642394159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5158615642394159\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[590]\tvalid_0's multi_logloss: 1.49262\n",
      "[CV 2/2] END bagging_fraction=0.7156397724275876, bagging_freq=5, feature_fraction=0.5158615642394159, lambda_l1=4.102538733566344, lambda_l2=8.391077893890646, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=221, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=64;, score=0.329 total time=  21.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6642368440903477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6642368440903477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6592873463448142, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6592873463448142\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.924261188030173, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.924261188030173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6727861207948008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6727861207948008\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's multi_logloss: 1.49986\n",
      "[CV 2/2] END bagging_fraction=0.6592873463448142, bagging_freq=3, feature_fraction=0.6727861207948008, lambda_l1=2.6642368440903477, lambda_l2=5.924261188030173, learning_rate=0.05, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=453, objective=l, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=1;, score=0.332 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.461531821817612, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.461531821817612\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7224029633436029, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7224029633436029\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.275763741390918, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.275763741390918\n",
      "[LightGBM] [Warning] feature_fraction is set=0.681611420288475, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.681611420288475\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1137]\tvalid_0's multi_logloss: 1.50738\n",
      "[CV 1/2] END bagging_fraction=0.7224029633436029, bagging_freq=3, feature_fraction=0.681611420288475, lambda_l1=9.461531821817612, lambda_l2=9.275763741390918, learning_rate=0.05, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=2, objective=a, reg_lambda=0.0001, subsample=0.7, subsample_freq=32;, score=0.335 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.682317853171636, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.682317853171636\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4486458914249612, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4486458914249612\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.179148937182035, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.179148937182035\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48232408296894147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48232408296894147\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1473]\tvalid_0's multi_logloss: 1.49623\n",
      "[CV 2/2] END bagging_fraction=0.4486458914249612, bagging_freq=3, feature_fraction=0.48232408296894147, lambda_l1=9.682317853171636, lambda_l2=2.179148937182035, learning_rate=0.01, metric=multi_logloss, min_child_samples=37, num_class=5, num_leaves=371, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=16;, score=0.331 total time=  23.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3018873473422293, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3018873473422293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6620553104913389, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6620553104913389\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.698173720467889, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.698173720467889\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5808430146028161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5808430146028161\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 1.49897\n",
      "[CV 1/2] END bagging_fraction=0.6620553104913389, bagging_freq=7, feature_fraction=0.5808430146028161, lambda_l1=0.3018873473422293, lambda_l2=8.698173720467889, learning_rate=0.2, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=511, objective=a, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=4;, score=0.309 total time=  16.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3018873473422293, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3018873473422293\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6620553104913389, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6620553104913389\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.698173720467889, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.698173720467889\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5808430146028161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5808430146028161\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.50591\n",
      "[CV 2/2] END bagging_fraction=0.6620553104913389, bagging_freq=7, feature_fraction=0.5808430146028161, lambda_l1=0.3018873473422293, lambda_l2=8.698173720467889, learning_rate=0.2, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=511, objective=a, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=4;, score=0.327 total time=  14.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9735878522364838, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9735878522364838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6441151493045535, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6441151493045535\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.707067450669791, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.707067450669791\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7733842634989025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7733842634989025\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.49601\n",
      "[CV 1/2] END bagging_fraction=0.6441151493045535, bagging_freq=2, feature_fraction=0.7733842634989025, lambda_l1=1.9735878522364838, lambda_l2=7.707067450669791, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=208, objective=s, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=128;, score=0.333 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9735878522364838, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9735878522364838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6441151493045535, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6441151493045535\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.707067450669791, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.707067450669791\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7733842634989025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7733842634989025\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.49685\n",
      "[CV 2/2] END bagging_fraction=0.6441151493045535, bagging_freq=2, feature_fraction=0.7733842634989025, lambda_l1=1.9735878522364838, lambda_l2=7.707067450669791, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=208, objective=s, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=128;, score=0.327 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.065606828008145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.065606828008145\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8238717753097301, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8238717753097301\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.74163993597232, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.74163993597232\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7874076328097548, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7874076328097548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 1.49313\n",
      "[CV 1/2] END bagging_fraction=0.8238717753097301, bagging_freq=4, feature_fraction=0.7874076328097548, lambda_l1=4.065606828008145, lambda_l2=5.74163993597232, learning_rate=0.2, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=403, objective=l, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.315 total time=  13.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.840666213618334, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.840666213618334\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8735571648436709, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8735571648436709\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.838279906012886, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.838279906012886\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5548453282448493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5548453282448493\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1515]\tvalid_0's multi_logloss: 1.49591\n",
      "[CV 1/2] END bagging_fraction=0.8735571648436709, bagging_freq=3, feature_fraction=0.5548453282448493, lambda_l1=9.840666213618334, lambda_l2=9.838279906012886, learning_rate=0.01, metric=multi_logloss, min_child_samples=32, num_class=5, num_leaves=36, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.334 total time=  36.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.103596290638735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.103596290638735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9726479536485366, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9726479536485366\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.5977151902569915, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.5977151902569915\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6155875781924183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6155875781924183\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[732]\tvalid_0's multi_logloss: 1.49368\n",
      "[CV 2/2] END bagging_fraction=0.9726479536485366, bagging_freq=2, feature_fraction=0.6155875781924183, lambda_l1=7.103596290638735, lambda_l2=3.5977151902569915, learning_rate=0.01, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=494, objective=l, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.332 total time=  27.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.206625310964401, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.206625310964401\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8726031212099202, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8726031212099202\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.41689358304044, reg_lambda=0 will be ignored. Current value: lambda_l2=8.41689358304044\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5313867963498167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5313867963498167\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's multi_logloss: 1.49476\n",
      "[CV 2/2] END bagging_fraction=0.8726031212099202, bagging_freq=8, feature_fraction=0.5313867963498167, lambda_l1=6.206625310964401, lambda_l2=8.41689358304044, learning_rate=0.05, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=243, objective=l, reg_lambda=0, subsample=0.6, subsample_freq=4;, score=0.329 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.410333371136626, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.410333371136626\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7855922685939485, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7855922685939485\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.468113256218229, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.468113256218229\n",
      "[LightGBM] [Warning] feature_fraction is set=0.779168248967123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.779168248967123\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "[CV 1/2] END bagging_fraction=0.4486458914249612, bagging_freq=3, feature_fraction=0.48232408296894147, lambda_l1=9.682317853171636, lambda_l2=2.179148937182035, learning_rate=0.01, metric=multi_logloss, min_child_samples=37, num_class=5, num_leaves=371, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=16;, score=0.326 total time=  12.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.035638878056263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.035638878056263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9779231208737217, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9779231208737217\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.696819626685253, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.696819626685253\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5866093425848047, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5866093425848047\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1841]\tvalid_0's multi_logloss: 1.49188\n",
      "[CV 1/2] END bagging_fraction=0.9779231208737217, bagging_freq=3, feature_fraction=0.5866093425848047, lambda_l1=9.035638878056263, lambda_l2=5.696819626685253, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=50, objective=m, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.336 total time= 1.4min\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5084114642419033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5084114642419033\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6557989503659887, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6557989503659887\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2235537409081834, reg_lambda=0 will be ignored. Current value: lambda_l2=1.2235537409081834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5178665906986258, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5178665906986258\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=256 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's multi_logloss: 1.51537\n",
      "[CV 1/2] END bagging_fraction=0.6557989503659887, bagging_freq=4, feature_fraction=0.5178665906986258, lambda_l1=2.5084114642419033, lambda_l2=1.2235537409081834, learning_rate=0.2, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=182, objective=a, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=256;, score=0.323 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5084114642419033, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5084114642419033\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6557989503659887, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6557989503659887\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2235537409081834, reg_lambda=0 will be ignored. Current value: lambda_l2=1.2235537409081834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5178665906986258, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5178665906986258\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=256 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 1.50112\n",
      "[CV 2/2] END bagging_fraction=0.6557989503659887, bagging_freq=4, feature_fraction=0.5178665906986258, lambda_l1=2.5084114642419033, lambda_l2=1.2235537409081834, learning_rate=0.2, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=182, objective=a, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=256;, score=0.326 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.103596290638735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.103596290638735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9726479536485366, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9726479536485366\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.5977151902569915, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.5977151902569915\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6155875781924183, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6155875781924183\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1178]\tvalid_0's multi_logloss: 1.49522\n",
      "[CV 1/2] END bagging_fraction=0.9726479536485366, bagging_freq=2, feature_fraction=0.6155875781924183, lambda_l1=7.103596290638735, lambda_l2=3.5977151902569915, learning_rate=0.01, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=494, objective=l, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.332 total time=  36.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.225138485196565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.225138485196565\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5660683053454761, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5660683053454761\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1077407259124517, reg_lambda=0 will be ignored. Current value: lambda_l2=3.1077407259124517\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6090644721730741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6090644721730741\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's multi_logloss: 1.51418\n",
      "[CV 1/2] END bagging_fraction=0.5660683053454761, bagging_freq=6, feature_fraction=0.6090644721730741, lambda_l1=9.225138485196565, lambda_l2=3.1077407259124517, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=224, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=4;, score=0.324 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.206625310964401, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.206625310964401\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8726031212099202, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8726031212099202\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.41689358304044, reg_lambda=0 will be ignored. Current value: lambda_l2=8.41689358304044\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5313867963498167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5313867963498167\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's multi_logloss: 1.49753\n",
      "[CV 1/2] END bagging_fraction=0.8726031212099202, bagging_freq=8, feature_fraction=0.5313867963498167, lambda_l1=6.206625310964401, lambda_l2=8.41689358304044, learning_rate=0.05, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=243, objective=l, reg_lambda=0, subsample=0.6, subsample_freq=4;, score=0.333 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.353268270947368, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.353268270947368\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5804278225488144, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5804278225488144\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.326323281773156, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.326323281773156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6961351894941873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6961351894941873\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[733]\tvalid_0's multi_logloss: 1.49328\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1158]\tvalid_0's multi_logloss: 1.48938\n",
      "[CV 2/2] END bagging_fraction=0.9779231208737217, bagging_freq=3, feature_fraction=0.5866093425848047, lambda_l1=9.035638878056263, lambda_l2=5.696819626685253, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=50, objective=m, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.332 total time=  59.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.065606828008145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.065606828008145\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8238717753097301, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8238717753097301\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.74163993597232, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.74163993597232\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7874076328097548, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7874076328097548\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 1.49518\n",
      "[CV 2/2] END bagging_fraction=0.8238717753097301, bagging_freq=4, feature_fraction=0.7874076328097548, lambda_l1=4.065606828008145, lambda_l2=5.74163993597232, learning_rate=0.2, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=403, objective=l, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.332 total time=  13.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.840666213618334, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.840666213618334\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8735571648436709, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8735571648436709\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.838279906012886, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.838279906012886\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5548453282448493, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5548453282448493\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1283]\tvalid_0's multi_logloss: 1.48999\n",
      "[CV 2/2] END bagging_fraction=0.8735571648436709, bagging_freq=3, feature_fraction=0.5548453282448493, lambda_l1=9.840666213618334, lambda_l2=9.838279906012886, learning_rate=0.01, metric=multi_logloss, min_child_samples=32, num_class=5, num_leaves=36, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.333 total time=  35.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8099307878017429, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8099307878017429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4553362714000967, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4553362714000967\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.64422484561852, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.64422484561852\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8505615048641161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8505615048641161\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's multi_logloss: 1.51029\n",
      "[CV 1/2] END bagging_fraction=0.4553362714000967, bagging_freq=6, feature_fraction=0.8505615048641161, lambda_l1=0.8099307878017429, lambda_l2=6.64422484561852, learning_rate=0.01, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=80, objective=c, reg_lambda=0.001, subsample=0.5, subsample_freq=256;, score=0.324 total time=   7.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8099307878017429, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8099307878017429\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4553362714000967, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4553362714000967\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.64422484561852, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.64422484561852\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8505615048641161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8505615048641161\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid_0's multi_logloss: 1.50006\n",
      "[CV 2/2] END bagging_fraction=0.4553362714000967, bagging_freq=6, feature_fraction=0.8505615048641161, lambda_l1=0.8099307878017429, lambda_l2=6.64422484561852, learning_rate=0.01, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=80, objective=c, reg_lambda=0.001, subsample=0.5, subsample_freq=256;, score=0.329 total time=   9.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.225138485196565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.225138485196565\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5660683053454761, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5660683053454761\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1077407259124517, reg_lambda=0 will be ignored. Current value: lambda_l2=3.1077407259124517\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6090644721730741, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6090644721730741\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[366]\tvalid_0's multi_logloss: 1.50033\n",
      "[CV 2/2] END bagging_fraction=0.5660683053454761, bagging_freq=6, feature_fraction=0.6090644721730741, lambda_l1=9.225138485196565, lambda_l2=3.1077407259124517, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=224, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=4;, score=0.325 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.353268270947368, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.353268270947368\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5804278225488144, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5804278225488144\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.326323281773156, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.326323281773156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6961351894941873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6961351894941873\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1070]\tvalid_0's multi_logloss: 1.49486\n",
      "[CV 1/2] END bagging_fraction=0.5804278225488144, bagging_freq=2, feature_fraction=0.6961351894941873, lambda_l1=7.353268270947368, lambda_l2=8.326323281773156, learning_rate=0.01, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=188, objective=i, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.333 total time=  33.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.218146145134895, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.218146145134895\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49210905346980627, subsample=0.6 will be ignored. Current value: bagging_fraction=0.49210905346980627\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.575353706110461, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.575353706110461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's multi_logloss: 1.5069\n",
      "[CV 1/2] END bagging_fraction=0.7855922685939485, bagging_freq=5, feature_fraction=0.779168248967123, lambda_l1=6.410333371136626, lambda_l2=6.468113256218229, learning_rate=0.05, metric=multi_logloss, min_child_samples=89, num_class=5, num_leaves=47, objective=a, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.328 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.410333371136626, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.410333371136626\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7855922685939485, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7855922685939485\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.468113256218229, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.468113256218229\n",
      "[LightGBM] [Warning] feature_fraction is set=0.779168248967123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.779168248967123\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 1.49906\n",
      "[CV 2/2] END bagging_fraction=0.7855922685939485, bagging_freq=5, feature_fraction=0.779168248967123, lambda_l1=6.410333371136626, lambda_l2=6.468113256218229, learning_rate=0.05, metric=multi_logloss, min_child_samples=89, num_class=5, num_leaves=47, objective=a, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.331 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.181448266448176, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.181448266448176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4016002769069991, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.4016002769069991\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.69232583327486, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.69232583327486\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8341507629385225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8341507629385225\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's multi_logloss: 1.52352\n",
      "[CV 1/2] END bagging_fraction=0.4016002769069991, bagging_freq=8, feature_fraction=0.8341507629385225, lambda_l1=3.181448266448176, lambda_l2=8.69232583327486, learning_rate=0.01, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=348, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=16;, score=0.324 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.181448266448176, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.181448266448176\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4016002769069991, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.4016002769069991\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.69232583327486, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.69232583327486\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8341507629385225, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8341507629385225\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[648]\tvalid_0's multi_logloss: 1.50928\n",
      "[CV 2/2] END bagging_fraction=0.4016002769069991, bagging_freq=8, feature_fraction=0.8341507629385225, lambda_l1=3.181448266448176, lambda_l2=8.69232583327486, learning_rate=0.01, metric=multi_logloss, min_child_samples=90, num_class=5, num_leaves=348, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=16;, score=0.317 total time=   8.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.47294712434629155, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.47294712434629155\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6919438625223178, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6919438625223178\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8661855733168293, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.8661855733168293\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6153409471406311, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6153409471406311\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's multi_logloss: 1.50277\n",
      "[CV 2/2] END bagging_fraction=0.6919438625223178, bagging_freq=9, feature_fraction=0.6153409471406311, lambda_l1=0.47294712434629155, lambda_l2=3.8661855733168293, learning_rate=0.01, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=149, objective=i, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=256;, score=0.332 total time=   7.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.404147806848231, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.404147806848231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5714856070468901, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5714856070468901\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.433178885787868, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.433178885787868\n",
      "[LightGBM] [Warning] feature_fraction is set=0.43390979527605644, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43390979527605644\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's multi_logloss: 1.50715\n",
      "[CV 1/2] END bagging_fraction=0.5714856070468901, bagging_freq=3, feature_fraction=0.43390979527605644, lambda_l1=0.404147806848231, lambda_l2=4.433178885787868, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=176, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.326 total time=   8.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3854750731510297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3854750731510297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9397286711616458, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9397286711616458\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.289903599123722, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.289903599123722\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4716514669996941, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4716514669996941\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.49526\n",
      "[CV 2/2] END bagging_fraction=0.9397286711616458, bagging_freq=4, feature_fraction=0.4716514669996941, lambda_l1=3.3854750731510297, lambda_l2=9.289903599123722, learning_rate=0.2, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=272, objective=l, reg_lambda=1e-06, subsample=0.5, subsample_freq=2;, score=0.329 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.953093457207265, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.953093457207265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710073656292929, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9710073656292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.813565777299659, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.813565777299659\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5230986813332692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5230986813332692\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 1.4941\n",
      "[CV 2/2] END bagging_fraction=0.9710073656292929, bagging_freq=7, feature_fraction=0.5230986813332692, lambda_l1=8.953093457207265, lambda_l2=5.813565777299659, learning_rate=0.2, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=272, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.328 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.959921882820855, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.959921882820855\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5712773305919235, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5712773305919235\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8608541889140957, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.8608541889140957\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134784884224867, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134784884224867\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[648]\tvalid_0's multi_logloss: 1.49834\n",
      "[CV 2/2] END bagging_fraction=0.5712773305919235, bagging_freq=7, feature_fraction=0.9134784884224867, lambda_l1=5.959921882820855, lambda_l2=3.8608541889140957, learning_rate=0.01, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=233, objective=t, reg_lambda=1e-05, subsample=0.6, subsample_freq=64;, score=0.328 total time=  11.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.060360030709721, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.060360030709721\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7070774695050905, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7070774695050905\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9054311766134715, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.9054311766134715\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9500461339599316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9500461339599316\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.50035\n",
      "[CV 1/2] END bagging_fraction=0.7070774695050905, bagging_freq=4, feature_fraction=0.9500461339599316, lambda_l1=4.060360030709721, lambda_l2=1.9054311766134715, learning_rate=0.2, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=423, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.330 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.060360030709721, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.060360030709721\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7070774695050905, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7070774695050905\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9054311766134715, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.9054311766134715\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9500461339599316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9500461339599316\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.5001\n",
      "[CV 2/2] END bagging_fraction=0.7070774695050905, bagging_freq=4, feature_fraction=0.9500461339599316, lambda_l1=4.060360030709721, lambda_l2=1.9054311766134715, learning_rate=0.2, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=423, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.327 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6178142565540687, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6178142565540687\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8487261741979784, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8487261741979784\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.387130119473373, reg_lambda=0 will be ignored. Current value: lambda_l2=8.387130119473373\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5714628434105593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5714628434105593\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's multi_logloss: 1.50086\n",
      "[CV 1/2] END bagging_fraction=0.8487261741979784, bagging_freq=3, feature_fraction=0.5714628434105593, lambda_l1=2.6178142565540687, lambda_l2=8.387130119473373, learning_rate=0.05, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=260, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=1;, score=0.330 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6178142565540687, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6178142565540687\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8487261741979784, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8487261741979784\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.387130119473373, reg_lambda=0 will be ignored. Current value: lambda_l2=8.387130119473373\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5714628434105593, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5714628434105593\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's multi_logloss: 1.4946\n",
      "[CV 2/2] END bagging_fraction=0.8487261741979784, bagging_freq=3, feature_fraction=0.5714628434105593, lambda_l1=2.6178142565540687, lambda_l2=8.387130119473373, learning_rate=0.05, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=260, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=1;, score=0.328 total time=   6.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1569501293962046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1569501293962046\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40529038491372354, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.40529038491372354\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4629128901465123, reg_lambda=0 will be ignored. Current value: lambda_l2=3.4629128901465123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4403431196988268, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4403431196988268\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 1.51389\n",
      "[CV 1/2] END bagging_fraction=0.40529038491372354, bagging_freq=6, feature_fraction=0.4403431196988268, lambda_l1=3.1569501293962046, lambda_l2=3.4629128901465123, learning_rate=0.2, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=124, objective=t, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=32;, score=0.325 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1569501293962046, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1569501293962046\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40529038491372354, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.40529038491372354\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4629128901465123, reg_lambda=0 will be ignored. Current value: lambda_l2=3.4629128901465123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4403431196988268, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4403431196988268\n",
      "[CV 2/2] END bagging_fraction=0.5804278225488144, bagging_freq=2, feature_fraction=0.6961351894941873, lambda_l1=7.353268270947368, lambda_l2=8.326323281773156, learning_rate=0.01, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=188, objective=i, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.331 total time=  24.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.47294712434629155, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.47294712434629155\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6919438625223178, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6919438625223178\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8661855733168293, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.8661855733168293\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6153409471406311, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6153409471406311\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 1.51036\n",
      "[CV 1/2] END bagging_fraction=0.6919438625223178, bagging_freq=9, feature_fraction=0.6153409471406311, lambda_l1=0.47294712434629155, lambda_l2=3.8661855733168293, learning_rate=0.01, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=149, objective=i, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=256;, score=0.327 total time=   7.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.218146145134895, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.218146145134895\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49210905346980627, subsample=0.6 will be ignored. Current value: bagging_fraction=0.49210905346980627\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.575353706110461, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.575353706110461\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7784767682296345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7784767682296345\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_logloss: 1.49557\n",
      "[CV 2/2] END bagging_fraction=0.49210905346980627, bagging_freq=6, feature_fraction=0.7784767682296345, lambda_l1=6.218146145134895, lambda_l2=7.575353706110461, learning_rate=0.2, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=42, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.331 total time=   7.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.404147806848231, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.404147806848231\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5714856070468901, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5714856070468901\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.433178885787868, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.433178885787868\n",
      "[LightGBM] [Warning] feature_fraction is set=0.43390979527605644, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.43390979527605644\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid_0's multi_logloss: 1.49808\n",
      "[CV 2/2] END bagging_fraction=0.5714856070468901, bagging_freq=3, feature_fraction=0.43390979527605644, lambda_l1=0.404147806848231, lambda_l2=4.433178885787868, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=176, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.331 total time=  10.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6925755976163823, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6925755976163823\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9051178154063568, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9051178154063568\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.744941445179832, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.744941445179832\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6546045770080007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6546045770080007\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_logloss: 1.49928\n",
      "[CV 1/2] END bagging_fraction=0.9051178154063568, bagging_freq=8, feature_fraction=0.6546045770080007, lambda_l1=3.6925755976163823, lambda_l2=9.744941445179832, learning_rate=0.2, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=330, objective=a, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=8;, score=0.330 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6925755976163823, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6925755976163823\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9051178154063568, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9051178154063568\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.744941445179832, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.744941445179832\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6546045770080007, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6546045770080007\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 1.49473\n",
      "[CV 2/2] END bagging_fraction=0.9051178154063568, bagging_freq=8, feature_fraction=0.6546045770080007, lambda_l1=3.6925755976163823, lambda_l2=9.744941445179832, learning_rate=0.2, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=330, objective=a, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=8;, score=0.328 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7347300833506987, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7347300833506987\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5783318877105657, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5783318877105657\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2983566562812143, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.2983566562812143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6316587135489113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6316587135489113\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's multi_logloss: 1.49048\n",
      "[CV 2/2] END bagging_fraction=0.5783318877105657, bagging_freq=4, feature_fraction=0.6316587135489113, lambda_l1=1.7347300833506987, lambda_l2=2.2983566562812143, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=211, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.334 total time=  47.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.25384966942576, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.25384966942576\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835347411284246, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9835347411284246\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3230150460375825, reg_lambda=0 will be ignored. Current value: lambda_l2=2.3230150460375825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5893192359029327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5893192359029327\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7784767682296345, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7784767682296345\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's multi_logloss: 1.49628\n",
      "[CV 1/2] END bagging_fraction=0.49210905346980627, bagging_freq=6, feature_fraction=0.7784767682296345, lambda_l1=6.218146145134895, lambda_l2=7.575353706110461, learning_rate=0.2, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=42, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.332 total time=   9.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3854750731510297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3854750731510297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9397286711616458, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9397286711616458\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.289903599123722, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.289903599123722\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4716514669996941, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4716514669996941\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_logloss: 1.49912\n",
      "[CV 1/2] END bagging_fraction=0.9397286711616458, bagging_freq=4, feature_fraction=0.4716514669996941, lambda_l1=3.3854750731510297, lambda_l2=9.289903599123722, learning_rate=0.2, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=272, objective=l, reg_lambda=1e-06, subsample=0.5, subsample_freq=2;, score=0.329 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.953093457207265, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.953093457207265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710073656292929, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9710073656292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.813565777299659, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.813565777299659\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5230986813332692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5230986813332692\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's multi_logloss: 1.49872\n",
      "[CV 1/2] END bagging_fraction=0.9710073656292929, bagging_freq=7, feature_fraction=0.5230986813332692, lambda_l1=8.953093457207265, lambda_l2=5.813565777299659, learning_rate=0.2, metric=multi_logloss, min_child_samples=63, num_class=5, num_leaves=272, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.332 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.959921882820855, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.959921882820855\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5712773305919235, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5712773305919235\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8608541889140957, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.8608541889140957\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9134784884224867, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9134784884224867\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's multi_logloss: 1.51245\n",
      "[CV 1/2] END bagging_fraction=0.5712773305919235, bagging_freq=7, feature_fraction=0.9134784884224867, lambda_l1=5.959921882820855, lambda_l2=3.8608541889140957, learning_rate=0.01, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=233, objective=t, reg_lambda=1e-05, subsample=0.6, subsample_freq=64;, score=0.325 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7347300833506987, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7347300833506987\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5783318877105657, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5783318877105657\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2983566562812143, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.2983566562812143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6316587135489113, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6316587135489113\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's multi_logloss: 1.48684\n",
      "[CV 1/2] END bagging_fraction=0.5783318877105657, bagging_freq=4, feature_fraction=0.6316587135489113, lambda_l1=1.7347300833506987, lambda_l2=2.2983566562812143, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=211, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.331 total time=  49.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.390748156245209, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.390748156245209\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.41163552716973545, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.41163552716973545\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.3522645310464645, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.3522645310464645\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9182099801553599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9182099801553599\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=2 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[527]\tvalid_0's multi_logloss: 1.49892\n",
      "[CV 2/2] END bagging_fraction=0.41163552716973545, bagging_freq=8, feature_fraction=0.9182099801553599, lambda_l1=3.390748156245209, lambda_l2=6.3522645310464645, learning_rate=0.01, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=144, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.328 total time=   9.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8674600662276144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8674600662276144\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611222083561571, subsample=0.7 will be ignored. Current value: bagging_fraction=0.611222083561571\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.953185592575081, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.953185592575081\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9989643381968014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9989643381968014\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 1.51207\n",
      "[CV 1/2] END bagging_fraction=0.611222083561571, bagging_freq=3, feature_fraction=0.9989643381968014, lambda_l1=1.8674600662276144, lambda_l2=5.953185592575081, learning_rate=0.01, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=39, objective=l, reg_lambda=1e-05, subsample=0.7, subsample_freq=8;, score=0.322 total time=   7.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.656260683454107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.656260683454107\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9670534035721766, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9670534035721766\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's multi_logloss: 1.50104\n",
      "[CV 2/2] END bagging_fraction=0.40529038491372354, bagging_freq=6, feature_fraction=0.4403431196988268, lambda_l1=3.1569501293962046, lambda_l2=3.4629128901465123, learning_rate=0.2, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=124, objective=t, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=32;, score=0.326 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.914723894434316, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.914723894434316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6308294314713934, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6308294314713934\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.686858781796914, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.686858781796914\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5866358738103972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5866358738103972\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 1.50656\n",
      "[CV 1/2] END bagging_fraction=0.6308294314713934, bagging_freq=3, feature_fraction=0.5866358738103972, lambda_l1=5.914723894434316, lambda_l2=9.686858781796914, learning_rate=0.05, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=441, objective=i, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.326 total time=   5.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.914723894434316, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.914723894434316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6308294314713934, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6308294314713934\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.686858781796914, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.686858781796914\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5866358738103972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5866358738103972\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's multi_logloss: 1.49612\n",
      "[CV 2/2] END bagging_fraction=0.6308294314713934, bagging_freq=3, feature_fraction=0.5866358738103972, lambda_l1=5.914723894434316, lambda_l2=9.686858781796914, learning_rate=0.05, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=441, objective=i, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.329 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.390748156245209, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.390748156245209\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.41163552716973545, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.41163552716973545\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.3522645310464645, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.3522645310464645\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9182099801553599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9182099801553599\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=2 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's multi_logloss: 1.51238\n",
      "[CV 1/2] END bagging_fraction=0.41163552716973545, bagging_freq=8, feature_fraction=0.9182099801553599, lambda_l1=3.390748156245209, lambda_l2=6.3522645310464645, learning_rate=0.01, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=144, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.325 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.25384966942576, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.25384966942576\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835347411284246, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9835347411284246\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3230150460375825, reg_lambda=0 will be ignored. Current value: lambda_l2=2.3230150460375825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5893192359029327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5893192359029327\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49812\n",
      "[CV 2/2] END bagging_fraction=0.9835347411284246, bagging_freq=8, feature_fraction=0.5893192359029327, lambda_l1=4.25384966942576, lambda_l2=2.3230150460375825, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=429, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=32;, score=0.333 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.3076686088858755, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.3076686088858755\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6382877244666065, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6382877244666065\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.746108524340298, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.746108524340298\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6658258019644571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6658258019644571\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 1.50024\n",
      "[CV 2/2] END bagging_fraction=0.6382877244666065, bagging_freq=6, feature_fraction=0.6658258019644571, lambda_l1=7.3076686088858755, lambda_l2=7.746108524340298, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=301, objective=a, reg_lambda=0.0001, subsample=0.6, subsample_freq=32;, score=0.332 total time=   2.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.656260683454107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.656260683454107\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9670534035721766, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9670534035721766\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.846640311286842, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.846640311286842\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8754555341834711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8754555341834711\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's multi_logloss: 1.49609\n",
      "[CV 1/2] END bagging_fraction=0.9670534035721766, bagging_freq=8, feature_fraction=0.8754555341834711, lambda_l1=7.656260683454107, lambda_l2=7.846640311286842, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=342, objective=t, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=8;, score=0.333 total time=   8.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.889294210861199, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.889294210861199\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.443020416442128, subsample=0.6 will be ignored. Current value: bagging_fraction=0.443020416442128\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.621194898046306, reg_lambda=0 will be ignored. Current value: lambda_l2=5.621194898046306\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9617687603462276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9617687603462276\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.846640311286842, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.846640311286842\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8754555341834711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8754555341834711\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 1.49333\n",
      "[CV 2/2] END bagging_fraction=0.9670534035721766, bagging_freq=8, feature_fraction=0.8754555341834711, lambda_l1=7.656260683454107, lambda_l2=7.846640311286842, learning_rate=0.05, metric=multi_logloss, min_child_samples=31, num_class=5, num_leaves=342, objective=t, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=8;, score=0.332 total time=   9.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.80076028657905, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.80076028657905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5827636462881518, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5827636462881518\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7374642690182598, reg_lambda=0 will be ignored. Current value: lambda_l2=1.7374642690182598\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8182293363386584, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8182293363386584\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[736]\tvalid_0's multi_logloss: 1.50762\n",
      "[CV 1/2] END bagging_fraction=0.5827636462881518, bagging_freq=4, feature_fraction=0.8182293363386584, lambda_l1=8.80076028657905, lambda_l2=1.7374642690182598, learning_rate=0.01, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=131, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=4;, score=0.329 total time=  10.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.80076028657905, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.80076028657905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5827636462881518, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5827636462881518\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7374642690182598, reg_lambda=0 will be ignored. Current value: lambda_l2=1.7374642690182598\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8182293363386584, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8182293363386584\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=4 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[866]\tvalid_0's multi_logloss: 1.4991\n",
      "[CV 2/2] END bagging_fraction=0.5827636462881518, bagging_freq=4, feature_fraction=0.8182293363386584, lambda_l1=8.80076028657905, lambda_l2=1.7374642690182598, learning_rate=0.01, metric=multi_logloss, min_child_samples=62, num_class=5, num_leaves=131, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=4;, score=0.331 total time=  14.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.142323679483233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.142323679483233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8529654344146557, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8529654344146557\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.09317408330592164, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.09317408330592164\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6277727707211948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6277727707211948\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's multi_logloss: 1.49949\n",
      "[CV 1/2] END bagging_fraction=0.8529654344146557, bagging_freq=8, feature_fraction=0.6277727707211948, lambda_l1=8.142323679483233, lambda_l2=0.09317408330592164, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=503, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=64;, score=0.328 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.142323679483233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.142323679483233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8529654344146557, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8529654344146557\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.09317408330592164, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.09317408330592164\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6277727707211948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6277727707211948\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 1.49482\n",
      "[CV 2/2] END bagging_fraction=0.8529654344146557, bagging_freq=8, feature_fraction=0.6277727707211948, lambda_l1=8.142323679483233, lambda_l2=0.09317408330592164, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=503, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=64;, score=0.329 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7131635730769725, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7131635730769725\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8502544329802448, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8502544329802448\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.549646141843912, reg_lambda=0 will be ignored. Current value: lambda_l2=3.549646141843912\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9670469064099574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9670469064099574\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.49711\n",
      "[CV 1/2] END bagging_fraction=0.8502544329802448, bagging_freq=9, feature_fraction=0.9670469064099574, lambda_l1=1.7131635730769725, lambda_l2=3.549646141843912, learning_rate=0.05, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=220, objective=s, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=128;, score=0.328 total time=  10.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7131635730769725, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7131635730769725\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8502544329802448, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8502544329802448\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.549646141843912, reg_lambda=0 will be ignored. Current value: lambda_l2=3.549646141843912\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9670469064099574, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9670469064099574\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 1.49867\n",
      "[CV 2/2] END bagging_fraction=0.8502544329802448, bagging_freq=9, feature_fraction=0.9670469064099574, lambda_l1=1.7131635730769725, lambda_l2=3.549646141843912, learning_rate=0.05, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=220, objective=s, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=128;, score=0.326 total time=  10.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.992114712553356, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.992114712553356\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 1.49169\n",
      "[CV 1/2] END bagging_fraction=0.9835347411284246, bagging_freq=8, feature_fraction=0.5893192359029327, lambda_l1=4.25384966942576, lambda_l2=2.3230150460375825, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=429, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=32;, score=0.330 total time=   6.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.3076686088858755, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.3076686088858755\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6382877244666065, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6382877244666065\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.746108524340298, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.746108524340298\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6658258019644571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6658258019644571\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's multi_logloss: 1.51321\n",
      "[CV 1/2] END bagging_fraction=0.6382877244666065, bagging_freq=6, feature_fraction=0.6658258019644571, lambda_l1=7.3076686088858755, lambda_l2=7.746108524340298, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=301, objective=a, reg_lambda=0.0001, subsample=0.6, subsample_freq=32;, score=0.322 total time=   2.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8674600662276144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8674600662276144\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611222083561571, subsample=0.7 will be ignored. Current value: bagging_fraction=0.611222083561571\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.953185592575081, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.953185592575081\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9989643381968014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9989643381968014\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's multi_logloss: 1.50106\n",
      "[CV 2/2] END bagging_fraction=0.611222083561571, bagging_freq=3, feature_fraction=0.9989643381968014, lambda_l1=1.8674600662276144, lambda_l2=5.953185592575081, learning_rate=0.01, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=39, objective=l, reg_lambda=1e-05, subsample=0.7, subsample_freq=8;, score=0.330 total time=  10.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.889294210861199, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.889294210861199\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.443020416442128, subsample=0.6 will be ignored. Current value: bagging_fraction=0.443020416442128\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.621194898046306, reg_lambda=0 will be ignored. Current value: lambda_l2=5.621194898046306\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9617687603462276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9617687603462276\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 1.50478\n",
      "[CV 2/2] END bagging_fraction=0.443020416442128, bagging_freq=9, feature_fraction=0.9617687603462276, lambda_l1=6.889294210861199, lambda_l2=5.621194898046306, learning_rate=0.2, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=503, objective=a, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.324 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.207911967189589, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.207911967189589\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.728568978440391, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.728568978440391\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1139578680276627, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.1139578680276627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8618826990318246, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8618826990318246\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's multi_logloss: 1.49369\n",
      "[CV 2/2] END bagging_fraction=0.728568978440391, bagging_freq=2, feature_fraction=0.8618826990318246, lambda_l1=4.207911967189589, lambda_l2=3.1139578680276627, learning_rate=0.01, metric=multi_logloss, min_child_samples=32, num_class=5, num_leaves=355, objective=t, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=1;, score=0.329 total time=  19.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7278787685920144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7278787685920144\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49209874685062127, subsample=0.6 will be ignored. Current value: bagging_fraction=0.49209874685062127\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.973972292969287, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.973972292969287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.421658396489069, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.421658396489069\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's multi_logloss: 1.4855\n",
      "[CV 1/2] END bagging_fraction=0.49209874685062127, bagging_freq=6, feature_fraction=0.421658396489069, lambda_l1=0.7278787685920144, lambda_l2=7.973972292969287, learning_rate=0.01, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=95, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=64;, score=0.331 total time=  48.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.545010555204443, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.545010555204443\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.556845045420356, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.556845045420356\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9933573541128707, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.9933573541128707\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8708469678991018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8708469678991018\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's multi_logloss: 1.49455\n",
      "[CV 2/2] END bagging_fraction=0.556845045420356, bagging_freq=4, feature_fraction=0.8708469678991018, lambda_l1=0.545010555204443, lambda_l2=0.9933573541128707, learning_rate=0.2, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=18, objective=c, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.328 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.215275163311922, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.215275163311922\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.502477681896813, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.502477681896813\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3109331146122405, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.3109331146122405\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9233260818937236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9233260818937236\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.50993\n",
      "[CV 1/2] END bagging_fraction=0.443020416442128, bagging_freq=9, feature_fraction=0.9617687603462276, lambda_l1=6.889294210861199, lambda_l2=5.621194898046306, learning_rate=0.2, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=503, objective=a, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.323 total time=   2.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.207911967189589, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.207911967189589\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.728568978440391, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.728568978440391\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1139578680276627, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.1139578680276627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8618826990318246, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8618826990318246\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[558]\tvalid_0's multi_logloss: 1.49378\n",
      "[CV 1/2] END bagging_fraction=0.728568978440391, bagging_freq=2, feature_fraction=0.8618826990318246, lambda_l1=4.207911967189589, lambda_l2=3.1139578680276627, learning_rate=0.01, metric=multi_logloss, min_child_samples=32, num_class=5, num_leaves=355, objective=t, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=1;, score=0.333 total time=  24.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7278787685920144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7278787685920144\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.49209874685062127, subsample=0.6 will be ignored. Current value: bagging_fraction=0.49209874685062127\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.973972292969287, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.973972292969287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.421658396489069, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.421658396489069\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\tvalid_0's multi_logloss: 1.48843\n",
      "[CV 2/2] END bagging_fraction=0.49209874685062127, bagging_freq=6, feature_fraction=0.421658396489069, lambda_l1=0.7278787685920144, lambda_l2=7.973972292969287, learning_rate=0.01, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=95, objective=i, reg_lambda=1e-05, subsample=0.6, subsample_freq=64;, score=0.331 total time=  40.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.992114712553356, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.992114712553356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7150101592003628, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7150101592003628\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.954145397797753, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.954145397797753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5799993565758744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5799993565758744\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's multi_logloss: 1.4953\n",
      "[CV 2/2] END bagging_fraction=0.7150101592003628, bagging_freq=6, feature_fraction=0.5799993565758744, lambda_l1=8.992114712553356, lambda_l2=6.954145397797753, learning_rate=0.05, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=103, objective=t, reg_lambda=1e-05, subsample=0.7, subsample_freq=256;, score=0.330 total time=   6.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7385626927078177, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7385626927078177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7847970140765708, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7847970140765708\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27663083972712804, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.27663083972712804\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4641895063902299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4641895063902299\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[491]\tvalid_0's multi_logloss: 1.49265\n",
      "[CV 1/2] END bagging_fraction=0.7847970140765708, bagging_freq=7, feature_fraction=0.4641895063902299, lambda_l1=3.7385626927078177, lambda_l2=0.27663083972712804, learning_rate=0.01, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=44, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=16;, score=0.335 total time=  15.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.471862176455803, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.471862176455803\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8151951586641744, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8151951586641744\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30959834858147267, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.30959834858147267\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9403948514388056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9403948514388056\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's multi_logloss: 1.50506\n",
      "[CV 1/2] END bagging_fraction=0.8151951586641744, bagging_freq=9, feature_fraction=0.9403948514388056, lambda_l1=8.471862176455803, lambda_l2=0.30959834858147267, learning_rate=0.01, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=87, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=1;, score=0.330 total time=   9.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7603206854396375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7603206854396375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8106767950166986, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8106767950166986\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.815723342487039, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.815723342487039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5237456804225809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5237456804225809\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 1.49849\n",
      "[CV 2/2] END bagging_fraction=0.8106767950166986, bagging_freq=2, feature_fraction=0.5237456804225809, lambda_l1=0.7603206854396375, lambda_l2=3.815723342487039, learning_rate=0.05, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=389, objective=u, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.328 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.230817731407928, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.230817731407928\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7756901160290486, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7756901160290486\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9930081814563603, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.9930081814563603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7150101592003628, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7150101592003628\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.954145397797753, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.954145397797753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5799993565758744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5799993565758744\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's multi_logloss: 1.49852\n",
      "[CV 1/2] END bagging_fraction=0.7150101592003628, bagging_freq=6, feature_fraction=0.5799993565758744, lambda_l1=8.992114712553356, lambda_l2=6.954145397797753, learning_rate=0.05, metric=multi_logloss, min_child_samples=50, num_class=5, num_leaves=103, objective=t, reg_lambda=1e-05, subsample=0.7, subsample_freq=256;, score=0.331 total time=  10.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.545010555204443, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.545010555204443\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.556845045420356, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.556845045420356\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9933573541128707, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.9933573541128707\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8708469678991018, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8708469678991018\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.49635\n",
      "[CV 1/2] END bagging_fraction=0.556845045420356, bagging_freq=4, feature_fraction=0.8708469678991018, lambda_l1=0.545010555204443, lambda_l2=0.9933573541128707, learning_rate=0.2, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=18, objective=c, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.330 total time=   2.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7385626927078177, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7385626927078177\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7847970140765708, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7847970140765708\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27663083972712804, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.27663083972712804\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4641895063902299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4641895063902299\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid_0's multi_logloss: 1.49067\n",
      "[CV 2/2] END bagging_fraction=0.7847970140765708, bagging_freq=7, feature_fraction=0.4641895063902299, lambda_l1=3.7385626927078177, lambda_l2=0.27663083972712804, learning_rate=0.01, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=44, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=16;, score=0.333 total time=  15.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.471862176455803, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.471862176455803\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8151951586641744, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8151951586641744\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30959834858147267, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.30959834858147267\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9403948514388056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9403948514388056\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[621]\tvalid_0's multi_logloss: 1.49771\n",
      "[CV 2/2] END bagging_fraction=0.8151951586641744, bagging_freq=9, feature_fraction=0.9403948514388056, lambda_l1=8.471862176455803, lambda_l2=0.30959834858147267, learning_rate=0.01, metric=multi_logloss, min_child_samples=85, num_class=5, num_leaves=87, objective=s, reg_lambda=1e-05, subsample=0.5, subsample_freq=1;, score=0.330 total time=  11.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.643234860180693, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.643234860180693\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917881882358968, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9917881882358968\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.023689748028148, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.023689748028148\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9523577073337051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9523577073337051\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 1.49882\n",
      "[CV 2/2] END bagging_fraction=0.9917881882358968, bagging_freq=4, feature_fraction=0.9523577073337051, lambda_l1=6.643234860180693, lambda_l2=4.023689748028148, learning_rate=0.2, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=490, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=64;, score=0.330 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.114341973527315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.114341973527315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8286306920066621, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8286306920066621\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.147861308998085, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.147861308998085\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5757629128334326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5757629128334326\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[931]\tvalid_0's multi_logloss: 1.49539\n",
      "[CV 2/2] END bagging_fraction=0.8286306920066621, bagging_freq=7, feature_fraction=0.5757629128334326, lambda_l1=6.114341973527315, lambda_l2=8.147861308998085, learning_rate=0.01, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=204, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.330 total time=  18.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1021671832151014, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1021671832151014\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9973112473189107, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9973112473189107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0895315270426858, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.0895315270426858\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8405368817955569, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8405368817955569\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's multi_logloss: 1.48929\n",
      "[CV 1/2] END bagging_fraction=0.9973112473189107, bagging_freq=5, feature_fraction=0.8405368817955569, lambda_l1=3.1021671832151014, lambda_l2=0.0895315270426858, learning_rate=0.01, metric=multi_logloss, min_child_samples=13, num_class=5, num_leaves=24, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=16;, score=0.342 total time=  22.2s\n",
      "Early stopping, best iteration is:\n",
      "[852]\tvalid_0's multi_logloss: 1.50362\n",
      "[CV 1/2] END bagging_fraction=0.502477681896813, bagging_freq=3, feature_fraction=0.9233260818937236, lambda_l1=8.215275163311922, lambda_l2=2.3109331146122405, learning_rate=0.01, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=14, objective=m, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.331 total time=  10.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.215275163311922, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.215275163311922\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.502477681896813, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.502477681896813\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3109331146122405, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.3109331146122405\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9233260818937236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9233260818937236\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[702]\tvalid_0's multi_logloss: 1.49925\n",
      "[CV 2/2] END bagging_fraction=0.502477681896813, bagging_freq=3, feature_fraction=0.9233260818937236, lambda_l1=8.215275163311922, lambda_l2=2.3109331146122405, learning_rate=0.01, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=14, objective=m, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.332 total time=   9.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7603206854396375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7603206854396375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8106767950166986, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8106767950166986\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.815723342487039, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.815723342487039\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5237456804225809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5237456804225809\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_logloss: 1.50047\n",
      "[CV 1/2] END bagging_fraction=0.8106767950166986, bagging_freq=2, feature_fraction=0.5237456804225809, lambda_l1=0.7603206854396375, lambda_l2=3.815723342487039, learning_rate=0.05, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=389, objective=u, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=8;, score=0.329 total time=   5.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.643234860180693, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.643234860180693\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917881882358968, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9917881882358968\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.023689748028148, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.023689748028148\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9523577073337051, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9523577073337051\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.50191\n",
      "[CV 1/2] END bagging_fraction=0.9917881882358968, bagging_freq=4, feature_fraction=0.9523577073337051, lambda_l1=6.643234860180693, lambda_l2=4.023689748028148, learning_rate=0.2, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=490, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=64;, score=0.329 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.114341973527315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.114341973527315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8286306920066621, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8286306920066621\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.147861308998085, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.147861308998085\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5757629128334326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5757629128334326\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[917]\tvalid_0's multi_logloss: 1.50307\n",
      "[CV 1/2] END bagging_fraction=0.8286306920066621, bagging_freq=7, feature_fraction=0.5757629128334326, lambda_l1=6.114341973527315, lambda_l2=8.147861308998085, learning_rate=0.01, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=204, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=16;, score=0.329 total time=  15.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.266716832330218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.266716832330218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6132013091602915, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6132013091602915\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.275019500846962, reg_lambda=0 will be ignored. Current value: lambda_l2=9.275019500846962\n",
      "[LightGBM] [Warning] feature_fraction is set=0.496959433557394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.496959433557394\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.49168\n",
      "[CV 2/2] END bagging_fraction=0.6132013091602915, bagging_freq=5, feature_fraction=0.496959433557394, lambda_l1=7.266716832330218, lambda_l2=9.275019500846962, learning_rate=0.2, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=331, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=8;, score=0.328 total time=  15.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1021671832151014, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1021671832151014\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9973112473189107, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9973112473189107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0895315270426858, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.0895315270426858\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8405368817955569, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8405368817955569\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[554]\tvalid_0's multi_logloss: 1.49065\n",
      "[CV 2/2] END bagging_fraction=0.9973112473189107, bagging_freq=5, feature_fraction=0.8405368817955569, lambda_l1=3.1021671832151014, lambda_l2=0.0895315270426858, learning_rate=0.01, metric=multi_logloss, min_child_samples=13, num_class=5, num_leaves=24, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=16;, score=0.339 total time=  19.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4985093185476783, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4985093185476783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5118395725461128, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5118395725461128\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3783831438331386, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.3783831438331386\n",
      "[LightGBM] [Warning] feature_fraction is set=0.402196807464377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.402196807464377\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9497390179894881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9497390179894881\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's multi_logloss: 1.4984\n",
      "[CV 1/2] END bagging_fraction=0.7756901160290486, bagging_freq=5, feature_fraction=0.9497390179894881, lambda_l1=8.230817731407928, lambda_l2=3.9930081814563603, learning_rate=0.05, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=121, objective=u, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=1;, score=0.330 total time=   7.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.230817731407928, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.230817731407928\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7756901160290486, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7756901160290486\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9930081814563603, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.9930081814563603\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9497390179894881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9497390179894881\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's multi_logloss: 1.49591\n",
      "[CV 2/2] END bagging_fraction=0.7756901160290486, bagging_freq=5, feature_fraction=0.9497390179894881, lambda_l1=8.230817731407928, lambda_l2=3.9930081814563603, learning_rate=0.05, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=121, objective=u, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=1;, score=0.331 total time=   6.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.266716832330218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.266716832330218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6132013091602915, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6132013091602915\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.275019500846962, reg_lambda=0 will be ignored. Current value: lambda_l2=9.275019500846962\n",
      "[LightGBM] [Warning] feature_fraction is set=0.496959433557394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.496959433557394\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 1.49701\n",
      "[CV 1/2] END bagging_fraction=0.6132013091602915, bagging_freq=5, feature_fraction=0.496959433557394, lambda_l1=7.266716832330218, lambda_l2=9.275019500846962, learning_rate=0.2, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=331, objective=l, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=8;, score=0.324 total time=  16.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7471004041462859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7471004041462859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7169939417784528, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7169939417784528\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.810506906104665, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.810506906104665\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5423391000878287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5423391000878287\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[436]\tvalid_0's multi_logloss: 1.50566\n",
      "[CV 1/2] END bagging_fraction=0.7169939417784528, bagging_freq=6, feature_fraction=0.5423391000878287, lambda_l1=1.7471004041462859, lambda_l2=7.810506906104665, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=394, objective=l, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=32;, score=0.327 total time=  11.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4985093185476783, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4985093185476783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5118395725461128, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5118395725461128\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3783831438331386, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.3783831438331386\n",
      "[LightGBM] [Warning] feature_fraction is set=0.402196807464377, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.402196807464377\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=128 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[505]\tvalid_0's multi_logloss: 1.49045\n",
      "[CV 1/2] END bagging_fraction=0.5118395725461128, bagging_freq=5, feature_fraction=0.402196807464377, lambda_l1=2.4985093185476783, lambda_l2=1.3783831438331386, learning_rate=0.01, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=333, objective=s, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.334 total time=  20.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7400391813252675, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7400391813252675\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9763846566884109, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9763846566884109\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.48532118021959, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.48532118021959\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7531226802723541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7531226802723541\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=16 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.49687\n",
      "[CV 2/2] END bagging_fraction=0.9763846566884109, bagging_freq=2, feature_fraction=0.7531226802723541, lambda_l1=0.7400391813252675, lambda_l2=6.48532118021959, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=369, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.334 total time=  35.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.624200580863009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.624200580863009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672441753575574, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9672441753575574\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0747843250141955, reg_lambda=0 will be ignored. Current value: lambda_l2=1.0747843250141955\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47621153634041746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47621153634041746\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[699]\tvalid_0's multi_logloss: 1.49627\n",
      "[CV 1/2] END bagging_fraction=0.9672441753575574, bagging_freq=3, feature_fraction=0.47621153634041746, lambda_l1=5.624200580863009, lambda_l2=1.0747843250141955, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=415, objective=a, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=8;, score=0.334 total time=  23.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.037357549342799, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.037357549342799\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8340124521294416, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8340124521294416\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=128 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's multi_logloss: 1.4916\n",
      "[CV 2/2] END bagging_fraction=0.5118395725461128, bagging_freq=5, feature_fraction=0.402196807464377, lambda_l1=2.4985093185476783, lambda_l2=1.3783831438331386, learning_rate=0.01, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=333, objective=s, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.329 total time=  19.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.860141213267894, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.860141213267894\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7448726936593998, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7448726936593998\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.995725298467539, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.995725298467539\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8954763416898002, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8954763416898002\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 1.49474\n",
      "[CV 1/2] END bagging_fraction=0.7448726936593998, bagging_freq=3, feature_fraction=0.8954763416898002, lambda_l1=7.860141213267894, lambda_l2=7.995725298467539, learning_rate=0.05, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=275, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=1;, score=0.330 total time=  15.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.860141213267894, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.860141213267894\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7448726936593998, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7448726936593998\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.995725298467539, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.995725298467539\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8954763416898002, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8954763416898002\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 1.49314\n",
      "[CV 2/2] END bagging_fraction=0.7448726936593998, bagging_freq=3, feature_fraction=0.8954763416898002, lambda_l1=7.860141213267894, lambda_l2=7.995725298467539, learning_rate=0.05, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=275, objective=s, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=1;, score=0.331 total time=  12.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0229770708648966, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0229770708648966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8625966426607071, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8625966426607071\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.740106760696687, reg_lambda=0 will be ignored. Current value: lambda_l2=9.740106760696687\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5769102785849035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5769102785849035\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 1.49401\n",
      "[CV 2/2] END bagging_fraction=0.8625966426607071, bagging_freq=6, feature_fraction=0.5769102785849035, lambda_l1=2.0229770708648966, lambda_l2=9.740106760696687, learning_rate=0.05, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=456, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=1;, score=0.330 total time=  16.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.408564356293031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.408564356293031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.926082618811823, subsample=0.7 will be ignored. Current value: bagging_fraction=0.926082618811823\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.508851448401565, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.508851448401565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.916615281770603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.916615281770603\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.50309\n",
      "[CV 1/2] END bagging_fraction=0.926082618811823, bagging_freq=5, feature_fraction=0.916615281770603, lambda_l1=2.408564356293031, lambda_l2=8.508851448401565, learning_rate=0.05, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=272, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=1;, score=0.329 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.408564356293031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.408564356293031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.926082618811823, subsample=0.7 will be ignored. Current value: bagging_fraction=0.926082618811823\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.508851448401565, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.508851448401565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.916615281770603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.916615281770603\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 1.50249\n",
      "[CV 2/2] END bagging_fraction=0.926082618811823, bagging_freq=5, feature_fraction=0.916615281770603, lambda_l1=2.408564356293031, lambda_l2=8.508851448401565, learning_rate=0.05, metric=multi_logloss, min_child_samples=92, num_class=5, num_leaves=272, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=1;, score=0.332 total time=   4.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.037357549342799, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.037357549342799\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8340124521294416, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8340124521294416\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.06583844992890026, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.06583844992890026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.697060576011163, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.697060576011163\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's multi_logloss: 1.4965\n",
      "[CV 2/2] END bagging_fraction=0.8340124521294416, bagging_freq=8, feature_fraction=0.697060576011163, lambda_l1=9.037357549342799, lambda_l2=0.06583844992890026, learning_rate=0.05, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=163, objective=u, reg_lambda=0.001, subsample=0.7, subsample_freq=32;, score=0.331 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.400178108298259, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.400178108298259\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5188323605500929, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5188323605500929\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.0726114574751975, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.0726114574751975\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7471004041462859, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7471004041462859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7169939417784528, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7169939417784528\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.810506906104665, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.810506906104665\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5423391000878287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5423391000878287\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's multi_logloss: 1.49757\n",
      "[CV 2/2] END bagging_fraction=0.7169939417784528, bagging_freq=6, feature_fraction=0.5423391000878287, lambda_l1=1.7471004041462859, lambda_l2=7.810506906104665, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=394, objective=l, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=32;, score=0.331 total time=  13.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7400391813252675, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7400391813252675\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9763846566884109, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9763846566884109\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.48532118021959, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.48532118021959\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7531226802723541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7531226802723541\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=16 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.49347\n",
      "[CV 1/2] END bagging_fraction=0.9763846566884109, bagging_freq=2, feature_fraction=0.7531226802723541, lambda_l1=0.7400391813252675, lambda_l2=6.48532118021959, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=369, objective=s, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.330 total time=  37.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0229770708648966, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0229770708648966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8625966426607071, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8625966426607071\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.740106760696687, reg_lambda=0 will be ignored. Current value: lambda_l2=9.740106760696687\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5769102785849035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5769102785849035\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 1.48987\n",
      "[CV 1/2] END bagging_fraction=0.8625966426607071, bagging_freq=6, feature_fraction=0.5769102785849035, lambda_l1=2.0229770708648966, lambda_l2=9.740106760696687, learning_rate=0.05, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=456, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=1;, score=0.330 total time=  20.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.624200580863009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.624200580863009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9672441753575574, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9672441753575574\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0747843250141955, reg_lambda=0 will be ignored. Current value: lambda_l2=1.0747843250141955\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47621153634041746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47621153634041746\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's multi_logloss: 1.49409\n",
      "[CV 2/2] END bagging_fraction=0.9672441753575574, bagging_freq=3, feature_fraction=0.47621153634041746, lambda_l1=5.624200580863009, lambda_l2=1.0747843250141955, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=415, objective=a, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=8;, score=0.332 total time=  17.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1523663837330886, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1523663837330886\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5309625295689093, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5309625295689093\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.95100891352875, reg_lambda=0 will be ignored. Current value: lambda_l2=6.95100891352875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6713847118084667, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6713847118084667\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 1.49644\n",
      "[CV 2/2] END bagging_fraction=0.5309625295689093, bagging_freq=2, feature_fraction=0.6713847118084667, lambda_l1=3.1523663837330886, lambda_l2=6.95100891352875, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=493, objective=i, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=32;, score=0.327 total time=   6.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7010194519526339, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7010194519526339\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7144129827946357, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7144129827946357\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.420882519076054, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.420882519076054\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894061343714702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894061343714702\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.49928\n",
      "[CV 1/2] END bagging_fraction=0.7144129827946357, bagging_freq=6, feature_fraction=0.9894061343714702, lambda_l1=0.7010194519526339, lambda_l2=9.420882519076054, learning_rate=0.2, metric=multi_logloss, min_child_samples=27, num_class=5, num_leaves=458, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=1;, score=0.333 total time=   8.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7010194519526339, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7010194519526339\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7144129827946357, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7144129827946357\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.420882519076054, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.420882519076054\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894061343714702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894061343714702\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's multi_logloss: 1.50142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4670225212969193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4670225212969193\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_logloss: 1.50319\n",
      "[CV 2/2] END bagging_fraction=0.5188323605500929, bagging_freq=7, feature_fraction=0.4670225212969193, lambda_l1=4.400178108298259, lambda_l2=4.0726114574751975, learning_rate=0.2, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=401, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=16;, score=0.326 total time=   2.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.2415269700093434, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2415269700093434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5526961567206388, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5526961567206388\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4105956002311792, reg_lambda=0 will be ignored. Current value: lambda_l2=2.4105956002311792\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001387577868109, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001387577868109\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 1.4923\n",
      "[CV 1/2] END bagging_fraction=0.5526961567206388, bagging_freq=8, feature_fraction=0.6001387577868109, lambda_l1=3.2415269700093434, lambda_l2=2.4105956002311792, learning_rate=0.05, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=82, objective=t, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=8;, score=0.333 total time=  14.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.43164320576070697, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.43164320576070697\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7436222962989703, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7436222962989703\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.364538355035228, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.364538355035228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.40270721534845705, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.40270721534845705\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid_0's multi_logloss: 1.49865\n",
      "[CV 1/2] END bagging_fraction=0.7436222962989703, bagging_freq=5, feature_fraction=0.40270721534845705, lambda_l1=0.43164320576070697, lambda_l2=4.364538355035228, learning_rate=0.01, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=269, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=4;, score=0.332 total time=  12.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.11136780793055, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.11136780793055\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611101136659728, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8611101136659728\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.044369283542933, reg_lambda=0 will be ignored. Current value: lambda_l2=3.044369283542933\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7911436349831982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7911436349831982\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_logloss: 1.49893\n",
      "[CV 1/2] END bagging_fraction=0.8611101136659728, bagging_freq=4, feature_fraction=0.7911436349831982, lambda_l1=6.11136780793055, lambda_l2=3.044369283542933, learning_rate=0.2, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=94, objective=u, reg_lambda=0, subsample=0.6, subsample_freq=128;, score=0.331 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.11136780793055, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.11136780793055\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8611101136659728, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8611101136659728\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.044369283542933, reg_lambda=0 will be ignored. Current value: lambda_l2=3.044369283542933\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7911436349831982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7911436349831982\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.49206\n",
      "[CV 2/2] END bagging_fraction=0.8611101136659728, bagging_freq=4, feature_fraction=0.7911436349831982, lambda_l1=6.11136780793055, lambda_l2=3.044369283542933, learning_rate=0.2, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=94, objective=u, reg_lambda=0, subsample=0.6, subsample_freq=128;, score=0.330 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.449734272720438, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.449734272720438\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7012063668600381, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7012063668600381\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.692115247539963, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.692115247539963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9810115657764857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9810115657764857\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[846]\tvalid_0's multi_logloss: 1.49829\n",
      "[CV 1/2] END bagging_fraction=0.7012063668600381, bagging_freq=2, feature_fraction=0.9810115657764857, lambda_l1=8.449734272720438, lambda_l2=5.692115247539963, learning_rate=0.01, metric=multi_logloss, min_child_samples=41, num_class=5, num_leaves=259, objective=m, reg_lambda=0.001, subsample=0.5, subsample_freq=1;, score=0.332 total time=  21.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.346920369888373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.346920369888373\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7372536928038879, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7372536928038879\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.58299547597748, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.58299547597748\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5095152885545446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5095152885545446\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid_0's multi_logloss: 1.495\n",
      "[CV 2/2] END bagging_fraction=0.7372536928038879, bagging_freq=8, feature_fraction=0.5095152885545446, lambda_l1=8.346920369888373, lambda_l2=9.58299547597748, learning_rate=0.05, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=244, objective=l, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=4;, score=0.329 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.989725480852808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.989725480852808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46525884468656636, subsample=0.7 will be ignored. Current value: bagging_fraction=0.46525884468656636\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7198985407751235, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.7198985407751235\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.06583844992890026, reg_lambda=0.001 will be ignored. Current value: lambda_l2=0.06583844992890026\n",
      "[LightGBM] [Warning] feature_fraction is set=0.697060576011163, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.697060576011163\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's multi_logloss: 1.50244\n",
      "[CV 1/2] END bagging_fraction=0.8340124521294416, bagging_freq=8, feature_fraction=0.697060576011163, lambda_l1=9.037357549342799, lambda_l2=0.06583844992890026, learning_rate=0.05, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=163, objective=u, reg_lambda=0.001, subsample=0.7, subsample_freq=32;, score=0.329 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.400178108298259, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.400178108298259\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5188323605500929, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5188323605500929\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.0726114574751975, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.0726114574751975\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4670225212969193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4670225212969193\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 1.51199\n",
      "[CV 1/2] END bagging_fraction=0.5188323605500929, bagging_freq=7, feature_fraction=0.4670225212969193, lambda_l1=4.400178108298259, lambda_l2=4.0726114574751975, learning_rate=0.2, metric=multi_logloss, min_child_samples=69, num_class=5, num_leaves=401, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=16;, score=0.324 total time=   2.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1523663837330886, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1523663837330886\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5309625295689093, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5309625295689093\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.95100891352875, reg_lambda=0 will be ignored. Current value: lambda_l2=6.95100891352875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6713847118084667, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6713847118084667\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 1.49388\n",
      "[CV 1/2] END bagging_fraction=0.5309625295689093, bagging_freq=2, feature_fraction=0.6713847118084667, lambda_l1=3.1523663837330886, lambda_l2=6.95100891352875, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=493, objective=i, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=32;, score=0.327 total time=   6.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.2415269700093434, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2415269700093434\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5526961567206388, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5526961567206388\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4105956002311792, reg_lambda=0 will be ignored. Current value: lambda_l2=2.4105956002311792\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001387577868109, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001387577868109\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 1.49386\n",
      "[CV 2/2] END bagging_fraction=0.5526961567206388, bagging_freq=8, feature_fraction=0.6001387577868109, lambda_l1=3.2415269700093434, lambda_l2=2.4105956002311792, learning_rate=0.05, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=82, objective=t, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=8;, score=0.333 total time=  12.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.43164320576070697, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.43164320576070697\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7436222962989703, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7436222962989703\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.364538355035228, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.364538355035228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.40270721534845705, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.40270721534845705\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's multi_logloss: 1.49708\n",
      "[CV 2/2] END bagging_fraction=0.7436222962989703, bagging_freq=5, feature_fraction=0.40270721534845705, lambda_l1=0.43164320576070697, lambda_l2=4.364538355035228, learning_rate=0.01, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=269, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=4;, score=0.326 total time=  13.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2128211210525188, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2128211210525188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8530311893320517, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8530311893320517\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.150265022447071, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.150265022447071\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7776378232562731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7776378232562731\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's multi_logloss: 1.49293\n",
      "[CV 1/2] END bagging_fraction=0.8530311893320517, bagging_freq=4, feature_fraction=0.7776378232562731, lambda_l1=1.2128211210525188, lambda_l2=2.150265022447071, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=384, objective=a, reg_lambda=0.0001, subsample=0.6, subsample_freq=128;, score=0.332 total time=  16.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.449734272720438, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.449734272720438\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7012063668600381, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7012063668600381\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.692115247539963, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.692115247539963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9810115657764857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9810115657764857\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[732]\tvalid_0's multi_logloss: 1.49534\n",
      "[CV 2/2] END bagging_fraction=0.7012063668600381, bagging_freq=2, feature_fraction=0.9810115657764857, lambda_l1=8.449734272720438, lambda_l2=5.692115247539963, learning_rate=0.01, metric=multi_logloss, min_child_samples=41, num_class=5, num_leaves=259, objective=m, reg_lambda=0.001, subsample=0.5, subsample_freq=1;, score=0.332 total time=  20.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8930959146222553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8930959146222553\n",
      "[CV 2/2] END bagging_fraction=0.7144129827946357, bagging_freq=6, feature_fraction=0.9894061343714702, lambda_l1=0.7010194519526339, lambda_l2=9.420882519076054, learning_rate=0.2, metric=multi_logloss, min_child_samples=27, num_class=5, num_leaves=458, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=1;, score=0.325 total time=   8.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.260831762357681, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.260831762357681\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5575704622248734, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5575704622248734\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.901996150475465, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.901996150475465\n",
      "[LightGBM] [Warning] feature_fraction is set=0.810470456307306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.810470456307306\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 1.50616\n",
      "[CV 1/2] END bagging_fraction=0.5575704622248734, bagging_freq=9, feature_fraction=0.810470456307306, lambda_l1=6.260831762357681, lambda_l2=7.901996150475465, learning_rate=0.05, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=236, objective=u, reg_lambda=1e-07, subsample=0.6, subsample_freq=4;, score=0.330 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.260831762357681, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.260831762357681\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5575704622248734, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5575704622248734\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.901996150475465, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.901996150475465\n",
      "[LightGBM] [Warning] feature_fraction is set=0.810470456307306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.810470456307306\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's multi_logloss: 1.49932\n",
      "[CV 2/2] END bagging_fraction=0.5575704622248734, bagging_freq=9, feature_fraction=0.810470456307306, lambda_l1=6.260831762357681, lambda_l2=7.901996150475465, learning_rate=0.05, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=236, objective=u, reg_lambda=1e-07, subsample=0.6, subsample_freq=4;, score=0.329 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2128211210525188, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2128211210525188\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8530311893320517, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8530311893320517\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.150265022447071, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.150265022447071\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7776378232562731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7776378232562731\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's multi_logloss: 1.49571\n",
      "[CV 2/2] END bagging_fraction=0.8530311893320517, bagging_freq=4, feature_fraction=0.7776378232562731, lambda_l1=1.2128211210525188, lambda_l2=2.150265022447071, learning_rate=0.01, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=384, objective=a, reg_lambda=0.0001, subsample=0.6, subsample_freq=128;, score=0.328 total time=  15.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.346920369888373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.346920369888373\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7372536928038879, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7372536928038879\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.58299547597748, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.58299547597748\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5095152885545446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5095152885545446\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's multi_logloss: 1.49787\n",
      "[CV 1/2] END bagging_fraction=0.7372536928038879, bagging_freq=8, feature_fraction=0.5095152885545446, lambda_l1=8.346920369888373, lambda_l2=9.58299547597748, learning_rate=0.05, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=244, objective=l, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=4;, score=0.328 total time=   9.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.989725480852808, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.989725480852808\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46525884468656636, subsample=0.7 will be ignored. Current value: bagging_fraction=0.46525884468656636\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7198985407751235, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.7198985407751235\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8925540773665812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8925540773665812\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[776]\tvalid_0's multi_logloss: 1.50556\n",
      "[CV 1/2] END bagging_fraction=0.46525884468656636, bagging_freq=4, feature_fraction=0.8925540773665812, lambda_l1=9.989725480852808, lambda_l2=1.7198985407751235, learning_rate=0.01, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=440, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=128;, score=0.328 total time=  13.1s\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5274958141538697, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5274958141538697\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.198315321137893, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.198315321137893\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4263112247469417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4263112247469417\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 1.51201\n",
      "[CV 1/2] END bagging_fraction=0.5274958141538697, bagging_freq=6, feature_fraction=0.4263112247469417, lambda_l1=0.8930959146222553, lambda_l2=1.198315321137893, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=327, objective=i, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=16;, score=0.318 total time=  18.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3198366278926879, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3198366278926879\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4133661313000456, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.4133661313000456\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.022995497765665, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.022995497765665\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7296572116333497, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7296572116333497\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.52551\n",
      "[CV 1/2] END bagging_fraction=0.4133661313000456, bagging_freq=6, feature_fraction=0.7296572116333497, lambda_l1=1.3198366278926879, lambda_l2=3.022995497765665, learning_rate=0.2, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=15, objective=m, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.323 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7605874287568835, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7605874287568835\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.437100652162578, subsample=0.6 will be ignored. Current value: bagging_fraction=0.437100652162578\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.531039971007747, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.531039971007747\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8319823429667066, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8319823429667066\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[606]\tvalid_0's multi_logloss: 1.51431\n",
      "[CV 1/2] END bagging_fraction=0.437100652162578, bagging_freq=6, feature_fraction=0.8319823429667066, lambda_l1=3.7605874287568835, lambda_l2=2.531039971007747, learning_rate=0.01, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=160, objective=t, reg_lambda=1e-05, subsample=0.6, subsample_freq=4;, score=0.324 total time=   8.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2780041059907923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2780041059907923\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8002267188946578, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8002267188946578\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.176987882007162, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.176987882007162\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9705904006907402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9705904006907402\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.4976\n",
      "[CV 2/2] END bagging_fraction=0.8002267188946578, bagging_freq=7, feature_fraction=0.9705904006907402, lambda_l1=1.2780041059907923, lambda_l2=7.176987882007162, learning_rate=0.2, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=231, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=2;, score=0.327 total time=   7.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.1156286315756905, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.1156286315756905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9711126304392451, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9711126304392451\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.531276047866771, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.531276047866771\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8144739788440337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8144739788440337\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_logloss: 1.50123\n",
      "[CV 1/2] END bagging_fraction=0.9711126304392451, bagging_freq=7, feature_fraction=0.8144739788440337, lambda_l1=7.1156286315756905, lambda_l2=2.531276047866771, learning_rate=0.2, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=388, objective=s, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=128;, score=0.328 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.1156286315756905, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.1156286315756905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9711126304392451, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9711126304392451\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.531276047866771, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.531276047866771\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8144739788440337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8144739788440337\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's multi_logloss: 1.49777\n",
      "[CV 2/2] END bagging_fraction=0.9711126304392451, bagging_freq=7, feature_fraction=0.8144739788440337, lambda_l1=7.1156286315756905, lambda_l2=2.531276047866771, learning_rate=0.2, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=388, objective=s, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=128;, score=0.330 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.141681999122212, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.141681999122212\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5656941511109447, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5656941511109447\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.347185735230811, reg_lambda=0 will be ignored. Current value: lambda_l2=9.347185735230811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5196005892474275, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5196005892474275\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[505]\tvalid_0's multi_logloss: 1.48806\n",
      "[CV 1/2] END bagging_fraction=0.5656941511109447, bagging_freq=5, feature_fraction=0.5196005892474275, lambda_l1=2.141681999122212, lambda_l2=9.347185735230811, learning_rate=0.01, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=316, objective=u, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=16;, score=0.330 total time=  48.7s\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8925540773665812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8925540773665812\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[880]\tvalid_0's multi_logloss: 1.49777\n",
      "[CV 2/2] END bagging_fraction=0.46525884468656636, bagging_freq=4, feature_fraction=0.8925540773665812, lambda_l1=9.989725480852808, lambda_l2=1.7198985407751235, learning_rate=0.01, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=440, objective=m, reg_lambda=1e-07, subsample=0.7, subsample_freq=128;, score=0.331 total time=  17.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.789205498274542, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.789205498274542\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4559160040206445, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4559160040206445\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.955485446282789, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.955485446282789\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6097236410752594, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6097236410752594\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's multi_logloss: 1.49917\n",
      "[CV 1/2] END bagging_fraction=0.4559160040206445, bagging_freq=6, feature_fraction=0.6097236410752594, lambda_l1=8.789205498274542, lambda_l2=7.955485446282789, learning_rate=0.2, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=462, objective=u, reg_lambda=0.0001, subsample=0.5, subsample_freq=4;, score=0.328 total time=   5.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.789205498274542, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.789205498274542\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4559160040206445, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4559160040206445\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.955485446282789, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.955485446282789\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6097236410752594, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6097236410752594\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 1.49989\n",
      "[CV 2/2] END bagging_fraction=0.4559160040206445, bagging_freq=6, feature_fraction=0.6097236410752594, lambda_l1=8.789205498274542, lambda_l2=7.955485446282789, learning_rate=0.2, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=462, objective=u, reg_lambda=0.0001, subsample=0.5, subsample_freq=4;, score=0.328 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3198366278926879, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3198366278926879\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4133661313000456, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.4133661313000456\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.022995497765665, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.022995497765665\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7296572116333497, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7296572116333497\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.5165\n",
      "[CV 2/2] END bagging_fraction=0.4133661313000456, bagging_freq=6, feature_fraction=0.7296572116333497, lambda_l1=1.3198366278926879, lambda_l2=3.022995497765665, learning_rate=0.2, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=15, objective=m, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=2;, score=0.319 total time=   2.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7605874287568835, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7605874287568835\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.437100652162578, subsample=0.6 will be ignored. Current value: bagging_fraction=0.437100652162578\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.531039971007747, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.531039971007747\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8319823429667066, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8319823429667066\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's multi_logloss: 1.50268\n",
      "[CV 2/2] END bagging_fraction=0.437100652162578, bagging_freq=6, feature_fraction=0.8319823429667066, lambda_l1=3.7605874287568835, lambda_l2=2.531039971007747, learning_rate=0.01, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=160, objective=t, reg_lambda=1e-05, subsample=0.6, subsample_freq=4;, score=0.323 total time=   7.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8450468957512525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8450468957512525\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.846944483941136, subsample=0.7 will be ignored. Current value: bagging_fraction=0.846944483941136\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.681179624803344, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.681179624803344\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89710021380045, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89710021380045\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1019]\tvalid_0's multi_logloss: 1.48666\n",
      "[CV 1/2] END bagging_fraction=0.846944483941136, bagging_freq=5, feature_fraction=0.89710021380045, lambda_l1=1.8450468957512525, lambda_l2=4.681179624803344, learning_rate=0.01, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=12, objective=l, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.339 total time=  17.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.141681999122212, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.141681999122212\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5656941511109447, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5656941511109447\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.347185735230811, reg_lambda=0 will be ignored. Current value: lambda_l2=9.347185735230811\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5196005892474275, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5196005892474275\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's multi_logloss: 1.48915\n",
      "[CV 2/2] END bagging_fraction=0.5656941511109447, bagging_freq=5, feature_fraction=0.5196005892474275, lambda_l1=2.141681999122212, lambda_l2=9.347185735230811, learning_rate=0.01, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=316, objective=u, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=16;, score=0.332 total time=  48.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.751720161735679, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.751720161735679\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.944282960745405, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.944282960745405\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.280318225845682, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.280318225845682\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8930959146222553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8930959146222553\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5274958141538697, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5274958141538697\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.198315321137893, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.198315321137893\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4263112247469417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4263112247469417\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.51105\n",
      "[CV 2/2] END bagging_fraction=0.5274958141538697, bagging_freq=6, feature_fraction=0.4263112247469417, lambda_l1=0.8930959146222553, lambda_l2=1.198315321137893, learning_rate=0.2, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=327, objective=i, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=16;, score=0.322 total time=  19.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2780041059907923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2780041059907923\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8002267188946578, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8002267188946578\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.176987882007162, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.176987882007162\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9705904006907402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9705904006907402\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.49793\n",
      "[CV 1/2] END bagging_fraction=0.8002267188946578, bagging_freq=7, feature_fraction=0.9705904006907402, lambda_l1=1.2780041059907923, lambda_l2=7.176987882007162, learning_rate=0.2, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=231, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=2;, score=0.327 total time=   7.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8450468957512525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8450468957512525\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.846944483941136, subsample=0.7 will be ignored. Current value: bagging_fraction=0.846944483941136\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.681179624803344, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=4.681179624803344\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89710021380045, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89710021380045\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1010]\tvalid_0's multi_logloss: 1.48862\n",
      "[CV 2/2] END bagging_fraction=0.846944483941136, bagging_freq=5, feature_fraction=0.89710021380045, lambda_l1=1.8450468957512525, lambda_l2=4.681179624803344, learning_rate=0.01, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=12, objective=l, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.339 total time=  19.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4774758138410613, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4774758138410613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7981372819709177, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7981372819709177\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.90805289620262, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.90805289620262\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4803548966982122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4803548966982122\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[441]\tvalid_0's multi_logloss: 1.50315\n",
      "[CV 1/2] END bagging_fraction=0.7981372819709177, bagging_freq=4, feature_fraction=0.4803548966982122, lambda_l1=2.4774758138410613, lambda_l2=8.90805289620262, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=432, objective=t, reg_lambda=1e-06, subsample=0.5, subsample_freq=32;, score=0.330 total time=  12.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.4774758138410613, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.4774758138410613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7981372819709177, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7981372819709177\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.90805289620262, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.90805289620262\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4803548966982122, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4803548966982122\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's multi_logloss: 1.49558\n",
      "[CV 2/2] END bagging_fraction=0.7981372819709177, bagging_freq=4, feature_fraction=0.4803548966982122, lambda_l1=2.4774758138410613, lambda_l2=8.90805289620262, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=432, objective=t, reg_lambda=1e-06, subsample=0.5, subsample_freq=32;, score=0.331 total time=  17.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.062422903192402, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.062422903192402\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7419133037555399, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7419133037555399\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.29720633483825, reg_lambda=0 will be ignored. Current value: lambda_l2=7.29720633483825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6214444264466277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6214444264466277\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1256]\tvalid_0's multi_logloss: 1.50373\n",
      "[CV 1/2] END bagging_fraction=0.7419133037555399, bagging_freq=2, feature_fraction=0.6214444264466277, lambda_l1=7.062422903192402, lambda_l2=7.29720633483825, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=76, objective=l, reg_lambda=0, subsample=0.6, subsample_freq=2;, score=0.329 total time=  21.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.744728232124521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.744728232124521\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9388748668669442, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9388748668669442\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.735459151171, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.735459151171\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4135960565367712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4135960565367712\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1516]\tvalid_0's multi_logloss: 1.50721\n",
      "[CV 1/2] END bagging_fraction=0.9388748668669442, bagging_freq=4, feature_fraction=0.4135960565367712, lambda_l1=7.744728232124521, lambda_l2=5.735459151171, learning_rate=0.01, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=35, objective=s, reg_lambda=1e-07, subsample=0.6, subsample_freq=32;, score=0.327 total time=  19.3s\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56145260814294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56145260814294\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 1.4977\n",
      "[CV 1/2] END bagging_fraction=0.944282960745405, bagging_freq=6, feature_fraction=0.56145260814294, lambda_l1=6.751720161735679, lambda_l2=6.280318225845682, learning_rate=0.2, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=377, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=2;, score=0.333 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.751720161735679, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.751720161735679\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.944282960745405, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.944282960745405\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.280318225845682, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.280318225845682\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56145260814294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56145260814294\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 1.49434\n",
      "[CV 2/2] END bagging_fraction=0.944282960745405, bagging_freq=6, feature_fraction=0.56145260814294, lambda_l1=6.751720161735679, lambda_l2=6.280318225845682, learning_rate=0.2, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=377, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=2;, score=0.329 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.744728232124521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.744728232124521\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9388748668669442, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9388748668669442\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.735459151171, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.735459151171\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4135960565367712, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4135960565367712\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=32 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1164]\tvalid_0's multi_logloss: 1.49641\n",
      "[CV 2/2] END bagging_fraction=0.9388748668669442, bagging_freq=4, feature_fraction=0.4135960565367712, lambda_l1=7.744728232124521, lambda_l2=5.735459151171, learning_rate=0.01, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=35, objective=s, reg_lambda=1e-07, subsample=0.6, subsample_freq=32;, score=0.332 total time=  18.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.59217789165417, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.59217789165417\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669116419840901, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8669116419840901\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.631395291958426, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.631395291958426\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8280796845863643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8280796845863643\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's multi_logloss: 1.50868\n",
      "[CV 1/2] END bagging_fraction=0.8669116419840901, bagging_freq=2, feature_fraction=0.8280796845863643, lambda_l1=9.59217789165417, lambda_l2=7.631395291958426, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=367, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=4;, score=0.326 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.59217789165417, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.59217789165417\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8669116419840901, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8669116419840901\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.631395291958426, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.631395291958426\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8280796845863643, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8280796845863643\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's multi_logloss: 1.49875\n",
      "[CV 2/2] END bagging_fraction=0.8669116419840901, bagging_freq=2, feature_fraction=0.8280796845863643, lambda_l1=9.59217789165417, lambda_l2=7.631395291958426, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=367, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=4;, score=0.330 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.386999348166352, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.386999348166352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5572432586695879, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5572432586695879\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.195512636259766, reg_lambda=0 will be ignored. Current value: lambda_l2=8.195512636259766\n",
      "[LightGBM] [Warning] feature_fraction is set=0.876351760469313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.876351760469313\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's multi_logloss: 1.49541\n",
      "[CV 1/2] END bagging_fraction=0.5572432586695879, bagging_freq=8, feature_fraction=0.876351760469313, lambda_l1=9.386999348166352, lambda_l2=8.195512636259766, learning_rate=0.05, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=258, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=1;, score=0.331 total time=  12.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.272427832974618, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.272427832974618\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8629049257426396, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8629049257426396\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.038783016012543, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.038783016012543\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6618475012645533, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6618475012645533\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's multi_logloss: 1.49614\n",
      "[CV 1/2] END bagging_fraction=0.8629049257426396, bagging_freq=9, feature_fraction=0.6618475012645533, lambda_l1=7.272427832974618, lambda_l2=3.038783016012543, learning_rate=0.2, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=329, objective=m, reg_lambda=0.0001, subsample=0.5, subsample_freq=128;, score=0.332 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.139191661199654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.139191661199654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5001461748628339, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5001461748628339\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.162290441216525, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.162290441216525\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.062422903192402, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.062422903192402\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7419133037555399, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7419133037555399\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.29720633483825, reg_lambda=0 will be ignored. Current value: lambda_l2=7.29720633483825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6214444264466277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6214444264466277\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[886]\tvalid_0's multi_logloss: 1.49596\n",
      "[CV 2/2] END bagging_fraction=0.7419133037555399, bagging_freq=2, feature_fraction=0.6214444264466277, lambda_l1=7.062422903192402, lambda_l2=7.29720633483825, learning_rate=0.01, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=76, objective=l, reg_lambda=0, subsample=0.6, subsample_freq=2;, score=0.330 total time=  15.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0334074095799375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0334074095799375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5361772536666796, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5361772536666796\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.48006931781666, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.48006931781666\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9344548843383012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9344548843383012\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 1.50416\n",
      "[CV 1/2] END bagging_fraction=0.5361772536666796, bagging_freq=5, feature_fraction=0.9344548843383012, lambda_l1=1.0334074095799375, lambda_l2=9.48006931781666, learning_rate=0.2, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=463, objective=s, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=2;, score=0.329 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0334074095799375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0334074095799375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5361772536666796, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5361772536666796\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.48006931781666, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.48006931781666\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9344548843383012, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9344548843383012\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's multi_logloss: 1.50543\n",
      "[CV 2/2] END bagging_fraction=0.5361772536666796, bagging_freq=5, feature_fraction=0.9344548843383012, lambda_l1=1.0334074095799375, lambda_l2=9.48006931781666, learning_rate=0.2, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=463, objective=s, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=2;, score=0.327 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.771168413669958, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.771168413669958\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6612015705905789, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6612015705905789\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.417210536045869, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.417210536045869\n",
      "[LightGBM] [Warning] feature_fraction is set=0.715993829206891, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.715993829206891\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.49944\n",
      "[CV 1/2] END bagging_fraction=0.6612015705905789, bagging_freq=8, feature_fraction=0.715993829206891, lambda_l1=9.771168413669958, lambda_l2=7.417210536045869, learning_rate=0.2, metric=multi_logloss, min_child_samples=9, num_class=5, num_leaves=234, objective=a, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=256;, score=0.327 total time=  13.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.234191757055857, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.234191757055857\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9252991810390451, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9252991810390451\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4549326662218176, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.4549326662218176\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6434587680765089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6434587680765089\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's multi_logloss: 1.49176\n",
      "[CV 1/2] END bagging_fraction=0.9252991810390451, bagging_freq=2, feature_fraction=0.6434587680765089, lambda_l1=8.234191757055857, lambda_l2=2.4549326662218176, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=79, objective=a, reg_lambda=0.0001, subsample=0.7, subsample_freq=128;, score=0.333 total time=  13.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.386999348166352, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.386999348166352\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5572432586695879, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5572432586695879\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.195512636259766, reg_lambda=0 will be ignored. Current value: lambda_l2=8.195512636259766\n",
      "[LightGBM] [Warning] feature_fraction is set=0.876351760469313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.876351760469313\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's multi_logloss: 1.49652\n",
      "[CV 2/2] END bagging_fraction=0.5572432586695879, bagging_freq=8, feature_fraction=0.876351760469313, lambda_l1=9.386999348166352, lambda_l2=8.195512636259766, learning_rate=0.05, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=258, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=1;, score=0.329 total time=  12.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8013145738488514, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8013145738488514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6636111930869717, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6636111930869717\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9927278882462953, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.9927278882462953\n",
      "[LightGBM] [Warning] feature_fraction is set=0.82486679514715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.82486679514715\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 1.51466\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7577963906646452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7577963906646452\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[938]\tvalid_0's multi_logloss: 1.51416\n",
      "[CV 1/2] END bagging_fraction=0.5001461748628339, bagging_freq=2, feature_fraction=0.7577963906646452, lambda_l1=7.139191661199654, lambda_l2=8.162290441216525, learning_rate=0.01, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=436, objective=m, reg_lambda=0.0001, subsample=0.5, subsample_freq=2;, score=0.325 total time=  10.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.322290606412363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.322290606412363\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7120956753007166, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7120956753007166\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.221871460628978, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.221871460628978\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9052924680358538, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9052924680358538\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's multi_logloss: 1.50285\n",
      "[CV 1/2] END bagging_fraction=0.7120956753007166, bagging_freq=4, feature_fraction=0.9052924680358538, lambda_l1=4.322290606412363, lambda_l2=4.221871460628978, learning_rate=0.05, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=159, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.329 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.713451921564928, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.713451921564928\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6238677596209318, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6238677596209318\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.8522777082541095, reg_lambda=0 will be ignored. Current value: lambda_l2=5.8522777082541095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4412002060687995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4412002060687995\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's multi_logloss: 1.49866\n",
      "[CV 2/2] END bagging_fraction=0.6238677596209318, bagging_freq=7, feature_fraction=0.4412002060687995, lambda_l1=6.713451921564928, lambda_l2=5.8522777082541095, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=53, objective=s, reg_lambda=0, subsample=0.5, subsample_freq=8;, score=0.330 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4915008701729853, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4915008701729853\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8601746659259181, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8601746659259181\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.290579797241202, reg_lambda=0 will be ignored. Current value: lambda_l2=5.290579797241202\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6398802807799502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6398802807799502\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.50319\n",
      "[CV 1/2] END bagging_fraction=0.8601746659259181, bagging_freq=7, feature_fraction=0.6398802807799502, lambda_l1=0.4915008701729853, lambda_l2=5.290579797241202, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=419, objective=s, reg_lambda=0, subsample=0.5, subsample_freq=64;, score=0.331 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4915008701729853, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4915008701729853\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8601746659259181, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8601746659259181\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.290579797241202, reg_lambda=0 will be ignored. Current value: lambda_l2=5.290579797241202\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6398802807799502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6398802807799502\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's multi_logloss: 1.50252\n",
      "[CV 2/2] END bagging_fraction=0.8601746659259181, bagging_freq=7, feature_fraction=0.6398802807799502, lambda_l1=0.4915008701729853, lambda_l2=5.290579797241202, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=419, objective=s, reg_lambda=0, subsample=0.5, subsample_freq=64;, score=0.327 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.001714216885864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.001714216885864\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.570360724674712, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.570360724674712\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7173142695212684, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.7173142695212684\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999767784527625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999767784527625\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's multi_logloss: 1.51145\n",
      "[CV 1/2] END bagging_fraction=0.570360724674712, bagging_freq=3, feature_fraction=0.8999767784527625, lambda_l1=9.001714216885864, lambda_l2=2.7173142695212684, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=117, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=256;, score=0.326 total time=   9.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.001714216885864, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.001714216885864\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.570360724674712, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.570360724674712\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7173142695212684, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.7173142695212684\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999767784527625, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999767784527625\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[699]\tvalid_0's multi_logloss: 1.50068\n",
      "[CV 2/2] END bagging_fraction=0.570360724674712, bagging_freq=3, feature_fraction=0.8999767784527625, lambda_l1=9.001714216885864, lambda_l2=2.7173142695212684, learning_rate=0.01, metric=multi_logloss, min_child_samples=65, num_class=5, num_leaves=117, objective=i, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=256;, score=0.330 total time=  11.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7366276556889062, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7366276556889062\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4075026632611324, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4075026632611324\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.771168413669958, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.771168413669958\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6612015705905789, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6612015705905789\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.417210536045869, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.417210536045869\n",
      "[LightGBM] [Warning] feature_fraction is set=0.715993829206891, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.715993829206891\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's multi_logloss: 1.49831\n",
      "[CV 2/2] END bagging_fraction=0.6612015705905789, bagging_freq=8, feature_fraction=0.715993829206891, lambda_l1=9.771168413669958, lambda_l2=7.417210536045869, learning_rate=0.2, metric=multi_logloss, min_child_samples=9, num_class=5, num_leaves=234, objective=a, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=256;, score=0.327 total time=  14.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.234191757055857, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.234191757055857\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9252991810390451, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9252991810390451\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4549326662218176, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.4549326662218176\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6434587680765089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6434587680765089\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 1.48941\n",
      "[CV 2/2] END bagging_fraction=0.9252991810390451, bagging_freq=2, feature_fraction=0.6434587680765089, lambda_l1=8.234191757055857, lambda_l2=2.4549326662218176, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=79, objective=a, reg_lambda=0.0001, subsample=0.7, subsample_freq=128;, score=0.333 total time=  14.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.272427832974618, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.272427832974618\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8629049257426396, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8629049257426396\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.038783016012543, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.038783016012543\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6618475012645533, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6618475012645533\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 1.4949\n",
      "[CV 2/2] END bagging_fraction=0.8629049257426396, bagging_freq=9, feature_fraction=0.6618475012645533, lambda_l1=7.272427832974618, lambda_l2=3.038783016012543, learning_rate=0.2, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=329, objective=m, reg_lambda=0.0001, subsample=0.5, subsample_freq=128;, score=0.326 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.139191661199654, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.139191661199654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5001461748628339, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5001461748628339\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.162290441216525, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=8.162290441216525\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7577963906646452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7577963906646452\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[982]\tvalid_0's multi_logloss: 1.5012\n",
      "[CV 2/2] END bagging_fraction=0.5001461748628339, bagging_freq=2, feature_fraction=0.7577963906646452, lambda_l1=7.139191661199654, lambda_l2=8.162290441216525, learning_rate=0.01, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=436, objective=m, reg_lambda=0.0001, subsample=0.5, subsample_freq=2;, score=0.325 total time=  12.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.713451921564928, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.713451921564928\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6238677596209318, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6238677596209318\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.8522777082541095, reg_lambda=0 will be ignored. Current value: lambda_l2=5.8522777082541095\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4412002060687995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4412002060687995\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's multi_logloss: 1.51156\n",
      "[CV 1/2] END bagging_fraction=0.6238677596209318, bagging_freq=7, feature_fraction=0.4412002060687995, lambda_l1=6.713451921564928, lambda_l2=5.8522777082541095, learning_rate=0.05, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=53, objective=s, reg_lambda=0, subsample=0.5, subsample_freq=8;, score=0.323 total time=   4.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.537879842702974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.537879842702974\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42041440855801926, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.42041440855801926\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1377007470626312, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.1377007470626312\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8980917725860798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8980917725860798\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's multi_logloss: 1.49408\n",
      "[CV 1/2] END bagging_fraction=0.42041440855801926, bagging_freq=2, feature_fraction=0.8980917725860798, lambda_l1=4.537879842702974, lambda_l2=1.1377007470626312, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=371, objective=l, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.329 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.977453742032804, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.977453742032804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9393861354837102, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9393861354837102\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.581471376572342, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.581471376572342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6767808614469208, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6767808614469208\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[529]\tvalid_0's multi_logloss: 1.49176\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.61052267773909, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.61052267773909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8885321898834739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8885321898834739\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[378]\tvalid_0's multi_logloss: 1.50028\n",
      "[CV 1/2] END bagging_fraction=0.4075026632611324, bagging_freq=9, feature_fraction=0.8885321898834739, lambda_l1=1.7366276556889062, lambda_l2=9.61052267773909, learning_rate=0.01, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=49, objective=u, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.331 total time=  13.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7366276556889062, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7366276556889062\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4075026632611324, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4075026632611324\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.61052267773909, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.61052267773909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8885321898834739, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8885321898834739\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's multi_logloss: 1.49664\n",
      "[CV 2/2] END bagging_fraction=0.4075026632611324, bagging_freq=9, feature_fraction=0.8885321898834739, lambda_l1=1.7366276556889062, lambda_l2=9.61052267773909, learning_rate=0.01, metric=multi_logloss, min_child_samples=35, num_class=5, num_leaves=49, objective=u, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=64;, score=0.330 total time=  20.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1672258945290739, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1672258945290739\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611308624451929, subsample=0.6 will be ignored. Current value: bagging_fraction=0.611308624451929\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.566570109515707, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.566570109515707\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7700274237230461, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7700274237230461\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's multi_logloss: 1.50039\n",
      "[CV 2/2] END bagging_fraction=0.611308624451929, bagging_freq=2, feature_fraction=0.7700274237230461, lambda_l1=1.1672258945290739, lambda_l2=8.566570109515707, learning_rate=0.01, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=426, objective=a, reg_lambda=0.001, subsample=0.6, subsample_freq=2;, score=0.331 total time=   8.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.653183045417461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.653183045417461\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6965842229568961, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6965842229568961\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.496137853913163, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.496137853913163\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604116840528736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604116840528736\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's multi_logloss: 1.4904\n",
      "[CV 2/2] END bagging_fraction=0.6965842229568961, bagging_freq=4, feature_fraction=0.8604116840528736, lambda_l1=5.653183045417461, lambda_l2=8.496137853913163, learning_rate=0.01, metric=multi_logloss, min_child_samples=9, num_class=5, num_leaves=325, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.333 total time=  46.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7847131481453321, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7847131481453321\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179530830715937, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9179530830715937\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3349433426946305, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.3349433426946305\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6504748612471201, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6504748612471201\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 1.48726\n",
      "[CV 1/2] END bagging_fraction=0.9179530830715937, bagging_freq=2, feature_fraction=0.6504748612471201, lambda_l1=0.7847131481453321, lambda_l2=0.3349433426946305, learning_rate=0.05, metric=multi_logloss, min_child_samples=18, num_class=5, num_leaves=17, objective=i, reg_lambda=1e-06, subsample=0.5, subsample_freq=64;, score=0.338 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7847131481453321, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7847131481453321\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179530830715937, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9179530830715937\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3349433426946305, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.3349433426946305\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6504748612471201, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6504748612471201\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=64 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 1.48947\n",
      "[CV 2/2] END bagging_fraction=0.9179530830715937, bagging_freq=2, feature_fraction=0.6504748612471201, lambda_l1=0.7847131481453321, lambda_l2=0.3349433426946305, learning_rate=0.05, metric=multi_logloss, min_child_samples=18, num_class=5, num_leaves=17, objective=i, reg_lambda=1e-06, subsample=0.5, subsample_freq=64;, score=0.339 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8608970867977073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8608970867977073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5847596623036161, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5847596623036161\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.294172565513995, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.294172565513995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71656491393768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71656491393768\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.50103\n",
      "[CV 1/2] END bagging_fraction=0.5847596623036161, bagging_freq=8, feature_fraction=0.71656491393768, lambda_l1=1.8608970867977073, lambda_l2=4.294172565513995, learning_rate=0.2, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=482, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=16;, score=0.330 total time=   8.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8608970867977073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8608970867977073\n",
      "[CV 1/2] END bagging_fraction=0.6636111930869717, bagging_freq=6, feature_fraction=0.82486679514715, lambda_l1=1.8013145738488514, lambda_l2=1.9927278882462953, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=354, objective=l, reg_lambda=1e-05, subsample=0.7, subsample_freq=16;, score=0.327 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8013145738488514, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8013145738488514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6636111930869717, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6636111930869717\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9927278882462953, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.9927278882462953\n",
      "[LightGBM] [Warning] feature_fraction is set=0.82486679514715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.82486679514715\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.50191\n",
      "[CV 2/2] END bagging_fraction=0.6636111930869717, bagging_freq=6, feature_fraction=0.82486679514715, lambda_l1=1.8013145738488514, lambda_l2=1.9927278882462953, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=354, objective=l, reg_lambda=1e-05, subsample=0.7, subsample_freq=16;, score=0.328 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.322290606412363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.322290606412363\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7120956753007166, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7120956753007166\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.221871460628978, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.221871460628978\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9052924680358538, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9052924680358538\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 1.49819\n",
      "[CV 2/2] END bagging_fraction=0.7120956753007166, bagging_freq=4, feature_fraction=0.9052924680358538, lambda_l1=4.322290606412363, lambda_l2=4.221871460628978, learning_rate=0.05, metric=multi_logloss, min_child_samples=75, num_class=5, num_leaves=159, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.330 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.537879842702974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.537879842702974\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42041440855801926, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.42041440855801926\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1377007470626312, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.1377007470626312\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8980917725860798, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8980917725860798\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 1.4948\n",
      "[CV 2/2] END bagging_fraction=0.42041440855801926, bagging_freq=2, feature_fraction=0.8980917725860798, lambda_l1=4.537879842702974, lambda_l2=1.1377007470626312, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=371, objective=l, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.329 total time=   7.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.977453742032804, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.977453742032804\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9393861354837102, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9393861354837102\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.581471376572342, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.581471376572342\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6767808614469208, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6767808614469208\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[598]\tvalid_0's multi_logloss: 1.49211\n",
      "[CV 1/2] END bagging_fraction=0.9393861354837102, bagging_freq=9, feature_fraction=0.6767808614469208, lambda_l1=5.977453742032804, lambda_l2=9.581471376572342, learning_rate=0.01, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=453, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=1;, score=0.331 total time=  51.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1672258945290739, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1672258945290739\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611308624451929, subsample=0.6 will be ignored. Current value: bagging_fraction=0.611308624451929\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.566570109515707, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.566570109515707\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7700274237230461, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7700274237230461\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=2 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid_0's multi_logloss: 1.51185\n",
      "[CV 1/2] END bagging_fraction=0.611308624451929, bagging_freq=2, feature_fraction=0.7700274237230461, lambda_l1=1.1672258945290739, lambda_l2=8.566570109515707, learning_rate=0.01, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=426, objective=a, reg_lambda=0.001, subsample=0.6, subsample_freq=2;, score=0.325 total time=   8.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.6838577796558765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.6838577796558765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8400091119684541, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8400091119684541\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.10596896910904, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.10596896910904\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4075515488051173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4075515488051173\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 1.49222\n",
      "[CV 2/2] END bagging_fraction=0.8400091119684541, bagging_freq=9, feature_fraction=0.4075515488051173, lambda_l1=4.6838577796558765, lambda_l2=5.10596896910904, learning_rate=0.2, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=403, objective=s, reg_lambda=1e-06, subsample=0.7, subsample_freq=8;, score=0.331 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.06438771543392, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.06438771543392\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7698838002060622, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7698838002060622\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.930458897508748, reg_lambda=0 will be ignored. Current value: lambda_l2=8.930458897508748\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5045569916197759, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5045569916197759\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[CV 2/2] END bagging_fraction=0.9393861354837102, bagging_freq=9, feature_fraction=0.6767808614469208, lambda_l1=5.977453742032804, lambda_l2=9.581471376572342, learning_rate=0.01, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=453, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=1;, score=0.333 total time=  54.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.6838577796558765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.6838577796558765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8400091119684541, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8400091119684541\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.10596896910904, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.10596896910904\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4075515488051173, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4075515488051173\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 1.49536\n",
      "[CV 1/2] END bagging_fraction=0.8400091119684541, bagging_freq=9, feature_fraction=0.4075515488051173, lambda_l1=4.6838577796558765, lambda_l2=5.10596896910904, learning_rate=0.2, metric=multi_logloss, min_child_samples=24, num_class=5, num_leaves=403, objective=s, reg_lambda=1e-06, subsample=0.7, subsample_freq=8;, score=0.335 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.653183045417461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.653183045417461\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6965842229568961, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6965842229568961\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.496137853913163, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.496137853913163\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8604116840528736, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8604116840528736\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[404]\tvalid_0's multi_logloss: 1.49272\n",
      "[CV 1/2] END bagging_fraction=0.6965842229568961, bagging_freq=4, feature_fraction=0.8604116840528736, lambda_l1=5.653183045417461, lambda_l2=8.496137853913163, learning_rate=0.01, metric=multi_logloss, min_child_samples=9, num_class=5, num_leaves=325, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=1;, score=0.328 total time=  45.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.06438771543392, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.06438771543392\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7698838002060622, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7698838002060622\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.930458897508748, reg_lambda=0 will be ignored. Current value: lambda_l2=8.930458897508748\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5045569916197759, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5045569916197759\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's multi_logloss: 1.48912\n",
      "[CV 2/2] END bagging_fraction=0.7698838002060622, bagging_freq=3, feature_fraction=0.5045569916197759, lambda_l1=2.06438771543392, lambda_l2=8.930458897508748, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=303, objective=i, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.333 total time= 1.0min\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.290521702864861, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.290521702864861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9129547194285672, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9129547194285672\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9120397145621528, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.9120397145621528\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508489199851636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508489199851636\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's multi_logloss: 1.49448\n",
      "[CV 2/2] END bagging_fraction=0.9129547194285672, bagging_freq=8, feature_fraction=0.5508489199851636, lambda_l1=9.290521702864861, lambda_l2=1.9120397145621528, learning_rate=0.2, metric=multi_logloss, min_child_samples=53, num_class=5, num_leaves=212, objective=s, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=8;, score=0.329 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.025218350149745224, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.025218350149745224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6421737993764045, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6421737993764045\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8474295490266015, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.8474295490266015\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612467268808061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612467268808061\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's multi_logloss: 1.50131\n",
      "[CV 1/2] END bagging_fraction=0.6421737993764045, bagging_freq=8, feature_fraction=0.8612467268808061, lambda_l1=0.025218350149745224, lambda_l2=1.8474295490266015, learning_rate=0.05, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=235, objective=m, reg_lambda=0.001, subsample=0.5, subsample_freq=4;, score=0.334 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.025218350149745224, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.025218350149745224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6421737993764045, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6421737993764045\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8474295490266015, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.8474295490266015\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612467268808061, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612467268808061\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_logloss: 1.50446\n",
      "[CV 2/2] END bagging_fraction=0.6421737993764045, bagging_freq=8, feature_fraction=0.8612467268808061, lambda_l1=0.025218350149745224, lambda_l2=1.8474295490266015, learning_rate=0.05, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=235, objective=m, reg_lambda=0.001, subsample=0.5, subsample_freq=4;, score=0.325 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4883813346100363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4883813346100363\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44873321355565154, subsample=0.7 will be ignored. Current value: bagging_fraction=0.44873321355565154\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.73757733598631, reg_lambda=0 will be ignored. Current value: lambda_l2=7.73757733598631\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4273166778931278, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4273166778931278\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5847596623036161, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5847596623036161\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.294172565513995, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.294172565513995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71656491393768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71656491393768\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's multi_logloss: 1.4984\n",
      "[CV 2/2] END bagging_fraction=0.5847596623036161, bagging_freq=8, feature_fraction=0.71656491393768, lambda_l1=1.8608970867977073, lambda_l2=4.294172565513995, learning_rate=0.2, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=482, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=16;, score=0.328 total time=   9.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1115123523165193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1115123523165193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8056315984747424, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8056315984747424\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.433402088783339, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.433402088783339\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5964230988390087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5964230988390087\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's multi_logloss: 1.49702\n",
      "[CV 1/2] END bagging_fraction=0.8056315984747424, bagging_freq=7, feature_fraction=0.5964230988390087, lambda_l1=3.1115123523165193, lambda_l2=7.433402088783339, learning_rate=0.2, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=95, objective=c, reg_lambda=1e-06, subsample=0.5, subsample_freq=8;, score=0.328 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1115123523165193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1115123523165193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8056315984747424, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8056315984747424\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.433402088783339, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.433402088783339\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5964230988390087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5964230988390087\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49952\n",
      "[CV 2/2] END bagging_fraction=0.8056315984747424, bagging_freq=7, feature_fraction=0.5964230988390087, lambda_l1=3.1115123523165193, lambda_l2=7.433402088783339, learning_rate=0.2, metric=multi_logloss, min_child_samples=48, num_class=5, num_leaves=95, objective=c, reg_lambda=1e-06, subsample=0.5, subsample_freq=8;, score=0.328 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2371407521767477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2371407521767477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7169022209630929, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7169022209630929\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.3296845751106705, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.3296845751106705\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8352432709305257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8352432709305257\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's multi_logloss: 1.49588\n",
      "[CV 2/2] END bagging_fraction=0.7169022209630929, bagging_freq=3, feature_fraction=0.8352432709305257, lambda_l1=1.2371407521767477, lambda_l2=4.3296845751106705, learning_rate=0.01, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=375, objective=l, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=8;, score=0.329 total time=  19.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.853328603782638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.853328603782638\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8952239160923927, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8952239160923927\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.513454086828373, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.513454086828373\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8628598106660259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8628598106660259\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's multi_logloss: 1.49413\n",
      "[CV 1/2] END bagging_fraction=0.8952239160923927, bagging_freq=9, feature_fraction=0.8628598106660259, lambda_l1=6.853328603782638, lambda_l2=9.513454086828373, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=336, objective=a, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.332 total time=  32.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.6438450292188085, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.6438450292188085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5541670046453093, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5541670046453093\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.697856290497988, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.697856290497988\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5857054108378726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5857054108378726\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 1.51352\n",
      "[CV 1/2] END bagging_fraction=0.5541670046453093, bagging_freq=8, feature_fraction=0.5857054108378726, lambda_l1=7.6438450292188085, lambda_l2=6.697856290497988, learning_rate=0.2, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=22, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=256;, score=0.323 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.702809246920623, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.702809246920623\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6716351872715803, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6716351872715803\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.894943489975294, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.894943489975294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9406402356263008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9406402356263008\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's multi_logloss: 1.4968\n",
      "[CV 1/2] END bagging_fraction=0.6716351872715803, bagging_freq=9, feature_fraction=0.9406402356263008, lambda_l1=0.702809246920623, lambda_l2=9.894943489975294, learning_rate=0.01, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=402, objective=t, reg_lambda=1e-06, subsample=0.7, subsample_freq=8;, score=0.333 total time=  16.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7463084286899783, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7463084286899783\n",
      "Early stopping, best iteration is:\n",
      "[502]\tvalid_0's multi_logloss: 1.48867\n",
      "[CV 1/2] END bagging_fraction=0.7698838002060622, bagging_freq=3, feature_fraction=0.5045569916197759, lambda_l1=2.06438771543392, lambda_l2=8.930458897508748, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=303, objective=i, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.333 total time= 1.4min\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2371407521767477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2371407521767477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7169022209630929, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7169022209630929\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.3296845751106705, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=4.3296845751106705\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8352432709305257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8352432709305257\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=8 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's multi_logloss: 1.49434\n",
      "[CV 1/2] END bagging_fraction=0.7169022209630929, bagging_freq=3, feature_fraction=0.8352432709305257, lambda_l1=1.2371407521767477, lambda_l2=4.3296845751106705, learning_rate=0.01, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=375, objective=l, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=8;, score=0.330 total time=  19.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.290521702864861, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.290521702864861\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9129547194285672, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9129547194285672\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9120397145621528, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.9120397145621528\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508489199851636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508489199851636\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's multi_logloss: 1.49788\n",
      "[CV 1/2] END bagging_fraction=0.9129547194285672, bagging_freq=8, feature_fraction=0.5508489199851636, lambda_l1=9.290521702864861, lambda_l2=1.9120397145621528, learning_rate=0.2, metric=multi_logloss, min_child_samples=53, num_class=5, num_leaves=212, objective=s, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=8;, score=0.328 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.853328603782638, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.853328603782638\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8952239160923927, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8952239160923927\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.513454086828373, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.513454086828373\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8628598106660259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8628598106660259\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[531]\tvalid_0's multi_logloss: 1.49224\n",
      "[CV 2/2] END bagging_fraction=0.8952239160923927, bagging_freq=9, feature_fraction=0.8628598106660259, lambda_l1=6.853328603782638, lambda_l2=9.513454086828373, learning_rate=0.01, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=336, objective=a, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.332 total time=  31.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.143997669314792, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.143997669314792\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6056186649753997, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6056186649753997\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.9347180094485035, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.9347180094485035\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8400643575225472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8400643575225472\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 1.50206\n",
      "[CV 2/2] END bagging_fraction=0.6056186649753997, bagging_freq=9, feature_fraction=0.8400643575225472, lambda_l1=4.143997669314792, lambda_l2=6.9347180094485035, learning_rate=0.05, metric=multi_logloss, min_child_samples=66, num_class=5, num_leaves=270, objective=i, reg_lambda=1e-05, subsample=0.5, subsample_freq=32;, score=0.331 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.702809246920623, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.702809246920623\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6716351872715803, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6716351872715803\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.894943489975294, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.894943489975294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9406402356263008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9406402356263008\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's multi_logloss: 1.49866\n",
      "[CV 2/2] END bagging_fraction=0.6716351872715803, bagging_freq=9, feature_fraction=0.9406402356263008, lambda_l1=0.702809246920623, lambda_l2=9.894943489975294, learning_rate=0.01, metric=multi_logloss, min_child_samples=49, num_class=5, num_leaves=402, objective=t, reg_lambda=1e-06, subsample=0.7, subsample_freq=8;, score=0.330 total time=  14.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.244167072759619, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.244167072759619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47361902592481175, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.47361902592481175\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23316991605418141, reg_lambda=0 will be ignored. Current value: lambda_l2=0.23316991605418141\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7851039262376787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7851039262376787\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[579]\tvalid_0's multi_logloss: 1.49831\n",
      "[CV 2/2] END bagging_fraction=0.47361902592481175, bagging_freq=3, feature_fraction=0.7851039262376787, lambda_l1=5.244167072759619, lambda_l2=0.23316991605418141, learning_rate=0.01, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=440, objective=m, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=64;, score=0.331 total time=  10.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0623886658661255, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0623886658661255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44463061452427544, subsample=0.6 will be ignored. Current value: bagging_fraction=0.44463061452427544\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.945229271189298, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.945229271189298\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4832047246025927, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4832047246025927\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 1.52562\n",
      "[CV 1/2] END bagging_fraction=0.44873321355565154, bagging_freq=6, feature_fraction=0.4273166778931278, lambda_l1=1.4883813346100363, lambda_l2=7.73757733598631, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=271, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=8;, score=0.322 total time=   1.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4883813346100363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4883813346100363\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44873321355565154, subsample=0.7 will be ignored. Current value: bagging_fraction=0.44873321355565154\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.73757733598631, reg_lambda=0 will be ignored. Current value: lambda_l2=7.73757733598631\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4273166778931278, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4273166778931278\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.51762\n",
      "[CV 2/2] END bagging_fraction=0.44873321355565154, bagging_freq=6, feature_fraction=0.4273166778931278, lambda_l1=1.4883813346100363, lambda_l2=7.73757733598631, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=271, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=8;, score=0.317 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.760508294391403, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.760508294391403\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881997971355754, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8881997971355754\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.318368214077616, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.318368214077616\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9393741101760102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9393741101760102\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 1.50417\n",
      "[CV 1/2] END bagging_fraction=0.8881997971355754, bagging_freq=7, feature_fraction=0.9393741101760102, lambda_l1=8.760508294391403, lambda_l2=5.318368214077616, learning_rate=0.05, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=145, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=2;, score=0.330 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.760508294391403, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.760508294391403\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8881997971355754, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8881997971355754\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.318368214077616, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.318368214077616\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9393741101760102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9393741101760102\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 1.49767\n",
      "[CV 2/2] END bagging_fraction=0.8881997971355754, bagging_freq=7, feature_fraction=0.9393741101760102, lambda_l1=8.760508294391403, lambda_l2=5.318368214077616, learning_rate=0.05, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=145, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=2;, score=0.329 total time=   5.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.143997669314792, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.143997669314792\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6056186649753997, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6056186649753997\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.9347180094485035, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=6.9347180094485035\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8400643575225472, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8400643575225472\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's multi_logloss: 1.50684\n",
      "[CV 1/2] END bagging_fraction=0.6056186649753997, bagging_freq=9, feature_fraction=0.8400643575225472, lambda_l1=4.143997669314792, lambda_l2=6.9347180094485035, learning_rate=0.05, metric=multi_logloss, min_child_samples=66, num_class=5, num_leaves=270, objective=i, reg_lambda=1e-05, subsample=0.5, subsample_freq=32;, score=0.327 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.6438450292188085, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.6438450292188085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5541670046453093, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5541670046453093\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.697856290497988, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.697856290497988\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5857054108378726, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5857054108378726\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's multi_logloss: 1.50331\n",
      "[CV 2/2] END bagging_fraction=0.5541670046453093, bagging_freq=8, feature_fraction=0.5857054108378726, lambda_l1=7.6438450292188085, lambda_l2=6.697856290497988, learning_rate=0.2, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=22, objective=l, reg_lambda=0.0001, subsample=0.5, subsample_freq=256;, score=0.326 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.244167072759619, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.244167072759619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47361902592481175, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.47361902592481175\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23316991605418141, reg_lambda=0 will be ignored. Current value: lambda_l2=0.23316991605418141\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7851039262376787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7851039262376787\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[852]\tvalid_0's multi_logloss: 1.50736\n",
      "[CV 1/2] END bagging_fraction=0.47361902592481175, bagging_freq=3, feature_fraction=0.7851039262376787, lambda_l1=5.244167072759619, lambda_l2=0.23316991605418141, learning_rate=0.01, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=440, objective=m, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=64;, score=0.327 total time=  13.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7463084286899783, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7463084286899783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8382254076741243, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8382254076741243\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.648263411502385, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.648263411502385\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4248759962840858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4248759962840858\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8382254076741243, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8382254076741243\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.648263411502385, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=3.648263411502385\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4248759962840858, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4248759962840858\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 1.49157\n",
      "[CV 2/2] END bagging_fraction=0.8382254076741243, bagging_freq=3, feature_fraction=0.4248759962840858, lambda_l1=0.7463084286899783, lambda_l2=3.648263411502385, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=447, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=128;, score=0.330 total time=  58.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6178207459833267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6178207459833267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9575749419772733, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9575749419772733\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8355042399642825, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.8355042399642825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8396190487407176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8396190487407176\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.50062\n",
      "[CV 1/2] END bagging_fraction=0.9575749419772733, bagging_freq=2, feature_fraction=0.8396190487407176, lambda_l1=3.6178207459833267, lambda_l2=3.8355042399642825, learning_rate=0.2, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=188, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.330 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.404426167407319, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.404426167407319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.646837089966515, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.646837089966515\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0279703702459044, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.0279703702459044\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8238458980545058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8238458980545058\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 1.49889\n",
      "[CV 1/2] END bagging_fraction=0.646837089966515, bagging_freq=9, feature_fraction=0.8238458980545058, lambda_l1=5.404426167407319, lambda_l2=1.0279703702459044, learning_rate=0.2, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=188, objective=t, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=16;, score=0.332 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.916885105216373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.916885105216373\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.889985763779874, subsample=0.5 will be ignored. Current value: bagging_fraction=0.889985763779874\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.534031667433746, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.534031667433746\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585974983522537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585974983522537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 1.50769\n",
      "[CV 1/2] END bagging_fraction=0.889985763779874, bagging_freq=4, feature_fraction=0.8585974983522537, lambda_l1=5.916885105216373, lambda_l2=6.534031667433746, learning_rate=0.2, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=469, objective=c, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.325 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.7735284245166385, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.7735284245166385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4387577382276503, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4387577382276503\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.987564474122745, reg_lambda=0 will be ignored. Current value: lambda_l2=4.987564474122745\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5640264788132076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5640264788132076\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[864]\tvalid_0's multi_logloss: 1.50513\n",
      "[CV 1/2] END bagging_fraction=0.4387577382276503, bagging_freq=9, feature_fraction=0.5640264788132076, lambda_l1=7.7735284245166385, lambda_l2=4.987564474122745, learning_rate=0.01, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=60, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.330 total time=  14.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.007354379783729, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.007354379783729\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.725497759707334, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.725497759707334\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.501917073754638, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.501917073754638\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8337531087866308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8337531087866308\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.51292\n",
      "[CV 1/2] END bagging_fraction=0.725497759707334, bagging_freq=7, feature_fraction=0.8337531087866308, lambda_l1=2.007354379783729, lambda_l2=5.501917073754638, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=67, objective=l, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=128;, score=0.328 total time=   2.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.007354379783729, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.007354379783729\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.725497759707334, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.725497759707334\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.501917073754638, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.501917073754638\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8337531087866308, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8337531087866308\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's multi_logloss: 1.50686\n",
      "[CV 2/2] END bagging_fraction=0.725497759707334, bagging_freq=7, feature_fraction=0.8337531087866308, lambda_l1=2.007354379783729, lambda_l2=5.501917073754638, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=67, objective=l, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=128;, score=0.328 total time=   2.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 1.49365\n",
      "[CV 1/2] END bagging_fraction=0.44463061452427544, bagging_freq=8, feature_fraction=0.4832047246025927, lambda_l1=1.0623886658661255, lambda_l2=9.945229271189298, learning_rate=0.05, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=304, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=32;, score=0.323 total time=  30.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0623886658661255, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0623886658661255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44463061452427544, subsample=0.6 will be ignored. Current value: bagging_fraction=0.44463061452427544\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.945229271189298, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=9.945229271189298\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4832047246025927, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4832047246025927\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's multi_logloss: 1.4931\n",
      "[CV 2/2] END bagging_fraction=0.44463061452427544, bagging_freq=8, feature_fraction=0.4832047246025927, lambda_l1=1.0623886658661255, lambda_l2=9.945229271189298, learning_rate=0.05, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=304, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=32;, score=0.332 total time=  27.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.916885105216373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.916885105216373\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.889985763779874, subsample=0.5 will be ignored. Current value: bagging_fraction=0.889985763779874\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.534031667433746, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.534031667433746\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8585974983522537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8585974983522537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 1.49922\n",
      "[CV 2/2] END bagging_fraction=0.889985763779874, bagging_freq=4, feature_fraction=0.8585974983522537, lambda_l1=5.916885105216373, lambda_l2=6.534031667433746, learning_rate=0.2, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=469, objective=c, reg_lambda=0.001, subsample=0.5, subsample_freq=16;, score=0.327 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.142560192669248, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.142560192669248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8756076017577863, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8756076017577863\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3606655561341228, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.3606655561341228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4038497152064839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4038497152064839\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's multi_logloss: 1.50452\n",
      "[CV 1/2] END bagging_fraction=0.8756076017577863, bagging_freq=7, feature_fraction=0.4038497152064839, lambda_l1=6.142560192669248, lambda_l2=2.3606655561341228, learning_rate=0.05, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=329, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=4;, score=0.326 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.142560192669248, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.142560192669248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8756076017577863, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8756076017577863\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3606655561341228, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.3606655561341228\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4038497152064839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4038497152064839\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=4 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 1.4958\n",
      "[CV 2/2] END bagging_fraction=0.8756076017577863, bagging_freq=7, feature_fraction=0.4038497152064839, lambda_l1=6.142560192669248, lambda_l2=2.3606655561341228, learning_rate=0.05, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=329, objective=l, reg_lambda=0.0001, subsample=0.6, subsample_freq=4;, score=0.331 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0364855157605229, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0364855157605229\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.677261896353643, subsample=0.6 will be ignored. Current value: bagging_fraction=0.677261896353643\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4208947500218905, reg_lambda=0 will be ignored. Current value: lambda_l2=2.4208947500218905\n",
      "[LightGBM] [Warning] feature_fraction is set=0.914145691501048, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.914145691501048\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 1.50134\n",
      "[CV 1/2] END bagging_fraction=0.677261896353643, bagging_freq=2, feature_fraction=0.914145691501048, lambda_l1=0.0364855157605229, lambda_l2=2.4208947500218905, learning_rate=0.05, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=497, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=8;, score=0.329 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.59218963700447, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.59218963700447\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8380496088691242, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8380496088691242\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2920972210691692, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.2920972210691692\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8976422059395484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8976422059395484\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's multi_logloss: 1.50101\n",
      "[CV 1/2] END bagging_fraction=0.8380496088691242, bagging_freq=5, feature_fraction=0.8976422059395484, lambda_l1=5.59218963700447, lambda_l2=2.2920972210691692, learning_rate=0.05, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=123, objective=a, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.329 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.486391883475193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.486391883475193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48602324843631567, subsample=0.7 will be ignored. Current value: bagging_fraction=0.48602324843631567\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.777627274264856, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.777627274264856\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9292256366274805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9292256366274805\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's multi_logloss: 1.48559\n",
      "[CV 1/2] END bagging_fraction=0.8382254076741243, bagging_freq=3, feature_fraction=0.4248759962840858, lambda_l1=0.7463084286899783, lambda_l2=3.648263411502385, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=447, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=128;, score=0.331 total time= 1.1min\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6178207459833267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6178207459833267\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9575749419772733, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9575749419772733\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8355042399642825, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.8355042399642825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8396190487407176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8396190487407176\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's multi_logloss: 1.49932\n",
      "[CV 2/2] END bagging_fraction=0.9575749419772733, bagging_freq=2, feature_fraction=0.8396190487407176, lambda_l1=3.6178207459833267, lambda_l2=3.8355042399642825, learning_rate=0.2, metric=multi_logloss, min_child_samples=77, num_class=5, num_leaves=188, objective=l, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=1;, score=0.329 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.404426167407319, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.404426167407319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.646837089966515, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.646837089966515\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0279703702459044, reg_lambda=0.001 will be ignored. Current value: lambda_l2=1.0279703702459044\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8238458980545058, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8238458980545058\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's multi_logloss: 1.49846\n",
      "[CV 2/2] END bagging_fraction=0.646837089966515, bagging_freq=9, feature_fraction=0.8238458980545058, lambda_l1=5.404426167407319, lambda_l2=1.0279703702459044, learning_rate=0.2, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=188, objective=t, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=16;, score=0.326 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.7735284245166385, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.7735284245166385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4387577382276503, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4387577382276503\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.987564474122745, reg_lambda=0 will be ignored. Current value: lambda_l2=4.987564474122745\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5640264788132076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5640264788132076\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=64 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's multi_logloss: 1.50082\n",
      "[CV 2/2] END bagging_fraction=0.4387577382276503, bagging_freq=9, feature_fraction=0.5640264788132076, lambda_l1=7.7735284245166385, lambda_l2=4.987564474122745, learning_rate=0.01, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=60, objective=c, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.332 total time=  12.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0364855157605229, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0364855157605229\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.677261896353643, subsample=0.6 will be ignored. Current value: bagging_fraction=0.677261896353643\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4208947500218905, reg_lambda=0 will be ignored. Current value: lambda_l2=2.4208947500218905\n",
      "[LightGBM] [Warning] feature_fraction is set=0.914145691501048, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.914145691501048\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=8 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_logloss: 1.5034\n",
      "[CV 2/2] END bagging_fraction=0.677261896353643, bagging_freq=2, feature_fraction=0.914145691501048, lambda_l1=0.0364855157605229, lambda_l2=2.4208947500218905, learning_rate=0.05, metric=multi_logloss, min_child_samples=59, num_class=5, num_leaves=497, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=8;, score=0.329 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.59218963700447, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.59218963700447\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8380496088691242, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8380496088691242\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2920972210691692, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=2.2920972210691692\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8976422059395484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8976422059395484\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 1.49632\n",
      "[CV 2/2] END bagging_fraction=0.8380496088691242, bagging_freq=5, feature_fraction=0.8976422059395484, lambda_l1=5.59218963700447, lambda_l2=2.2920972210691692, learning_rate=0.05, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=123, objective=a, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.328 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9007160537178397, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9007160537178397\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6338192949233163, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6338192949233163\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.766852428135888, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.766852428135888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9786456937167586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9786456937167586\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.51641\n",
      "[CV 1/2] END bagging_fraction=0.6338192949233163, bagging_freq=5, feature_fraction=0.9786456937167586, lambda_l1=0.9007160537178397, lambda_l2=8.766852428135888, learning_rate=0.2, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=217, objective=c, reg_lambda=1e-06, subsample=0.6, subsample_freq=64;, score=0.321 total time=   3.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9007160537178397, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9007160537178397\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6338192949233163, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6338192949233163\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.766852428135888, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=8.766852428135888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9786456937167586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9786456937167586\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.486391883475193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.486391883475193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48602324843631567, subsample=0.7 will be ignored. Current value: bagging_fraction=0.48602324843631567\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.777627274264856, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.777627274264856\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9292256366274805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9292256366274805\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.50039\n",
      "[CV 1/2] END bagging_fraction=0.48602324843631567, bagging_freq=3, feature_fraction=0.9292256366274805, lambda_l1=4.486391883475193, lambda_l2=4.777627274264856, learning_rate=0.2, metric=multi_logloss, min_child_samples=9, num_class=5, num_leaves=306, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.314 total time=   9.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.563571525546412, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.563571525546412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9285598545918459, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9285598545918459\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.843569725914644, reg_lambda=0 will be ignored. Current value: lambda_l2=6.843569725914644\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8425028644450205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8425028644450205\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's multi_logloss: 1.50667\n",
      "[CV 1/2] END bagging_fraction=0.9285598545918459, bagging_freq=7, feature_fraction=0.8425028644450205, lambda_l1=2.563571525546412, lambda_l2=6.843569725914644, learning_rate=0.01, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=402, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=32;, score=0.325 total time=  11.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.072602207877921, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.072602207877921\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5888348703511688, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5888348703511688\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5694914819332634, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.5694914819332634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41214670840591344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41214670840591344\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1260]\tvalid_0's multi_logloss: 1.48797\n",
      "[CV 2/2] END bagging_fraction=0.5888348703511688, bagging_freq=7, feature_fraction=0.41214670840591344, lambda_l1=8.072602207877921, lambda_l2=0.5694914819332634, learning_rate=0.01, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=278, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.332 total time=  46.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.403448662931559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.403448662931559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9667825833440544, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9667825833440544\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.565201700314147, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.565201700314147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4415160438180872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4415160438180872\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's multi_logloss: 1.49138\n",
      "[CV 1/2] END bagging_fraction=0.9667825833440544, bagging_freq=9, feature_fraction=0.4415160438180872, lambda_l1=4.403448662931559, lambda_l2=6.565201700314147, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=30, objective=u, reg_lambda=0.0001, subsample=0.7, subsample_freq=1;, score=0.337 total time=  12.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.403448662931559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.403448662931559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9667825833440544, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9667825833440544\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.565201700314147, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.565201700314147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4415160438180872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4415160438180872\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 1.4909\n",
      "[CV 2/2] END bagging_fraction=0.9667825833440544, bagging_freq=9, feature_fraction=0.4415160438180872, lambda_l1=4.403448662931559, lambda_l2=6.565201700314147, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=30, objective=u, reg_lambda=0.0001, subsample=0.7, subsample_freq=1;, score=0.336 total time=   8.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2386367758547106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2386367758547106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7486879095615557, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7486879095615557\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.599425996538204, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.599425996538204\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7433427890064084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7433427890064084\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's multi_logloss: 1.51209\n",
      "[CV 1/2] END bagging_fraction=0.7486879095615557, bagging_freq=6, feature_fraction=0.7433427890064084, lambda_l1=0.2386367758547106, lambda_l2=5.599425996538204, learning_rate=0.01, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=326, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=256;, score=0.326 total time=   7.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2386367758547106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2386367758547106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7486879095615557, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7486879095615557\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.599425996538204, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.599425996538204\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7433427890064084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7433427890064084\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's multi_logloss: 1.50334\n",
      "[CV 2/2] END bagging_fraction=0.7486879095615557, bagging_freq=6, feature_fraction=0.7433427890064084, lambda_l1=0.2386367758547106, lambda_l2=5.599425996538204, learning_rate=0.01, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=326, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=256;, score=0.330 total time=  10.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.540559220996936, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.540559220996936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8099410799731308, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8099410799731308\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.905563424115954, reg_lambda=0 will be ignored. Current value: lambda_l2=8.905563424115954\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4036139211047423, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4036139211047423\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 1.49027\n",
      "[CV 1/2] END bagging_fraction=0.8099410799731308, bagging_freq=4, feature_fraction=0.4036139211047423, lambda_l1=7.540559220996936, lambda_l2=8.905563424115954, learning_rate=0.2, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=86, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=16;, score=0.332 total time=   9.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.540559220996936, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.540559220996936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8099410799731308, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8099410799731308\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.905563424115954, reg_lambda=0 will be ignored. Current value: lambda_l2=8.905563424115954\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4036139211047423, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4036139211047423\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 1.48795\n",
      "[CV 2/2] END bagging_fraction=0.8099410799731308, bagging_freq=4, feature_fraction=0.4036139211047423, lambda_l1=7.540559220996936, lambda_l2=8.905563424115954, learning_rate=0.2, metric=multi_logloss, min_child_samples=16, num_class=5, num_leaves=86, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=16;, score=0.329 total time=   8.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9975158439537775, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9975158439537775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9138408608588268, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9138408608588268\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.518035079324006, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.518035079324006\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9283484545509527, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9283484545509527\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 1.49852\n",
      "[CV 1/2] END bagging_fraction=0.9138408608588268, bagging_freq=3, feature_fraction=0.9283484545509527, lambda_l1=3.9975158439537775, lambda_l2=8.518035079324006, learning_rate=0.05, metric=multi_logloss, min_child_samples=66, num_class=5, num_leaves=117, objective=c, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.329 total time=   5.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9975158439537775, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9975158439537775\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9138408608588268, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9138408608588268\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.518035079324006, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.518035079324006\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9283484545509527, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9283484545509527\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 1.4971\n",
      "[CV 2/2] END bagging_fraction=0.9138408608588268, bagging_freq=3, feature_fraction=0.9283484545509527, lambda_l1=3.9975158439537775, lambda_l2=8.518035079324006, learning_rate=0.05, metric=multi_logloss, min_child_samples=66, num_class=5, num_leaves=117, objective=c, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.327 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9440844805202842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9440844805202842\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9531335028170191, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9531335028170191\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8000171025420422, reg_lambda=0 will be ignored. Current value: lambda_l2=1.8000171025420422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7434017497241342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7434017497241342\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.50191\n",
      "[CV 1/2] END bagging_fraction=0.9531335028170191, bagging_freq=6, feature_fraction=0.7434017497241342, lambda_l1=1.9440844805202842, lambda_l2=1.8000171025420422, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=493, objective=u, reg_lambda=0, subsample=0.5, subsample_freq=4;, score=0.328 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9440844805202842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9440844805202842\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9531335028170191, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9531335028170191\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8000171025420422, reg_lambda=0 will be ignored. Current value: lambda_l2=1.8000171025420422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7434017497241342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7434017497241342\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 1.50208\n",
      "[CV 2/2] END bagging_fraction=0.9531335028170191, bagging_freq=6, feature_fraction=0.7434017497241342, lambda_l1=1.9440844805202842, lambda_l2=1.8000171025420422, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=493, objective=u, reg_lambda=0, subsample=0.5, subsample_freq=4;, score=0.331 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.148395150887541, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.148395150887541\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054829836119568, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9054829836119568\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.5944944917483825, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.5944944917483825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785925436239856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785925436239856\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1082]\tvalid_0's multi_logloss: 1.49944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.50821\n",
      "[CV 2/2] END bagging_fraction=0.6338192949233163, bagging_freq=5, feature_fraction=0.9786456937167586, lambda_l1=0.9007160537178397, lambda_l2=8.766852428135888, learning_rate=0.2, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=217, objective=c, reg_lambda=1e-06, subsample=0.6, subsample_freq=64;, score=0.320 total time=   3.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.563571525546412, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.563571525546412\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9285598545918459, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9285598545918459\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.843569725914644, reg_lambda=0 will be ignored. Current value: lambda_l2=6.843569725914644\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8425028644450205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8425028644450205\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=32 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid_0's multi_logloss: 1.50161\n",
      "[CV 2/2] END bagging_fraction=0.9285598545918459, bagging_freq=7, feature_fraction=0.8425028644450205, lambda_l1=2.563571525546412, lambda_l2=6.843569725914644, learning_rate=0.01, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=402, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=32;, score=0.333 total time=  10.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.186190662795218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.186190662795218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770070127243937, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.770070127243937\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.954162563711502, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.954162563711502\n",
      "[LightGBM] [Warning] feature_fraction is set=0.40016233707611376, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.40016233707611376\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[404]\tvalid_0's multi_logloss: 1.49052\n",
      "[CV 1/2] END bagging_fraction=0.770070127243937, bagging_freq=4, feature_fraction=0.40016233707611376, lambda_l1=8.186190662795218, lambda_l2=4.954162563711502, learning_rate=0.05, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=194, objective=u, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.333 total time=  22.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.195313834029086, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.195313834029086\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.883448650212604, subsample=0.6 will be ignored. Current value: bagging_fraction=0.883448650212604\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.125866041615295, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.125866041615295\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41799648570711473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41799648570711473\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1374]\tvalid_0's multi_logloss: 1.48719\n",
      "[CV 1/2] END bagging_fraction=0.883448650212604, bagging_freq=3, feature_fraction=0.41799648570711473, lambda_l1=8.195313834029086, lambda_l2=8.125866041615295, learning_rate=0.01, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=195, objective=l, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.333 total time= 2.4min\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.874910790083747, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.874910790083747\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.81988594134626, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.81988594134626\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6581215840646713, reg_lambda=0 will be ignored. Current value: lambda_l2=2.6581215840646713\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48912287383409864, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48912287383409864\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 1.4946\n",
      "[CV 2/2] END bagging_fraction=0.81988594134626, bagging_freq=6, feature_fraction=0.48912287383409864, lambda_l1=5.874910790083747, lambda_l2=2.6581215840646713, learning_rate=0.05, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=449, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=4;, score=0.329 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9713021258788201, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9713021258788201\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6111900324653282, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6111900324653282\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6046265355025463, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.6046265355025463\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47467154131201866, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47467154131201866\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's multi_logloss: 1.51764\n",
      "[CV 1/2] END bagging_fraction=0.6111900324653282, bagging_freq=9, feature_fraction=0.47467154131201866, lambda_l1=1.9713021258788201, lambda_l2=0.6046265355025463, learning_rate=0.01, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=312, objective=c, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.325 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5067345208522585, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5067345208522585\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8929820975736451, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8929820975736451\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.337138533533041, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.337138533533041\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6714997027383316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6714997027383316\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's multi_logloss: 1.49351\n",
      "[CV 1/2] END bagging_fraction=0.8929820975736451, bagging_freq=2, feature_fraction=0.6714997027383316, lambda_l1=3.5067345208522585, lambda_l2=9.337138533533041, learning_rate=0.2, metric=multi_logloss, min_child_samples=23, num_class=5, num_leaves=169, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=128;, score=0.330 total time=   8.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.539933156226406, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.539933156226406\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7140938733907936, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7140938733907936\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.57386954515618, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.57386954515618\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554122980023883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554122980023883\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=256 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 1.49988\n",
      "[CV 2/2] END bagging_fraction=0.48602324843631567, bagging_freq=3, feature_fraction=0.9292256366274805, lambda_l1=4.486391883475193, lambda_l2=4.777627274264856, learning_rate=0.2, metric=multi_logloss, min_child_samples=9, num_class=5, num_leaves=306, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.324 total time=   9.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.072602207877921, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.072602207877921\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5888348703511688, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5888348703511688\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5694914819332634, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.5694914819332634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41214670840591344, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41214670840591344\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[672]\tvalid_0's multi_logloss: 1.49926\n",
      "[CV 1/2] END bagging_fraction=0.5888348703511688, bagging_freq=7, feature_fraction=0.41214670840591344, lambda_l1=8.072602207877921, lambda_l2=0.5694914819332634, learning_rate=0.01, metric=multi_logloss, min_child_samples=15, num_class=5, num_leaves=278, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=64;, score=0.334 total time=  22.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.186190662795218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.186190662795218\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770070127243937, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.770070127243937\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.954162563711502, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.954162563711502\n",
      "[LightGBM] [Warning] feature_fraction is set=0.40016233707611376, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.40016233707611376\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's multi_logloss: 1.48548\n",
      "[CV 2/2] END bagging_fraction=0.770070127243937, bagging_freq=4, feature_fraction=0.40016233707611376, lambda_l1=8.186190662795218, lambda_l2=4.954162563711502, learning_rate=0.05, metric=multi_logloss, min_child_samples=11, num_class=5, num_leaves=194, objective=u, reg_lambda=0.001, subsample=0.8999999999999999, subsample_freq=64;, score=0.334 total time=  16.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.195313834029086, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.195313834029086\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.883448650212604, subsample=0.6 will be ignored. Current value: bagging_fraction=0.883448650212604\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.125866041615295, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.125866041615295\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41799648570711473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41799648570711473\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=4 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1281]\tvalid_0's multi_logloss: 1.48436\n",
      "[CV 2/2] END bagging_fraction=0.883448650212604, bagging_freq=3, feature_fraction=0.41799648570711473, lambda_l1=8.195313834029086, lambda_l2=8.125866041615295, learning_rate=0.01, metric=multi_logloss, min_child_samples=5, num_class=5, num_leaves=195, objective=l, reg_lambda=0.001, subsample=0.6, subsample_freq=4;, score=0.336 total time= 2.3min\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.874910790083747, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.874910790083747\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.81988594134626, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.81988594134626\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6581215840646713, reg_lambda=0 will be ignored. Current value: lambda_l2=2.6581215840646713\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48912287383409864, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48912287383409864\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=4 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's multi_logloss: 1.49765\n",
      "[CV 1/2] END bagging_fraction=0.81988594134626, bagging_freq=6, feature_fraction=0.48912287383409864, lambda_l1=5.874910790083747, lambda_l2=2.6581215840646713, learning_rate=0.05, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=449, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=4;, score=0.330 total time=   7.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.659375327086715, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.659375327086715\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8158050202114389, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8158050202114389\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.763840781371156, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.763840781371156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7481731767902333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7481731767902333\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.48847\n",
      "[CV 2/2] END bagging_fraction=0.8158050202114389, bagging_freq=6, feature_fraction=0.7481731767902333, lambda_l1=7.659375327086715, lambda_l2=7.763840781371156, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=349, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=1;, score=0.330 total time=   9.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5067345208522585, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5067345208522585\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8929820975736451, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8929820975736451\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.337138533533041, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.337138533533041\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6714997027383316, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6714997027383316\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 1.49145\n",
      "[CV 2/2] END bagging_fraction=0.8929820975736451, bagging_freq=2, feature_fraction=0.6714997027383316, lambda_l1=3.5067345208522585, lambda_l2=9.337138533533041, learning_rate=0.2, metric=multi_logloss, min_child_samples=23, num_class=5, num_leaves=169, objective=a, reg_lambda=1e-06, subsample=0.7, subsample_freq=128;, score=0.329 total time=   7.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.539933156226406, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.539933156226406\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7140938733907936, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7140938733907936\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.57386954515618, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.57386954515618\n",
      "[CV 1/2] END bagging_fraction=0.9054829836119568, bagging_freq=3, feature_fraction=0.785925436239856, lambda_l1=7.148395150887541, lambda_l2=5.5944944917483825, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=428, objective=c, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.328 total time=  24.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.148395150887541, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.148395150887541\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9054829836119568, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9054829836119568\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.5944944917483825, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.5944944917483825\n",
      "[LightGBM] [Warning] feature_fraction is set=0.785925436239856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.785925436239856\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[775]\tvalid_0's multi_logloss: 1.49502\n",
      "[CV 2/2] END bagging_fraction=0.9054829836119568, bagging_freq=3, feature_fraction=0.785925436239856, lambda_l1=7.148395150887541, lambda_l2=5.5944944917483825, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=428, objective=c, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.329 total time=  24.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.659375327086715, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.659375327086715\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8158050202114389, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8158050202114389\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.763840781371156, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.763840781371156\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7481731767902333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7481731767902333\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=1 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's multi_logloss: 1.49561\n",
      "[CV 1/2] END bagging_fraction=0.8158050202114389, bagging_freq=6, feature_fraction=0.7481731767902333, lambda_l1=7.659375327086715, lambda_l2=7.763840781371156, learning_rate=0.2, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=349, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=1;, score=0.326 total time=   9.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9713021258788201, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9713021258788201\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6111900324653282, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6111900324653282\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6046265355025463, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.6046265355025463\n",
      "[LightGBM] [Warning] feature_fraction is set=0.47467154131201866, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47467154131201866\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[486]\tvalid_0's multi_logloss: 1.50422\n",
      "[CV 2/2] END bagging_fraction=0.6111900324653282, bagging_freq=9, feature_fraction=0.47467154131201866, lambda_l1=1.9713021258788201, lambda_l2=0.6046265355025463, learning_rate=0.01, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=312, objective=c, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.325 total time=   9.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.381900688967903, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.381900688967903\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6598171418802372, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6598171418802372\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6431454407931991, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.6431454407931991\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5280749263649669, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5280749263649669\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=256 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's multi_logloss: 1.49106\n",
      "[CV 1/2] END bagging_fraction=0.6598171418802372, bagging_freq=4, feature_fraction=0.5280749263649669, lambda_l1=6.381900688967903, lambda_l2=1.6431454407931991, learning_rate=0.05, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=405, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=256;, score=0.329 total time=  36.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.049320369346574085, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.049320369346574085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9871749967799851, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9871749967799851\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.514405200145508, reg_lambda=0 will be ignored. Current value: lambda_l2=5.514405200145508\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4739244425250513, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4739244425250513\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's multi_logloss: 1.48638\n",
      "[CV 1/2] END bagging_fraction=0.9871749967799851, bagging_freq=4, feature_fraction=0.4739244425250513, lambda_l1=0.049320369346574085, lambda_l2=5.514405200145508, learning_rate=0.01, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=210, objective=t, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.330 total time=  49.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.276490185866262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.276490185866262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7790350677812578, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7790350677812578\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.382049352876492, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.382049352876492\n",
      "[LightGBM] [Warning] feature_fraction is set=0.700384147952767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.700384147952767\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 1.50115\n",
      "[CV 1/2] END bagging_fraction=0.7790350677812578, bagging_freq=9, feature_fraction=0.700384147952767, lambda_l1=8.276490185866262, lambda_l2=4.382049352876492, learning_rate=0.2, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=430, objective=c, reg_lambda=1e-06, subsample=0.6, subsample_freq=256;, score=0.330 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.276490185866262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.276490185866262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7790350677812578, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7790350677812578\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.382049352876492, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=4.382049352876492\n",
      "[LightGBM] [Warning] feature_fraction is set=0.700384147952767, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.700384147952767\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 1.49613\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's multi_logloss: 1.49691\n",
      "[CV 1/2] END bagging_fraction=0.7140938733907936, bagging_freq=8, feature_fraction=0.5554122980023883, lambda_l1=8.539933156226406, lambda_l2=4.57386954515618, learning_rate=0.2, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=215, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=4;, score=0.329 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.445437894130281, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445437894130281\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677088364987809, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6677088364987809\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.793033581804403, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.793033581804403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.898881694301326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.898881694301326\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's multi_logloss: 1.49045\n",
      "[CV 1/2] END bagging_fraction=0.6677088364987809, bagging_freq=7, feature_fraction=0.898881694301326, lambda_l1=3.445437894130281, lambda_l2=2.793033581804403, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=215, objective=i, reg_lambda=1e-07, subsample=0.5, subsample_freq=128;, score=0.328 total time=  49.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.049320369346574085, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.049320369346574085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9871749967799851, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9871749967799851\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.514405200145508, reg_lambda=0 will be ignored. Current value: lambda_l2=5.514405200145508\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4739244425250513, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4739244425250513\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=16 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 1.49354\n",
      "[CV 2/2] END bagging_fraction=0.9871749967799851, bagging_freq=4, feature_fraction=0.4739244425250513, lambda_l1=0.049320369346574085, lambda_l2=5.514405200145508, learning_rate=0.01, metric=multi_logloss, min_child_samples=12, num_class=5, num_leaves=210, objective=t, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.330 total time=  44.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.270524082473448, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.270524082473448\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5032573955434505, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5032573955434505\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7765192647019085, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.7765192647019085\n",
      "[LightGBM] [Warning] feature_fraction is set=0.554047391060121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554047391060121\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.5241\n",
      "[CV 1/2] END bagging_fraction=0.5032573955434505, bagging_freq=8, feature_fraction=0.554047391060121, lambda_l1=5.270524082473448, lambda_l2=0.7765192647019085, learning_rate=0.2, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=207, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=32;, score=0.325 total time=   1.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.270524082473448, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.270524082473448\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5032573955434505, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5032573955434505\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7765192647019085, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=0.7765192647019085\n",
      "[LightGBM] [Warning] feature_fraction is set=0.554047391060121, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554047391060121\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 1.50949\n",
      "[CV 2/2] END bagging_fraction=0.5032573955434505, bagging_freq=8, feature_fraction=0.554047391060121, lambda_l1=5.270524082473448, lambda_l2=0.7765192647019085, learning_rate=0.2, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=207, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=32;, score=0.320 total time=   2.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.427327680856335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.427327680856335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7221589838276068, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7221589838276068\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.508595581466181, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.508595581466181\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5488060877854647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5488060877854647\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's multi_logloss: 1.49636\n",
      "[CV 2/2] END bagging_fraction=0.7221589838276068, bagging_freq=8, feature_fraction=0.5488060877854647, lambda_l1=8.427327680856335, lambda_l2=2.508595581466181, learning_rate=0.05, metric=multi_logloss, min_child_samples=66, num_class=5, num_leaves=369, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=4;, score=0.330 total time=   6.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1385384504738827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1385384504738827\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9568935921537326, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9568935921537326\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.990390658258348, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.990390658258348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8386177289447867, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8386177289447867\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 1.50775\n",
      "[CV 1/2] END bagging_fraction=0.9568935921537326, bagging_freq=8, feature_fraction=0.8386177289447867, lambda_l1=2.1385384504738827, lambda_l2=7.990390658258348, learning_rate=0.2, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=339, objective=a, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.325 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.668824589747643, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.668824589747643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917279955681458, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9917279955681458\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.512259001930591, reg_lambda=0 will be ignored. Current value: lambda_l2=9.512259001930591\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554122980023883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554122980023883\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 1.49681\n",
      "[CV 2/2] END bagging_fraction=0.7140938733907936, bagging_freq=8, feature_fraction=0.5554122980023883, lambda_l1=8.539933156226406, lambda_l2=4.57386954515618, learning_rate=0.2, metric=multi_logloss, min_child_samples=42, num_class=5, num_leaves=215, objective=l, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=4;, score=0.326 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.381900688967903, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.381900688967903\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6598171418802372, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6598171418802372\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6431454407931991, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.6431454407931991\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5280749263649669, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5280749263649669\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=256 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 1.48923\n",
      "[CV 2/2] END bagging_fraction=0.6598171418802372, bagging_freq=4, feature_fraction=0.5280749263649669, lambda_l1=6.381900688967903, lambda_l2=1.6431454407931991, learning_rate=0.05, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=405, objective=i, reg_lambda=1e-05, subsample=0.7, subsample_freq=256;, score=0.336 total time=  26.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.445437894130281, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445437894130281\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677088364987809, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6677088364987809\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.793033581804403, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.793033581804403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.898881694301326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.898881694301326\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 1.49352\n",
      "[CV 2/2] END bagging_fraction=0.6677088364987809, bagging_freq=7, feature_fraction=0.898881694301326, lambda_l1=3.445437894130281, lambda_l2=2.793033581804403, learning_rate=0.01, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=215, objective=i, reg_lambda=1e-07, subsample=0.5, subsample_freq=128;, score=0.333 total time=  32.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2607978393521762, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2607978393521762\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9130470800815934, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9130470800815934\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.52713124094661, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.52713124094661\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7565075103545849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7565075103545849\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's multi_logloss: 1.49452\n",
      "[CV 1/2] END bagging_fraction=0.9130470800815934, bagging_freq=3, feature_fraction=0.7565075103545849, lambda_l1=0.2607978393521762, lambda_l2=6.52713124094661, learning_rate=0.01, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=243, objective=l, reg_lambda=0.001, subsample=0.5, subsample_freq=64;, score=0.331 total time=  20.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2607978393521762, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2607978393521762\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9130470800815934, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9130470800815934\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.52713124094661, reg_lambda=0.001 will be ignored. Current value: lambda_l2=6.52713124094661\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7565075103545849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7565075103545849\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's multi_logloss: 1.49791\n",
      "[CV 2/2] END bagging_fraction=0.9130470800815934, bagging_freq=3, feature_fraction=0.7565075103545849, lambda_l1=0.2607978393521762, lambda_l2=6.52713124094661, learning_rate=0.01, metric=multi_logloss, min_child_samples=40, num_class=5, num_leaves=243, objective=l, reg_lambda=0.001, subsample=0.5, subsample_freq=64;, score=0.325 total time=  19.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.427327680856335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.427327680856335\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7221589838276068, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7221589838276068\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.508595581466181, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.508595581466181\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5488060877854647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5488060877854647\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's multi_logloss: 1.50239\n",
      "[CV 1/2] END bagging_fraction=0.7221589838276068, bagging_freq=8, feature_fraction=0.5488060877854647, lambda_l1=8.427327680856335, lambda_l2=2.508595581466181, learning_rate=0.05, metric=multi_logloss, min_child_samples=66, num_class=5, num_leaves=369, objective=l, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=4;, score=0.327 total time=   6.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1385384504738827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1385384504738827\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9568935921537326, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.9568935921537326\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.990390658258348, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.990390658258348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8386177289447867, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8386177289447867\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.50254\n",
      "[CV 2/2] END bagging_fraction=0.9568935921537326, bagging_freq=8, feature_fraction=0.8386177289447867, lambda_l1=2.1385384504738827, lambda_l2=7.990390658258348, learning_rate=0.2, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=339, objective=a, reg_lambda=0.0001, subsample=0.8999999999999999, subsample_freq=128;, score=0.329 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.2254615834441074, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2254615834441074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7116908721569599, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7116908721569599\n",
      "[CV 2/2] END bagging_fraction=0.7790350677812578, bagging_freq=9, feature_fraction=0.700384147952767, lambda_l1=8.276490185866262, lambda_l2=4.382049352876492, learning_rate=0.2, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=430, objective=c, reg_lambda=1e-06, subsample=0.6, subsample_freq=256;, score=0.330 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3078064569762373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3078064569762373\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6549505503345534, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6549505503345534\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.9548249605812655, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.9548249605812655\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9056713116796064, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9056713116796064\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.50454\n",
      "[CV 1/2] END bagging_fraction=0.6549505503345534, bagging_freq=7, feature_fraction=0.9056713116796064, lambda_l1=1.3078064569762373, lambda_l2=6.9548249605812655, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=150, objective=s, reg_lambda=0.0001, subsample=0.6, subsample_freq=128;, score=0.330 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3078064569762373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3078064569762373\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6549505503345534, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6549505503345534\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.9548249605812655, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.9548249605812655\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9056713116796064, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9056713116796064\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.50348\n",
      "[CV 2/2] END bagging_fraction=0.6549505503345534, bagging_freq=7, feature_fraction=0.9056713116796064, lambda_l1=1.3078064569762373, lambda_l2=6.9548249605812655, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=150, objective=s, reg_lambda=0.0001, subsample=0.6, subsample_freq=128;, score=0.326 total time=   5.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.549273571174548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.549273571174548\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9769132692603799, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9769132692603799\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9079410969412995, reg_lambda=0 will be ignored. Current value: lambda_l2=5.9079410969412995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236190196080072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236190196080072\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's multi_logloss: 1.49722\n",
      "[CV 1/2] END bagging_fraction=0.9769132692603799, bagging_freq=3, feature_fraction=0.9236190196080072, lambda_l1=4.549273571174548, lambda_l2=5.9079410969412995, learning_rate=0.2, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=105, objective=i, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=1;, score=0.328 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.549273571174548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.549273571174548\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9769132692603799, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9769132692603799\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9079410969412995, reg_lambda=0 will be ignored. Current value: lambda_l2=5.9079410969412995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236190196080072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236190196080072\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49697\n",
      "[CV 2/2] END bagging_fraction=0.9769132692603799, bagging_freq=3, feature_fraction=0.9236190196080072, lambda_l1=4.549273571174548, lambda_l2=5.9079410969412995, learning_rate=0.2, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=105, objective=i, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=1;, score=0.328 total time=   3.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.668824589747643, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.668824589747643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917279955681458, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9917279955681458\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.512259001930591, reg_lambda=0 will be ignored. Current value: lambda_l2=9.512259001930591\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7821232707026822, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7821232707026822\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's multi_logloss: 1.49914\n",
      "[CV 1/2] END bagging_fraction=0.9917279955681458, bagging_freq=6, feature_fraction=0.7821232707026822, lambda_l1=6.668824589747643, lambda_l2=9.512259001930591, learning_rate=0.05, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=369, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=32;, score=0.328 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.2254615834441074, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.2254615834441074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7116908721569599, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7116908721569599\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9785567333322707, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.9785567333322707\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774970997259239, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774970997259239\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's multi_logloss: 1.49538\n",
      "[CV 2/2] END bagging_fraction=0.7116908721569599, bagging_freq=9, feature_fraction=0.9774970997259239, lambda_l1=3.2254615834441074, lambda_l2=3.9785567333322707, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=266, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=32;, score=0.330 total time=  18.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.778668430070601, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.778668430070601\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8117316354406015, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8117316354406015\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.273240926333881, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.273240926333881\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4386245442856647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4386245442856647\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7821232707026822, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7821232707026822\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=32 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 1.49507\n",
      "[CV 2/2] END bagging_fraction=0.9917279955681458, bagging_freq=6, feature_fraction=0.7821232707026822, lambda_l1=6.668824589747643, lambda_l2=9.512259001930591, learning_rate=0.05, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=369, objective=s, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=32;, score=0.330 total time=   6.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.540780520513605, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.540780520513605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.403752880101497, subsample=0.6 will be ignored. Current value: bagging_fraction=0.403752880101497\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.047261773506866, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.047261773506866\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5810145972320477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5810145972320477\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's multi_logloss: 1.51575\n",
      "[CV 1/2] END bagging_fraction=0.403752880101497, bagging_freq=4, feature_fraction=0.5810145972320477, lambda_l1=2.540780520513605, lambda_l2=9.047261773506866, learning_rate=0.01, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=312, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.325 total time=   6.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.540780520513605, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.540780520513605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.403752880101497, subsample=0.6 will be ignored. Current value: bagging_fraction=0.403752880101497\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.047261773506866, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.047261773506866\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5810145972320477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5810145972320477\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[566]\tvalid_0's multi_logloss: 1.50311\n",
      "[CV 2/2] END bagging_fraction=0.403752880101497, bagging_freq=4, feature_fraction=0.5810145972320477, lambda_l1=2.540780520513605, lambda_l2=9.047261773506866, learning_rate=0.01, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=312, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.326 total time=   9.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.407217607435311, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.407217607435311\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9065917487139171, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9065917487139171\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1508277263461073, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.1508277263461073\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6045163325692284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6045163325692284\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[621]\tvalid_0's multi_logloss: 1.49392\n",
      "[CV 2/2] END bagging_fraction=0.9065917487139171, bagging_freq=9, feature_fraction=0.6045163325692284, lambda_l1=7.407217607435311, lambda_l2=3.1508277263461073, learning_rate=0.01, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=445, objective=c, reg_lambda=0.0001, subsample=0.5, subsample_freq=4;, score=0.330 total time=  19.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.00262183783214, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.00262183783214\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6144945820275098, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6144945820275098\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.842089674063936, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.842089674063936\n",
      "[LightGBM] [Warning] feature_fraction is set=0.888957508910422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.888957508910422\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's multi_logloss: 1.50603\n",
      "[CV 1/2] END bagging_fraction=0.6144945820275098, bagging_freq=9, feature_fraction=0.888957508910422, lambda_l1=9.00262183783214, lambda_l2=3.842089674063936, learning_rate=0.01, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=490, objective=l, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=1;, score=0.328 total time=   8.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.14941554555466, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.14941554555466\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46774916193661653, subsample=0.6 will be ignored. Current value: bagging_fraction=0.46774916193661653\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.969144654447159, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.969144654447159\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9646911902343359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9646911902343359\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's multi_logloss: 1.51475\n",
      "[CV 1/2] END bagging_fraction=0.46774916193661653, bagging_freq=6, feature_fraction=0.9646911902343359, lambda_l1=8.14941554555466, lambda_l2=6.969144654447159, learning_rate=0.05, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=61, objective=a, reg_lambda=1e-07, subsample=0.6, subsample_freq=128;, score=0.324 total time=   4.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.14941554555466, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.14941554555466\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46774916193661653, subsample=0.6 will be ignored. Current value: bagging_fraction=0.46774916193661653\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.969144654447159, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.969144654447159\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9646911902343359, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9646911902343359\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[378]\tvalid_0's multi_logloss: 1.50025\n",
      "[CV 2/2] END bagging_fraction=0.46774916193661653, bagging_freq=6, feature_fraction=0.9646911902343359, lambda_l1=8.14941554555466, lambda_l2=6.969144654447159, learning_rate=0.05, metric=multi_logloss, min_child_samples=79, num_class=5, num_leaves=61, objective=a, reg_lambda=1e-07, subsample=0.6, subsample_freq=128;, score=0.322 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3526001373344405, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3526001373344405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8969895696347261, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8969895696347261\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.215507069659847, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.215507069659847\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9785567333322707, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.9785567333322707\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9774970997259239, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9774970997259239\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's multi_logloss: 1.49191\n",
      "[CV 1/2] END bagging_fraction=0.7116908721569599, bagging_freq=9, feature_fraction=0.9774970997259239, lambda_l1=3.2254615834441074, lambda_l2=3.9785567333322707, learning_rate=0.01, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=266, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=32;, score=0.331 total time=  20.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.407217607435311, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.407217607435311\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9065917487139171, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9065917487139171\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1508277263461073, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.1508277263461073\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6045163325692284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6045163325692284\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's multi_logloss: 1.49813\n",
      "[CV 1/2] END bagging_fraction=0.9065917487139171, bagging_freq=9, feature_fraction=0.6045163325692284, lambda_l1=7.407217607435311, lambda_l2=3.1508277263461073, learning_rate=0.01, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=445, objective=c, reg_lambda=0.0001, subsample=0.5, subsample_freq=4;, score=0.335 total time=  18.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.778668430070601, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.778668430070601\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8117316354406015, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8117316354406015\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.273240926333881, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=7.273240926333881\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4386245442856647, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4386245442856647\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[622]\tvalid_0's multi_logloss: 1.49164\n",
      "[CV 2/2] END bagging_fraction=0.8117316354406015, bagging_freq=9, feature_fraction=0.4386245442856647, lambda_l1=4.778668430070601, lambda_l2=7.273240926333881, learning_rate=0.01, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=261, objective=m, reg_lambda=1e-06, subsample=0.6, subsample_freq=1;, score=0.329 total time=  23.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8272068857501683, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8272068857501683\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6454197323767829, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6454197323767829\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.051081900059984, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.051081900059984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.845491661709402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.845491661709402\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[300]\tvalid_0's multi_logloss: 1.49857\n",
      "[CV 1/2] END bagging_fraction=0.6454197323767829, bagging_freq=4, feature_fraction=0.845491661709402, lambda_l1=0.8272068857501683, lambda_l2=5.051081900059984, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=247, objective=c, reg_lambda=1e-06, subsample=0.7, subsample_freq=64;, score=0.330 total time=  14.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8272068857501683, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8272068857501683\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6454197323767829, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6454197323767829\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.051081900059984, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.051081900059984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.845491661709402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.845491661709402\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's multi_logloss: 1.49872\n",
      "[CV 2/2] END bagging_fraction=0.6454197323767829, bagging_freq=4, feature_fraction=0.845491661709402, lambda_l1=0.8272068857501683, lambda_l2=5.051081900059984, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=247, objective=c, reg_lambda=1e-06, subsample=0.7, subsample_freq=64;, score=0.330 total time=  11.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0648258482625663, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0648258482625663\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48555530602945063, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.48555530602945063\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.77651360552988, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.77651360552988\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9854209077188928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9854209077188928\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 1.52032\n",
      "[CV 1/2] END bagging_fraction=0.48555530602945063, bagging_freq=7, feature_fraction=0.9854209077188928, lambda_l1=1.0648258482625663, lambda_l2=3.77651360552988, learning_rate=0.05, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=123, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=128;, score=0.326 total time=   3.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0648258482625663, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0648258482625663\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48555530602945063, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.48555530602945063\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.77651360552988, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=3.77651360552988\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9854209077188928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9854209077188928\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.50843\n",
      "[CV 2/2] END bagging_fraction=0.48555530602945063, bagging_freq=7, feature_fraction=0.9854209077188928, lambda_l1=1.0648258482625663, lambda_l2=3.77651360552988, learning_rate=0.05, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=123, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=128;, score=0.322 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.403074821568154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.403074821568154\n",
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's multi_logloss: 1.49507\n",
      "[CV 1/2] END bagging_fraction=0.8117316354406015, bagging_freq=9, feature_fraction=0.4386245442856647, lambda_l1=4.778668430070601, lambda_l2=7.273240926333881, learning_rate=0.01, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=261, objective=m, reg_lambda=1e-06, subsample=0.6, subsample_freq=1;, score=0.335 total time=  20.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.00262183783214, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.00262183783214\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6144945820275098, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6144945820275098\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.842089674063936, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.842089674063936\n",
      "[LightGBM] [Warning] feature_fraction is set=0.888957508910422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.888957508910422\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=1 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[835]\tvalid_0's multi_logloss: 1.49772\n",
      "[CV 2/2] END bagging_fraction=0.6144945820275098, bagging_freq=9, feature_fraction=0.888957508910422, lambda_l1=9.00262183783214, lambda_l2=3.842089674063936, learning_rate=0.01, metric=multi_logloss, min_child_samples=54, num_class=5, num_leaves=490, objective=l, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=1;, score=0.330 total time=  14.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3526001373344405, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3526001373344405\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8969895696347261, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8969895696347261\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.215507069659847, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.215507069659847\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41184274701829715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41184274701829715\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 1.4961\n",
      "[CV 1/2] END bagging_fraction=0.8969895696347261, bagging_freq=3, feature_fraction=0.41184274701829715, lambda_l1=3.3526001373344405, lambda_l2=7.215507069659847, learning_rate=0.2, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=496, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.333 total time=  24.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.605928904202117, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.605928904202117\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5931524077482327, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5931524077482327\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8684417795631054, reg_lambda=0 will be ignored. Current value: lambda_l2=3.8684417795631054\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8996716094041585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8996716094041585\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1008]\tvalid_0's multi_logloss: 1.49682\n",
      "[CV 1/2] END bagging_fraction=0.5931524077482327, bagging_freq=2, feature_fraction=0.8996716094041585, lambda_l1=4.605928904202117, lambda_l2=3.8684417795631054, learning_rate=0.01, metric=multi_logloss, min_child_samples=45, num_class=5, num_leaves=16, objective=t, reg_lambda=0, subsample=0.5, subsample_freq=1;, score=0.333 total time=  14.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.574272714952858, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.574272714952858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46206563828990377, subsample=0.6 will be ignored. Current value: bagging_fraction=0.46206563828990377\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.434898339484234, reg_lambda=0 will be ignored. Current value: lambda_l2=2.434898339484234\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7960259380425763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7960259380425763\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's multi_logloss: 1.50084\n",
      "[CV 1/2] END bagging_fraction=0.46206563828990377, bagging_freq=7, feature_fraction=0.7960259380425763, lambda_l1=8.574272714952858, lambda_l2=2.434898339484234, learning_rate=0.2, metric=multi_logloss, min_child_samples=18, num_class=5, num_leaves=154, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.329 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.574272714952858, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.574272714952858\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46206563828990377, subsample=0.6 will be ignored. Current value: bagging_fraction=0.46206563828990377\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.434898339484234, reg_lambda=0 will be ignored. Current value: lambda_l2=2.434898339484234\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7960259380425763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7960259380425763\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's multi_logloss: 1.49914\n",
      "[CV 2/2] END bagging_fraction=0.46206563828990377, bagging_freq=7, feature_fraction=0.7960259380425763, lambda_l1=8.574272714952858, lambda_l2=2.434898339484234, learning_rate=0.2, metric=multi_logloss, min_child_samples=18, num_class=5, num_leaves=154, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.323 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.006162734811224, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.006162734811224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8682608216639864, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8682608216639864\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.156572052513294, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.156572052513294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8420113131835731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8420113131835731\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 1.49788\n",
      "[CV 1/2] END bagging_fraction=0.8682608216639864, bagging_freq=8, feature_fraction=0.8420113131835731, lambda_l1=7.006162734811224, lambda_l2=9.156572052513294, learning_rate=0.2, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=366, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=16;, score=0.330 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.006162734811224, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.006162734811224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8682608216639864, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8682608216639864\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.156572052513294, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.156572052513294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8420113131835731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8420113131835731\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4982490913698059, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4982490913698059\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1460611981898274, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.1460611981898274\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7708394211810332, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7708394211810332\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's multi_logloss: 1.48943\n",
      "[CV 1/2] END bagging_fraction=0.4982490913698059, bagging_freq=6, feature_fraction=0.7708394211810332, lambda_l1=3.403074821568154, lambda_l2=1.1460611981898274, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=472, objective=a, reg_lambda=1e-05, subsample=0.7, subsample_freq=16;, score=0.329 total time=  51.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.161666819572764, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.161666819572764\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137434700482415, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9137434700482415\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.827340569036849, reg_lambda=0 will be ignored. Current value: lambda_l2=2.827340569036849\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8035312792863283, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8035312792863283\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 1.49371\n",
      "[CV 2/2] END bagging_fraction=0.9137434700482415, bagging_freq=7, feature_fraction=0.8035312792863283, lambda_l1=5.161666819572764, lambda_l2=2.827340569036849, learning_rate=0.05, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=310, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.333 total time=   8.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.540197591163274, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.540197591163274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.61616468219567, subsample=0.6 will be ignored. Current value: bagging_fraction=0.61616468219567\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.908479838420989, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.908479838420989\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5755989940995514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5755989940995514\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 1.5206\n",
      "[CV 1/2] END bagging_fraction=0.61616468219567, bagging_freq=7, feature_fraction=0.5755989940995514, lambda_l1=2.540197591163274, lambda_l2=2.908479838420989, learning_rate=0.2, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=285, objective=m, reg_lambda=1e-05, subsample=0.6, subsample_freq=8;, score=0.323 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.540197591163274, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.540197591163274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.61616468219567, subsample=0.6 will be ignored. Current value: bagging_fraction=0.61616468219567\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.908479838420989, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=2.908479838420989\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5755989940995514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5755989940995514\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=8 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's multi_logloss: 1.50568\n",
      "[CV 2/2] END bagging_fraction=0.61616468219567, bagging_freq=7, feature_fraction=0.5755989940995514, lambda_l1=2.540197591163274, lambda_l2=2.908479838420989, learning_rate=0.2, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=285, objective=m, reg_lambda=1e-05, subsample=0.6, subsample_freq=8;, score=0.323 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.598234364995042, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.598234364995042\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680386831246852, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5680386831246852\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6176789808297012, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.6176789808297012\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9530357755300428, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9530357755300428\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 1.5101\n",
      "[CV 1/2] END bagging_fraction=0.5680386831246852, bagging_freq=4, feature_fraction=0.9530357755300428, lambda_l1=9.598234364995042, lambda_l2=1.6176789808297012, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=267, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=128;, score=0.323 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.598234364995042, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.598234364995042\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680386831246852, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5680386831246852\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6176789808297012, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.6176789808297012\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9530357755300428, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9530357755300428\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 1.50188\n",
      "[CV 2/2] END bagging_fraction=0.5680386831246852, bagging_freq=4, feature_fraction=0.9530357755300428, lambda_l1=9.598234364995042, lambda_l2=1.6176789808297012, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=267, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=128;, score=0.326 total time=   2.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.572904946429917, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.572904946429917\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7525963076302989, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7525963076302989\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.463152127579686, reg_lambda=0 will be ignored. Current value: lambda_l2=0.463152127579686\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5601490488846257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5601490488846257\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 1.50415\n",
      "[CV 1/2] END bagging_fraction=0.7525963076302989, bagging_freq=7, feature_fraction=0.5601490488846257, lambda_l1=2.572904946429917, lambda_l2=0.463152127579686, learning_rate=0.05, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=64, objective=a, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=256;, score=0.330 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.572904946429917, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.572904946429917\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41184274701829715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41184274701829715\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=1 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's multi_logloss: 1.49263\n",
      "[CV 2/2] END bagging_fraction=0.8969895696347261, bagging_freq=3, feature_fraction=0.41184274701829715, lambda_l1=3.3526001373344405, lambda_l2=7.215507069659847, learning_rate=0.2, metric=multi_logloss, min_child_samples=6, num_class=5, num_leaves=496, objective=u, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.330 total time=  22.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.605928904202117, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.605928904202117\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5931524077482327, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5931524077482327\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8684417795631054, reg_lambda=0 will be ignored. Current value: lambda_l2=3.8684417795631054\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8996716094041585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8996716094041585\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[734]\tvalid_0's multi_logloss: 1.4933\n",
      "[CV 2/2] END bagging_fraction=0.5931524077482327, bagging_freq=2, feature_fraction=0.8996716094041585, lambda_l1=4.605928904202117, lambda_l2=3.8684417795631054, learning_rate=0.01, metric=multi_logloss, min_child_samples=45, num_class=5, num_leaves=16, objective=t, reg_lambda=0, subsample=0.5, subsample_freq=1;, score=0.332 total time=  11.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.403074821568154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.403074821568154\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4982490913698059, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4982490913698059\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1460611981898274, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=1.1460611981898274\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7708394211810332, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7708394211810332\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 1.49133\n",
      "[CV 2/2] END bagging_fraction=0.4982490913698059, bagging_freq=6, feature_fraction=0.7708394211810332, lambda_l1=3.403074821568154, lambda_l2=1.1460611981898274, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=472, objective=a, reg_lambda=1e-05, subsample=0.7, subsample_freq=16;, score=0.335 total time=  37.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.506360016081413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.506360016081413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7224141762402978, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7224141762402978\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.5208279510578384, reg_lambda=0 will be ignored. Current value: lambda_l2=1.5208279510578384\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528496219156293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528496219156293\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's multi_logloss: 1.49729\n",
      "[CV 2/2] END bagging_fraction=0.7224141762402978, bagging_freq=6, feature_fraction=0.8528496219156293, lambda_l1=8.506360016081413, lambda_l2=1.5208279510578384, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=118, objective=i, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.330 total time=  14.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3766119208859611, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3766119208859611\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9333348921106651, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9333348921106651\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.85573382010081, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.85573382010081\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9475046494887369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9475046494887369\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 1.49448\n",
      "[CV 1/2] END bagging_fraction=0.9333348921106651, bagging_freq=6, feature_fraction=0.9475046494887369, lambda_l1=0.3766119208859611, lambda_l2=3.85573382010081, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=395, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=8;, score=0.331 total time=  59.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5991707677678607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5991707677678607\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7150623770888318, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7150623770888318\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.1507356207563975, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.1507356207563975\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8181207048115412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8181207048115412\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.5036\n",
      "[CV 2/2] END bagging_fraction=0.7150623770888318, bagging_freq=5, feature_fraction=0.8181207048115412, lambda_l1=0.5991707677678607, lambda_l2=6.1507356207563975, learning_rate=0.2, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=58, objective=i, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.328 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.216742405112487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.216742405112487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6352102244607307, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6352102244607307\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.590517177847379, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.590517177847379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5515638629719628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5515638629719628\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.51181\n",
      "[CV 1/2] END bagging_fraction=0.6352102244607307, bagging_freq=3, feature_fraction=0.5515638629719628, lambda_l1=5.216742405112487, lambda_l2=4.590517177847379, learning_rate=0.2, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=154, objective=s, reg_lambda=0.001, subsample=0.5, subsample_freq=64;, score=0.323 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.216742405112487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.216742405112487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6352102244607307, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6352102244607307\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.590517177847379, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.590517177847379\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7525963076302989, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7525963076302989\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.463152127579686, reg_lambda=0 will be ignored. Current value: lambda_l2=0.463152127579686\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5601490488846257, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5601490488846257\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=256 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's multi_logloss: 1.4978\n",
      "[CV 2/2] END bagging_fraction=0.7525963076302989, bagging_freq=7, feature_fraction=0.5601490488846257, lambda_l1=2.572904946429917, lambda_l2=0.463152127579686, learning_rate=0.05, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=64, objective=a, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=256;, score=0.330 total time=   4.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3202600549895425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3202600549895425\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6414453496707163, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6414453496707163\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.146593136889637, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.146593136889637\n",
      "[LightGBM] [Warning] feature_fraction is set=0.666344900744695, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.666344900744695\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.4971\n",
      "[CV 1/2] END bagging_fraction=0.6414453496707163, bagging_freq=4, feature_fraction=0.666344900744695, lambda_l1=3.3202600549895425, lambda_l2=0.146593136889637, learning_rate=0.2, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=321, objective=c, reg_lambda=1e-06, subsample=0.6, subsample_freq=128;, score=0.336 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3202600549895425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3202600549895425\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6414453496707163, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6414453496707163\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.146593136889637, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.146593136889637\n",
      "[LightGBM] [Warning] feature_fraction is set=0.666344900744695, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.666344900744695\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's multi_logloss: 1.49738\n",
      "[CV 2/2] END bagging_fraction=0.6414453496707163, bagging_freq=4, feature_fraction=0.666344900744695, lambda_l1=3.3202600549895425, lambda_l2=0.146593136889637, learning_rate=0.2, metric=multi_logloss, min_child_samples=30, num_class=5, num_leaves=321, objective=c, reg_lambda=1e-06, subsample=0.6, subsample_freq=128;, score=0.328 total time=   4.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.028813754164105, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.028813754164105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8212674282065009, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8212674282065009\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.374946201437987, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.374946201437987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.804719526964842, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.804719526964842\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's multi_logloss: 1.49253\n",
      "[CV 1/2] END bagging_fraction=0.8212674282065009, bagging_freq=7, feature_fraction=0.804719526964842, lambda_l1=7.028813754164105, lambda_l2=0.374946201437987, learning_rate=0.05, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=183, objective=s, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=128;, score=0.333 total time=   9.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.028813754164105, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.028813754164105\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8212674282065009, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8212674282065009\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.374946201437987, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.374946201437987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.804719526964842, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.804719526964842\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=128 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 1.4934\n",
      "[CV 2/2] END bagging_fraction=0.8212674282065009, bagging_freq=7, feature_fraction=0.804719526964842, lambda_l1=7.028813754164105, lambda_l2=0.374946201437987, learning_rate=0.05, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=183, objective=s, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=128;, score=0.329 total time=  10.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5991707677678607, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5991707677678607\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7150623770888318, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7150623770888318\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.1507356207563975, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.1507356207563975\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8181207048115412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8181207048115412\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.50722\n",
      "[CV 1/2] END bagging_fraction=0.7150623770888318, bagging_freq=5, feature_fraction=0.8181207048115412, lambda_l1=0.5991707677678607, lambda_l2=6.1507356207563975, learning_rate=0.2, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=58, objective=i, reg_lambda=1e-07, subsample=0.7, subsample_freq=1;, score=0.330 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7483957465504502, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7483957465504502\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9093711209536007, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9093711209536007\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.19664348316936, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.19664348316936\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7604667568014967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7604667568014967\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's multi_logloss: 1.50081\n",
      "[CV 2/2] END bagging_fraction=0.9093711209536007, bagging_freq=6, feature_fraction=0.7604667568014967, lambda_l1=0.7483957465504502, lambda_l2=8.19664348316936, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=119, objective=a, reg_lambda=1e-07, subsample=0.5, subsample_freq=256;, score=0.330 total time=  12.8s\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_logloss: 1.49582\n",
      "[CV 2/2] END bagging_fraction=0.8682608216639864, bagging_freq=8, feature_fraction=0.8420113131835731, lambda_l1=7.006162734811224, lambda_l2=9.156572052513294, learning_rate=0.2, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=366, objective=s, reg_lambda=1e-05, subsample=0.6, subsample_freq=16;, score=0.330 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.9313830439000848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9313830439000848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5772836154709264, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5772836154709264\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3948563332966137, reg_lambda=0 will be ignored. Current value: lambda_l2=1.3948563332966137\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5179794921844487, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5179794921844487\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 1.51401\n",
      "[CV 1/2] END bagging_fraction=0.5772836154709264, bagging_freq=3, feature_fraction=0.5179794921844487, lambda_l1=2.9313830439000848, lambda_l2=1.3948563332966137, learning_rate=0.2, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=484, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.324 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.9313830439000848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.9313830439000848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5772836154709264, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5772836154709264\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3948563332966137, reg_lambda=0 will be ignored. Current value: lambda_l2=1.3948563332966137\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5179794921844487, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5179794921844487\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 1.5044\n",
      "[CV 2/2] END bagging_fraction=0.5772836154709264, bagging_freq=3, feature_fraction=0.5179794921844487, lambda_l1=2.9313830439000848, lambda_l2=1.3948563332966137, learning_rate=0.2, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=484, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=16;, score=0.326 total time=   2.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.506360016081413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.506360016081413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7224141762402978, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7224141762402978\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.5208279510578384, reg_lambda=0 will be ignored. Current value: lambda_l2=1.5208279510578384\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528496219156293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528496219156293\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[780]\tvalid_0's multi_logloss: 1.50078\n",
      "[CV 1/2] END bagging_fraction=0.7224141762402978, bagging_freq=6, feature_fraction=0.8528496219156293, lambda_l1=8.506360016081413, lambda_l2=1.5208279510578384, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=118, objective=i, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.333 total time=  16.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.161666819572764, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.161666819572764\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137434700482415, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9137434700482415\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.827340569036849, reg_lambda=0 will be ignored. Current value: lambda_l2=2.827340569036849\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8035312792863283, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8035312792863283\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=16 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's multi_logloss: 1.4938\n",
      "[CV 1/2] END bagging_fraction=0.9137434700482415, bagging_freq=7, feature_fraction=0.8035312792863283, lambda_l1=5.161666819572764, lambda_l2=2.827340569036849, learning_rate=0.05, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=310, objective=m, reg_lambda=0, subsample=0.6, subsample_freq=16;, score=0.331 total time=  10.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3766119208859611, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3766119208859611\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9333348921106651, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9333348921106651\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.85573382010081, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.85573382010081\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9475046494887369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9475046494887369\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 1.50193\n",
      "[CV 2/2] END bagging_fraction=0.9333348921106651, bagging_freq=6, feature_fraction=0.9475046494887369, lambda_l1=0.3766119208859611, lambda_l2=3.85573382010081, learning_rate=0.01, metric=multi_logloss, min_child_samples=8, num_class=5, num_leaves=395, objective=s, reg_lambda=1e-05, subsample=0.7, subsample_freq=8;, score=0.334 total time=  58.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7483957465504502, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7483957465504502\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9093711209536007, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9093711209536007\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.19664348316936, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=8.19664348316936\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7604667568014967, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7604667568014967\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid_0's multi_logloss: 1.50111\n",
      "[CV 1/2] END bagging_fraction=0.9093711209536007, bagging_freq=6, feature_fraction=0.7604667568014967, lambda_l1=0.7483957465504502, lambda_l2=8.19664348316936, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=119, objective=a, reg_lambda=1e-07, subsample=0.5, subsample_freq=256;, score=0.330 total time=  15.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.723118871805334, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.723118871805334\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9616828933303643, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9616828933303643\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.775926035461783, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.775926035461783\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5829803322919278, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5829803322919278\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_logloss: 1.50221\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.144480756114268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.144480756114268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47650971369550627, subsample=0.6 will be ignored. Current value: bagging_fraction=0.47650971369550627\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2855105864570557, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.2855105864570557\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6417091819526365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6417091819526365\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's multi_logloss: 1.49114\n",
      "[CV 2/2] END bagging_fraction=0.47650971369550627, bagging_freq=3, feature_fraction=0.6417091819526365, lambda_l1=9.144480756114268, lambda_l2=2.2855105864570557, learning_rate=0.01, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=426, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.330 total time=  32.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.98486932205967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.98486932205967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5924189434900275, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5924189434900275\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.998311086191403, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.998311086191403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6226030975022245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6226030975022245\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1413]\tvalid_0's multi_logloss: 1.50382\n",
      "[CV 1/2] END bagging_fraction=0.5924189434900275, bagging_freq=3, feature_fraction=0.6226030975022245, lambda_l1=7.98486932205967, lambda_l2=7.998311086191403, learning_rate=0.01, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=99, objective=l, reg_lambda=0.001, subsample=0.5, subsample_freq=32;, score=0.330 total time=  23.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.055636167743398, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.055636167743398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6592748137311487, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6592748137311487\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.451372226843456, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.451372226843456\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46137441640878385, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46137441640878385\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[510]\tvalid_0's multi_logloss: 1.51123\n",
      "[CV 1/2] END bagging_fraction=0.6592748137311487, bagging_freq=7, feature_fraction=0.46137441640878385, lambda_l1=4.055636167743398, lambda_l2=2.451372226843456, learning_rate=0.01, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=361, objective=a, reg_lambda=1e-07, subsample=0.5, subsample_freq=1;, score=0.324 total time=  11.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.055636167743398, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.055636167743398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6592748137311487, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6592748137311487\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.451372226843456, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.451372226843456\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46137441640878385, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46137441640878385\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's multi_logloss: 1.49811\n",
      "[CV 2/2] END bagging_fraction=0.6592748137311487, bagging_freq=7, feature_fraction=0.46137441640878385, lambda_l1=4.055636167743398, lambda_l2=2.451372226843456, learning_rate=0.01, metric=multi_logloss, min_child_samples=83, num_class=5, num_leaves=361, objective=a, reg_lambda=1e-07, subsample=0.5, subsample_freq=1;, score=0.332 total time=  10.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.6168580601286233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6168580601286233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5302522461554237, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5302522461554237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.338108188220341, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.338108188220341\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9854688119340612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9854688119340612\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's multi_logloss: 1.50501\n",
      "[CV 1/2] END bagging_fraction=0.5302522461554237, bagging_freq=6, feature_fraction=0.9854688119340612, lambda_l1=1.6168580601286233, lambda_l2=0.338108188220341, learning_rate=0.05, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=260, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=8;, score=0.329 total time=   5.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.6168580601286233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6168580601286233\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5302522461554237, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5302522461554237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.338108188220341, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.338108188220341\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9854688119340612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9854688119340612\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=8 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's multi_logloss: 1.50208\n",
      "[CV 2/2] END bagging_fraction=0.5302522461554237, bagging_freq=6, feature_fraction=0.9854688119340612, lambda_l1=1.6168580601286233, lambda_l2=0.338108188220341, learning_rate=0.05, metric=multi_logloss, min_child_samples=56, num_class=5, num_leaves=260, objective=s, reg_lambda=0.0001, subsample=0.7, subsample_freq=8;, score=0.328 total time=   5.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.8957535584120997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8957535584120997\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5857342398695734, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5857342398695734\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6956399726563474, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.6956399726563474\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6344221570365592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6344221570365592\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_logloss: 1.50865\n",
      "[CV 1/2] END bagging_fraction=0.5857342398695734, bagging_freq=8, feature_fraction=0.6344221570365592, lambda_l1=2.8957535584120997, lambda_l2=3.6956399726563474, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=282, objective=u, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.326 total time=   3.4s\n",
      "[CV 1/2] END bagging_fraction=0.9616828933303643, bagging_freq=8, feature_fraction=0.5829803322919278, lambda_l1=4.723118871805334, lambda_l2=5.775926035461783, learning_rate=0.2, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=199, objective=l, reg_lambda=1e-07, subsample=0.7, subsample_freq=16;, score=0.328 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.723118871805334, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.723118871805334\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9616828933303643, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9616828933303643\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.775926035461783, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.775926035461783\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5829803322919278, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5829803322919278\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=16 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 1.49413\n",
      "[CV 2/2] END bagging_fraction=0.9616828933303643, bagging_freq=8, feature_fraction=0.5829803322919278, lambda_l1=4.723118871805334, lambda_l2=5.775926035461783, learning_rate=0.2, metric=multi_logloss, min_child_samples=78, num_class=5, num_leaves=199, objective=l, reg_lambda=1e-07, subsample=0.7, subsample_freq=16;, score=0.328 total time=   3.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.053033638782881, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.053033638782881\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5434475825787329, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5434475825787329\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1487792710544103, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.1487792710544103\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8293009263115869, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8293009263115869\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[477]\tvalid_0's multi_logloss: 1.50365\n",
      "[CV 1/2] END bagging_fraction=0.5434475825787329, bagging_freq=9, feature_fraction=0.8293009263115869, lambda_l1=5.053033638782881, lambda_l2=0.1487792710544103, learning_rate=0.01, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=485, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=8;, score=0.329 total time=  10.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.053033638782881, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.053033638782881\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5434475825787329, subsample=0.7 will be ignored. Current value: bagging_fraction=0.5434475825787329\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1487792710544103, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.1487792710544103\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8293009263115869, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8293009263115869\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's multi_logloss: 1.49671\n",
      "[CV 2/2] END bagging_fraction=0.5434475825787329, bagging_freq=9, feature_fraction=0.8293009263115869, lambda_l1=5.053033638782881, lambda_l2=0.1487792710544103, learning_rate=0.01, metric=multi_logloss, min_child_samples=57, num_class=5, num_leaves=485, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=8;, score=0.329 total time=  14.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.98486932205967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.98486932205967\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5924189434900275, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5924189434900275\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.998311086191403, reg_lambda=0.001 will be ignored. Current value: lambda_l2=7.998311086191403\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6226030975022245, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6226030975022245\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's multi_logloss: 1.49682\n",
      "[CV 2/2] END bagging_fraction=0.5924189434900275, bagging_freq=3, feature_fraction=0.6226030975022245, lambda_l1=7.98486932205967, lambda_l2=7.998311086191403, learning_rate=0.01, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=99, objective=l, reg_lambda=0.001, subsample=0.5, subsample_freq=32;, score=0.331 total time=  19.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.628591432957643, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.628591432957643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42052422843278076, subsample=0.7 will be ignored. Current value: bagging_fraction=0.42052422843278076\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.3813500877568865, reg_lambda=0 will be ignored. Current value: lambda_l2=7.3813500877568865\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415455734962559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415455734962559\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's multi_logloss: 1.49094\n",
      "[CV 2/2] END bagging_fraction=0.42052422843278076, bagging_freq=8, feature_fraction=0.7415455734962559, lambda_l1=9.628591432957643, lambda_l2=7.3813500877568865, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=301, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=32;, score=0.332 total time=  38.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.8957535584120997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8957535584120997\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5857342398695734, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5857342398695734\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6956399726563474, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.6956399726563474\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6344221570365592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6344221570365592\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=256 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.50203\n",
      "[CV 2/2] END bagging_fraction=0.5857342398695734, bagging_freq=8, feature_fraction=0.6344221570365592, lambda_l1=2.8957535584120997, lambda_l2=3.6956399726563474, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=282, objective=u, reg_lambda=0.0001, subsample=0.6, subsample_freq=256;, score=0.326 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.11224195427411, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.11224195427411\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8690093228630855, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8690093228630855\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9318713874500262, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.9318713874500262\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9107121787410516, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9107121787410516\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.49858\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5515638629719628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5515638629719628\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's multi_logloss: 1.50186\n",
      "[CV 2/2] END bagging_fraction=0.6352102244607307, bagging_freq=3, feature_fraction=0.5515638629719628, lambda_l1=5.216742405112487, lambda_l2=4.590517177847379, learning_rate=0.2, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=154, objective=s, reg_lambda=0.001, subsample=0.5, subsample_freq=64;, score=0.331 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.144480756114268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.144480756114268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47650971369550627, subsample=0.6 will be ignored. Current value: bagging_fraction=0.47650971369550627\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2855105864570557, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.2855105864570557\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6417091819526365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6417091819526365\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[852]\tvalid_0's multi_logloss: 1.49766\n",
      "[CV 1/2] END bagging_fraction=0.47650971369550627, bagging_freq=3, feature_fraction=0.6417091819526365, lambda_l1=9.144480756114268, lambda_l2=2.2855105864570557, learning_rate=0.01, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=426, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.330 total time=  22.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8938619614142973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8938619614142973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8586262702877937, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8586262702877937\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.891872883084141, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.891872883084141\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6226489372974768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6226489372974768\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[397]\tvalid_0's multi_logloss: 1.50758\n",
      "[CV 1/2] END bagging_fraction=0.8586262702877937, bagging_freq=4, feature_fraction=0.6226489372974768, lambda_l1=1.8938619614142973, lambda_l2=5.891872883084141, learning_rate=0.01, metric=multi_logloss, min_child_samples=94, num_class=5, num_leaves=136, objective=u, reg_lambda=1e-05, subsample=0.5, subsample_freq=2;, score=0.327 total time=  12.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8938619614142973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8938619614142973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8586262702877937, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8586262702877937\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.891872883084141, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=5.891872883084141\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6226489372974768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6226489372974768\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[312]\tvalid_0's multi_logloss: 1.50006\n",
      "[CV 2/2] END bagging_fraction=0.8586262702877937, bagging_freq=4, feature_fraction=0.6226489372974768, lambda_l1=1.8938619614142973, lambda_l2=5.891872883084141, learning_rate=0.01, metric=multi_logloss, min_child_samples=94, num_class=5, num_leaves=136, objective=u, reg_lambda=1e-05, subsample=0.5, subsample_freq=2;, score=0.333 total time=  10.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.628591432957643, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.628591432957643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42052422843278076, subsample=0.7 will be ignored. Current value: bagging_fraction=0.42052422843278076\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.3813500877568865, reg_lambda=0 will be ignored. Current value: lambda_l2=7.3813500877568865\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415455734962559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415455734962559\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=32 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[808]\tvalid_0's multi_logloss: 1.49179\n",
      "[CV 1/2] END bagging_fraction=0.42052422843278076, bagging_freq=8, feature_fraction=0.7415455734962559, lambda_l1=9.628591432957643, lambda_l2=7.3813500877568865, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=301, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=32;, score=0.332 total time=  56.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0247916033207485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0247916033207485\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9572892584046345, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9572892584046345\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.705081626289994, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.705081626289994\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9564590626990441, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9564590626990441\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's multi_logloss: 1.48916\n",
      "[CV 1/2] END bagging_fraction=0.9572892584046345, bagging_freq=5, feature_fraction=0.9564590626990441, lambda_l1=2.0247916033207485, lambda_l2=5.705081626289994, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=28, objective=s, reg_lambda=1e-06, subsample=0.5, subsample_freq=32;, score=0.340 total time=   9.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.679632519271441, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.679632519271441\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5109314256584416, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5109314256584416\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.145701664698004, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.145701664698004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5542297930345175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5542297930345175\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 1.49999\n",
      "[CV 2/2] END bagging_fraction=0.5109314256584416, bagging_freq=9, feature_fraction=0.5542297930345175, lambda_l1=7.679632519271441, lambda_l2=9.145701664698004, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=196, objective=l, reg_lambda=1e-06, subsample=0.5, subsample_freq=8;, score=0.329 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.309837645815827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.309837645815827\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987990178605095, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9987990178605095\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1933465580862856, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.1933465580862856\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.11224195427411, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.11224195427411\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8690093228630855, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8690093228630855\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9318713874500262, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=1.9318713874500262\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9107121787410516, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9107121787410516\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's multi_logloss: 1.50262\n",
      "[CV 1/2] END bagging_fraction=0.8690093228630855, bagging_freq=3, feature_fraction=0.9107121787410516, lambda_l1=4.11224195427411, lambda_l2=1.9318713874500262, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=402, objective=s, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=16;, score=0.331 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.1510995571997915, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.1510995571997915\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9754668100738155, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9754668100738155\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.992502410603268, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.992502410603268\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9313567507878848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9313567507878848\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's multi_logloss: 1.5061\n",
      "[CV 1/2] END bagging_fraction=0.9754668100738155, bagging_freq=3, feature_fraction=0.9313567507878848, lambda_l1=7.1510995571997915, lambda_l2=6.992502410603268, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=404, objective=i, reg_lambda=1e-06, subsample=0.7, subsample_freq=2;, score=0.326 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.0247916033207485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.0247916033207485\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9572892584046345, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9572892584046345\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.705081626289994, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.705081626289994\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9564590626990441, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9564590626990441\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 1.49041\n",
      "[CV 2/2] END bagging_fraction=0.9572892584046345, bagging_freq=5, feature_fraction=0.9564590626990441, lambda_l1=2.0247916033207485, lambda_l2=5.705081626289994, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=28, objective=s, reg_lambda=1e-06, subsample=0.5, subsample_freq=32;, score=0.339 total time=   9.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.742888173558263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.742888173558263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892191426093645, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8892191426093645\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34079486489493577, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.34079486489493577\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5861235995059207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5861235995059207\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's multi_logloss: 1.4988\n",
      "[CV 2/2] END bagging_fraction=0.8892191426093645, bagging_freq=9, feature_fraction=0.5861235995059207, lambda_l1=0.742888173558263, lambda_l2=0.34079486489493577, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=437, objective=l, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.330 total time=   9.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10809534327873488, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10809534327873488\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5723882269424752, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5723882269424752\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.144800125206595, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.144800125206595\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8843873791519572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8843873791519572\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 1.50683\n",
      "[CV 2/2] END bagging_fraction=0.5723882269424752, bagging_freq=4, feature_fraction=0.8843873791519572, lambda_l1=0.10809534327873488, lambda_l2=9.144800125206595, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=191, objective=t, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.323 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.786993137211602, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.786993137211602\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4539831360492655, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4539831360492655\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3206247898618086, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.3206247898618086\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9138783950483537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9138783950483537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[776]\tvalid_0's multi_logloss: 1.49866\n",
      "[CV 1/2] END bagging_fraction=0.4539831360492655, bagging_freq=4, feature_fraction=0.9138783950483537, lambda_l1=6.786993137211602, lambda_l2=1.3206247898618086, learning_rate=0.01, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=159, objective=t, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.332 total time=  18.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.415349474336594, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.415349474336594\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581088380786437, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8581088380786437\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.966028981548661, reg_lambda=0 will be ignored. Current value: lambda_l2=4.966028981548661\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6138485183729814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6138485183729814\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's multi_logloss: 1.49308\n",
      "[CV 2/2] END bagging_fraction=0.8690093228630855, bagging_freq=3, feature_fraction=0.9107121787410516, lambda_l1=4.11224195427411, lambda_l2=1.9318713874500262, learning_rate=0.2, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=402, objective=s, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=16;, score=0.330 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.1510995571997915, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.1510995571997915\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9754668100738155, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9754668100738155\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.992502410603268, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.992502410603268\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9313567507878848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9313567507878848\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's multi_logloss: 1.49772\n",
      "[CV 2/2] END bagging_fraction=0.9754668100738155, bagging_freq=3, feature_fraction=0.9313567507878848, lambda_l1=7.1510995571997915, lambda_l2=6.992502410603268, learning_rate=0.05, metric=multi_logloss, min_child_samples=99, num_class=5, num_leaves=404, objective=i, reg_lambda=1e-06, subsample=0.7, subsample_freq=2;, score=0.331 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.679632519271441, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.679632519271441\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5109314256584416, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5109314256584416\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.145701664698004, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.145701664698004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5542297930345175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5542297930345175\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=8 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's multi_logloss: 1.50065\n",
      "[CV 1/2] END bagging_fraction=0.5109314256584416, bagging_freq=9, feature_fraction=0.5542297930345175, lambda_l1=7.679632519271441, lambda_l2=9.145701664698004, learning_rate=0.2, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=196, objective=l, reg_lambda=1e-06, subsample=0.5, subsample_freq=8;, score=0.332 total time=   6.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.742888173558263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.742888173558263\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8892191426093645, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8892191426093645\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34079486489493577, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.34079486489493577\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5861235995059207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5861235995059207\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=32 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's multi_logloss: 1.50116\n",
      "[CV 1/2] END bagging_fraction=0.8892191426093645, bagging_freq=9, feature_fraction=0.5861235995059207, lambda_l1=0.742888173558263, lambda_l2=0.34079486489493577, learning_rate=0.01, metric=multi_logloss, min_child_samples=81, num_class=5, num_leaves=437, objective=l, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.329 total time=   9.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.576447217577932, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.576447217577932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4565718310940887, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4565718310940887\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6713181032596833, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.6713181032596833\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8353756141737714, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8353756141737714\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=8 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 1.50376\n",
      "[CV 1/2] END bagging_fraction=0.4565718310940887, bagging_freq=4, feature_fraction=0.8353756141737714, lambda_l1=4.576447217577932, lambda_l2=3.6713181032596833, learning_rate=0.2, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=342, objective=a, reg_lambda=1e-05, subsample=0.5, subsample_freq=8;, score=0.333 total time=   4.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.786993137211602, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.786993137211602\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4539831360492655, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4539831360492655\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3206247898618086, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.3206247898618086\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9138783950483537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9138783950483537\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[740]\tvalid_0's multi_logloss: 1.4953\n",
      "[CV 2/2] END bagging_fraction=0.4539831360492655, bagging_freq=4, feature_fraction=0.9138783950483537, lambda_l1=6.786993137211602, lambda_l2=1.3206247898618086, learning_rate=0.01, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=159, objective=t, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=2;, score=0.330 total time=  21.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.750319366418603, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.750319366418603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8458289077188477, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8458289077188477\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.054022593773071, reg_lambda=0 will be ignored. Current value: lambda_l2=5.054022593773071\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9060426941632309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9060426941632309\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 1.50935\n",
      "[CV 1/2] END bagging_fraction=0.8458289077188477, bagging_freq=9, feature_fraction=0.9060426941632309, lambda_l1=8.750319366418603, lambda_l2=5.054022593773071, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=251, objective=u, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=16;, score=0.326 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1846331285406133, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1846331285406133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4976446817814888, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4976446817814888\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7825811978236423, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.7825811978236423\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8205488329820708, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8205488329820708\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7293415493165949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7293415493165949\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=2 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 1.50272\n",
      "[CV 1/2] END bagging_fraction=0.9987990178605095, bagging_freq=8, feature_fraction=0.7293415493165949, lambda_l1=1.309837645815827, lambda_l2=3.1933465580862856, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=289, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=2;, score=0.327 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.309837645815827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.309837645815827\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987990178605095, subsample=0.6 will be ignored. Current value: bagging_fraction=0.9987990178605095\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1933465580862856, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.1933465580862856\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7293415493165949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7293415493165949\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=2 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.50341\n",
      "[CV 2/2] END bagging_fraction=0.9987990178605095, bagging_freq=8, feature_fraction=0.7293415493165949, lambda_l1=1.309837645815827, lambda_l2=3.1933465580862856, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=289, objective=s, reg_lambda=0.001, subsample=0.6, subsample_freq=2;, score=0.331 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10809534327873488, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10809534327873488\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5723882269424752, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5723882269424752\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.144800125206595, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=9.144800125206595\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8843873791519572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8843873791519572\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 1.51865\n",
      "[CV 1/2] END bagging_fraction=0.5723882269424752, bagging_freq=4, feature_fraction=0.8843873791519572, lambda_l1=0.10809534327873488, lambda_l2=9.144800125206595, learning_rate=0.05, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=191, objective=t, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=1;, score=0.323 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.576447217577932, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.576447217577932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4565718310940887, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4565718310940887\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.6713181032596833, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=3.6713181032596833\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8353756141737714, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8353756141737714\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=8 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.50159\n",
      "[CV 2/2] END bagging_fraction=0.4565718310940887, bagging_freq=4, feature_fraction=0.8353756141737714, lambda_l1=4.576447217577932, lambda_l2=3.6713181032596833, learning_rate=0.2, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=342, objective=a, reg_lambda=1e-05, subsample=0.5, subsample_freq=8;, score=0.322 total time=   4.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.415349474336594, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.415349474336594\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8581088380786437, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8581088380786437\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.966028981548661, reg_lambda=0 will be ignored. Current value: lambda_l2=4.966028981548661\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6138485183729814, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6138485183729814\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's multi_logloss: 1.49703\n",
      "[CV 1/2] END bagging_fraction=0.8581088380786437, bagging_freq=8, feature_fraction=0.6138485183729814, lambda_l1=5.415349474336594, lambda_l2=4.966028981548661, learning_rate=0.01, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=337, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=8;, score=0.333 total time=  18.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.750319366418603, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.750319366418603\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8458289077188477, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8458289077188477\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.054022593773071, reg_lambda=0 will be ignored. Current value: lambda_l2=5.054022593773071\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9060426941632309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9060426941632309\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's multi_logloss: 1.49879\n",
      "[CV 2/2] END bagging_fraction=0.8458289077188477, bagging_freq=9, feature_fraction=0.9060426941632309, lambda_l1=8.750319366418603, lambda_l2=5.054022593773071, learning_rate=0.05, metric=multi_logloss, min_child_samples=96, num_class=5, num_leaves=251, objective=u, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=16;, score=0.328 total time=   3.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1846331285406133, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1846331285406133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4976446817814888, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4976446817814888\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.7825811978236423, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.7825811978236423\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8205488329820708, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8205488329820708\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=256 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's multi_logloss: 1.49396\n",
      "[CV 2/2] END bagging_fraction=0.4976446817814888, bagging_freq=9, feature_fraction=0.8205488329820708, lambda_l1=1.1846331285406133, lambda_l2=3.7825811978236423, learning_rate=0.01, metric=multi_logloss, min_child_samples=26, num_class=5, num_leaves=315, objective=a, reg_lambda=0.001, subsample=0.7, subsample_freq=256;, score=0.328 total time=  19.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.5987278138423155, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.5987278138423155\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8773152944388184, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8773152944388184\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.3791086288955725, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.3791086288955725\n",
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's multi_logloss: 1.49264\n",
      "[CV 1/2] END bagging_fraction=0.4976446817814888, bagging_freq=9, feature_fraction=0.8205488329820708, lambda_l1=1.1846331285406133, lambda_l2=3.7825811978236423, learning_rate=0.01, metric=multi_logloss, min_child_samples=26, num_class=5, num_leaves=315, objective=a, reg_lambda=0.001, subsample=0.7, subsample_freq=256;, score=0.332 total time=  20.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.5987278138423155, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.5987278138423155\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8773152944388184, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8773152944388184\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.3791086288955725, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.3791086288955725\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9308996778010029, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9308996778010029\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 1.49956\n",
      "[CV 1/2] END bagging_fraction=0.8773152944388184, bagging_freq=8, feature_fraction=0.9308996778010029, lambda_l1=7.5987278138423155, lambda_l2=6.3791086288955725, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=341, objective=c, reg_lambda=1e-07, subsample=0.6, subsample_freq=8;, score=0.332 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.1513903495162, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.1513903495162\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4599583596686188, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4599583596686188\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.243655612794035, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.243655612794035\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46815328534868406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46815328534868406\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1792]\tvalid_0's multi_logloss: 1.50769\n",
      "[CV 2/2] END bagging_fraction=0.4599583596686188, bagging_freq=8, feature_fraction=0.46815328534868406, lambda_l1=9.1513903495162, lambda_l2=9.243655612794035, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=3, objective=a, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=1;, score=0.327 total time=   8.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.999752962074453, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.999752962074453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9952139844189305, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9952139844189305\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.650782513742585, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.650782513742585\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5704235011410792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5704235011410792\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 1.4922\n",
      "[CV 1/2] END bagging_fraction=0.9952139844189305, bagging_freq=7, feature_fraction=0.5704235011410792, lambda_l1=9.999752962074453, lambda_l2=7.650782513742585, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=190, objective=c, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=64;, score=0.331 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8341859712729519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8341859712729519\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6771310724204841, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6771310724204841\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.446246055387362, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.446246055387362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8463134808565527, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8463134808565527\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's multi_logloss: 1.50254\n",
      "[CV 2/2] END bagging_fraction=0.6771310724204841, bagging_freq=2, feature_fraction=0.8463134808565527, lambda_l1=0.8341859712729519, lambda_l2=4.446246055387362, learning_rate=0.05, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=45, objective=c, reg_lambda=1e-07, subsample=0.6, subsample_freq=4;, score=0.332 total time=   4.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9204012892500135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9204012892500135\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4490358951555042, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4490358951555042\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.447376860144894, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.447376860144894\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6769784775626924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6769784775626924\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 1.52396\n",
      "[CV 1/2] END bagging_fraction=0.4490358951555042, bagging_freq=4, feature_fraction=0.6769784775626924, lambda_l1=1.9204012892500135, lambda_l2=9.447376860144894, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=80, objective=t, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=64;, score=0.324 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9204012892500135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9204012892500135\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4490358951555042, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4490358951555042\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.447376860144894, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=9.447376860144894\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6769784775626924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6769784775626924\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 1.50967\n",
      "[CV 2/2] END bagging_fraction=0.4490358951555042, bagging_freq=4, feature_fraction=0.6769784775626924, lambda_l1=1.9204012892500135, lambda_l2=9.447376860144894, learning_rate=0.05, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=80, objective=t, reg_lambda=1e-06, subsample=0.7999999999999999, subsample_freq=64;, score=0.319 total time=   3.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2538785401459945, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2538785401459945\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.889585159213358, subsample=0.6 will be ignored. Current value: bagging_fraction=0.889585159213358\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.6972453841478226, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.6972453841478226\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9868956883756315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9868956883756315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9308996778010029, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9308996778010029\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=8 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's multi_logloss: 1.4965\n",
      "[CV 2/2] END bagging_fraction=0.8773152944388184, bagging_freq=8, feature_fraction=0.9308996778010029, lambda_l1=7.5987278138423155, lambda_l2=6.3791086288955725, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=341, objective=c, reg_lambda=1e-07, subsample=0.6, subsample_freq=8;, score=0.328 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.77263568574593, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.77263568574593\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.41454359460692075, subsample=0.7 will be ignored. Current value: bagging_fraction=0.41454359460692075\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38371027437660993, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.38371027437660993\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4526752831292872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4526752831292872\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 1.52327\n",
      "[CV 1/2] END bagging_fraction=0.41454359460692075, bagging_freq=6, feature_fraction=0.4526752831292872, lambda_l1=8.77263568574593, lambda_l2=0.38371027437660993, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=182, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.324 total time=   2.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.77263568574593, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.77263568574593\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.41454359460692075, subsample=0.7 will be ignored. Current value: bagging_fraction=0.41454359460692075\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38371027437660993, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=0.38371027437660993\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4526752831292872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4526752831292872\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=64 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's multi_logloss: 1.50773\n",
      "[CV 2/2] END bagging_fraction=0.41454359460692075, bagging_freq=6, feature_fraction=0.4526752831292872, lambda_l1=8.77263568574593, lambda_l2=0.38371027437660993, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=182, objective=c, reg_lambda=0.0001, subsample=0.7, subsample_freq=64;, score=0.323 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3989204628550964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3989204628550964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7711272368627793, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7711272368627793\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.073734726066864, reg_lambda=0 will be ignored. Current value: lambda_l2=7.073734726066864\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41123355520377214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41123355520377214\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 1.49561\n",
      "[CV 2/2] END bagging_fraction=0.7711272368627793, bagging_freq=9, feature_fraction=0.41123355520377214, lambda_l1=3.3989204628550964, lambda_l2=7.073734726066864, learning_rate=0.05, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=155, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=4;, score=0.329 total time=   4.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.999752962074453, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.999752962074453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9952139844189305, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9952139844189305\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.650782513742585, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.650782513742585\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5704235011410792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5704235011410792\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 1.48986\n",
      "[CV 2/2] END bagging_fraction=0.9952139844189305, bagging_freq=7, feature_fraction=0.5704235011410792, lambda_l1=9.999752962074453, lambda_l2=7.650782513742585, learning_rate=0.2, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=190, objective=c, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=64;, score=0.331 total time=   6.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.181548943102013, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.181548943102013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8531503109029019, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8531503109029019\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.357425480980372, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.357425480980372\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6813294590919834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813294590919834\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's multi_logloss: 1.49292\n",
      "[CV 2/2] END bagging_fraction=0.8531503109029019, bagging_freq=5, feature_fraction=0.6813294590919834, lambda_l1=2.181548943102013, lambda_l2=4.357425480980372, learning_rate=0.01, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=309, objective=i, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.331 total time=  25.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.474485565130196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.474485565130196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581592326431006, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5581592326431006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3766861337915864, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.3766861337915864\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6843578418670399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6843578418670399\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's multi_logloss: 1.49628\n",
      "[CV 2/2] END bagging_fraction=0.5581592326431006, bagging_freq=8, feature_fraction=0.6843578418670399, lambda_l1=7.474485565130196, lambda_l2=0.3766861337915864, learning_rate=0.2, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=248, objective=i, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=64;, score=0.328 total time=  11.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5882455375590756, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5882455375590756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5549902258097323, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5549902258097323\n",
      "[CV 2/2] END bagging_fraction=0.8581088380786437, bagging_freq=8, feature_fraction=0.6138485183729814, lambda_l1=5.415349474336594, lambda_l2=4.966028981548661, learning_rate=0.01, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=337, objective=s, reg_lambda=0, subsample=0.7, subsample_freq=8;, score=0.328 total time=  19.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.439551900852899, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.439551900852899\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7937180310133396, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7937180310133396\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.477693181143418, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.477693181143418\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8816450870046216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8816450870046216\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 1.49775\n",
      "[CV 1/2] END bagging_fraction=0.7937180310133396, bagging_freq=9, feature_fraction=0.8816450870046216, lambda_l1=7.439551900852899, lambda_l2=4.477693181143418, learning_rate=0.05, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=295, objective=s, reg_lambda=0.001, subsample=0.7, subsample_freq=2;, score=0.331 total time=   6.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.439551900852899, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.439551900852899\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7937180310133396, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7937180310133396\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.477693181143418, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.477693181143418\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8816450870046216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8816450870046216\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=2 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 1.49722\n",
      "[CV 2/2] END bagging_fraction=0.7937180310133396, bagging_freq=9, feature_fraction=0.8816450870046216, lambda_l1=7.439551900852899, lambda_l2=4.477693181143418, learning_rate=0.05, metric=multi_logloss, min_child_samples=60, num_class=5, num_leaves=295, objective=s, reg_lambda=0.001, subsample=0.7, subsample_freq=2;, score=0.329 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.1513903495162, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.1513903495162\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4599583596686188, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.4599583596686188\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.243655612794035, reg_lambda=0.001 will be ignored. Current value: lambda_l2=9.243655612794035\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46815328534868406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46815328534868406\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=1 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1576]\tvalid_0's multi_logloss: 1.51912\n",
      "[CV 1/2] END bagging_fraction=0.4599583596686188, bagging_freq=8, feature_fraction=0.46815328534868406, lambda_l1=9.1513903495162, lambda_l2=9.243655612794035, learning_rate=0.01, metric=multi_logloss, min_child_samples=70, num_class=5, num_leaves=3, objective=a, reg_lambda=0.001, subsample=0.7999999999999999, subsample_freq=1;, score=0.325 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3989204628550964, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3989204628550964\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7711272368627793, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7711272368627793\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.073734726066864, reg_lambda=0 will be ignored. Current value: lambda_l2=7.073734726066864\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41123355520377214, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41123355520377214\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 1.50337\n",
      "[CV 1/2] END bagging_fraction=0.7711272368627793, bagging_freq=9, feature_fraction=0.41123355520377214, lambda_l1=3.3989204628550964, lambda_l2=7.073734726066864, learning_rate=0.05, metric=multi_logloss, min_child_samples=76, num_class=5, num_leaves=155, objective=l, reg_lambda=0, subsample=0.7, subsample_freq=4;, score=0.327 total time=   6.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8341859712729519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8341859712729519\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6771310724204841, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6771310724204841\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.446246055387362, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.446246055387362\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8463134808565527, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8463134808565527\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 1.51074\n",
      "[CV 1/2] END bagging_fraction=0.6771310724204841, bagging_freq=2, feature_fraction=0.8463134808565527, lambda_l1=0.8341859712729519, lambda_l2=4.446246055387362, learning_rate=0.05, metric=multi_logloss, min_child_samples=84, num_class=5, num_leaves=45, objective=c, reg_lambda=1e-07, subsample=0.6, subsample_freq=4;, score=0.325 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.181548943102013, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.181548943102013\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8531503109029019, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8531503109029019\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.357425480980372, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.357425480980372\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6813294590919834, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6813294590919834\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=4 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's multi_logloss: 1.48847\n",
      "[CV 1/2] END bagging_fraction=0.8531503109029019, bagging_freq=5, feature_fraction=0.6813294590919834, lambda_l1=2.181548943102013, lambda_l2=4.357425480980372, learning_rate=0.01, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=309, objective=i, reg_lambda=0.001, subsample=0.7, subsample_freq=4;, score=0.331 total time=  34.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4708812691329065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4708812691329065\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6384640767158506, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6384640767158506\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.753640227944978, reg_lambda=0 will be ignored. Current value: lambda_l2=4.753640227944978\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41341347801082384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41341347801082384\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 1.49025\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 1.5033\n",
      "[CV 1/2] END bagging_fraction=0.889585159213358, bagging_freq=2, feature_fraction=0.9868956883756315, lambda_l1=0.2538785401459945, lambda_l2=5.6972453841478226, learning_rate=0.05, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=218, objective=i, reg_lambda=0.001, subsample=0.6, subsample_freq=32;, score=0.329 total time=   5.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2538785401459945, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2538785401459945\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.889585159213358, subsample=0.6 will be ignored. Current value: bagging_fraction=0.889585159213358\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.6972453841478226, reg_lambda=0.001 will be ignored. Current value: lambda_l2=5.6972453841478226\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9868956883756315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9868956883756315\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 1.50322\n",
      "[CV 2/2] END bagging_fraction=0.889585159213358, bagging_freq=2, feature_fraction=0.9868956883756315, lambda_l1=0.2538785401459945, lambda_l2=5.6972453841478226, learning_rate=0.05, metric=multi_logloss, min_child_samples=86, num_class=5, num_leaves=218, objective=i, reg_lambda=0.001, subsample=0.6, subsample_freq=32;, score=0.331 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.474485565130196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.474485565130196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581592326431006, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.5581592326431006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3766861337915864, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.3766861337915864\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6843578418670399, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6843578418670399\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 1.4973\n",
      "[CV 1/2] END bagging_fraction=0.5581592326431006, bagging_freq=8, feature_fraction=0.6843578418670399, lambda_l1=7.474485565130196, lambda_l2=0.3766861337915864, learning_rate=0.2, metric=multi_logloss, min_child_samples=10, num_class=5, num_leaves=248, objective=i, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=64;, score=0.316 total time=  12.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4708812691329065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4708812691329065\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6384640767158506, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6384640767158506\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.753640227944978, reg_lambda=0 will be ignored. Current value: lambda_l2=4.753640227944978\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41341347801082384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41341347801082384\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's multi_logloss: 1.49025\n",
      "[CV 1/2] END bagging_fraction=0.6384640767158506, bagging_freq=4, feature_fraction=0.41341347801082384, lambda_l1=3.4708812691329065, lambda_l2=4.753640227944978, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=109, objective=u, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.332 total time=  14.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9215642332761615, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9215642332761615\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7713692134597273, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7713692134597273\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8742896297933381, reg_lambda=0 will be ignored. Current value: lambda_l2=0.8742896297933381\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8674368179730211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8674368179730211\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's multi_logloss: 1.49464\n",
      "[CV 1/2] END bagging_fraction=0.7713692134597273, bagging_freq=8, feature_fraction=0.8674368179730211, lambda_l1=3.9215642332761615, lambda_l2=0.8742896297933381, learning_rate=0.05, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=280, objective=t, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.331 total time=   7.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.81194122023068, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.81194122023068\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6066815418278342, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6066815418278342\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.6719122003976254, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.6719122003976254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5853580004395238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5853580004395238\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 1.49441\n",
      "[CV 1/2] END bagging_fraction=0.6066815418278342, bagging_freq=9, feature_fraction=0.5853580004395238, lambda_l1=9.81194122023068, lambda_l2=4.6719122003976254, learning_rate=0.2, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=45, objective=l, reg_lambda=1e-07, subsample=0.5, subsample_freq=128;, score=0.330 total time=   5.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.836110543310472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.836110543310472\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272473814816409, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8272473814816409\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.485909081979916, reg_lambda=0 will be ignored. Current value: lambda_l2=9.485909081979916\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6092676325175599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6092676325175599\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 1.4946\n",
      "[CV 2/2] END bagging_fraction=0.8272473814816409, bagging_freq=7, feature_fraction=0.6092676325175599, lambda_l1=9.836110543310472, lambda_l2=9.485909081979916, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=399, objective=c, reg_lambda=0, subsample=0.7, subsample_freq=2;, score=0.329 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.40377095667319, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.40377095667319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45482057575272816, subsample=0.7 will be ignored. Current value: bagging_fraction=0.45482057575272816\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.385492964262347, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.385492964262347\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46728222331658076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46728222331658076\n",
      "[CV 2/2] END bagging_fraction=0.6384640767158506, bagging_freq=4, feature_fraction=0.41341347801082384, lambda_l1=3.4708812691329065, lambda_l2=4.753640227944978, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=109, objective=u, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.336 total time=  12.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5882455375590756, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5882455375590756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5549902258097323, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5549902258097323\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1884374534022204, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.1884374534022204\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5867966848194768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5867966848194768\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's multi_logloss: 1.49894\n",
      "[CV 2/2] END bagging_fraction=0.5549902258097323, bagging_freq=8, feature_fraction=0.5867966848194768, lambda_l1=1.5882455375590756, lambda_l2=1.1884374534022204, learning_rate=0.01, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=456, objective=m, reg_lambda=0.0001, subsample=0.5, subsample_freq=4;, score=0.332 total time=   9.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.836110543310472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.836110543310472\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8272473814816409, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8272473814816409\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.485909081979916, reg_lambda=0 will be ignored. Current value: lambda_l2=9.485909081979916\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6092676325175599, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6092676325175599\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=2 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's multi_logloss: 1.50162\n",
      "[CV 1/2] END bagging_fraction=0.8272473814816409, bagging_freq=7, feature_fraction=0.6092676325175599, lambda_l1=9.836110543310472, lambda_l2=9.485909081979916, learning_rate=0.2, metric=multi_logloss, min_child_samples=68, num_class=5, num_leaves=399, objective=c, reg_lambda=0, subsample=0.7, subsample_freq=2;, score=0.328 total time=   5.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.823713605947763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.823713605947763\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.776554270000275, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.776554270000275\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.50812249277382, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.50812249277382\n",
      "[LightGBM] [Warning] feature_fraction is set=0.569127490398326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.569127490398326\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.49186\n",
      "[CV 2/2] END bagging_fraction=0.776554270000275, bagging_freq=9, feature_fraction=0.569127490398326, lambda_l1=9.823713605947763, lambda_l2=6.50812249277382, learning_rate=0.2, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=259, objective=a, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.328 total time=   5.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5224613031977285, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5224613031977285\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.587394752260668, subsample=0.6 will be ignored. Current value: bagging_fraction=0.587394752260668\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.153270627102655, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.153270627102655\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7780600850042099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7780600850042099\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.51858\n",
      "[CV 1/2] END bagging_fraction=0.587394752260668, bagging_freq=4, feature_fraction=0.7780600850042099, lambda_l1=2.5224613031977285, lambda_l2=6.153270627102655, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=395, objective=m, reg_lambda=0.0001, subsample=0.6, subsample_freq=1;, score=0.326 total time=   2.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.527875695373952, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.527875695373952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5478462274873739, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5478462274873739\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.304562061461012, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.304562061461012\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6742395882910619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6742395882910619\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 1.51159\n",
      "[CV 1/2] END bagging_fraction=0.5478462274873739, bagging_freq=4, feature_fraction=0.6742395882910619, lambda_l1=8.527875695373952, lambda_l2=5.304562061461012, learning_rate=0.05, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=389, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=64;, score=0.324 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8968419424657548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8968419424657548\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7645639676809706, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7645639676809706\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.317879264190794, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.317879264190794\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8154650880931797, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8154650880931797\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's multi_logloss: 1.50166\n",
      "[CV 2/2] END bagging_fraction=0.7645639676809706, bagging_freq=2, feature_fraction=0.8154650880931797, lambda_l1=1.8968419424657548, lambda_l2=7.317879264190794, learning_rate=0.01, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=289, objective=m, reg_lambda=0.0001, subsample=0.6, subsample_freq=32;, score=0.332 total time=   9.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5365442305119936, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5365442305119936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7972335308628029, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7972335308628029\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.292605891509674, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.292605891509674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9528322860353792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9528322860353792\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 1.49981\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1884374534022204, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=1.1884374534022204\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5867966848194768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5867966848194768\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=4 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 1.5059\n",
      "[CV 1/2] END bagging_fraction=0.5549902258097323, bagging_freq=8, feature_fraction=0.5867966848194768, lambda_l1=1.5882455375590756, lambda_l2=1.1884374534022204, learning_rate=0.01, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=456, objective=m, reg_lambda=0.0001, subsample=0.5, subsample_freq=4;, score=0.325 total time=   9.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.9215642332761615, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.9215642332761615\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7713692134597273, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7713692134597273\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8742896297933381, reg_lambda=0 will be ignored. Current value: lambda_l2=0.8742896297933381\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8674368179730211, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8674368179730211\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=64 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's multi_logloss: 1.49583\n",
      "[CV 2/2] END bagging_fraction=0.7713692134597273, bagging_freq=8, feature_fraction=0.8674368179730211, lambda_l1=3.9215642332761615, lambda_l2=0.8742896297933381, learning_rate=0.05, metric=multi_logloss, min_child_samples=39, num_class=5, num_leaves=280, objective=t, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=64;, score=0.331 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.81194122023068, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.81194122023068\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6066815418278342, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6066815418278342\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.6719122003976254, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.6719122003976254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5853580004395238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5853580004395238\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=128 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's multi_logloss: 1.49621\n",
      "[CV 2/2] END bagging_fraction=0.6066815418278342, bagging_freq=9, feature_fraction=0.5853580004395238, lambda_l1=9.81194122023068, lambda_l2=4.6719122003976254, learning_rate=0.2, metric=multi_logloss, min_child_samples=25, num_class=5, num_leaves=45, objective=l, reg_lambda=1e-07, subsample=0.5, subsample_freq=128;, score=0.330 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.823713605947763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.823713605947763\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.776554270000275, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.776554270000275\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.50812249277382, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.50812249277382\n",
      "[LightGBM] [Warning] feature_fraction is set=0.569127490398326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.569127490398326\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 1.49578\n",
      "[CV 1/2] END bagging_fraction=0.776554270000275, bagging_freq=9, feature_fraction=0.569127490398326, lambda_l1=9.823713605947763, lambda_l2=6.50812249277382, learning_rate=0.2, metric=multi_logloss, min_child_samples=29, num_class=5, num_leaves=259, objective=a, reg_lambda=1e-06, subsample=0.8999999999999999, subsample_freq=16;, score=0.330 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.40377095667319, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.40377095667319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.45482057575272816, subsample=0.7 will be ignored. Current value: bagging_fraction=0.45482057575272816\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.385492964262347, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.385492964262347\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46728222331658076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46728222331658076\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's multi_logloss: 1.5038\n",
      "[CV 2/2] END bagging_fraction=0.45482057575272816, bagging_freq=5, feature_fraction=0.46728222331658076, lambda_l1=9.40377095667319, lambda_l2=8.385492964262347, learning_rate=0.05, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=114, objective=i, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.325 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.527875695373952, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.527875695373952\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5478462274873739, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5478462274873739\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.304562061461012, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=5.304562061461012\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6742395882910619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6742395882910619\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=64 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's multi_logloss: 1.49944\n",
      "[CV 2/2] END bagging_fraction=0.5478462274873739, bagging_freq=4, feature_fraction=0.6742395882910619, lambda_l1=8.527875695373952, lambda_l2=5.304562061461012, learning_rate=0.05, metric=multi_logloss, min_child_samples=72, num_class=5, num_leaves=389, objective=a, reg_lambda=0.0001, subsample=0.5, subsample_freq=64;, score=0.329 total time=   4.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.601047827402025, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.601047827402025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6965553283483579, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6965553283483579\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151647572468911, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.151647572468911\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9175604952342999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9175604952342999\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[932]\tvalid_0's multi_logloss: 1.49852\n",
      "[CV 1/2] END bagging_fraction=0.6965553283483579, bagging_freq=4, feature_fraction=0.9175604952342999, lambda_l1=8.601047827402025, lambda_l2=7.151647572468911, learning_rate=0.01, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=223, objective=c, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=128;, score=0.332 total time=  24.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2158480278047084, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2158480278047084\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=1 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\tvalid_0's multi_logloss: 1.5154\n",
      "[CV 1/2] END bagging_fraction=0.45482057575272816, bagging_freq=5, feature_fraction=0.46728222331658076, lambda_l1=9.40377095667319, lambda_l2=8.385492964262347, learning_rate=0.05, metric=multi_logloss, min_child_samples=74, num_class=5, num_leaves=114, objective=i, reg_lambda=0.001, subsample=0.7, subsample_freq=1;, score=0.323 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5224613031977285, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5224613031977285\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.587394752260668, subsample=0.6 will be ignored. Current value: bagging_fraction=0.587394752260668\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.153270627102655, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=6.153270627102655\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7780600850042099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7780600850042099\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=1 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 1.50785\n",
      "[CV 2/2] END bagging_fraction=0.587394752260668, bagging_freq=4, feature_fraction=0.7780600850042099, lambda_l1=2.5224613031977285, lambda_l2=6.153270627102655, learning_rate=0.2, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=395, objective=m, reg_lambda=0.0001, subsample=0.6, subsample_freq=1;, score=0.324 total time=   2.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8968419424657548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8968419424657548\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7645639676809706, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7645639676809706\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.317879264190794, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.317879264190794\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8154650880931797, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8154650880931797\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=32 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's multi_logloss: 1.511\n",
      "[CV 1/2] END bagging_fraction=0.7645639676809706, bagging_freq=2, feature_fraction=0.8154650880931797, lambda_l1=1.8968419424657548, lambda_l2=7.317879264190794, learning_rate=0.01, metric=multi_logloss, min_child_samples=97, num_class=5, num_leaves=289, objective=m, reg_lambda=0.0001, subsample=0.6, subsample_freq=32;, score=0.324 total time=   8.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.601047827402025, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.601047827402025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6965553283483579, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6965553283483579\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.151647572468911, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.151647572468911\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9175604952342999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9175604952342999\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[896]\tvalid_0's multi_logloss: 1.49568\n",
      "[CV 2/2] END bagging_fraction=0.6965553283483579, bagging_freq=4, feature_fraction=0.9175604952342999, lambda_l1=8.601047827402025, lambda_l2=7.151647572468911, learning_rate=0.01, metric=multi_logloss, min_child_samples=38, num_class=5, num_leaves=223, objective=c, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=128;, score=0.329 total time=  26.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9868173456078347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9868173456078347\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7492527404319742, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7492527404319742\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.728183438343597, reg_lambda=0 will be ignored. Current value: lambda_l2=4.728183438343597\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7277021836985333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7277021836985333\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's multi_logloss: 1.49666\n",
      "[CV 2/2] END bagging_fraction=0.7492527404319742, bagging_freq=8, feature_fraction=0.7277021836985333, lambda_l1=0.9868173456078347, lambda_l2=4.728183438343597, learning_rate=0.05, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=306, objective=i, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=128;, score=0.328 total time=  14.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.99163632378228, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.99163632378228\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6143500034674888, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6143500034674888\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.35453265912438, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.35453265912438\n",
      "[LightGBM] [Warning] feature_fraction is set=0.609344158886547, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.609344158886547\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[490]\tvalid_0's multi_logloss: 1.51531\n",
      "[CV 1/2] END bagging_fraction=0.6143500034674888, bagging_freq=5, feature_fraction=0.609344158886547, lambda_l1=6.99163632378228, lambda_l2=3.35453265912438, learning_rate=0.01, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=411, objective=l, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=8;, score=0.325 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.99163632378228, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.99163632378228\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6143500034674888, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.6143500034674888\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.35453265912438, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.35453265912438\n",
      "[LightGBM] [Warning] feature_fraction is set=0.609344158886547, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.609344158886547\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=8 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[930]\tvalid_0's multi_logloss: 1.50031\n",
      "[CV 2/2] END bagging_fraction=0.6143500034674888, bagging_freq=5, feature_fraction=0.609344158886547, lambda_l1=6.99163632378228, lambda_l2=3.35453265912438, learning_rate=0.01, metric=multi_logloss, min_child_samples=93, num_class=5, num_leaves=411, objective=l, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=8;, score=0.326 total time=  12.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.472357601542338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.472357601542338\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8061750601224766, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8061750601224766\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.592710054436431, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.592710054436431\n",
      "[CV 1/2] END bagging_fraction=0.7972335308628029, bagging_freq=7, feature_fraction=0.9528322860353792, lambda_l1=3.5365442305119936, lambda_l2=4.292605891509674, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=259, objective=s, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.330 total time=   3.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.5365442305119936, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5365442305119936\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7972335308628029, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7972335308628029\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.292605891509674, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=4.292605891509674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9528322860353792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9528322860353792\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's multi_logloss: 1.49936\n",
      "[CV 2/2] END bagging_fraction=0.7972335308628029, bagging_freq=7, feature_fraction=0.9528322860353792, lambda_l1=3.5365442305119936, lambda_l2=4.292605891509674, learning_rate=0.2, metric=multi_logloss, min_child_samples=58, num_class=5, num_leaves=259, objective=s, reg_lambda=1e-07, subsample=0.6, subsample_freq=64;, score=0.331 total time=   3.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.150759696578932, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.150759696578932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7006891077082984, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7006891077082984\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2489427821950674, reg_lambda=0 will be ignored. Current value: lambda_l2=1.2489427821950674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8903620765245936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8903620765245936\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 1.49645\n",
      "[CV 1/2] END bagging_fraction=0.7006891077082984, bagging_freq=3, feature_fraction=0.8903620765245936, lambda_l1=3.150759696578932, lambda_l2=1.2489427821950674, learning_rate=0.2, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=168, objective=l, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.332 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.150759696578932, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.150759696578932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7006891077082984, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7006891077082984\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2489427821950674, reg_lambda=0 will be ignored. Current value: lambda_l2=1.2489427821950674\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8903620765245936, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8903620765245936\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 1.49921\n",
      "[CV 2/2] END bagging_fraction=0.7006891077082984, bagging_freq=3, feature_fraction=0.8903620765245936, lambda_l1=3.150759696578932, lambda_l2=1.2489427821950674, learning_rate=0.2, metric=multi_logloss, min_child_samples=34, num_class=5, num_leaves=168, objective=l, reg_lambda=0, subsample=0.6, subsample_freq=64;, score=0.325 total time=   6.0s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2158480278047084, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2158480278047084\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.926446124471149, subsample=0.5 will be ignored. Current value: bagging_fraction=0.926446124471149\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.504433239345545, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.504433239345545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5469198047977524, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5469198047977524\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.49904\n",
      "[CV 2/2] END bagging_fraction=0.926446124471149, bagging_freq=6, feature_fraction=0.5469198047977524, lambda_l1=0.2158480278047084, lambda_l2=8.504433239345545, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=412, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=128;, score=0.328 total time=   5.3s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.724001057744262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.724001057744262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8121962330154695, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8121962330154695\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.854518718755088, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.854518718755088\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8558857590827817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8558857590827817\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's multi_logloss: 1.49707\n",
      "[CV 1/2] END bagging_fraction=0.8121962330154695, bagging_freq=8, feature_fraction=0.8558857590827817, lambda_l1=9.724001057744262, lambda_l2=7.854518718755088, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=68, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=128;, score=0.335 total time=  29.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.472357601542338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.472357601542338\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8061750601224766, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8061750601224766\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.592710054436431, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=5.592710054436431\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9264545845814706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9264545845814706\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 1.4932\n",
      "[CV 1/2] END bagging_fraction=0.8061750601224766, bagging_freq=6, feature_fraction=0.9264545845814706, lambda_l1=5.472357601542338, lambda_l2=5.592710054436431, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=483, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=16;, score=0.327 total time=  14.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.082360166518533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.082360166518533\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4249994490715323, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4249994490715323\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.014732190401514, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.014732190401514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9261338535193284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9261338535193284\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 1.51345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.926446124471149, subsample=0.5 will be ignored. Current value: bagging_fraction=0.926446124471149\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.504433239345545, reg_lambda=0.001 will be ignored. Current value: lambda_l2=8.504433239345545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5469198047977524, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5469198047977524\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=128 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 1.50634\n",
      "[CV 1/2] END bagging_fraction=0.926446124471149, bagging_freq=6, feature_fraction=0.5469198047977524, lambda_l1=0.2158480278047084, lambda_l2=8.504433239345545, learning_rate=0.2, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=412, objective=t, reg_lambda=0.001, subsample=0.5, subsample_freq=128;, score=0.327 total time=   4.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9868173456078347, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9868173456078347\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7492527404319742, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.7492527404319742\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.728183438343597, reg_lambda=0 will be ignored. Current value: lambda_l2=4.728183438343597\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7277021836985333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7277021836985333\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 1.49165\n",
      "[CV 1/2] END bagging_fraction=0.7492527404319742, bagging_freq=8, feature_fraction=0.7277021836985333, lambda_l1=0.9868173456078347, lambda_l2=4.728183438343597, learning_rate=0.05, metric=multi_logloss, min_child_samples=19, num_class=5, num_leaves=306, objective=i, reg_lambda=0, subsample=0.7999999999999999, subsample_freq=128;, score=0.333 total time=  15.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.724001057744262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.724001057744262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8121962330154695, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8121962330154695\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.854518718755088, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.854518718755088\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8558857590827817, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8558857590827817\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=128 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[551]\tvalid_0's multi_logloss: 1.48989\n",
      "[CV 2/2] END bagging_fraction=0.8121962330154695, bagging_freq=8, feature_fraction=0.8558857590827817, lambda_l1=9.724001057744262, lambda_l2=7.854518718755088, learning_rate=0.01, metric=multi_logloss, min_child_samples=7, num_class=5, num_leaves=68, objective=l, reg_lambda=1e-05, subsample=0.5, subsample_freq=128;, score=0.332 total time=  33.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.082360166518533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.082360166518533\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4249994490715323, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4249994490715323\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.014732190401514, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=1.014732190401514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9261338535193284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9261338535193284\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=1 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 1.50419\n",
      "[CV 2/2] END bagging_fraction=0.4249994490715323, bagging_freq=7, feature_fraction=0.9261338535193284, lambda_l1=7.082360166518533, lambda_l2=1.014732190401514, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=152, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=1;, score=0.324 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.535410605685753, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.535410605685753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48733913847593435, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.48733913847593435\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.442699470377767, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.442699470377767\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5107798584109883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5107798584109883\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[672]\tvalid_0's multi_logloss: 1.51699\n",
      "[CV 1/2] END bagging_fraction=0.48733913847593435, bagging_freq=7, feature_fraction=0.5107798584109883, lambda_l1=9.535410605685753, lambda_l2=7.442699470377767, learning_rate=0.01, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=129, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=64;, score=0.326 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.535410605685753, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.535410605685753\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.48733913847593435, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.48733913847593435\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.442699470377767, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.442699470377767\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5107798584109883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5107798584109883\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=64 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[861]\tvalid_0's multi_logloss: 1.50577\n",
      "[CV 2/2] END bagging_fraction=0.48733913847593435, bagging_freq=7, feature_fraction=0.5107798584109883, lambda_l1=9.535410605685753, lambda_l2=7.442699470377767, learning_rate=0.01, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=129, objective=s, reg_lambda=1e-05, subsample=0.7999999999999999, subsample_freq=64;, score=0.328 total time=   9.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.369085426920027, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.369085426920027\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8684932775007265, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8684932775007265\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18703587279278816, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.18703587279278816\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6114878832387142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6114878832387142\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's multi_logloss: 1.49734\n",
      "[CV 2/2] END bagging_fraction=0.8684932775007265, bagging_freq=6, feature_fraction=0.6114878832387142, lambda_l1=9.369085426920027, lambda_l2=0.18703587279278816, learning_rate=0.05, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=77, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=2;, score=0.330 total time=   6.2s\n",
      "[CV 1/2] END bagging_fraction=0.4249994490715323, bagging_freq=7, feature_fraction=0.9261338535193284, lambda_l1=7.082360166518533, lambda_l2=1.014732190401514, learning_rate=0.2, metric=multi_logloss, min_child_samples=61, num_class=5, num_leaves=152, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=1;, score=0.322 total time=   2.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.602468937297789, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.602468937297789\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6103395729215753, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6103395729215753\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.545776562550809, reg_lambda=0 will be ignored. Current value: lambda_l2=6.545776562550809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5515379810518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5515379810518184\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1108]\tvalid_0's multi_logloss: 1.50062\n",
      "[CV 2/2] END bagging_fraction=0.6103395729215753, bagging_freq=2, feature_fraction=0.5515379810518184, lambda_l1=7.602468937297789, lambda_l2=6.545776562550809, learning_rate=0.01, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=378, objective=t, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.328 total time=  14.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.67982995876063, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.67982995876063\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6372402341123782, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6372402341123782\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.404923319909192, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.404923319909192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4087256257093836, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4087256257093836\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's multi_logloss: 1.50524\n",
      "[CV 1/2] END bagging_fraction=0.6372402341123782, bagging_freq=5, feature_fraction=0.4087256257093836, lambda_l1=8.67982995876063, lambda_l2=6.404923319909192, learning_rate=0.2, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=159, objective=i, reg_lambda=1e-06, subsample=0.7, subsample_freq=64;, score=0.326 total time=   3.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.369085426920027, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.369085426920027\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8684932775007265, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8684932775007265\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18703587279278816, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.18703587279278816\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6114878832387142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6114878832387142\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's multi_logloss: 1.50811\n",
      "[CV 1/2] END bagging_fraction=0.8684932775007265, bagging_freq=6, feature_fraction=0.6114878832387142, lambda_l1=9.369085426920027, lambda_l2=0.18703587279278816, learning_rate=0.05, metric=multi_logloss, min_child_samples=98, num_class=5, num_leaves=77, objective=s, reg_lambda=1e-07, subsample=0.7, subsample_freq=2;, score=0.326 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3603935023258265, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3603935023258265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6499983433774907, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6499983433774907\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.454554522679579, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.454554522679579\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9619969889796103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9619969889796103\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 1.49931\n",
      "[CV 2/2] END bagging_fraction=0.6499983433774907, bagging_freq=3, feature_fraction=0.9619969889796103, lambda_l1=2.3603935023258265, lambda_l2=4.454554522679579, learning_rate=0.05, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=136, objective=c, reg_lambda=0.001, subsample=0.6, subsample_freq=64;, score=0.329 total time=   6.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3527683955738854, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3527683955738854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6550938232259771, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6550938232259771\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.142408882749283, reg_lambda=0 will be ignored. Current value: lambda_l2=8.142408882749283\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5936466655513992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5936466655513992\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[592]\tvalid_0's multi_logloss: 1.51042\n",
      "[CV 1/2] END bagging_fraction=0.6550938232259771, bagging_freq=2, feature_fraction=0.5936466655513992, lambda_l1=3.3527683955738854, lambda_l2=8.142408882749283, learning_rate=0.01, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=433, objective=i, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=4;, score=0.323 total time=  10.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.051632717265924, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.051632717265924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5619640979398458, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5619640979398458\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0738461893605606, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.0738461893605606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5303915374315105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5303915374315105\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 1.51388\n",
      "[CV 1/2] END bagging_fraction=0.5619640979398458, bagging_freq=3, feature_fraction=0.5303915374315105, lambda_l1=5.051632717265924, lambda_l2=3.0738461893605606, learning_rate=0.2, metric=multi_logloss, min_child_samples=89, num_class=5, num_leaves=47, objective=s, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=2;, score=0.323 total time=   2.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7783137699388298, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7783137699388298\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9728160788684318, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9728160788684318\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6815787926996526, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.6815787926996526\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7112667523046912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7112667523046912\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9264545845814706, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9264545845814706\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.49363\n",
      "[CV 2/2] END bagging_fraction=0.8061750601224766, bagging_freq=6, feature_fraction=0.9264545845814706, lambda_l1=5.472357601542338, lambda_l2=5.592710054436431, learning_rate=0.05, metric=multi_logloss, min_child_samples=14, num_class=5, num_leaves=483, objective=i, reg_lambda=1e-07, subsample=0.6, subsample_freq=16;, score=0.333 total time=  13.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.602468937297789, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.602468937297789\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6103395729215753, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6103395729215753\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.545776562550809, reg_lambda=0 will be ignored. Current value: lambda_l2=6.545776562550809\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5515379810518184, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5515379810518184\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=128 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1246]\tvalid_0's multi_logloss: 1.51383\n",
      "[CV 1/2] END bagging_fraction=0.6103395729215753, bagging_freq=2, feature_fraction=0.5515379810518184, lambda_l1=7.602468937297789, lambda_l2=6.545776562550809, learning_rate=0.01, metric=multi_logloss, min_child_samples=91, num_class=5, num_leaves=378, objective=t, reg_lambda=0, subsample=0.7, subsample_freq=128;, score=0.323 total time=  14.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.67982995876063, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.67982995876063\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6372402341123782, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6372402341123782\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.404923319909192, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.404923319909192\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4087256257093836, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4087256257093836\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=64 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's multi_logloss: 1.49901\n",
      "[CV 2/2] END bagging_fraction=0.6372402341123782, bagging_freq=5, feature_fraction=0.4087256257093836, lambda_l1=8.67982995876063, lambda_l2=6.404923319909192, learning_rate=0.2, metric=multi_logloss, min_child_samples=71, num_class=5, num_leaves=159, objective=i, reg_lambda=1e-06, subsample=0.7, subsample_freq=64;, score=0.330 total time=   4.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3603935023258265, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3603935023258265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6499983433774907, subsample=0.6 will be ignored. Current value: bagging_fraction=0.6499983433774907\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.454554522679579, reg_lambda=0.001 will be ignored. Current value: lambda_l2=4.454554522679579\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9619969889796103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9619969889796103\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=64 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 1.4953\n",
      "[CV 1/2] END bagging_fraction=0.6499983433774907, bagging_freq=3, feature_fraction=0.9619969889796103, lambda_l1=2.3603935023258265, lambda_l2=4.454554522679579, learning_rate=0.05, metric=multi_logloss, min_child_samples=46, num_class=5, num_leaves=136, objective=c, reg_lambda=0.001, subsample=0.6, subsample_freq=64;, score=0.333 total time=   6.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4931439241923241, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4931439241923241\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5359560929950576, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5359560929950576\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.712378986559485, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.712378986559485\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6135909143344291, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6135909143344291\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 1.49471\n",
      "[CV 2/2] END bagging_fraction=0.5359560929950576, bagging_freq=6, feature_fraction=0.6135909143344291, lambda_l1=1.4931439241923241, lambda_l2=7.712378986559485, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=489, objective=c, reg_lambda=1e-07, subsample=0.5, subsample_freq=16;, score=0.325 total time=   8.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3527683955738854, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3527683955738854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6550938232259771, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.6550938232259771\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.142408882749283, reg_lambda=0 will be ignored. Current value: lambda_l2=8.142408882749283\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5936466655513992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5936466655513992\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=4 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[516]\tvalid_0's multi_logloss: 1.49904\n",
      "[CV 2/2] END bagging_fraction=0.6550938232259771, bagging_freq=2, feature_fraction=0.5936466655513992, lambda_l1=3.3527683955738854, lambda_l2=8.142408882749283, learning_rate=0.01, metric=multi_logloss, min_child_samples=82, num_class=5, num_leaves=433, objective=i, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=4;, score=0.333 total time=   9.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3779228396209495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3779228396209495\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5202463094400165, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5202463094400165\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.077415392369303, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.077415392369303\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5466342967605103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5466342967605103\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[584]\tvalid_0's multi_logloss: 1.50411\n",
      "[CV 1/2] END bagging_fraction=0.5202463094400165, bagging_freq=2, feature_fraction=0.5466342967605103, lambda_l1=3.3779228396209495, lambda_l2=6.077415392369303, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=454, objective=l, reg_lambda=1e-07, subsample=0.5, subsample_freq=1;, score=0.330 total time=  11.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.454906627625237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.454906627625237\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8933789681009902, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8933789681009902\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49701391486533214, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.49701391486533214\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4931439241923241, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4931439241923241\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5359560929950576, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5359560929950576\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.712378986559485, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=7.712378986559485\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6135909143344291, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6135909143344291\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=16 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 1.49612\n",
      "[CV 1/2] END bagging_fraction=0.5359560929950576, bagging_freq=6, feature_fraction=0.6135909143344291, lambda_l1=1.4931439241923241, lambda_l2=7.712378986559485, learning_rate=0.05, metric=multi_logloss, min_child_samples=20, num_class=5, num_leaves=489, objective=c, reg_lambda=1e-07, subsample=0.5, subsample_freq=16;, score=0.333 total time=   9.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.522260577637817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.522260577637817\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8441390225350152, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8441390225350152\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.710500055157094, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.710500055157094\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9388468139761236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9388468139761236\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's multi_logloss: 1.50087\n",
      "[CV 1/2] END bagging_fraction=0.8441390225350152, bagging_freq=4, feature_fraction=0.9388468139761236, lambda_l1=6.522260577637817, lambda_l2=6.710500055157094, learning_rate=0.2, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=118, objective=c, reg_lambda=1e-06, subsample=0.5, subsample_freq=2;, score=0.330 total time=   3.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.522260577637817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.522260577637817\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8441390225350152, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8441390225350152\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.710500055157094, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=6.710500055157094\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9388468139761236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9388468139761236\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=2 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's multi_logloss: 1.49741\n",
      "[CV 2/2] END bagging_fraction=0.8441390225350152, bagging_freq=4, feature_fraction=0.9388468139761236, lambda_l1=6.522260577637817, lambda_l2=6.710500055157094, learning_rate=0.2, metric=multi_logloss, min_child_samples=67, num_class=5, num_leaves=118, objective=c, reg_lambda=1e-06, subsample=0.5, subsample_freq=2;, score=0.329 total time=   3.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.051632717265924, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.051632717265924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5619640979398458, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.5619640979398458\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0738461893605606, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=3.0738461893605606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5303915374315105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5303915374315105\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=2 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's multi_logloss: 1.50306\n",
      "[CV 2/2] END bagging_fraction=0.5619640979398458, bagging_freq=3, feature_fraction=0.5303915374315105, lambda_l1=5.051632717265924, lambda_l2=3.0738461893605606, learning_rate=0.2, metric=multi_logloss, min_child_samples=89, num_class=5, num_leaves=47, objective=s, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=2;, score=0.325 total time=   2.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7783137699388298, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7783137699388298\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9728160788684318, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9728160788684318\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6815787926996526, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=2.6815787926996526\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7112667523046912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7112667523046912\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=32 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 1.498\n",
      "[CV 2/2] END bagging_fraction=0.9728160788684318, bagging_freq=5, feature_fraction=0.7112667523046912, lambda_l1=1.7783137699388298, lambda_l2=2.6815787926996526, learning_rate=0.05, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=297, objective=c, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=32;, score=0.329 total time=   6.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.454906627625237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.454906627625237\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8933789681009902, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8933789681009902\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49701391486533214, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=0.49701391486533214\n",
      "[LightGBM] [Warning] feature_fraction is set=0.474101237616755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.474101237616755\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's multi_logloss: 1.48972\n",
      "[CV 1/2] END bagging_fraction=0.8933789681009902, bagging_freq=3, feature_fraction=0.474101237616755, lambda_l1=6.454906627625237, lambda_l2=0.49701391486533214, learning_rate=0.2, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=326, objective=l, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.331 total time=   7.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.432064718361993, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.432064718361993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8993895942210343, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8993895942210343\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715834880065383, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.715834880065383\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5213263796938586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5213263796938586\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 1.49675\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's multi_logloss: 1.49802\n",
      "[CV 1/2] END bagging_fraction=0.9728160788684318, bagging_freq=5, feature_fraction=0.7112667523046912, lambda_l1=1.7783137699388298, lambda_l2=2.6815787926996526, learning_rate=0.05, metric=multi_logloss, min_child_samples=64, num_class=5, num_leaves=297, objective=c, reg_lambda=1e-07, subsample=0.7999999999999999, subsample_freq=32;, score=0.329 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3779228396209495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3779228396209495\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5202463094400165, subsample=0.5 will be ignored. Current value: bagging_fraction=0.5202463094400165\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.077415392369303, reg_lambda=1e-07 will be ignored. Current value: lambda_l2=6.077415392369303\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5466342967605103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5466342967605103\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=1 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's multi_logloss: 1.49627\n",
      "[CV 2/2] END bagging_fraction=0.5202463094400165, bagging_freq=2, feature_fraction=0.5466342967605103, lambda_l1=3.3779228396209495, lambda_l2=6.077415392369303, learning_rate=0.01, metric=multi_logloss, min_child_samples=52, num_class=5, num_leaves=454, objective=l, reg_lambda=1e-07, subsample=0.5, subsample_freq=1;, score=0.330 total time=  14.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.432064718361993, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.432064718361993\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8993895942210343, subsample=0.5 will be ignored. Current value: bagging_fraction=0.8993895942210343\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.715834880065383, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=8.715834880065383\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5213263796938586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5213263796938586\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=4 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 1.49334\n",
      "[CV 2/2] END bagging_fraction=0.8993895942210343, bagging_freq=9, feature_fraction=0.5213263796938586, lambda_l1=7.432064718361993, lambda_l2=8.715834880065383, learning_rate=0.05, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=197, objective=t, reg_lambda=1e-05, subsample=0.5, subsample_freq=4;, score=0.328 total time=   7.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.388552106109199, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.388552106109199\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8061406626766394, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8061406626766394\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.792643764437274, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.792643764437274\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9694981609105621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9694981609105621\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[419]\tvalid_0's multi_logloss: 1.49654\n",
      "[CV 1/2] END bagging_fraction=0.8061406626766394, bagging_freq=6, feature_fraction=0.9694981609105621, lambda_l1=8.388552106109199, lambda_l2=2.792643764437274, learning_rate=0.05, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=510, objective=a, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=256;, score=0.328 total time=  10.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4867182325721204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4867182325721204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5342075916780376, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5342075916780376\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7066629030309538, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.7066629030309538\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9465971162626713, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9465971162626713\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 1.49812\n",
      "[CV 2/2] END bagging_fraction=0.5342075916780376, bagging_freq=3, feature_fraction=0.9465971162626713, lambda_l1=3.4867182325721204, lambda_l2=0.7066629030309538, learning_rate=0.05, metric=multi_logloss, min_child_samples=45, num_class=5, num_leaves=474, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.331 total time=   5.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.76824532105067, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.76824532105067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8773630633764082, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8773630633764082\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.467465262291041, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.467465262291041\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7963829448182822, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7963829448182822\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's multi_logloss: 1.49655\n",
      "[CV 1/2] END bagging_fraction=0.8773630633764082, bagging_freq=6, feature_fraction=0.7963829448182822, lambda_l1=3.76824532105067, lambda_l2=7.467465262291041, learning_rate=0.05, metric=multi_logloss, min_child_samples=53, num_class=5, num_leaves=81, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.329 total time=   7.4s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.76824532105067, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.76824532105067\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8773630633764082, subsample=0.7 will be ignored. Current value: bagging_fraction=0.8773630633764082\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.467465262291041, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=7.467465262291041\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7963829448182822, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7963829448182822\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=2 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 1.49712\n",
      "[CV 2/2] END bagging_fraction=0.8773630633764082, bagging_freq=6, feature_fraction=0.7963829448182822, lambda_l1=3.76824532105067, lambda_l2=7.467465262291041, learning_rate=0.05, metric=multi_logloss, min_child_samples=53, num_class=5, num_leaves=81, objective=t, reg_lambda=0.0001, subsample=0.7, subsample_freq=2;, score=0.330 total time=   7.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.72414254313204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.72414254313204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8418703093999174, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8418703093999174\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.75464497925123, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.75464497925123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.724704793299165, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.724704793299165\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[CV 1/2] END bagging_fraction=0.8993895942210343, bagging_freq=9, feature_fraction=0.5213263796938586, lambda_l1=7.432064718361993, lambda_l2=8.715834880065383, learning_rate=0.05, metric=multi_logloss, min_child_samples=43, num_class=5, num_leaves=197, objective=t, reg_lambda=1e-05, subsample=0.5, subsample_freq=4;, score=0.333 total time=   7.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.579747982827822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.579747982827822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9638553865676097, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9638553865676097\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.746821066958319, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.746821066958319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897489014140031, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897489014140031\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 1.4901\n",
      "[CV 2/2] END bagging_fraction=0.9638553865676097, bagging_freq=2, feature_fraction=0.8897489014140031, lambda_l1=5.579747982827822, lambda_l2=5.746821066958319, learning_rate=0.05, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=49, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.333 total time=   7.9s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.376604692441381, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.376604692441381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4944347421968921, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4944347421968921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12673075900030112, reg_lambda=0 will be ignored. Current value: lambda_l2=0.12673075900030112\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7062633684808322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062633684808322\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 1.50101\n",
      "[CV 1/2] END bagging_fraction=0.4944347421968921, bagging_freq=3, feature_fraction=0.7062633684808322, lambda_l1=6.376604692441381, lambda_l2=0.12673075900030112, learning_rate=0.05, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=170, objective=l, reg_lambda=0, subsample=0.5, subsample_freq=128;, score=0.330 total time=   5.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.4867182325721204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.4867182325721204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5342075916780376, subsample=0.6 will be ignored. Current value: bagging_fraction=0.5342075916780376\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7066629030309538, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.7066629030309538\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9465971162626713, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9465971162626713\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's multi_logloss: 1.49732\n",
      "[CV 1/2] END bagging_fraction=0.5342075916780376, bagging_freq=3, feature_fraction=0.9465971162626713, lambda_l1=3.4867182325721204, lambda_l2=0.7066629030309538, learning_rate=0.05, metric=multi_logloss, min_child_samples=45, num_class=5, num_leaves=474, objective=s, reg_lambda=1e-06, subsample=0.6, subsample_freq=32;, score=0.333 total time=   4.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6398103475817655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6398103475817655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42530556043732237, subsample=0.6 will be ignored. Current value: bagging_fraction=0.42530556043732237\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2631574938071397, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.2631574938071397\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6789233879103613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6789233879103613\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's multi_logloss: 1.49518\n",
      "[CV 2/2] END bagging_fraction=0.42530556043732237, bagging_freq=3, feature_fraction=0.6789233879103613, lambda_l1=0.6398103475817655, lambda_l2=3.2631574938071397, learning_rate=0.01, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=72, objective=i, reg_lambda=0.001, subsample=0.6, subsample_freq=16;, score=0.328 total time=  13.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.469982716092264, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.469982716092264\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6897938680182623, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6897938680182623\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.18710823546008, reg_lambda=0 will be ignored. Current value: lambda_l2=2.18710823546008\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6049073957845684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6049073957845684\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid_0's multi_logloss: 1.49012\n",
      "[CV 2/2] END bagging_fraction=0.6897938680182623, bagging_freq=5, feature_fraction=0.6049073957845684, lambda_l1=8.469982716092264, lambda_l2=2.18710823546008, learning_rate=0.05, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=399, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=2;, score=0.331 total time=  15.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.72414254313204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.72414254313204\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8418703093999174, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.8418703093999174\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.75464497925123, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=9.75464497925123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.724704793299165, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.724704793299165\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=256 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[667]\tvalid_0's multi_logloss: 1.49817\n",
      "[CV 2/2] END bagging_fraction=0.8418703093999174, bagging_freq=5, feature_fraction=0.724704793299165, lambda_l1=6.72414254313204, lambda_l2=9.75464497925123, learning_rate=0.01, metric=multi_logloss, min_child_samples=88, num_class=5, num_leaves=395, objective=m, reg_lambda=1e-05, subsample=0.8999999999999999, subsample_freq=256;, score=0.331 total time=  13.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.369045018590926, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.369045018590926\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7278447362605645, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.7278447362605645\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.084153582000821, reg_lambda=1e-05 will be ignored. Current value: lambda_l2=7.084153582000821\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8591357013682017, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8591357013682017\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=128 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 1.49476\n",
      "[LightGBM] [Warning] feature_fraction is set=0.474101237616755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.474101237616755\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=32 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's multi_logloss: 1.49265\n",
      "[CV 2/2] END bagging_fraction=0.8933789681009902, bagging_freq=3, feature_fraction=0.474101237616755, lambda_l1=6.454906627625237, lambda_l2=0.49701391486533214, learning_rate=0.2, metric=multi_logloss, min_child_samples=22, num_class=5, num_leaves=326, objective=l, reg_lambda=1e-07, subsample=0.8999999999999999, subsample_freq=32;, score=0.332 total time=   6.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.579747982827822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.579747982827822\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9638553865676097, subsample=0.7 will be ignored. Current value: bagging_fraction=0.9638553865676097\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.746821066958319, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=5.746821066958319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8897489014140031, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8897489014140031\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=256 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's multi_logloss: 1.49393\n",
      "[CV 1/2] END bagging_fraction=0.9638553865676097, bagging_freq=2, feature_fraction=0.8897489014140031, lambda_l1=5.579747982827822, lambda_l2=5.746821066958319, learning_rate=0.05, metric=multi_logloss, min_child_samples=28, num_class=5, num_leaves=49, objective=l, reg_lambda=1e-06, subsample=0.7, subsample_freq=256;, score=0.335 total time=   7.8s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.388552106109199, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.388552106109199\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8061406626766394, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.8061406626766394\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.792643764437274, reg_lambda=0.0001 will be ignored. Current value: lambda_l2=2.792643764437274\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9694981609105621, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9694981609105621\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=256 will be ignored. Current value: bagging_freq=6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's multi_logloss: 1.49586\n",
      "[CV 2/2] END bagging_fraction=0.8061406626766394, bagging_freq=6, feature_fraction=0.9694981609105621, lambda_l1=8.388552106109199, lambda_l2=2.792643764437274, learning_rate=0.05, metric=multi_logloss, min_child_samples=36, num_class=5, num_leaves=510, objective=a, reg_lambda=0.0001, subsample=0.7999999999999999, subsample_freq=256;, score=0.331 total time=   7.2s\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.376604692441381, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.376604692441381\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4944347421968921, subsample=0.5 will be ignored. Current value: bagging_fraction=0.4944347421968921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12673075900030112, reg_lambda=0 will be ignored. Current value: lambda_l2=0.12673075900030112\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7062633684808322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062633684808322\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=128 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's multi_logloss: 1.49681\n",
      "[CV 2/2] END bagging_fraction=0.4944347421968921, bagging_freq=3, feature_fraction=0.7062633684808322, lambda_l1=6.376604692441381, lambda_l2=0.12673075900030112, learning_rate=0.05, metric=multi_logloss, min_child_samples=47, num_class=5, num_leaves=170, objective=l, reg_lambda=0, subsample=0.5, subsample_freq=128;, score=0.328 total time=   5.1s\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6398103475817655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6398103475817655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42530556043732237, subsample=0.6 will be ignored. Current value: bagging_fraction=0.42530556043732237\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2631574938071397, reg_lambda=0.001 will be ignored. Current value: lambda_l2=3.2631574938071397\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6789233879103613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6789233879103613\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=16 will be ignored. Current value: bagging_freq=3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's multi_logloss: 1.49717\n",
      "[CV 1/2] END bagging_fraction=0.42530556043732237, bagging_freq=3, feature_fraction=0.6789233879103613, lambda_l1=0.6398103475817655, lambda_l2=3.2631574938071397, learning_rate=0.01, metric=multi_logloss, min_child_samples=33, num_class=5, num_leaves=72, objective=i, reg_lambda=0.001, subsample=0.6, subsample_freq=16;, score=0.331 total time=  12.6s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.469982716092264, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.469982716092264\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6897938680182623, subsample=0.5 will be ignored. Current value: bagging_fraction=0.6897938680182623\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.18710823546008, reg_lambda=0 will be ignored. Current value: lambda_l2=2.18710823546008\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6049073957845684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6049073957845684\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=2 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid_0's multi_logloss: 1.49109\n",
      "[CV 1/2] END bagging_fraction=0.6897938680182623, bagging_freq=5, feature_fraction=0.6049073957845684, lambda_l1=8.469982716092264, lambda_l2=2.18710823546008, learning_rate=0.05, metric=multi_logloss, min_child_samples=21, num_class=5, num_leaves=399, objective=c, reg_lambda=0, subsample=0.5, subsample_freq=2;, score=0.327 total time=  17.7s\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.66803185220932, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.66803185220932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.770942981115402, subsample=0.8999999999999999 will be ignored. Current value: bagging_fraction=0.770942981115402\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.55278662729093, reg_lambda=0 will be ignored. Current value: lambda_l2=8.55278662729093\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9636865542435431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9636865542435431\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=16 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's multi_logloss: 1.49348\n",
      "[CV 1/2] END bagging_fraction=0.770942981115402, bagging_freq=9, feature_fraction=0.9636865542435431, lambda_l1=4.66803185220932, lambda_l2=8.55278662729093, learning_rate=0.01, metric=multi_logloss, min_child_samples=27, num_class=5, num_leaves=142, objective=m, reg_lambda=0, subsample=0.8999999999999999, subsample_freq=16;, score=0.333 total time=  28.5s\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.514051109732025, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.514051109732025\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9753395776863598, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9753395776863598\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1021671832151014, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1021671832151014\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9973112473189107, subsample=0.7999999999999999 will be ignored. Current value: bagging_fraction=0.9973112473189107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0895315270426858, reg_lambda=1e-06 will be ignored. Current value: lambda_l2=0.0895315270426858\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8405368817955569, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8405368817955569\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=16 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1303]\tvalid_0's multi_logloss: 1.45419\n",
      "最適パラメータ {'bagging_fraction': 0.9973112473189107, 'bagging_freq': 5, 'feature_fraction': 0.8405368817955569, 'lambda_l1': 3.1021671832151014, 'lambda_l2': 0.0895315270426858, 'learning_rate': 0.01, 'metric': 'multi_logloss', 'min_child_samples': 13, 'num_class': 5, 'num_leaves': 24, 'objective': 'i', 'reg_lambda': 1e-06, 'subsample': 0.7999999999999999, 'subsample_freq': 16}\n",
      "スコア 0.34063333333333334\n"
     ]
    }
   ],
   "source": [
    "# scikit-lean実装\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy as sp\n",
    "\n",
    "lightgbm_model = lgb.LGBMClassifier(n_estimators=10000, verbose=-1)\n",
    "\n",
    "param_lgb = {\n",
    "    'objective'         : 'multiclass',\n",
    "    'metric'       : ['multi_logloss'],\n",
    "    'num_class'         : [5],\n",
    "    \"subsample\"         : np.arange(0.5, 1.0, 0.1),\n",
    "    \"subsample_freq\"    : [1, 2, 4, 8, 16, 32, 64, 128, 256],\n",
    "    \"reg_lambda\"        : [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 0],\n",
    "    \"learning_rate\"     : [0.2 ,0.05, 0.01],\n",
    "    \"lambda_l1\"         : sp.stats.uniform(1e-8, 10.0),\n",
    "    \"lambda_l2\"         : sp.stats.uniform(1e-8, 10.0),\n",
    "    \"num_leaves\"        : sp.stats.randint(2, 512),\n",
    "    \"feature_fraction\"  : sp.stats.uniform(0.4, 0.6),\n",
    "    \"bagging_fraction\"  : sp.stats.uniform(0.4, 0.6),\n",
    "    \"bagging_freq\"      : sp.stats.randint(2, 10),\n",
    "    \"min_child_samples\" : sp.stats.randint(5, 100)\n",
    "}\n",
    "\n",
    "\n",
    "randcv = RandomizedSearchCV(estimator=lightgbm_model, param_distributions=param_lgb, scoring=\"accuracy\", n_jobs=3, verbose=3, cv=2, random_state = 47, n_iter=500)\n",
    "\n",
    "fit_params = {\"callbacks\": [lgb.early_stopping(\n",
    "                  stopping_rounds=100, # 学習時、評価指標がこの回数連続で改善しなくなった時点でストップ\n",
    "                  verbose=3)],  # 学習中のコマンドライン出力\n",
    "              \"eval_metric\": 'multiclass',  # early_stopping_roundsの評価指標\n",
    "              \"eval_set\": [(dev_vec, dev_label)]  # early_stopping_roundsの評価指標算出用データ\n",
    "              }\n",
    "\n",
    "# ランダムサーチ実行（学習実行）\n",
    "randcv.fit(train_vec, train_label, **fit_params)\n",
    "\n",
    "# 最適パラメータの表示と保持\n",
    "best_params = randcv.best_params_\n",
    "best_score = randcv.best_score_\n",
    "print(f\"最適パラメータ {best_params}\\nスコア {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bagging_fraction</th>\n",
       "      <th>param_bagging_freq</th>\n",
       "      <th>param_feature_fraction</th>\n",
       "      <th>param_lambda_l1</th>\n",
       "      <th>param_lambda_l2</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_min_child_samples</th>\n",
       "      <th>param_num_class</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_subsample_freq</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>23.508597</td>\n",
       "      <td>2.745423</td>\n",
       "      <td>2.695441</td>\n",
       "      <td>0.908180</td>\n",
       "      <td>0.944765</td>\n",
       "      <td>6</td>\n",
       "      <td>0.850137</td>\n",
       "      <td>4.934807</td>\n",
       "      <td>5.964912</td>\n",
       "      <td>0.01</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>a</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>{'bagging_fraction': 0.9447645033556015, 'bagg...</td>\n",
       "      <td>0.335733</td>\n",
       "      <td>0.334267</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10.930890</td>\n",
       "      <td>0.030695</td>\n",
       "      <td>0.572038</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.781611</td>\n",
       "      <td>6</td>\n",
       "      <td>0.450322</td>\n",
       "      <td>3.217934</td>\n",
       "      <td>9.766367</td>\n",
       "      <td>0.05</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>i</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64</td>\n",
       "      <td>{'bagging_fraction': 0.7816107335042664, 'bagg...</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.334733</td>\n",
       "      <td>0.335267</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>22.101219</td>\n",
       "      <td>1.723569</td>\n",
       "      <td>2.028142</td>\n",
       "      <td>0.210156</td>\n",
       "      <td>0.713462</td>\n",
       "      <td>2</td>\n",
       "      <td>0.772605</td>\n",
       "      <td>2.528727</td>\n",
       "      <td>1.883415</td>\n",
       "      <td>0.01</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>{'bagging_fraction': 0.713462160051048, 'baggi...</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.339800</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>39.800611</td>\n",
       "      <td>0.827871</td>\n",
       "      <td>2.456643</td>\n",
       "      <td>0.179142</td>\n",
       "      <td>0.596041</td>\n",
       "      <td>7</td>\n",
       "      <td>0.671049</td>\n",
       "      <td>2.888183</td>\n",
       "      <td>5.545352</td>\n",
       "      <td>0.01</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>m</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'bagging_fraction': 0.5960408375598203, 'bagg...</td>\n",
       "      <td>0.335867</td>\n",
       "      <td>0.336067</td>\n",
       "      <td>0.335967</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>25.044359</td>\n",
       "      <td>3.658995</td>\n",
       "      <td>2.345507</td>\n",
       "      <td>0.832782</td>\n",
       "      <td>0.932361</td>\n",
       "      <td>2</td>\n",
       "      <td>0.431527</td>\n",
       "      <td>2.96431</td>\n",
       "      <td>3.745915</td>\n",
       "      <td>0.01</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>64</td>\n",
       "      <td>{'bagging_fraction': 0.9323613273769479, 'bagg...</td>\n",
       "      <td>0.335733</td>\n",
       "      <td>0.336333</td>\n",
       "      <td>0.336033</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>19.158522</td>\n",
       "      <td>1.144842</td>\n",
       "      <td>1.541038</td>\n",
       "      <td>0.325682</td>\n",
       "      <td>0.997311</td>\n",
       "      <td>5</td>\n",
       "      <td>0.840537</td>\n",
       "      <td>3.102167</td>\n",
       "      <td>0.089532</td>\n",
       "      <td>0.01</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>i</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16</td>\n",
       "      <td>{'bagging_fraction': 0.9973112473189107, 'bagg...</td>\n",
       "      <td>0.342067</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.340633</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>15.981256</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>2.360892</td>\n",
       "      <td>0.259300</td>\n",
       "      <td>0.846944</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>1.845047</td>\n",
       "      <td>4.68118</td>\n",
       "      <td>0.01</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>l</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>64</td>\n",
       "      <td>{'bagging_fraction': 0.846944483941136, 'baggi...</td>\n",
       "      <td>0.338667</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.338633</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>5.756531</td>\n",
       "      <td>0.566233</td>\n",
       "      <td>0.317021</td>\n",
       "      <td>0.028647</td>\n",
       "      <td>0.917953</td>\n",
       "      <td>2</td>\n",
       "      <td>0.650475</td>\n",
       "      <td>0.784713</td>\n",
       "      <td>0.334943</td>\n",
       "      <td>0.05</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>i</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>{'bagging_fraction': 0.9179530830715937, 'bagg...</td>\n",
       "      <td>0.337867</td>\n",
       "      <td>0.339067</td>\n",
       "      <td>0.338467</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>9.568073</td>\n",
       "      <td>1.703233</td>\n",
       "      <td>0.711959</td>\n",
       "      <td>0.092591</td>\n",
       "      <td>0.966783</td>\n",
       "      <td>9</td>\n",
       "      <td>0.441516</td>\n",
       "      <td>4.403449</td>\n",
       "      <td>6.565202</td>\n",
       "      <td>0.05</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>u</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'bagging_fraction': 0.9667825833440544, 'bagg...</td>\n",
       "      <td>0.337133</td>\n",
       "      <td>0.335867</td>\n",
       "      <td>0.336500</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>8.516131</td>\n",
       "      <td>0.073302</td>\n",
       "      <td>0.458095</td>\n",
       "      <td>0.064904</td>\n",
       "      <td>0.957289</td>\n",
       "      <td>5</td>\n",
       "      <td>0.956459</td>\n",
       "      <td>2.024792</td>\n",
       "      <td>5.705082</td>\n",
       "      <td>0.05</td>\n",
       "      <td>multi_logloss</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>{'bagging_fraction': 0.9572892584046345, 'bagg...</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.338867</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "81       23.508597      2.745423         2.695441        0.908180   \n",
       "98       10.930890      0.030695         0.572038        0.016450   \n",
       "142      22.101219      1.723569         2.028142        0.210156   \n",
       "177      39.800611      0.827871         2.456643        0.179142   \n",
       "237      25.044359      3.658995         2.345507        0.832782   \n",
       "295      19.158522      1.144842         1.541038        0.325682   \n",
       "320      15.981256      1.096651         2.360892        0.259300   \n",
       "346       5.756531      0.566233         0.317021        0.028647   \n",
       "375       9.568073      1.703233         0.711959        0.092591   \n",
       "433       8.516131      0.073302         0.458095        0.064904   \n",
       "\n",
       "    param_bagging_fraction param_bagging_freq param_feature_fraction  \\\n",
       "81                0.944765                  6               0.850137   \n",
       "98                0.781611                  6               0.450322   \n",
       "142               0.713462                  2               0.772605   \n",
       "177               0.596041                  7               0.671049   \n",
       "237               0.932361                  2               0.431527   \n",
       "295               0.997311                  5               0.840537   \n",
       "320               0.846944                  5                 0.8971   \n",
       "346               0.917953                  2               0.650475   \n",
       "375               0.966783                  9               0.441516   \n",
       "433               0.957289                  5               0.956459   \n",
       "\n",
       "    param_lambda_l1 param_lambda_l2 param_learning_rate   param_metric  \\\n",
       "81         4.934807        5.964912                0.01  multi_logloss   \n",
       "98         3.217934        9.766367                0.05  multi_logloss   \n",
       "142        2.528727        1.883415                0.01  multi_logloss   \n",
       "177        2.888183        5.545352                0.01  multi_logloss   \n",
       "237         2.96431        3.745915                0.01  multi_logloss   \n",
       "295        3.102167        0.089532                0.01  multi_logloss   \n",
       "320        1.845047         4.68118                0.01  multi_logloss   \n",
       "346        0.784713        0.334943                0.05  multi_logloss   \n",
       "375        4.403449        6.565202                0.05  multi_logloss   \n",
       "433        2.024792        5.705082                0.05  multi_logloss   \n",
       "\n",
       "    param_min_child_samples param_num_class param_num_leaves param_objective  \\\n",
       "81                       24               5               54               a   \n",
       "98                       11               5               47               i   \n",
       "142                      10               5                7               s   \n",
       "177                       6               5              111               m   \n",
       "237                      19               5               44               s   \n",
       "295                      13               5               24               i   \n",
       "320                      25               5               12               l   \n",
       "346                      18               5               17               i   \n",
       "375                      20               5               30               u   \n",
       "433                      14               5               28               s   \n",
       "\n",
       "    param_reg_lambda param_subsample param_subsample_freq  \\\n",
       "81           0.00001             0.5                  256   \n",
       "98          0.000001             0.8                   64   \n",
       "142         0.000001             0.6                    8   \n",
       "177          0.00001             0.5                    1   \n",
       "237                0             0.7                   64   \n",
       "295         0.000001             0.8                   16   \n",
       "320          0.00001             0.7                   64   \n",
       "346         0.000001             0.5                   64   \n",
       "375           0.0001             0.7                    1   \n",
       "433         0.000001             0.5                   32   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "81   {'bagging_fraction': 0.9447645033556015, 'bagg...           0.335733   \n",
       "98   {'bagging_fraction': 0.7816107335042664, 'bagg...           0.335800   \n",
       "142  {'bagging_fraction': 0.713462160051048, 'baggi...           0.338600   \n",
       "177  {'bagging_fraction': 0.5960408375598203, 'bagg...           0.335867   \n",
       "237  {'bagging_fraction': 0.9323613273769479, 'bagg...           0.335733   \n",
       "295  {'bagging_fraction': 0.9973112473189107, 'bagg...           0.342067   \n",
       "320  {'bagging_fraction': 0.846944483941136, 'baggi...           0.338667   \n",
       "346  {'bagging_fraction': 0.9179530830715937, 'bagg...           0.337867   \n",
       "375  {'bagging_fraction': 0.9667825833440544, 'bagg...           0.337133   \n",
       "433  {'bagging_fraction': 0.9572892584046345, 'bagg...           0.339933   \n",
       "\n",
       "     split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "81            0.334267         0.335000        0.000733               10  \n",
       "98            0.334733         0.335267        0.000533                9  \n",
       "142           0.339800         0.339200        0.000600                3  \n",
       "177           0.336067         0.335967        0.000100                8  \n",
       "237           0.336333         0.336033        0.000300                7  \n",
       "295           0.339200         0.340633        0.001433                1  \n",
       "320           0.338600         0.338633        0.000033                4  \n",
       "346           0.339067         0.338467        0.000600                5  \n",
       "375           0.335867         0.336500        0.000633                6  \n",
       "433           0.338867         0.339400        0.000533                2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(bagging_fraction=0.9973112473189107, bagging_freq=5,\n",
      "               feature_fraction=0.8405368817955569,\n",
      "               lambda_l1=3.1021671832151014, lambda_l2=0.0895315270426858,\n",
      "               learning_rate=0.01, metric='multi_logloss', min_child_samples=13,\n",
      "               n_estimators=10000, num_class=5, num_leaves=24, objective='i',\n",
      "               reg_lambda=1e-06, subsample=0.7999999999999999,\n",
      "               subsample_freq=16, verbose=-1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(randcv.cv_results_)\n",
    "best_estimator = randcv.best_estimator_\n",
    "\n",
    "display(results[results[\"rank_test_score\"] <= 10])\n",
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テスト出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.9973112473189107, bagging_freq=5,\n",
       "               feature_fraction=0.8405368817955569,\n",
       "               lambda_l1=3.1021671832151014, lambda_l2=0.0895315270426858,\n",
       "               learning_rate=0.01, metric=&#x27;multi_logloss&#x27;, min_child_samples=13,\n",
       "               n_estimators=10000, num_class=5, num_leaves=24, objective=&#x27;i&#x27;,\n",
       "               reg_lambda=1e-06, subsample=0.7999999999999999,\n",
       "               subsample_freq=16, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.9973112473189107, bagging_freq=5,\n",
       "               feature_fraction=0.8405368817955569,\n",
       "               lambda_l1=3.1021671832151014, lambda_l2=0.0895315270426858,\n",
       "               learning_rate=0.01, metric=&#x27;multi_logloss&#x27;, min_child_samples=13,\n",
       "               n_estimators=10000, num_class=5, num_leaves=24, objective=&#x27;i&#x27;,\n",
       "               reg_lambda=1e-06, subsample=0.7999999999999999,\n",
       "               subsample_freq=16, verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9973112473189107, bagging_freq=5,\n",
       "               feature_fraction=0.8405368817955569,\n",
       "               lambda_l1=3.1021671832151014, lambda_l2=0.0895315270426858,\n",
       "               learning_rate=0.01, metric='multi_logloss', min_child_samples=13,\n",
       "               n_estimators=10000, num_class=5, num_leaves=24, objective='i',\n",
       "               reg_lambda=1e-06, subsample=0.7999999999999999,\n",
       "               subsample_freq=16, verbose=-1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy as sp\n",
    "\n",
    "model = lgb.LGBMClassifier(bagging_fraction=0.9973112473189107, bagging_freq=5,\n",
    "               feature_fraction=0.8405368817955569,\n",
    "               lambda_l1=3.1021671832151014, lambda_l2=0.0895315270426858,\n",
    "               learning_rate=0.01, metric='multi_logloss', min_child_samples=13,\n",
    "               n_estimators=10000, num_class=5, num_leaves=24, objective='i',\n",
    "               reg_lambda=1e-06, subsample=0.7999999999999999,\n",
    "               subsample_freq=16, verbose=-1)\n",
    "model.fit(train_vec, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正確率 = 0.344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -2.0       0.28      0.10      0.15       310\n",
      "        -1.0       0.30      0.24      0.27       415\n",
      "         0.0       0.31      0.61      0.41       647\n",
      "         1.0       0.44      0.36      0.40       837\n",
      "         2.0       0.28      0.11      0.16       291\n",
      "\n",
      "    accuracy                           0.34      2500\n",
      "   macro avg       0.32      0.29      0.28      2500\n",
      "weighted avg       0.35      0.34      0.32      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_pred = model.predict(dev_vec)\n",
    "acc = accuracy_score(dev_pred, dev_label)\n",
    "print(\"正確率 = %.3f\" % (acc))\n",
    "print(classification_report(dev_label, dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test出力\n",
    "test_pred = model.predict(test_vec)\n",
    "\n",
    "np.savetxt(outpath + \"/leaderboad/v0.0.3_LightGBM.txt\", test_pred, fmt=\"%.0f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
